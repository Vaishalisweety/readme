{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular Playground Series - Apr 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T07:36:19.629205Z",
     "start_time": "2021-04-05T07:36:19.625401Z"
    },
    "_cell_guid": "e084ed06-ea73-4241-8faa-7be314013adb",
    "_uuid": "8422c101-b93a-4f1e-b917-272554859ddb",
    "execution": {
     "iopub.execute_input": "2023-03-24T05:23:03.175538Z",
     "iopub.status.busy": "2023-03-24T05:23:03.175168Z",
     "iopub.status.idle": "2023-03-24T05:23:04.538379Z",
     "shell.execute_reply": "2023-03-24T05:23:04.537446Z",
     "shell.execute_reply.started": "2023-03-24T05:23:03.175458Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as ctb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T05:23:04.540790Z",
     "iopub.status.busy": "2023-03-24T05:23:04.540443Z",
     "iopub.status.idle": "2023-03-24T05:23:04.545813Z",
     "shell.execute_reply": "2023-03-24T05:23:04.544995Z",
     "shell.execute_reply.started": "2023-03-24T05:23:04.540753Z"
    }
   },
   "outputs": [],
   "source": [
    "TARGET = 'Survived'\n",
    "\n",
    "DEBUG = False #True #\n",
    "\n",
    "if DEBUG:\n",
    "    N_ESTIMATORS = 1\n",
    "    N_SPLITS = 2\n",
    "    SEED = 2021\n",
    "    EARLY_STOPPING_ROUNDS = 1\n",
    "    VERBOSE = 100\n",
    "    N_ITERS = 2\n",
    "else:\n",
    "    N_ESTIMATORS = 1000\n",
    "    N_SPLITS = 10\n",
    "    SEED = 2021\n",
    "    EARLY_STOPPING_ROUNDS = 100\n",
    "    VERBOSE = 100\n",
    "    N_ITERS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T05:23:04.547713Z",
     "iopub.status.busy": "2023-03-24T05:23:04.547111Z",
     "iopub.status.idle": "2023-03-24T05:23:04.558418Z",
     "shell.execute_reply": "2023-03-24T05:23:04.557547Z",
     "shell.execute_reply.started": "2023-03-24T05:23:04.547670Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T07:36:20.503129Z",
     "start_time": "2021-04-05T07:36:20.498496Z"
    },
    "_cell_guid": "9fb39135-47eb-4d2b-b41e-8c50544feb98",
    "_uuid": "4c503ac3-b779-4597-a37f-b94c97d0ebd9",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each passenger. Your model will be based on “features” like passengers’ gender and class. You can also use feature engineering to create new features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Synthanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T07:36:20.37188Z",
     "start_time": "2021-04-05T07:36:20.084718Z"
    },
    "_cell_guid": "af349323-3a02-4979-9345-74a25709144a",
    "_uuid": "7685b8a3-c0c9-48de-a607-5798e38e29cc",
    "execution": {
     "iopub.execute_input": "2023-03-24T05:23:04.560084Z",
     "iopub.status.busy": "2023-03-24T05:23:04.559722Z",
     "iopub.status.idle": "2023-03-24T05:23:05.167304Z",
     "shell.execute_reply": "2023-03-24T05:23:05.166549Z",
     "shell.execute_reply.started": "2023-03-24T05:23:04.560048Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\n",
    "test_df = pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')\n",
    "submission = pd.read_csv('../input/tabular-playground-series-apr-2021/sample_submission.csv')\n",
    "test_df[TARGET] = pd.read_csv(\"../input/tps-apr-2021-pseudo-labeling-voting-ensemble/voting_submission.csv\")[TARGET]\n",
    "\n",
    "all_df = pd.concat([train_df, test_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T07:36:21.336506Z",
     "start_time": "2021-04-05T07:36:21.28146Z"
    },
    "_cell_guid": "8fe82644-8eac-4bdc-8ff3-5537deb09e19",
    "_uuid": "bdf1b542-e552-4e8d-8233-71dfe29c4a39",
    "execution": {
     "iopub.execute_input": "2023-03-24T05:23:05.171307Z",
     "iopub.status.busy": "2023-03-24T05:23:05.171000Z",
     "iopub.status.idle": "2023-03-24T05:23:05.516098Z",
     "shell.execute_reply": "2023-03-24T05:23:05.515111Z",
     "shell.execute_reply.started": "2023-03-24T05:23:05.171275Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Age fillna with mean age for each class\n",
    "all_df['Age'] = all_df['Age'].fillna(all_df['Age'].mean())\n",
    "\n",
    "# Cabin, fillna with 'X' and take first letter\n",
    "all_df['Cabin'] = all_df['Cabin'].fillna('X').map(lambda x: x[0].strip())\n",
    "\n",
    "# Ticket, fillna with 'X', split string and take first split \n",
    "all_df['Ticket'] = all_df['Ticket'].fillna('X').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n",
    "\n",
    "# Fare, fillna with mean value\n",
    "fare_map = all_df[['Fare', 'Pclass']].dropna().groupby('Pclass').median().to_dict()\n",
    "all_df['Fare'] = all_df['Fare'].fillna(all_df['Pclass'].map(fare_map['Fare']))\n",
    "all_df['Fare'] = np.log1p(all_df['Fare'])\n",
    "\n",
    "# Embarked, fillna with 'X' value\n",
    "all_df['Embarked'] = all_df['Embarked'].fillna('X')\n",
    "\n",
    "# Name, take only surnames\n",
    "all_df['Name'] = all_df['Name'].map(lambda x: x.split(',')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T07:36:23.841679Z",
     "start_time": "2021-04-05T07:36:23.838273Z"
    },
    "_cell_guid": "5db0e9df-a909-40cc-8d9b-715e097aaf40",
    "_uuid": "94f46a4b-7657-4923-85d1-63e43aa64c50",
    "execution": {
     "iopub.execute_input": "2023-03-24T05:23:05.518726Z",
     "iopub.status.busy": "2023-03-24T05:23:05.518453Z",
     "iopub.status.idle": "2023-03-24T05:23:05.524849Z",
     "shell.execute_reply": "2023-03-24T05:23:05.523966Z",
     "shell.execute_reply.started": "2023-03-24T05:23:05.518699Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "label_cols = ['Name', 'Ticket', 'Sex']\n",
    "onehot_cols = ['Cabin', 'Embarked']\n",
    "numerical_cols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T07:36:24.590836Z",
     "start_time": "2021-04-05T07:36:24.384849Z"
    },
    "_cell_guid": "d9725940-ab11-4fce-a499-a4cc6c19ffd1",
    "_uuid": "dc723ead-6522-4ff0-bd01-00ff66506ffa",
    "execution": {
     "iopub.execute_input": "2023-03-24T05:23:05.527190Z",
     "iopub.status.busy": "2023-03-24T05:23:05.526532Z",
     "iopub.status.idle": "2023-03-24T05:23:05.801260Z",
     "shell.execute_reply": "2023-03-24T05:23:05.800348Z",
     "shell.execute_reply.started": "2023-03-24T05:23:05.527151Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def label_encoder(c):\n",
    "    le = LabelEncoder()\n",
    "    return le.fit_transform(c)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "onehot_encoded_df = pd.get_dummies(all_df[onehot_cols])\n",
    "label_encoded_df = all_df[label_cols].apply(label_encoder)\n",
    "numerical_df = pd.DataFrame(scaler.fit_transform(all_df[numerical_cols]), columns=numerical_cols)\n",
    "target_df = all_df[TARGET]\n",
    "\n",
    "all_df = pd.concat([numerical_df, label_encoded_df, onehot_encoded_df, target_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T05:23:05.804839Z",
     "iopub.status.busy": "2023-03-24T05:23:05.804574Z",
     "iopub.status.idle": "2023-03-24T05:23:05.810513Z",
     "shell.execute_reply": "2023-03-24T05:23:05.809417Z",
     "shell.execute_reply.started": "2023-03-24T05:23:05.804812Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_noise(df, p=.75):\n",
    "    should_not_swap = np.random.binomial(1, p, df.shape)\n",
    "    corrupted_df = df.where(should_not_swap == 1, np.random.permutation(df))\n",
    "    return corrupted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T07:42:10.128819Z",
     "start_time": "2021-04-05T07:42:10.1251Z"
    },
    "_cell_guid": "b49fc139-9689-45ea-a4d7-2855a559200e",
    "_uuid": "7d72bc52-7935-4878-ae4b-c18aafa33511",
    "execution": {
     "iopub.execute_input": "2023-03-24T05:23:05.812149Z",
     "iopub.status.busy": "2023-03-24T05:23:05.811799Z",
     "iopub.status.idle": "2023-03-24T05:23:05.820530Z",
     "shell.execute_reply": "2023-03-24T05:23:05.819652Z",
     "shell.execute_reply.started": "2023-03-24T05:23:05.812115Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'metric': 'binary_logloss',\n",
    "    'n_estimators': N_ESTIMATORS,\n",
    "    'objective': 'binary',\n",
    "    'random_state': SEED,\n",
    "    'learning_rate': 0.01,\n",
    "    'min_child_samples': 150,\n",
    "    'reg_alpha': 3e-5,\n",
    "    'reg_lambda': 9e-2,\n",
    "    'num_leaves': 20,\n",
    "    'max_depth': 16,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'subsample': 0.8,\n",
    "    'subsample_freq': 2,\n",
    "    'max_bin': 240,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T05:23:05.822692Z",
     "iopub.status.busy": "2023-03-24T05:23:05.822443Z",
     "iopub.status.idle": "2023-03-24T09:35:08.192524Z",
     "shell.execute_reply": "2023-03-24T09:35:08.191562Z",
     "shell.execute_reply.started": "2023-03-24T05:23:05.822668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50901\tvalid_1's binary_logloss: 0.529298\n",
      "[200]\ttraining's binary_logloss: 0.468509\tvalid_1's binary_logloss: 0.498198\n",
      "[300]\ttraining's binary_logloss: 0.454885\tvalid_1's binary_logloss: 0.492372\n",
      "[400]\ttraining's binary_logloss: 0.448899\tvalid_1's binary_logloss: 0.491815\n",
      "Early stopping, best iteration is:\n",
      "[374]\ttraining's binary_logloss: 0.450027\tvalid_1's binary_logloss: 0.491712\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.449905\tvalid_1's binary_logloss: 0.4917\n",
      "[500]\ttraining's binary_logloss: 0.449449\tvalid_1's binary_logloss: 0.491686\n",
      "[600]\ttraining's binary_logloss: 0.449018\tvalid_1's binary_logloss: 0.491712\n",
      "Early stopping, best iteration is:\n",
      "[501]\ttraining's binary_logloss: 0.449445\tvalid_1's binary_logloss: 0.491686\n",
      "===== ACCURACY SCORE 0.776997 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510089\tvalid_1's binary_logloss: 0.531115\n",
      "[200]\ttraining's binary_logloss: 0.469983\tvalid_1's binary_logloss: 0.499869\n",
      "[300]\ttraining's binary_logloss: 0.456494\tvalid_1's binary_logloss: 0.493897\n",
      "[400]\ttraining's binary_logloss: 0.450672\tvalid_1's binary_logloss: 0.492994\n",
      "[500]\ttraining's binary_logloss: 0.44725\tvalid_1's binary_logloss: 0.492779\n",
      "[600]\ttraining's binary_logloss: 0.445011\tvalid_1's binary_logloss: 0.492721\n",
      "Early stopping, best iteration is:\n",
      "[559]\ttraining's binary_logloss: 0.445811\tvalid_1's binary_logloss: 0.492692\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.445724\tvalid_1's binary_logloss: 0.492693\n",
      "[700]\ttraining's binary_logloss: 0.445523\tvalid_1's binary_logloss: 0.49267\n",
      "[800]\ttraining's binary_logloss: 0.445327\tvalid_1's binary_logloss: 0.492661\n",
      "[900]\ttraining's binary_logloss: 0.445142\tvalid_1's binary_logloss: 0.492664\n",
      "Early stopping, best iteration is:\n",
      "[822]\ttraining's binary_logloss: 0.445284\tvalid_1's binary_logloss: 0.492652\n",
      "===== ACCURACY SCORE 0.775345 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510102\tvalid_1's binary_logloss: 0.523816\n",
      "[200]\ttraining's binary_logloss: 0.469888\tvalid_1's binary_logloss: 0.490558\n",
      "[300]\ttraining's binary_logloss: 0.456034\tvalid_1's binary_logloss: 0.483284\n",
      "[400]\ttraining's binary_logloss: 0.450018\tvalid_1's binary_logloss: 0.4817\n",
      "[500]\ttraining's binary_logloss: 0.446467\tvalid_1's binary_logloss: 0.481377\n",
      "[600]\ttraining's binary_logloss: 0.444102\tvalid_1's binary_logloss: 0.481465\n",
      "Early stopping, best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.446467\tvalid_1's binary_logloss: 0.481377\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.446183\tvalid_1's binary_logloss: 0.481362\n",
      "[700]\ttraining's binary_logloss: 0.445902\tvalid_1's binary_logloss: 0.481347\n",
      "[800]\ttraining's binary_logloss: 0.445633\tvalid_1's binary_logloss: 0.48134\n",
      "[900]\ttraining's binary_logloss: 0.445378\tvalid_1's binary_logloss: 0.481346\n",
      "Early stopping, best iteration is:\n",
      "[860]\ttraining's binary_logloss: 0.445476\tvalid_1's binary_logloss: 0.481329\n",
      "===== ACCURACY SCORE 0.779864 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509659\tvalid_1's binary_logloss: 0.530113\n",
      "[200]\ttraining's binary_logloss: 0.469376\tvalid_1's binary_logloss: 0.4979\n",
      "[300]\ttraining's binary_logloss: 0.455825\tvalid_1's binary_logloss: 0.49139\n",
      "[400]\ttraining's binary_logloss: 0.449757\tvalid_1's binary_logloss: 0.490034\n",
      "[500]\ttraining's binary_logloss: 0.446344\tvalid_1's binary_logloss: 0.489724\n",
      "[600]\ttraining's binary_logloss: 0.44402\tvalid_1's binary_logloss: 0.489434\n",
      "[700]\ttraining's binary_logloss: 0.442514\tvalid_1's binary_logloss: 0.489313\n",
      "[800]\ttraining's binary_logloss: 0.441411\tvalid_1's binary_logloss: 0.489264\n",
      "[900]\ttraining's binary_logloss: 0.440537\tvalid_1's binary_logloss: 0.489284\n",
      "Early stopping, best iteration is:\n",
      "[807]\ttraining's binary_logloss: 0.441341\tvalid_1's binary_logloss: 0.489246\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[900]\ttraining's binary_logloss: 0.441256\tvalid_1's binary_logloss: 0.489236\n",
      "[1000]\ttraining's binary_logloss: 0.441165\tvalid_1's binary_logloss: 0.489218\n",
      "[1100]\ttraining's binary_logloss: 0.441078\tvalid_1's binary_logloss: 0.489204\n",
      "[1200]\ttraining's binary_logloss: 0.440988\tvalid_1's binary_logloss: 0.489199\n",
      "[1300]\ttraining's binary_logloss: 0.440899\tvalid_1's binary_logloss: 0.489187\n",
      "[1400]\ttraining's binary_logloss: 0.440816\tvalid_1's binary_logloss: 0.48918\n",
      "[1500]\ttraining's binary_logloss: 0.440731\tvalid_1's binary_logloss: 0.489167\n",
      "[1600]\ttraining's binary_logloss: 0.440651\tvalid_1's binary_logloss: 0.489152\n",
      "[1700]\ttraining's binary_logloss: 0.44057\tvalid_1's binary_logloss: 0.489151\n",
      "Early stopping, best iteration is:\n",
      "[1625]\ttraining's binary_logloss: 0.440631\tvalid_1's binary_logloss: 0.489146\n",
      "===== ACCURACY SCORE 0.775978 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509253\tvalid_1's binary_logloss: 0.52274\n",
      "[200]\ttraining's binary_logloss: 0.469099\tvalid_1's binary_logloss: 0.487474\n",
      "[300]\ttraining's binary_logloss: 0.455353\tvalid_1's binary_logloss: 0.479071\n",
      "[400]\ttraining's binary_logloss: 0.449461\tvalid_1's binary_logloss: 0.476737\n",
      "[500]\ttraining's binary_logloss: 0.445979\tvalid_1's binary_logloss: 0.475851\n",
      "[600]\ttraining's binary_logloss: 0.44378\tvalid_1's binary_logloss: 0.475542\n",
      "[700]\ttraining's binary_logloss: 0.442268\tvalid_1's binary_logloss: 0.475165\n",
      "[800]\ttraining's binary_logloss: 0.441167\tvalid_1's binary_logloss: 0.474961\n",
      "[900]\ttraining's binary_logloss: 0.44027\tvalid_1's binary_logloss: 0.474965\n",
      "Early stopping, best iteration is:\n",
      "[808]\ttraining's binary_logloss: 0.441084\tvalid_1's binary_logloss: 0.474931\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[900]\ttraining's binary_logloss: 0.440999\tvalid_1's binary_logloss: 0.474923\n",
      "[1000]\ttraining's binary_logloss: 0.440905\tvalid_1's binary_logloss: 0.474912\n",
      "[1100]\ttraining's binary_logloss: 0.440812\tvalid_1's binary_logloss: 0.474905\n",
      "[1200]\ttraining's binary_logloss: 0.440728\tvalid_1's binary_logloss: 0.474899\n",
      "[1300]\ttraining's binary_logloss: 0.44064\tvalid_1's binary_logloss: 0.474877\n",
      "[1400]\ttraining's binary_logloss: 0.440554\tvalid_1's binary_logloss: 0.47487\n",
      "Early stopping, best iteration is:\n",
      "[1378]\ttraining's binary_logloss: 0.440572\tvalid_1's binary_logloss: 0.474866\n",
      "===== ACCURACY SCORE 0.791592 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509824\tvalid_1's binary_logloss: 0.530342\n",
      "[200]\ttraining's binary_logloss: 0.469509\tvalid_1's binary_logloss: 0.499101\n",
      "[300]\ttraining's binary_logloss: 0.455948\tvalid_1's binary_logloss: 0.492671\n",
      "[400]\ttraining's binary_logloss: 0.449943\tvalid_1's binary_logloss: 0.491478\n",
      "[500]\ttraining's binary_logloss: 0.446441\tvalid_1's binary_logloss: 0.491392\n",
      "[600]\ttraining's binary_logloss: 0.44416\tvalid_1's binary_logloss: 0.491264\n",
      "[700]\ttraining's binary_logloss: 0.442654\tvalid_1's binary_logloss: 0.491194\n",
      "[800]\ttraining's binary_logloss: 0.44159\tvalid_1's binary_logloss: 0.491123\n",
      "Early stopping, best iteration is:\n",
      "[771]\ttraining's binary_logloss: 0.44187\tvalid_1's binary_logloss: 0.491099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.441839\tvalid_1's binary_logloss: 0.491104\n",
      "Early stopping, best iteration is:\n",
      "[774]\ttraining's binary_logloss: 0.441867\tvalid_1's binary_logloss: 0.4911\n",
      "===== ACCURACY SCORE 0.778630 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508913\tvalid_1's binary_logloss: 0.527587\n",
      "[200]\ttraining's binary_logloss: 0.468486\tvalid_1's binary_logloss: 0.496123\n",
      "[300]\ttraining's binary_logloss: 0.454673\tvalid_1's binary_logloss: 0.490061\n",
      "[400]\ttraining's binary_logloss: 0.448677\tvalid_1's binary_logloss: 0.489241\n",
      "Early stopping, best iteration is:\n",
      "[381]\ttraining's binary_logloss: 0.449493\tvalid_1's binary_logloss: 0.48922\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.449408\tvalid_1's binary_logloss: 0.489216\n",
      "[500]\ttraining's binary_logloss: 0.448967\tvalid_1's binary_logloss: 0.489212\n",
      "[600]\ttraining's binary_logloss: 0.448544\tvalid_1's binary_logloss: 0.489224\n",
      "Early stopping, best iteration is:\n",
      "[524]\ttraining's binary_logloss: 0.448867\tvalid_1's binary_logloss: 0.489202\n",
      "===== ACCURACY SCORE 0.778843 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510052\tvalid_1's binary_logloss: 0.52656\n",
      "[200]\ttraining's binary_logloss: 0.469818\tvalid_1's binary_logloss: 0.492955\n",
      "[300]\ttraining's binary_logloss: 0.456225\tvalid_1's binary_logloss: 0.485727\n",
      "[400]\ttraining's binary_logloss: 0.450267\tvalid_1's binary_logloss: 0.48401\n",
      "[500]\ttraining's binary_logloss: 0.446909\tvalid_1's binary_logloss: 0.483651\n",
      "[600]\ttraining's binary_logloss: 0.444685\tvalid_1's binary_logloss: 0.483295\n",
      "[700]\ttraining's binary_logloss: 0.443198\tvalid_1's binary_logloss: 0.48311\n",
      "[800]\ttraining's binary_logloss: 0.442112\tvalid_1's binary_logloss: 0.482928\n",
      "[900]\ttraining's binary_logloss: 0.441221\tvalid_1's binary_logloss: 0.482844\n",
      "[1000]\ttraining's binary_logloss: 0.440478\tvalid_1's binary_logloss: 0.482787\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440478\tvalid_1's binary_logloss: 0.482787\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.44041\tvalid_1's binary_logloss: 0.482778\n",
      "[1200]\ttraining's binary_logloss: 0.440341\tvalid_1's binary_logloss: 0.482773\n",
      "[1300]\ttraining's binary_logloss: 0.440274\tvalid_1's binary_logloss: 0.482772\n",
      "Early stopping, best iteration is:\n",
      "[1246]\ttraining's binary_logloss: 0.44031\tvalid_1's binary_logloss: 0.482769\n",
      "===== ACCURACY SCORE 0.781182 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508648\tvalid_1's binary_logloss: 0.529464\n",
      "[200]\ttraining's binary_logloss: 0.468302\tvalid_1's binary_logloss: 0.496608\n",
      "[300]\ttraining's binary_logloss: 0.454816\tvalid_1's binary_logloss: 0.489944\n",
      "[400]\ttraining's binary_logloss: 0.448796\tvalid_1's binary_logloss: 0.48847\n",
      "[500]\ttraining's binary_logloss: 0.445335\tvalid_1's binary_logloss: 0.487949\n",
      "[600]\ttraining's binary_logloss: 0.442983\tvalid_1's binary_logloss: 0.487383\n",
      "Early stopping, best iteration is:\n",
      "[584]\ttraining's binary_logloss: 0.44327\tvalid_1's binary_logloss: 0.487358\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.44324\tvalid_1's binary_logloss: 0.487354\n",
      "[700]\ttraining's binary_logloss: 0.443044\tvalid_1's binary_logloss: 0.487335\n",
      "[800]\ttraining's binary_logloss: 0.442864\tvalid_1's binary_logloss: 0.487327\n",
      "[900]\ttraining's binary_logloss: 0.442695\tvalid_1's binary_logloss: 0.487318\n",
      "Early stopping, best iteration is:\n",
      "[866]\ttraining's binary_logloss: 0.442749\tvalid_1's binary_logloss: 0.48731\n",
      "===== ACCURACY SCORE 0.777153 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509294\tvalid_1's binary_logloss: 0.530845\n",
      "[200]\ttraining's binary_logloss: 0.468778\tvalid_1's binary_logloss: 0.50067\n",
      "[300]\ttraining's binary_logloss: 0.455117\tvalid_1's binary_logloss: 0.495595\n",
      "[400]\ttraining's binary_logloss: 0.449247\tvalid_1's binary_logloss: 0.495058\n",
      "Early stopping, best iteration is:\n",
      "[376]\ttraining's binary_logloss: 0.450275\tvalid_1's binary_logloss: 0.495011\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.450163\tvalid_1's binary_logloss: 0.495006\n",
      "[500]\ttraining's binary_logloss: 0.449724\tvalid_1's binary_logloss: 0.495007\n",
      "Early stopping, best iteration is:\n",
      "[406]\ttraining's binary_logloss: 0.450135\tvalid_1's binary_logloss: 0.495006\n",
      "===== ACCURACY SCORE 0.773173 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778880 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508917\tvalid_1's binary_logloss: 0.527915\n",
      "[200]\ttraining's binary_logloss: 0.468524\tvalid_1's binary_logloss: 0.494217\n",
      "[300]\ttraining's binary_logloss: 0.454905\tvalid_1's binary_logloss: 0.487101\n",
      "[400]\ttraining's binary_logloss: 0.448891\tvalid_1's binary_logloss: 0.485648\n",
      "[500]\ttraining's binary_logloss: 0.445539\tvalid_1's binary_logloss: 0.485088\n",
      "[600]\ttraining's binary_logloss: 0.443281\tvalid_1's binary_logloss: 0.484576\n",
      "[700]\ttraining's binary_logloss: 0.441771\tvalid_1's binary_logloss: 0.48426\n",
      "[800]\ttraining's binary_logloss: 0.440709\tvalid_1's binary_logloss: 0.484201\n",
      "Early stopping, best iteration is:\n",
      "[721]\ttraining's binary_logloss: 0.441513\tvalid_1's binary_logloss: 0.484164\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.441424\tvalid_1's binary_logloss: 0.484161\n",
      "[900]\ttraining's binary_logloss: 0.441312\tvalid_1's binary_logloss: 0.484161\n",
      "Early stopping, best iteration is:\n",
      "[866]\ttraining's binary_logloss: 0.44135\tvalid_1's binary_logloss: 0.484155\n",
      "===== ACCURACY SCORE 0.782887 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510714\tvalid_1's binary_logloss: 0.524616\n",
      "[200]\ttraining's binary_logloss: 0.47058\tvalid_1's binary_logloss: 0.491387\n",
      "[300]\ttraining's binary_logloss: 0.456966\tvalid_1's binary_logloss: 0.484058\n",
      "[400]\ttraining's binary_logloss: 0.450989\tvalid_1's binary_logloss: 0.482378\n",
      "[500]\ttraining's binary_logloss: 0.447556\tvalid_1's binary_logloss: 0.481647\n",
      "[600]\ttraining's binary_logloss: 0.445305\tvalid_1's binary_logloss: 0.481015\n",
      "[700]\ttraining's binary_logloss: 0.443819\tvalid_1's binary_logloss: 0.480439\n",
      "[800]\ttraining's binary_logloss: 0.442743\tvalid_1's binary_logloss: 0.480186\n",
      "[900]\ttraining's binary_logloss: 0.441865\tvalid_1's binary_logloss: 0.479837\n",
      "[1000]\ttraining's binary_logloss: 0.441119\tvalid_1's binary_logloss: 0.47957\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.441119\tvalid_1's binary_logloss: 0.47957\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.441049\tvalid_1's binary_logloss: 0.479557\n",
      "[1200]\ttraining's binary_logloss: 0.44098\tvalid_1's binary_logloss: 0.47954\n",
      "[1300]\ttraining's binary_logloss: 0.440916\tvalid_1's binary_logloss: 0.479515\n",
      "[1400]\ttraining's binary_logloss: 0.440848\tvalid_1's binary_logloss: 0.479496\n",
      "[1500]\ttraining's binary_logloss: 0.440783\tvalid_1's binary_logloss: 0.479483\n",
      "[1600]\ttraining's binary_logloss: 0.440718\tvalid_1's binary_logloss: 0.479459\n",
      "[1700]\ttraining's binary_logloss: 0.440654\tvalid_1's binary_logloss: 0.479446\n",
      "[1800]\ttraining's binary_logloss: 0.440591\tvalid_1's binary_logloss: 0.479429\n",
      "[1900]\ttraining's binary_logloss: 0.440529\tvalid_1's binary_logloss: 0.47941\n",
      "[2000]\ttraining's binary_logloss: 0.440468\tvalid_1's binary_logloss: 0.479389\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.440468\tvalid_1's binary_logloss: 0.479389\n",
      "===== ACCURACY SCORE 0.785022 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508472\tvalid_1's binary_logloss: 0.532648\n",
      "[200]\ttraining's binary_logloss: 0.467891\tvalid_1's binary_logloss: 0.503078\n",
      "[300]\ttraining's binary_logloss: 0.454405\tvalid_1's binary_logloss: 0.497968\n",
      "[400]\ttraining's binary_logloss: 0.448407\tvalid_1's binary_logloss: 0.497468\n",
      "Early stopping, best iteration is:\n",
      "[376]\ttraining's binary_logloss: 0.449486\tvalid_1's binary_logloss: 0.497454\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.44937\tvalid_1's binary_logloss: 0.497453\n",
      "[500]\ttraining's binary_logloss: 0.448913\tvalid_1's binary_logloss: 0.497426\n",
      "[600]\ttraining's binary_logloss: 0.44847\tvalid_1's binary_logloss: 0.497395\n",
      "[700]\ttraining's binary_logloss: 0.448062\tvalid_1's binary_logloss: 0.497378\n",
      "[800]\ttraining's binary_logloss: 0.447669\tvalid_1's binary_logloss: 0.497384\n",
      "Early stopping, best iteration is:\n",
      "[757]\ttraining's binary_logloss: 0.447834\tvalid_1's binary_logloss: 0.497368\n",
      "===== ACCURACY SCORE 0.773606 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510003\tvalid_1's binary_logloss: 0.530627\n",
      "[200]\ttraining's binary_logloss: 0.469807\tvalid_1's binary_logloss: 0.498308\n",
      "[300]\ttraining's binary_logloss: 0.456222\tvalid_1's binary_logloss: 0.491824\n",
      "[400]\ttraining's binary_logloss: 0.450283\tvalid_1's binary_logloss: 0.49073\n",
      "[500]\ttraining's binary_logloss: 0.446841\tvalid_1's binary_logloss: 0.490656\n",
      "[600]\ttraining's binary_logloss: 0.444592\tvalid_1's binary_logloss: 0.490681\n",
      "Early stopping, best iteration is:\n",
      "[549]\ttraining's binary_logloss: 0.445601\tvalid_1's binary_logloss: 0.490605\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.445494\tvalid_1's binary_logloss: 0.490615\n",
      "Early stopping, best iteration is:\n",
      "[554]\ttraining's binary_logloss: 0.445589\tvalid_1's binary_logloss: 0.490603\n",
      "===== ACCURACY SCORE 0.778067 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509003\tvalid_1's binary_logloss: 0.521678\n",
      "[200]\ttraining's binary_logloss: 0.468506\tvalid_1's binary_logloss: 0.487567\n",
      "[300]\ttraining's binary_logloss: 0.454871\tvalid_1's binary_logloss: 0.479929\n",
      "[400]\ttraining's binary_logloss: 0.448876\tvalid_1's binary_logloss: 0.478277\n",
      "[500]\ttraining's binary_logloss: 0.445356\tvalid_1's binary_logloss: 0.477546\n",
      "[600]\ttraining's binary_logloss: 0.44307\tvalid_1's binary_logloss: 0.477061\n",
      "[700]\ttraining's binary_logloss: 0.441543\tvalid_1's binary_logloss: 0.476515\n",
      "[800]\ttraining's binary_logloss: 0.440451\tvalid_1's binary_logloss: 0.476335\n",
      "[900]\ttraining's binary_logloss: 0.439561\tvalid_1's binary_logloss: 0.476239\n",
      "[1000]\ttraining's binary_logloss: 0.438842\tvalid_1's binary_logloss: 0.476175\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.438842\tvalid_1's binary_logloss: 0.476175\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.438775\tvalid_1's binary_logloss: 0.476176\n",
      "[1200]\ttraining's binary_logloss: 0.438707\tvalid_1's binary_logloss: 0.47617\n",
      "[1300]\ttraining's binary_logloss: 0.438636\tvalid_1's binary_logloss: 0.476163\n",
      "[1400]\ttraining's binary_logloss: 0.438568\tvalid_1's binary_logloss: 0.476149\n",
      "[1500]\ttraining's binary_logloss: 0.4385\tvalid_1's binary_logloss: 0.476134\n",
      "[1600]\ttraining's binary_logloss: 0.438435\tvalid_1's binary_logloss: 0.476119\n",
      "[1700]\ttraining's binary_logloss: 0.438368\tvalid_1's binary_logloss: 0.476111\n",
      "[1800]\ttraining's binary_logloss: 0.438304\tvalid_1's binary_logloss: 0.476109\n",
      "[1900]\ttraining's binary_logloss: 0.438241\tvalid_1's binary_logloss: 0.476113\n",
      "Early stopping, best iteration is:\n",
      "[1830]\ttraining's binary_logloss: 0.438285\tvalid_1's binary_logloss: 0.476108\n",
      "===== ACCURACY SCORE 0.785044 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509432\tvalid_1's binary_logloss: 0.525797\n",
      "[200]\ttraining's binary_logloss: 0.46923\tvalid_1's binary_logloss: 0.493128\n",
      "[300]\ttraining's binary_logloss: 0.455741\tvalid_1's binary_logloss: 0.486431\n",
      "[400]\ttraining's binary_logloss: 0.44969\tvalid_1's binary_logloss: 0.485682\n",
      "[500]\ttraining's binary_logloss: 0.446156\tvalid_1's binary_logloss: 0.48608\n",
      "Early stopping, best iteration is:\n",
      "[402]\ttraining's binary_logloss: 0.449611\tvalid_1's binary_logloss: 0.485666\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.449225\tvalid_1's binary_logloss: 0.48568\n",
      "Early stopping, best iteration is:\n",
      "[405]\ttraining's binary_logloss: 0.449598\tvalid_1's binary_logloss: 0.485663\n",
      "===== ACCURACY SCORE 0.776257 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510065\tvalid_1's binary_logloss: 0.532454\n",
      "[200]\ttraining's binary_logloss: 0.469776\tvalid_1's binary_logloss: 0.502914\n",
      "[300]\ttraining's binary_logloss: 0.456372\tvalid_1's binary_logloss: 0.498044\n",
      "[400]\ttraining's binary_logloss: 0.450504\tvalid_1's binary_logloss: 0.497514\n",
      "[500]\ttraining's binary_logloss: 0.446991\tvalid_1's binary_logloss: 0.497188\n",
      "[600]\ttraining's binary_logloss: 0.444658\tvalid_1's binary_logloss: 0.496873\n",
      "[700]\ttraining's binary_logloss: 0.443137\tvalid_1's binary_logloss: 0.496734\n",
      "[800]\ttraining's binary_logloss: 0.442006\tvalid_1's binary_logloss: 0.496632\n",
      "[900]\ttraining's binary_logloss: 0.441124\tvalid_1's binary_logloss: 0.496471\n",
      "[1000]\ttraining's binary_logloss: 0.440391\tvalid_1's binary_logloss: 0.496304\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440391\tvalid_1's binary_logloss: 0.496304\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440321\tvalid_1's binary_logloss: 0.496296\n",
      "[1200]\ttraining's binary_logloss: 0.440251\tvalid_1's binary_logloss: 0.496279\n",
      "[1300]\ttraining's binary_logloss: 0.440184\tvalid_1's binary_logloss: 0.496267\n",
      "[1400]\ttraining's binary_logloss: 0.440116\tvalid_1's binary_logloss: 0.496262\n",
      "[1500]\ttraining's binary_logloss: 0.44005\tvalid_1's binary_logloss: 0.496242\n",
      "[1600]\ttraining's binary_logloss: 0.439983\tvalid_1's binary_logloss: 0.496232\n",
      "[1700]\ttraining's binary_logloss: 0.439915\tvalid_1's binary_logloss: 0.496217\n",
      "[1800]\ttraining's binary_logloss: 0.439848\tvalid_1's binary_logloss: 0.496204\n",
      "[1900]\ttraining's binary_logloss: 0.439783\tvalid_1's binary_logloss: 0.496198\n",
      "[2000]\ttraining's binary_logloss: 0.43972\tvalid_1's binary_logloss: 0.496185\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.43972\tvalid_1's binary_logloss: 0.496185\n",
      "===== ACCURACY SCORE 0.774805 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509341\tvalid_1's binary_logloss: 0.527601\n",
      "[200]\ttraining's binary_logloss: 0.468954\tvalid_1's binary_logloss: 0.494788\n",
      "[300]\ttraining's binary_logloss: 0.455395\tvalid_1's binary_logloss: 0.48817\n",
      "[400]\ttraining's binary_logloss: 0.449393\tvalid_1's binary_logloss: 0.486869\n",
      "[500]\ttraining's binary_logloss: 0.445974\tvalid_1's binary_logloss: 0.486332\n",
      "[600]\ttraining's binary_logloss: 0.443723\tvalid_1's binary_logloss: 0.486059\n",
      "[700]\ttraining's binary_logloss: 0.442209\tvalid_1's binary_logloss: 0.485768\n",
      "[800]\ttraining's binary_logloss: 0.441113\tvalid_1's binary_logloss: 0.485641\n",
      "[900]\ttraining's binary_logloss: 0.440267\tvalid_1's binary_logloss: 0.485534\n",
      "[1000]\ttraining's binary_logloss: 0.439542\tvalid_1's binary_logloss: 0.485464\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439542\tvalid_1's binary_logloss: 0.485464\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439472\tvalid_1's binary_logloss: 0.485446\n",
      "[1200]\ttraining's binary_logloss: 0.439403\tvalid_1's binary_logloss: 0.485436\n",
      "[1300]\ttraining's binary_logloss: 0.439334\tvalid_1's binary_logloss: 0.485429\n",
      "[1400]\ttraining's binary_logloss: 0.439265\tvalid_1's binary_logloss: 0.485421\n",
      "[1500]\ttraining's binary_logloss: 0.439199\tvalid_1's binary_logloss: 0.485418\n",
      "Early stopping, best iteration is:\n",
      "[1479]\ttraining's binary_logloss: 0.439212\tvalid_1's binary_logloss: 0.485416\n",
      "===== ACCURACY SCORE 0.779607 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510952\tvalid_1's binary_logloss: 0.527317\n",
      "[200]\ttraining's binary_logloss: 0.470989\tvalid_1's binary_logloss: 0.494626\n",
      "[300]\ttraining's binary_logloss: 0.457296\tvalid_1's binary_logloss: 0.486917\n",
      "[400]\ttraining's binary_logloss: 0.451279\tvalid_1's binary_logloss: 0.484793\n",
      "[500]\ttraining's binary_logloss: 0.447739\tvalid_1's binary_logloss: 0.483827\n",
      "[600]\ttraining's binary_logloss: 0.445453\tvalid_1's binary_logloss: 0.483431\n",
      "[700]\ttraining's binary_logloss: 0.443952\tvalid_1's binary_logloss: 0.483242\n",
      "[800]\ttraining's binary_logloss: 0.442834\tvalid_1's binary_logloss: 0.483109\n",
      "[900]\ttraining's binary_logloss: 0.441979\tvalid_1's binary_logloss: 0.48299\n",
      "[1000]\ttraining's binary_logloss: 0.441237\tvalid_1's binary_logloss: 0.48296\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.441237\tvalid_1's binary_logloss: 0.48296\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.441166\tvalid_1's binary_logloss: 0.48295\n",
      "[1200]\ttraining's binary_logloss: 0.441096\tvalid_1's binary_logloss: 0.482945\n",
      "[1300]\ttraining's binary_logloss: 0.441025\tvalid_1's binary_logloss: 0.482943\n",
      "[1400]\ttraining's binary_logloss: 0.440957\tvalid_1's binary_logloss: 0.482931\n",
      "[1500]\ttraining's binary_logloss: 0.44089\tvalid_1's binary_logloss: 0.482931\n",
      "[1600]\ttraining's binary_logloss: 0.440824\tvalid_1's binary_logloss: 0.482924\n",
      "[1700]\ttraining's binary_logloss: 0.440758\tvalid_1's binary_logloss: 0.482919\n",
      "[1800]\ttraining's binary_logloss: 0.440694\tvalid_1's binary_logloss: 0.482914\n",
      "[1900]\ttraining's binary_logloss: 0.440631\tvalid_1's binary_logloss: 0.482906\n",
      "[2000]\ttraining's binary_logloss: 0.440564\tvalid_1's binary_logloss: 0.482898\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.440564\tvalid_1's binary_logloss: 0.482898\n",
      "===== ACCURACY SCORE 0.781490 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509436\tvalid_1's binary_logloss: 0.530363\n",
      "[200]\ttraining's binary_logloss: 0.468989\tvalid_1's binary_logloss: 0.499269\n",
      "[300]\ttraining's binary_logloss: 0.45517\tvalid_1's binary_logloss: 0.493241\n",
      "[400]\ttraining's binary_logloss: 0.449176\tvalid_1's binary_logloss: 0.492387\n",
      "[500]\ttraining's binary_logloss: 0.445739\tvalid_1's binary_logloss: 0.492596\n",
      "Early stopping, best iteration is:\n",
      "[401]\ttraining's binary_logloss: 0.449133\tvalid_1's binary_logloss: 0.492372\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.448742\tvalid_1's binary_logloss: 0.492393\n",
      "Early stopping, best iteration is:\n",
      "[402]\ttraining's binary_logloss: 0.44913\tvalid_1's binary_logloss: 0.492372\n",
      "===== ACCURACY SCORE 0.774223 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779100 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509726\tvalid_1's binary_logloss: 0.528014\n",
      "[200]\ttraining's binary_logloss: 0.469455\tvalid_1's binary_logloss: 0.495378\n",
      "[300]\ttraining's binary_logloss: 0.455671\tvalid_1's binary_logloss: 0.488173\n",
      "[400]\ttraining's binary_logloss: 0.449698\tvalid_1's binary_logloss: 0.486748\n",
      "[500]\ttraining's binary_logloss: 0.44625\tvalid_1's binary_logloss: 0.486139\n",
      "[600]\ttraining's binary_logloss: 0.443959\tvalid_1's binary_logloss: 0.485586\n",
      "[700]\ttraining's binary_logloss: 0.442417\tvalid_1's binary_logloss: 0.48521\n",
      "[800]\ttraining's binary_logloss: 0.441312\tvalid_1's binary_logloss: 0.484962\n",
      "[900]\ttraining's binary_logloss: 0.440445\tvalid_1's binary_logloss: 0.484805\n",
      "[1000]\ttraining's binary_logloss: 0.439689\tvalid_1's binary_logloss: 0.484637\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439689\tvalid_1's binary_logloss: 0.484637\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439621\tvalid_1's binary_logloss: 0.484636\n",
      "[1200]\ttraining's binary_logloss: 0.439553\tvalid_1's binary_logloss: 0.484625\n",
      "[1300]\ttraining's binary_logloss: 0.439487\tvalid_1's binary_logloss: 0.484614\n",
      "[1400]\ttraining's binary_logloss: 0.439423\tvalid_1's binary_logloss: 0.484607\n",
      "[1500]\ttraining's binary_logloss: 0.439358\tvalid_1's binary_logloss: 0.484601\n",
      "[1600]\ttraining's binary_logloss: 0.439293\tvalid_1's binary_logloss: 0.484597\n",
      "[1700]\ttraining's binary_logloss: 0.439229\tvalid_1's binary_logloss: 0.48459\n",
      "[1800]\ttraining's binary_logloss: 0.439164\tvalid_1's binary_logloss: 0.484586\n",
      "[1900]\ttraining's binary_logloss: 0.439103\tvalid_1's binary_logloss: 0.484575\n",
      "[2000]\ttraining's binary_logloss: 0.43904\tvalid_1's binary_logloss: 0.484568\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.43904\tvalid_1's binary_logloss: 0.484568\n",
      "===== ACCURACY SCORE 0.780147 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509643\tvalid_1's binary_logloss: 0.527442\n",
      "[200]\ttraining's binary_logloss: 0.469245\tvalid_1's binary_logloss: 0.494295\n",
      "[300]\ttraining's binary_logloss: 0.455553\tvalid_1's binary_logloss: 0.486861\n",
      "[400]\ttraining's binary_logloss: 0.449521\tvalid_1's binary_logloss: 0.485242\n",
      "[500]\ttraining's binary_logloss: 0.446018\tvalid_1's binary_logloss: 0.484701\n",
      "[600]\ttraining's binary_logloss: 0.44376\tvalid_1's binary_logloss: 0.484552\n",
      "[700]\ttraining's binary_logloss: 0.442239\tvalid_1's binary_logloss: 0.484582\n",
      "Early stopping, best iteration is:\n",
      "[609]\ttraining's binary_logloss: 0.443587\tvalid_1's binary_logloss: 0.484518\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.443432\tvalid_1's binary_logloss: 0.484521\n",
      "Early stopping, best iteration is:\n",
      "[672]\ttraining's binary_logloss: 0.443477\tvalid_1's binary_logloss: 0.484515\n",
      "===== ACCURACY SCORE 0.777999 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508735\tvalid_1's binary_logloss: 0.533485\n",
      "[200]\ttraining's binary_logloss: 0.468275\tvalid_1's binary_logloss: 0.502787\n",
      "[300]\ttraining's binary_logloss: 0.454669\tvalid_1's binary_logloss: 0.496838\n",
      "[400]\ttraining's binary_logloss: 0.448534\tvalid_1's binary_logloss: 0.49573\n",
      "[500]\ttraining's binary_logloss: 0.44512\tvalid_1's binary_logloss: 0.495692\n",
      "[600]\ttraining's binary_logloss: 0.442808\tvalid_1's binary_logloss: 0.495453\n",
      "[700]\ttraining's binary_logloss: 0.441307\tvalid_1's binary_logloss: 0.495361\n",
      "[800]\ttraining's binary_logloss: 0.440201\tvalid_1's binary_logloss: 0.495233\n",
      "[900]\ttraining's binary_logloss: 0.439313\tvalid_1's binary_logloss: 0.495257\n",
      "Early stopping, best iteration is:\n",
      "[830]\ttraining's binary_logloss: 0.439918\tvalid_1's binary_logloss: 0.495197\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[900]\ttraining's binary_logloss: 0.439853\tvalid_1's binary_logloss: 0.495193\n",
      "[1000]\ttraining's binary_logloss: 0.439763\tvalid_1's binary_logloss: 0.495163\n",
      "[1100]\ttraining's binary_logloss: 0.439675\tvalid_1's binary_logloss: 0.495146\n",
      "[1200]\ttraining's binary_logloss: 0.43959\tvalid_1's binary_logloss: 0.495132\n",
      "[1300]\ttraining's binary_logloss: 0.439503\tvalid_1's binary_logloss: 0.495115\n",
      "[1400]\ttraining's binary_logloss: 0.439416\tvalid_1's binary_logloss: 0.495096\n",
      "[1500]\ttraining's binary_logloss: 0.439332\tvalid_1's binary_logloss: 0.495086\n",
      "[1600]\ttraining's binary_logloss: 0.439253\tvalid_1's binary_logloss: 0.495077\n",
      "[1700]\ttraining's binary_logloss: 0.439173\tvalid_1's binary_logloss: 0.495073\n",
      "[1800]\ttraining's binary_logloss: 0.439096\tvalid_1's binary_logloss: 0.495063\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1830]\ttraining's binary_logloss: 0.439073\tvalid_1's binary_logloss: 0.495062\n",
      "===== ACCURACY SCORE 0.771774 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50932\tvalid_1's binary_logloss: 0.533481\n",
      "[200]\ttraining's binary_logloss: 0.468871\tvalid_1's binary_logloss: 0.503174\n",
      "[300]\ttraining's binary_logloss: 0.455126\tvalid_1's binary_logloss: 0.497335\n",
      "[400]\ttraining's binary_logloss: 0.449142\tvalid_1's binary_logloss: 0.496671\n",
      "[500]\ttraining's binary_logloss: 0.445573\tvalid_1's binary_logloss: 0.496608\n",
      "Early stopping, best iteration is:\n",
      "[457]\ttraining's binary_logloss: 0.446957\tvalid_1's binary_logloss: 0.496584\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.44681\tvalid_1's binary_logloss: 0.496581\n",
      "[600]\ttraining's binary_logloss: 0.446482\tvalid_1's binary_logloss: 0.496578\n",
      "[700]\ttraining's binary_logloss: 0.446164\tvalid_1's binary_logloss: 0.496562\n",
      "[800]\ttraining's binary_logloss: 0.445856\tvalid_1's binary_logloss: 0.496541\n",
      "[900]\ttraining's binary_logloss: 0.445567\tvalid_1's binary_logloss: 0.496548\n",
      "Early stopping, best iteration is:\n",
      "[844]\ttraining's binary_logloss: 0.44572\tvalid_1's binary_logloss: 0.496532\n",
      "===== ACCURACY SCORE 0.773764 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50957\tvalid_1's binary_logloss: 0.527682\n",
      "[200]\ttraining's binary_logloss: 0.469323\tvalid_1's binary_logloss: 0.49587\n",
      "[300]\ttraining's binary_logloss: 0.455827\tvalid_1's binary_logloss: 0.489953\n",
      "[400]\ttraining's binary_logloss: 0.450049\tvalid_1's binary_logloss: 0.489337\n",
      "[500]\ttraining's binary_logloss: 0.446746\tvalid_1's binary_logloss: 0.489367\n",
      "Early stopping, best iteration is:\n",
      "[413]\ttraining's binary_logloss: 0.449517\tvalid_1's binary_logloss: 0.489317\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.449209\tvalid_1's binary_logloss: 0.489354\n",
      "Early stopping, best iteration is:\n",
      "[414]\ttraining's binary_logloss: 0.449513\tvalid_1's binary_logloss: 0.489316\n",
      "===== ACCURACY SCORE 0.780122 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509959\tvalid_1's binary_logloss: 0.526529\n",
      "[200]\ttraining's binary_logloss: 0.46953\tvalid_1's binary_logloss: 0.493013\n",
      "[300]\ttraining's binary_logloss: 0.455879\tvalid_1's binary_logloss: 0.485636\n",
      "[400]\ttraining's binary_logloss: 0.449878\tvalid_1's binary_logloss: 0.483845\n",
      "[500]\ttraining's binary_logloss: 0.44638\tvalid_1's binary_logloss: 0.483108\n",
      "[600]\ttraining's binary_logloss: 0.444115\tvalid_1's binary_logloss: 0.482473\n",
      "[700]\ttraining's binary_logloss: 0.442609\tvalid_1's binary_logloss: 0.482176\n",
      "[800]\ttraining's binary_logloss: 0.441468\tvalid_1's binary_logloss: 0.481838\n",
      "[900]\ttraining's binary_logloss: 0.440584\tvalid_1's binary_logloss: 0.48163\n",
      "[1000]\ttraining's binary_logloss: 0.439838\tvalid_1's binary_logloss: 0.481574\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439838\tvalid_1's binary_logloss: 0.481574\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439767\tvalid_1's binary_logloss: 0.481556\n",
      "[1200]\ttraining's binary_logloss: 0.439694\tvalid_1's binary_logloss: 0.48153\n",
      "[1300]\ttraining's binary_logloss: 0.439625\tvalid_1's binary_logloss: 0.481514\n",
      "[1400]\ttraining's binary_logloss: 0.439557\tvalid_1's binary_logloss: 0.481498\n",
      "[1500]\ttraining's binary_logloss: 0.439491\tvalid_1's binary_logloss: 0.481472\n",
      "[1600]\ttraining's binary_logloss: 0.439421\tvalid_1's binary_logloss: 0.481462\n",
      "[1700]\ttraining's binary_logloss: 0.439355\tvalid_1's binary_logloss: 0.481444\n",
      "[1800]\ttraining's binary_logloss: 0.439287\tvalid_1's binary_logloss: 0.481425\n",
      "[1900]\ttraining's binary_logloss: 0.439225\tvalid_1's binary_logloss: 0.481411\n",
      "[2000]\ttraining's binary_logloss: 0.439162\tvalid_1's binary_logloss: 0.48141\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439162\tvalid_1's binary_logloss: 0.48141\n",
      "===== ACCURACY SCORE 0.781650 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510623\tvalid_1's binary_logloss: 0.527222\n",
      "[200]\ttraining's binary_logloss: 0.470481\tvalid_1's binary_logloss: 0.494083\n",
      "[300]\ttraining's binary_logloss: 0.456967\tvalid_1's binary_logloss: 0.487137\n",
      "[400]\ttraining's binary_logloss: 0.451017\tvalid_1's binary_logloss: 0.485794\n",
      "[500]\ttraining's binary_logloss: 0.447683\tvalid_1's binary_logloss: 0.48527\n",
      "[600]\ttraining's binary_logloss: 0.445419\tvalid_1's binary_logloss: 0.484538\n",
      "[700]\ttraining's binary_logloss: 0.443947\tvalid_1's binary_logloss: 0.48433\n",
      "[800]\ttraining's binary_logloss: 0.442872\tvalid_1's binary_logloss: 0.484294\n",
      "Early stopping, best iteration is:\n",
      "[772]\ttraining's binary_logloss: 0.443149\tvalid_1's binary_logloss: 0.484268\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.44312\tvalid_1's binary_logloss: 0.484262\n",
      "[900]\ttraining's binary_logloss: 0.44302\tvalid_1's binary_logloss: 0.484251\n",
      "[1000]\ttraining's binary_logloss: 0.442921\tvalid_1's binary_logloss: 0.484249\n",
      "[1100]\ttraining's binary_logloss: 0.442826\tvalid_1's binary_logloss: 0.484239\n",
      "[1200]\ttraining's binary_logloss: 0.442728\tvalid_1's binary_logloss: 0.484235\n",
      "Early stopping, best iteration is:\n",
      "[1168]\ttraining's binary_logloss: 0.442759\tvalid_1's binary_logloss: 0.484233\n",
      "===== ACCURACY SCORE 0.781768 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510839\tvalid_1's binary_logloss: 0.526634\n",
      "[200]\ttraining's binary_logloss: 0.470984\tvalid_1's binary_logloss: 0.492756\n",
      "[300]\ttraining's binary_logloss: 0.457566\tvalid_1's binary_logloss: 0.485458\n",
      "[400]\ttraining's binary_logloss: 0.451544\tvalid_1's binary_logloss: 0.48362\n",
      "[500]\ttraining's binary_logloss: 0.448052\tvalid_1's binary_logloss: 0.482939\n",
      "[600]\ttraining's binary_logloss: 0.44571\tvalid_1's binary_logloss: 0.482473\n",
      "[700]\ttraining's binary_logloss: 0.444196\tvalid_1's binary_logloss: 0.482453\n",
      "[800]\ttraining's binary_logloss: 0.44308\tvalid_1's binary_logloss: 0.482246\n",
      "[900]\ttraining's binary_logloss: 0.442223\tvalid_1's binary_logloss: 0.482177\n",
      "[1000]\ttraining's binary_logloss: 0.44151\tvalid_1's binary_logloss: 0.482134\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.44151\tvalid_1's binary_logloss: 0.482134\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.44144\tvalid_1's binary_logloss: 0.482128\n",
      "[1200]\ttraining's binary_logloss: 0.441373\tvalid_1's binary_logloss: 0.482117\n",
      "[1300]\ttraining's binary_logloss: 0.441308\tvalid_1's binary_logloss: 0.48211\n",
      "[1400]\ttraining's binary_logloss: 0.441241\tvalid_1's binary_logloss: 0.482098\n",
      "[1500]\ttraining's binary_logloss: 0.441173\tvalid_1's binary_logloss: 0.482093\n",
      "[1600]\ttraining's binary_logloss: 0.441105\tvalid_1's binary_logloss: 0.482087\n",
      "[1700]\ttraining's binary_logloss: 0.441038\tvalid_1's binary_logloss: 0.482081\n",
      "[1800]\ttraining's binary_logloss: 0.440977\tvalid_1's binary_logloss: 0.482076\n",
      "[1900]\ttraining's binary_logloss: 0.440914\tvalid_1's binary_logloss: 0.482077\n",
      "Early stopping, best iteration is:\n",
      "[1826]\ttraining's binary_logloss: 0.440959\tvalid_1's binary_logloss: 0.482073\n",
      "===== ACCURACY SCORE 0.781266 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.507963\tvalid_1's binary_logloss: 0.528497\n",
      "[200]\ttraining's binary_logloss: 0.467136\tvalid_1's binary_logloss: 0.496876\n",
      "[300]\ttraining's binary_logloss: 0.453274\tvalid_1's binary_logloss: 0.490993\n",
      "[400]\ttraining's binary_logloss: 0.447116\tvalid_1's binary_logloss: 0.490315\n",
      "Early stopping, best iteration is:\n",
      "[375]\ttraining's binary_logloss: 0.448271\tvalid_1's binary_logloss: 0.490274\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.448151\tvalid_1's binary_logloss: 0.490269\n",
      "[500]\ttraining's binary_logloss: 0.447684\tvalid_1's binary_logloss: 0.49028\n",
      "Early stopping, best iteration is:\n",
      "[402]\ttraining's binary_logloss: 0.448141\tvalid_1's binary_logloss: 0.490269\n",
      "===== ACCURACY SCORE 0.777723 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509699\tvalid_1's binary_logloss: 0.522373\n",
      "[200]\ttraining's binary_logloss: 0.469402\tvalid_1's binary_logloss: 0.489521\n",
      "[300]\ttraining's binary_logloss: 0.455829\tvalid_1's binary_logloss: 0.48308\n",
      "[400]\ttraining's binary_logloss: 0.449979\tvalid_1's binary_logloss: 0.481987\n",
      "[500]\ttraining's binary_logloss: 0.446644\tvalid_1's binary_logloss: 0.481989\n",
      "[600]\ttraining's binary_logloss: 0.444406\tvalid_1's binary_logloss: 0.481761\n",
      "Early stopping, best iteration is:\n",
      "[597]\ttraining's binary_logloss: 0.444455\tvalid_1's binary_logloss: 0.481757\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.444449\tvalid_1's binary_logloss: 0.481753\n",
      "[700]\ttraining's binary_logloss: 0.444276\tvalid_1's binary_logloss: 0.48175\n",
      "Early stopping, best iteration is:\n",
      "[650]\ttraining's binary_logloss: 0.444362\tvalid_1's binary_logloss: 0.481744\n",
      "===== ACCURACY SCORE 0.782758 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778900 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509793\tvalid_1's binary_logloss: 0.52439\n",
      "[200]\ttraining's binary_logloss: 0.469591\tvalid_1's binary_logloss: 0.491166\n",
      "[300]\ttraining's binary_logloss: 0.455949\tvalid_1's binary_logloss: 0.484164\n",
      "[400]\ttraining's binary_logloss: 0.449923\tvalid_1's binary_logloss: 0.482637\n",
      "[500]\ttraining's binary_logloss: 0.446438\tvalid_1's binary_logloss: 0.482432\n",
      "Early stopping, best iteration is:\n",
      "[487]\ttraining's binary_logloss: 0.446797\tvalid_1's binary_logloss: 0.482358\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.446756\tvalid_1's binary_logloss: 0.482355\n",
      "[600]\ttraining's binary_logloss: 0.44647\tvalid_1's binary_logloss: 0.482359\n",
      "[700]\ttraining's binary_logloss: 0.446193\tvalid_1's binary_logloss: 0.482353\n",
      "Early stopping, best iteration is:\n",
      "[620]\ttraining's binary_logloss: 0.446412\tvalid_1's binary_logloss: 0.482348\n",
      "===== ACCURACY SCORE 0.777944 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508837\tvalid_1's binary_logloss: 0.528503\n",
      "[200]\ttraining's binary_logloss: 0.468392\tvalid_1's binary_logloss: 0.497095\n",
      "[300]\ttraining's binary_logloss: 0.454693\tvalid_1's binary_logloss: 0.491193\n",
      "[400]\ttraining's binary_logloss: 0.44883\tvalid_1's binary_logloss: 0.490183\n",
      "[500]\ttraining's binary_logloss: 0.445418\tvalid_1's binary_logloss: 0.490039\n",
      "[600]\ttraining's binary_logloss: 0.443093\tvalid_1's binary_logloss: 0.489835\n",
      "[700]\ttraining's binary_logloss: 0.441638\tvalid_1's binary_logloss: 0.489749\n",
      "Early stopping, best iteration is:\n",
      "[619]\ttraining's binary_logloss: 0.44278\tvalid_1's binary_logloss: 0.489742\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.442651\tvalid_1's binary_logloss: 0.489746\n",
      "[800]\ttraining's binary_logloss: 0.442499\tvalid_1's binary_logloss: 0.489745\n",
      "[900]\ttraining's binary_logloss: 0.44235\tvalid_1's binary_logloss: 0.489735\n",
      "[1000]\ttraining's binary_logloss: 0.442204\tvalid_1's binary_logloss: 0.489721\n",
      "[1100]\ttraining's binary_logloss: 0.442066\tvalid_1's binary_logloss: 0.489711\n",
      "[1200]\ttraining's binary_logloss: 0.441925\tvalid_1's binary_logloss: 0.489711\n",
      "Early stopping, best iteration is:\n",
      "[1107]\ttraining's binary_logloss: 0.442055\tvalid_1's binary_logloss: 0.489709\n",
      "===== ACCURACY SCORE 0.775915 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510632\tvalid_1's binary_logloss: 0.519799\n",
      "[200]\ttraining's binary_logloss: 0.470543\tvalid_1's binary_logloss: 0.484117\n",
      "[300]\ttraining's binary_logloss: 0.456877\tvalid_1's binary_logloss: 0.475424\n",
      "[400]\ttraining's binary_logloss: 0.451047\tvalid_1's binary_logloss: 0.47293\n",
      "[500]\ttraining's binary_logloss: 0.447631\tvalid_1's binary_logloss: 0.471756\n",
      "[600]\ttraining's binary_logloss: 0.445431\tvalid_1's binary_logloss: 0.470991\n",
      "[700]\ttraining's binary_logloss: 0.443957\tvalid_1's binary_logloss: 0.470713\n",
      "[800]\ttraining's binary_logloss: 0.442858\tvalid_1's binary_logloss: 0.470505\n",
      "[900]\ttraining's binary_logloss: 0.442009\tvalid_1's binary_logloss: 0.47046\n",
      "[1000]\ttraining's binary_logloss: 0.441309\tvalid_1's binary_logloss: 0.470364\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.441309\tvalid_1's binary_logloss: 0.470364\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.44124\tvalid_1's binary_logloss: 0.470361\n",
      "[1200]\ttraining's binary_logloss: 0.441173\tvalid_1's binary_logloss: 0.470356\n",
      "[1300]\ttraining's binary_logloss: 0.441106\tvalid_1's binary_logloss: 0.470358\n",
      "Early stopping, best iteration is:\n",
      "[1237]\ttraining's binary_logloss: 0.441149\tvalid_1's binary_logloss: 0.470354\n",
      "===== ACCURACY SCORE 0.789252 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50878\tvalid_1's binary_logloss: 0.532518\n",
      "[200]\ttraining's binary_logloss: 0.468088\tvalid_1's binary_logloss: 0.502242\n",
      "[300]\ttraining's binary_logloss: 0.454421\tvalid_1's binary_logloss: 0.496338\n",
      "[400]\ttraining's binary_logloss: 0.448498\tvalid_1's binary_logloss: 0.49554\n",
      "[500]\ttraining's binary_logloss: 0.445038\tvalid_1's binary_logloss: 0.495209\n",
      "[600]\ttraining's binary_logloss: 0.442762\tvalid_1's binary_logloss: 0.494928\n",
      "[700]\ttraining's binary_logloss: 0.441285\tvalid_1's binary_logloss: 0.494564\n",
      "[800]\ttraining's binary_logloss: 0.440212\tvalid_1's binary_logloss: 0.494478\n",
      "[900]\ttraining's binary_logloss: 0.439344\tvalid_1's binary_logloss: 0.494304\n",
      "[1000]\ttraining's binary_logloss: 0.438607\tvalid_1's binary_logloss: 0.494216\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.438607\tvalid_1's binary_logloss: 0.494216\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.438536\tvalid_1's binary_logloss: 0.494207\n",
      "[1200]\ttraining's binary_logloss: 0.438468\tvalid_1's binary_logloss: 0.494189\n",
      "[1300]\ttraining's binary_logloss: 0.438398\tvalid_1's binary_logloss: 0.494177\n",
      "[1400]\ttraining's binary_logloss: 0.438332\tvalid_1's binary_logloss: 0.49417\n",
      "[1500]\ttraining's binary_logloss: 0.438266\tvalid_1's binary_logloss: 0.494163\n",
      "[1600]\ttraining's binary_logloss: 0.438201\tvalid_1's binary_logloss: 0.494166\n",
      "Early stopping, best iteration is:\n",
      "[1512]\ttraining's binary_logloss: 0.438258\tvalid_1's binary_logloss: 0.494161\n",
      "===== ACCURACY SCORE 0.774938 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508732\tvalid_1's binary_logloss: 0.530385\n",
      "[200]\ttraining's binary_logloss: 0.468095\tvalid_1's binary_logloss: 0.498209\n",
      "[300]\ttraining's binary_logloss: 0.454344\tvalid_1's binary_logloss: 0.492109\n",
      "[400]\ttraining's binary_logloss: 0.448336\tvalid_1's binary_logloss: 0.491176\n",
      "[500]\ttraining's binary_logloss: 0.444823\tvalid_1's binary_logloss: 0.491217\n",
      "Early stopping, best iteration is:\n",
      "[456]\ttraining's binary_logloss: 0.446206\tvalid_1's binary_logloss: 0.491152\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.446061\tvalid_1's binary_logloss: 0.49114\n",
      "Early stopping, best iteration is:\n",
      "[495]\ttraining's binary_logloss: 0.446077\tvalid_1's binary_logloss: 0.491134\n",
      "===== ACCURACY SCORE 0.773503 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510276\tvalid_1's binary_logloss: 0.534389\n",
      "[200]\ttraining's binary_logloss: 0.470296\tvalid_1's binary_logloss: 0.503816\n",
      "[300]\ttraining's binary_logloss: 0.456625\tvalid_1's binary_logloss: 0.498002\n",
      "[400]\ttraining's binary_logloss: 0.45057\tvalid_1's binary_logloss: 0.497208\n",
      "[500]\ttraining's binary_logloss: 0.446936\tvalid_1's binary_logloss: 0.497075\n",
      "[600]\ttraining's binary_logloss: 0.444605\tvalid_1's binary_logloss: 0.496929\n",
      "[700]\ttraining's binary_logloss: 0.443026\tvalid_1's binary_logloss: 0.496726\n",
      "[800]\ttraining's binary_logloss: 0.441878\tvalid_1's binary_logloss: 0.496811\n",
      "Early stopping, best iteration is:\n",
      "[716]\ttraining's binary_logloss: 0.442814\tvalid_1's binary_logloss: 0.496707\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.442713\tvalid_1's binary_logloss: 0.496716\n",
      "Early stopping, best iteration is:\n",
      "[720]\ttraining's binary_logloss: 0.442808\tvalid_1's binary_logloss: 0.496705\n",
      "===== ACCURACY SCORE 0.778209 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509342\tvalid_1's binary_logloss: 0.525809\n",
      "[200]\ttraining's binary_logloss: 0.469094\tvalid_1's binary_logloss: 0.492884\n",
      "[300]\ttraining's binary_logloss: 0.455594\tvalid_1's binary_logloss: 0.486113\n",
      "[400]\ttraining's binary_logloss: 0.449559\tvalid_1's binary_logloss: 0.484763\n",
      "[500]\ttraining's binary_logloss: 0.446074\tvalid_1's binary_logloss: 0.484507\n",
      "[600]\ttraining's binary_logloss: 0.443779\tvalid_1's binary_logloss: 0.484395\n",
      "[700]\ttraining's binary_logloss: 0.442246\tvalid_1's binary_logloss: 0.484348\n",
      "Early stopping, best iteration is:\n",
      "[633]\ttraining's binary_logloss: 0.443207\tvalid_1's binary_logloss: 0.484265\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.443103\tvalid_1's binary_logloss: 0.484272\n",
      "Early stopping, best iteration is:\n",
      "[641]\ttraining's binary_logloss: 0.443195\tvalid_1's binary_logloss: 0.484265\n",
      "===== ACCURACY SCORE 0.781259 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50998\tvalid_1's binary_logloss: 0.530463\n",
      "[200]\ttraining's binary_logloss: 0.469861\tvalid_1's binary_logloss: 0.498275\n",
      "[300]\ttraining's binary_logloss: 0.456218\tvalid_1's binary_logloss: 0.491626\n",
      "[400]\ttraining's binary_logloss: 0.450203\tvalid_1's binary_logloss: 0.490316\n",
      "[500]\ttraining's binary_logloss: 0.44679\tvalid_1's binary_logloss: 0.489913\n",
      "[600]\ttraining's binary_logloss: 0.444524\tvalid_1's binary_logloss: 0.489695\n",
      "[700]\ttraining's binary_logloss: 0.44306\tvalid_1's binary_logloss: 0.489762\n",
      "Early stopping, best iteration is:\n",
      "[663]\ttraining's binary_logloss: 0.443521\tvalid_1's binary_logloss: 0.489677\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.443471\tvalid_1's binary_logloss: 0.489676\n",
      "[800]\ttraining's binary_logloss: 0.443334\tvalid_1's binary_logloss: 0.489666\n",
      "[900]\ttraining's binary_logloss: 0.443202\tvalid_1's binary_logloss: 0.489663\n",
      "[1000]\ttraining's binary_logloss: 0.443074\tvalid_1's binary_logloss: 0.489652\n",
      "[1100]\ttraining's binary_logloss: 0.442947\tvalid_1's binary_logloss: 0.489653\n",
      "[1200]\ttraining's binary_logloss: 0.442824\tvalid_1's binary_logloss: 0.48965\n",
      "Early stopping, best iteration is:\n",
      "[1149]\ttraining's binary_logloss: 0.442886\tvalid_1's binary_logloss: 0.489643\n",
      "===== ACCURACY SCORE 0.779796 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508756\tvalid_1's binary_logloss: 0.529535\n",
      "[200]\ttraining's binary_logloss: 0.468118\tvalid_1's binary_logloss: 0.497975\n",
      "[300]\ttraining's binary_logloss: 0.45425\tvalid_1's binary_logloss: 0.491846\n",
      "[400]\ttraining's binary_logloss: 0.44811\tvalid_1's binary_logloss: 0.490918\n",
      "[500]\ttraining's binary_logloss: 0.4445\tvalid_1's binary_logloss: 0.491026\n",
      "Early stopping, best iteration is:\n",
      "[402]\ttraining's binary_logloss: 0.448027\tvalid_1's binary_logloss: 0.490914\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.447621\tvalid_1's binary_logloss: 0.490919\n",
      "Early stopping, best iteration is:\n",
      "[420]\ttraining's binary_logloss: 0.44795\tvalid_1's binary_logloss: 0.490908\n",
      "===== ACCURACY SCORE 0.775929 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508556\tvalid_1's binary_logloss: 0.525193\n",
      "[200]\ttraining's binary_logloss: 0.467901\tvalid_1's binary_logloss: 0.492337\n",
      "[300]\ttraining's binary_logloss: 0.453981\tvalid_1's binary_logloss: 0.48594\n",
      "[400]\ttraining's binary_logloss: 0.447911\tvalid_1's binary_logloss: 0.485103\n",
      "[500]\ttraining's binary_logloss: 0.444201\tvalid_1's binary_logloss: 0.485014\n",
      "[600]\ttraining's binary_logloss: 0.441857\tvalid_1's binary_logloss: 0.484941\n",
      "Early stopping, best iteration is:\n",
      "[526]\ttraining's binary_logloss: 0.443471\tvalid_1's binary_logloss: 0.484873\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.443278\tvalid_1's binary_logloss: 0.484855\n",
      "[700]\ttraining's binary_logloss: 0.443041\tvalid_1's binary_logloss: 0.48485\n",
      "[800]\ttraining's binary_logloss: 0.442797\tvalid_1's binary_logloss: 0.484819\n",
      "[900]\ttraining's binary_logloss: 0.442574\tvalid_1's binary_logloss: 0.484827\n",
      "Early stopping, best iteration is:\n",
      "[838]\ttraining's binary_logloss: 0.442708\tvalid_1's binary_logloss: 0.484808\n",
      "===== ACCURACY SCORE 0.782305 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778900 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510009\tvalid_1's binary_logloss: 0.522384\n",
      "[200]\ttraining's binary_logloss: 0.469781\tvalid_1's binary_logloss: 0.487534\n",
      "[300]\ttraining's binary_logloss: 0.45627\tvalid_1's binary_logloss: 0.480004\n",
      "[400]\ttraining's binary_logloss: 0.450326\tvalid_1's binary_logloss: 0.478382\n",
      "[500]\ttraining's binary_logloss: 0.446911\tvalid_1's binary_logloss: 0.477989\n",
      "[600]\ttraining's binary_logloss: 0.444718\tvalid_1's binary_logloss: 0.477779\n",
      "[700]\ttraining's binary_logloss: 0.44322\tvalid_1's binary_logloss: 0.477696\n",
      "[800]\ttraining's binary_logloss: 0.442141\tvalid_1's binary_logloss: 0.477542\n",
      "[900]\ttraining's binary_logloss: 0.441282\tvalid_1's binary_logloss: 0.477544\n",
      "Early stopping, best iteration is:\n",
      "[870]\ttraining's binary_logloss: 0.441516\tvalid_1's binary_logloss: 0.477483\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[900]\ttraining's binary_logloss: 0.441491\tvalid_1's binary_logloss: 0.477482\n",
      "[1000]\ttraining's binary_logloss: 0.441405\tvalid_1's binary_logloss: 0.477468\n",
      "[1100]\ttraining's binary_logloss: 0.441323\tvalid_1's binary_logloss: 0.477467\n",
      "[1200]\ttraining's binary_logloss: 0.44124\tvalid_1's binary_logloss: 0.477456\n",
      "[1300]\ttraining's binary_logloss: 0.44116\tvalid_1's binary_logloss: 0.477451\n",
      "Early stopping, best iteration is:\n",
      "[1276]\ttraining's binary_logloss: 0.44118\tvalid_1's binary_logloss: 0.477447\n",
      "===== ACCURACY SCORE 0.788648 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509677\tvalid_1's binary_logloss: 0.52474\n",
      "[200]\ttraining's binary_logloss: 0.469322\tvalid_1's binary_logloss: 0.489705\n",
      "[300]\ttraining's binary_logloss: 0.455719\tvalid_1's binary_logloss: 0.482027\n",
      "[400]\ttraining's binary_logloss: 0.449762\tvalid_1's binary_logloss: 0.480137\n",
      "[500]\ttraining's binary_logloss: 0.446324\tvalid_1's binary_logloss: 0.479477\n",
      "[600]\ttraining's binary_logloss: 0.44405\tvalid_1's binary_logloss: 0.479093\n",
      "[700]\ttraining's binary_logloss: 0.442535\tvalid_1's binary_logloss: 0.478748\n",
      "[800]\ttraining's binary_logloss: 0.441441\tvalid_1's binary_logloss: 0.478715\n",
      "[900]\ttraining's binary_logloss: 0.44055\tvalid_1's binary_logloss: 0.478689\n",
      "Early stopping, best iteration is:\n",
      "[865]\ttraining's binary_logloss: 0.440853\tvalid_1's binary_logloss: 0.478633\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[900]\ttraining's binary_logloss: 0.440824\tvalid_1's binary_logloss: 0.478639\n",
      "Early stopping, best iteration is:\n",
      "[873]\ttraining's binary_logloss: 0.440846\tvalid_1's binary_logloss: 0.478632\n",
      "===== ACCURACY SCORE 0.783093 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509164\tvalid_1's binary_logloss: 0.53738\n",
      "[200]\ttraining's binary_logloss: 0.46875\tvalid_1's binary_logloss: 0.508961\n",
      "[300]\ttraining's binary_logloss: 0.455168\tvalid_1's binary_logloss: 0.504114\n",
      "[400]\ttraining's binary_logloss: 0.449312\tvalid_1's binary_logloss: 0.503563\n",
      "[500]\ttraining's binary_logloss: 0.445912\tvalid_1's binary_logloss: 0.50349\n",
      "[600]\ttraining's binary_logloss: 0.443635\tvalid_1's binary_logloss: 0.503458\n",
      "[700]\ttraining's binary_logloss: 0.442103\tvalid_1's binary_logloss: 0.503329\n",
      "[800]\ttraining's binary_logloss: 0.441018\tvalid_1's binary_logloss: 0.503274\n",
      "[900]\ttraining's binary_logloss: 0.440165\tvalid_1's binary_logloss: 0.503133\n",
      "[1000]\ttraining's binary_logloss: 0.439436\tvalid_1's binary_logloss: 0.503059\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439436\tvalid_1's binary_logloss: 0.503059\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439371\tvalid_1's binary_logloss: 0.503056\n",
      "[1200]\ttraining's binary_logloss: 0.439302\tvalid_1's binary_logloss: 0.503036\n",
      "[1300]\ttraining's binary_logloss: 0.439234\tvalid_1's binary_logloss: 0.503036\n",
      "[1400]\ttraining's binary_logloss: 0.439169\tvalid_1's binary_logloss: 0.503038\n",
      "Early stopping, best iteration is:\n",
      "[1351]\ttraining's binary_logloss: 0.4392\tvalid_1's binary_logloss: 0.503031\n",
      "===== ACCURACY SCORE 0.767908 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509769\tvalid_1's binary_logloss: 0.534955\n",
      "[200]\ttraining's binary_logloss: 0.469589\tvalid_1's binary_logloss: 0.505385\n",
      "[300]\ttraining's binary_logloss: 0.455928\tvalid_1's binary_logloss: 0.500241\n",
      "[400]\ttraining's binary_logloss: 0.449813\tvalid_1's binary_logloss: 0.499949\n",
      "Early stopping, best iteration is:\n",
      "[371]\ttraining's binary_logloss: 0.451212\tvalid_1's binary_logloss: 0.499799\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.45106\tvalid_1's binary_logloss: 0.499806\n",
      "Early stopping, best iteration is:\n",
      "[380]\ttraining's binary_logloss: 0.451162\tvalid_1's binary_logloss: 0.499796\n",
      "===== ACCURACY SCORE 0.772868 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509914\tvalid_1's binary_logloss: 0.534663\n",
      "[200]\ttraining's binary_logloss: 0.469925\tvalid_1's binary_logloss: 0.50552\n",
      "[300]\ttraining's binary_logloss: 0.45648\tvalid_1's binary_logloss: 0.500472\n",
      "[400]\ttraining's binary_logloss: 0.450545\tvalid_1's binary_logloss: 0.500016\n",
      "[500]\ttraining's binary_logloss: 0.447084\tvalid_1's binary_logloss: 0.500271\n",
      "Early stopping, best iteration is:\n",
      "[400]\ttraining's binary_logloss: 0.450545\tvalid_1's binary_logloss: 0.500016\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.450143\tvalid_1's binary_logloss: 0.500032\n",
      "Early stopping, best iteration is:\n",
      "[403]\ttraining's binary_logloss: 0.450533\tvalid_1's binary_logloss: 0.500012\n",
      "===== ACCURACY SCORE 0.773278 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508136\tvalid_1's binary_logloss: 0.52875\n",
      "[200]\ttraining's binary_logloss: 0.467515\tvalid_1's binary_logloss: 0.498116\n",
      "[300]\ttraining's binary_logloss: 0.453858\tvalid_1's binary_logloss: 0.492931\n",
      "[400]\ttraining's binary_logloss: 0.44781\tvalid_1's binary_logloss: 0.492898\n",
      "Early stopping, best iteration is:\n",
      "[325]\ttraining's binary_logloss: 0.451936\tvalid_1's binary_logloss: 0.492685\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.451415\tvalid_1's binary_logloss: 0.492662\n",
      "[500]\ttraining's binary_logloss: 0.450778\tvalid_1's binary_logloss: 0.492653\n",
      "Early stopping, best iteration is:\n",
      "[468]\ttraining's binary_logloss: 0.450973\tvalid_1's binary_logloss: 0.492644\n",
      "===== ACCURACY SCORE 0.777265 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508638\tvalid_1's binary_logloss: 0.528728\n",
      "[200]\ttraining's binary_logloss: 0.468163\tvalid_1's binary_logloss: 0.496327\n",
      "[300]\ttraining's binary_logloss: 0.454522\tvalid_1's binary_logloss: 0.489957\n",
      "[400]\ttraining's binary_logloss: 0.448716\tvalid_1's binary_logloss: 0.489106\n",
      "[500]\ttraining's binary_logloss: 0.44537\tvalid_1's binary_logloss: 0.489018\n",
      "[600]\ttraining's binary_logloss: 0.443152\tvalid_1's binary_logloss: 0.488884\n",
      "[700]\ttraining's binary_logloss: 0.441647\tvalid_1's binary_logloss: 0.48882\n",
      "[800]\ttraining's binary_logloss: 0.440561\tvalid_1's binary_logloss: 0.488718\n",
      "[900]\ttraining's binary_logloss: 0.439687\tvalid_1's binary_logloss: 0.488635\n",
      "[1000]\ttraining's binary_logloss: 0.438927\tvalid_1's binary_logloss: 0.488585\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.438927\tvalid_1's binary_logloss: 0.488585\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.438859\tvalid_1's binary_logloss: 0.488582\n",
      "[1200]\ttraining's binary_logloss: 0.438793\tvalid_1's binary_logloss: 0.488575\n",
      "[1300]\ttraining's binary_logloss: 0.438727\tvalid_1's binary_logloss: 0.48857\n",
      "[1400]\ttraining's binary_logloss: 0.438664\tvalid_1's binary_logloss: 0.488567\n",
      "[1500]\ttraining's binary_logloss: 0.438598\tvalid_1's binary_logloss: 0.488566\n",
      "Early stopping, best iteration is:\n",
      "[1498]\ttraining's binary_logloss: 0.438599\tvalid_1's binary_logloss: 0.488565\n",
      "===== ACCURACY SCORE 0.775726 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.51024\tvalid_1's binary_logloss: 0.52036\n",
      "[200]\ttraining's binary_logloss: 0.47012\tvalid_1's binary_logloss: 0.484718\n",
      "[300]\ttraining's binary_logloss: 0.456445\tvalid_1's binary_logloss: 0.475894\n",
      "[400]\ttraining's binary_logloss: 0.450482\tvalid_1's binary_logloss: 0.473251\n",
      "[500]\ttraining's binary_logloss: 0.446984\tvalid_1's binary_logloss: 0.472084\n",
      "[600]\ttraining's binary_logloss: 0.444759\tvalid_1's binary_logloss: 0.471405\n",
      "[700]\ttraining's binary_logloss: 0.443258\tvalid_1's binary_logloss: 0.471071\n",
      "[800]\ttraining's binary_logloss: 0.442179\tvalid_1's binary_logloss: 0.470893\n",
      "[900]\ttraining's binary_logloss: 0.441318\tvalid_1's binary_logloss: 0.470739\n",
      "[1000]\ttraining's binary_logloss: 0.440594\tvalid_1's binary_logloss: 0.470537\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440594\tvalid_1's binary_logloss: 0.470537\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440528\tvalid_1's binary_logloss: 0.470525\n",
      "[1200]\ttraining's binary_logloss: 0.440463\tvalid_1's binary_logloss: 0.47051\n",
      "[1300]\ttraining's binary_logloss: 0.440398\tvalid_1's binary_logloss: 0.470492\n",
      "[1400]\ttraining's binary_logloss: 0.440333\tvalid_1's binary_logloss: 0.470476\n",
      "[1500]\ttraining's binary_logloss: 0.440267\tvalid_1's binary_logloss: 0.470462\n",
      "[1600]\ttraining's binary_logloss: 0.440201\tvalid_1's binary_logloss: 0.470449\n",
      "[1700]\ttraining's binary_logloss: 0.440137\tvalid_1's binary_logloss: 0.470441\n",
      "[1800]\ttraining's binary_logloss: 0.440075\tvalid_1's binary_logloss: 0.470433\n",
      "[1900]\ttraining's binary_logloss: 0.440016\tvalid_1's binary_logloss: 0.470428\n",
      "[2000]\ttraining's binary_logloss: 0.439954\tvalid_1's binary_logloss: 0.470406\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439954\tvalid_1's binary_logloss: 0.470406\n",
      "===== ACCURACY SCORE 0.786547 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509636\tvalid_1's binary_logloss: 0.526881\n",
      "[200]\ttraining's binary_logloss: 0.469333\tvalid_1's binary_logloss: 0.494611\n",
      "[300]\ttraining's binary_logloss: 0.455658\tvalid_1's binary_logloss: 0.488019\n",
      "[400]\ttraining's binary_logloss: 0.449801\tvalid_1's binary_logloss: 0.48678\n",
      "[500]\ttraining's binary_logloss: 0.446349\tvalid_1's binary_logloss: 0.486334\n",
      "[600]\ttraining's binary_logloss: 0.444102\tvalid_1's binary_logloss: 0.486039\n",
      "[700]\ttraining's binary_logloss: 0.442595\tvalid_1's binary_logloss: 0.485772\n",
      "[800]\ttraining's binary_logloss: 0.441544\tvalid_1's binary_logloss: 0.485643\n",
      "[900]\ttraining's binary_logloss: 0.440676\tvalid_1's binary_logloss: 0.485644\n",
      "[1000]\ttraining's binary_logloss: 0.439957\tvalid_1's binary_logloss: 0.485592\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439957\tvalid_1's binary_logloss: 0.485592\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439887\tvalid_1's binary_logloss: 0.485592\n",
      "Early stopping, best iteration is:\n",
      "[1079]\ttraining's binary_logloss: 0.439902\tvalid_1's binary_logloss: 0.485589\n",
      "===== ACCURACY SCORE 0.778590 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508986\tvalid_1's binary_logloss: 0.523864\n",
      "[200]\ttraining's binary_logloss: 0.468447\tvalid_1's binary_logloss: 0.489825\n",
      "[300]\ttraining's binary_logloss: 0.454916\tvalid_1's binary_logloss: 0.482238\n",
      "[400]\ttraining's binary_logloss: 0.448945\tvalid_1's binary_logloss: 0.480588\n",
      "[500]\ttraining's binary_logloss: 0.445606\tvalid_1's binary_logloss: 0.47991\n",
      "[600]\ttraining's binary_logloss: 0.443375\tvalid_1's binary_logloss: 0.479407\n",
      "[700]\ttraining's binary_logloss: 0.441888\tvalid_1's binary_logloss: 0.479099\n",
      "[800]\ttraining's binary_logloss: 0.440818\tvalid_1's binary_logloss: 0.478935\n",
      "[900]\ttraining's binary_logloss: 0.439939\tvalid_1's binary_logloss: 0.478845\n",
      "[1000]\ttraining's binary_logloss: 0.439188\tvalid_1's binary_logloss: 0.478707\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439188\tvalid_1's binary_logloss: 0.478707\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439118\tvalid_1's binary_logloss: 0.478698\n",
      "[1200]\ttraining's binary_logloss: 0.439053\tvalid_1's binary_logloss: 0.478693\n",
      "[1300]\ttraining's binary_logloss: 0.438988\tvalid_1's binary_logloss: 0.478682\n",
      "[1400]\ttraining's binary_logloss: 0.438922\tvalid_1's binary_logloss: 0.478672\n",
      "[1500]\ttraining's binary_logloss: 0.438858\tvalid_1's binary_logloss: 0.478654\n",
      "[1600]\ttraining's binary_logloss: 0.438795\tvalid_1's binary_logloss: 0.478649\n",
      "[1700]\ttraining's binary_logloss: 0.43873\tvalid_1's binary_logloss: 0.478643\n",
      "[1800]\ttraining's binary_logloss: 0.438667\tvalid_1's binary_logloss: 0.478628\n",
      "[1900]\ttraining's binary_logloss: 0.438605\tvalid_1's binary_logloss: 0.478621\n",
      "[2000]\ttraining's binary_logloss: 0.438542\tvalid_1's binary_logloss: 0.478606\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.438542\tvalid_1's binary_logloss: 0.478606\n",
      "===== ACCURACY SCORE 0.785843 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779000 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510077\tvalid_1's binary_logloss: 0.525009\n",
      "[200]\ttraining's binary_logloss: 0.469631\tvalid_1's binary_logloss: 0.491331\n",
      "[300]\ttraining's binary_logloss: 0.455822\tvalid_1's binary_logloss: 0.484346\n",
      "[400]\ttraining's binary_logloss: 0.449813\tvalid_1's binary_logloss: 0.482996\n",
      "[500]\ttraining's binary_logloss: 0.44624\tvalid_1's binary_logloss: 0.482862\n",
      "Early stopping, best iteration is:\n",
      "[494]\ttraining's binary_logloss: 0.446423\tvalid_1's binary_logloss: 0.482805\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.446404\tvalid_1's binary_logloss: 0.482808\n",
      "Early stopping, best iteration is:\n",
      "[497]\ttraining's binary_logloss: 0.446413\tvalid_1's binary_logloss: 0.482805\n",
      "===== ACCURACY SCORE 0.780706 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509327\tvalid_1's binary_logloss: 0.525066\n",
      "[200]\ttraining's binary_logloss: 0.469115\tvalid_1's binary_logloss: 0.491185\n",
      "[300]\ttraining's binary_logloss: 0.455762\tvalid_1's binary_logloss: 0.483813\n",
      "[400]\ttraining's binary_logloss: 0.449904\tvalid_1's binary_logloss: 0.482289\n",
      "[500]\ttraining's binary_logloss: 0.446483\tvalid_1's binary_logloss: 0.481902\n",
      "[600]\ttraining's binary_logloss: 0.444264\tvalid_1's binary_logloss: 0.481681\n",
      "[700]\ttraining's binary_logloss: 0.442825\tvalid_1's binary_logloss: 0.481637\n",
      "[800]\ttraining's binary_logloss: 0.441745\tvalid_1's binary_logloss: 0.481424\n",
      "[900]\ttraining's binary_logloss: 0.440862\tvalid_1's binary_logloss: 0.481309\n",
      "[1000]\ttraining's binary_logloss: 0.44014\tvalid_1's binary_logloss: 0.481239\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.44014\tvalid_1's binary_logloss: 0.481239\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440071\tvalid_1's binary_logloss: 0.481235\n",
      "[1200]\ttraining's binary_logloss: 0.440005\tvalid_1's binary_logloss: 0.481221\n",
      "[1300]\ttraining's binary_logloss: 0.439941\tvalid_1's binary_logloss: 0.481213\n",
      "[1400]\ttraining's binary_logloss: 0.439878\tvalid_1's binary_logloss: 0.481206\n",
      "[1500]\ttraining's binary_logloss: 0.439812\tvalid_1's binary_logloss: 0.481195\n",
      "[1600]\ttraining's binary_logloss: 0.439749\tvalid_1's binary_logloss: 0.481184\n",
      "[1700]\ttraining's binary_logloss: 0.439686\tvalid_1's binary_logloss: 0.481173\n",
      "[1800]\ttraining's binary_logloss: 0.439622\tvalid_1's binary_logloss: 0.48115\n",
      "[1900]\ttraining's binary_logloss: 0.43956\tvalid_1's binary_logloss: 0.481136\n",
      "[2000]\ttraining's binary_logloss: 0.439499\tvalid_1's binary_logloss: 0.481127\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439499\tvalid_1's binary_logloss: 0.481127\n",
      "===== ACCURACY SCORE 0.785113 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509301\tvalid_1's binary_logloss: 0.531166\n",
      "[200]\ttraining's binary_logloss: 0.46903\tvalid_1's binary_logloss: 0.500295\n",
      "[300]\ttraining's binary_logloss: 0.455404\tvalid_1's binary_logloss: 0.494479\n",
      "[400]\ttraining's binary_logloss: 0.449445\tvalid_1's binary_logloss: 0.493747\n",
      "Early stopping, best iteration is:\n",
      "[396]\ttraining's binary_logloss: 0.449622\tvalid_1's binary_logloss: 0.493712\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.449605\tvalid_1's binary_logloss: 0.493712\n",
      "Early stopping, best iteration is:\n",
      "[399]\ttraining's binary_logloss: 0.44961\tvalid_1's binary_logloss: 0.493711\n",
      "===== ACCURACY SCORE 0.770898 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509515\tvalid_1's binary_logloss: 0.530678\n",
      "[200]\ttraining's binary_logloss: 0.46918\tvalid_1's binary_logloss: 0.498455\n",
      "[300]\ttraining's binary_logloss: 0.455761\tvalid_1's binary_logloss: 0.491862\n",
      "[400]\ttraining's binary_logloss: 0.449942\tvalid_1's binary_logloss: 0.490586\n",
      "[500]\ttraining's binary_logloss: 0.446593\tvalid_1's binary_logloss: 0.490291\n",
      "[600]\ttraining's binary_logloss: 0.444378\tvalid_1's binary_logloss: 0.490035\n",
      "[700]\ttraining's binary_logloss: 0.442888\tvalid_1's binary_logloss: 0.489832\n",
      "[800]\ttraining's binary_logloss: 0.441818\tvalid_1's binary_logloss: 0.489703\n",
      "[900]\ttraining's binary_logloss: 0.440987\tvalid_1's binary_logloss: 0.489643\n",
      "[1000]\ttraining's binary_logloss: 0.440264\tvalid_1's binary_logloss: 0.489563\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440264\tvalid_1's binary_logloss: 0.489563\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440194\tvalid_1's binary_logloss: 0.489551\n",
      "[1200]\ttraining's binary_logloss: 0.440126\tvalid_1's binary_logloss: 0.489547\n",
      "Early stopping, best iteration is:\n",
      "[1125]\ttraining's binary_logloss: 0.440177\tvalid_1's binary_logloss: 0.489545\n",
      "===== ACCURACY SCORE 0.777644 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508942\tvalid_1's binary_logloss: 0.535451\n",
      "[200]\ttraining's binary_logloss: 0.468486\tvalid_1's binary_logloss: 0.506829\n",
      "[300]\ttraining's binary_logloss: 0.454831\tvalid_1's binary_logloss: 0.502017\n",
      "[400]\ttraining's binary_logloss: 0.44884\tvalid_1's binary_logloss: 0.501877\n",
      "Early stopping, best iteration is:\n",
      "[325]\ttraining's binary_logloss: 0.452885\tvalid_1's binary_logloss: 0.5017\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.452378\tvalid_1's binary_logloss: 0.501688\n",
      "[500]\ttraining's binary_logloss: 0.451746\tvalid_1's binary_logloss: 0.501659\n",
      "[600]\ttraining's binary_logloss: 0.451154\tvalid_1's binary_logloss: 0.501649\n",
      "Early stopping, best iteration is:\n",
      "[516]\ttraining's binary_logloss: 0.451646\tvalid_1's binary_logloss: 0.501648\n",
      "===== ACCURACY SCORE 0.769666 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509602\tvalid_1's binary_logloss: 0.527057\n",
      "[200]\ttraining's binary_logloss: 0.469511\tvalid_1's binary_logloss: 0.493587\n",
      "[300]\ttraining's binary_logloss: 0.455953\tvalid_1's binary_logloss: 0.48601\n",
      "[400]\ttraining's binary_logloss: 0.449983\tvalid_1's binary_logloss: 0.484132\n",
      "[500]\ttraining's binary_logloss: 0.446581\tvalid_1's binary_logloss: 0.483422\n",
      "[600]\ttraining's binary_logloss: 0.444352\tvalid_1's binary_logloss: 0.483169\n",
      "[700]\ttraining's binary_logloss: 0.442879\tvalid_1's binary_logloss: 0.482835\n",
      "[800]\ttraining's binary_logloss: 0.441806\tvalid_1's binary_logloss: 0.48264\n",
      "[900]\ttraining's binary_logloss: 0.440975\tvalid_1's binary_logloss: 0.482521\n",
      "[1000]\ttraining's binary_logloss: 0.440255\tvalid_1's binary_logloss: 0.482441\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440255\tvalid_1's binary_logloss: 0.482441\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440189\tvalid_1's binary_logloss: 0.482424\n",
      "[1200]\ttraining's binary_logloss: 0.44012\tvalid_1's binary_logloss: 0.482417\n",
      "[1300]\ttraining's binary_logloss: 0.440057\tvalid_1's binary_logloss: 0.482409\n",
      "Early stopping, best iteration is:\n",
      "[1256]\ttraining's binary_logloss: 0.440085\tvalid_1's binary_logloss: 0.482408\n",
      "===== ACCURACY SCORE 0.783960 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509219\tvalid_1's binary_logloss: 0.52435\n",
      "[200]\ttraining's binary_logloss: 0.468612\tvalid_1's binary_logloss: 0.491346\n",
      "[300]\ttraining's binary_logloss: 0.454892\tvalid_1's binary_logloss: 0.484044\n",
      "[400]\ttraining's binary_logloss: 0.448928\tvalid_1's binary_logloss: 0.481981\n",
      "[500]\ttraining's binary_logloss: 0.445516\tvalid_1's binary_logloss: 0.481233\n",
      "[600]\ttraining's binary_logloss: 0.443165\tvalid_1's binary_logloss: 0.480536\n",
      "[700]\ttraining's binary_logloss: 0.441648\tvalid_1's binary_logloss: 0.480001\n",
      "[800]\ttraining's binary_logloss: 0.44056\tvalid_1's binary_logloss: 0.479719\n",
      "[900]\ttraining's binary_logloss: 0.439698\tvalid_1's binary_logloss: 0.479477\n",
      "[1000]\ttraining's binary_logloss: 0.438948\tvalid_1's binary_logloss: 0.479246\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.438948\tvalid_1's binary_logloss: 0.479246\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.438877\tvalid_1's binary_logloss: 0.479225\n",
      "[1200]\ttraining's binary_logloss: 0.43881\tvalid_1's binary_logloss: 0.47921\n",
      "[1300]\ttraining's binary_logloss: 0.438741\tvalid_1's binary_logloss: 0.479184\n",
      "[1400]\ttraining's binary_logloss: 0.438675\tvalid_1's binary_logloss: 0.479153\n",
      "[1500]\ttraining's binary_logloss: 0.438608\tvalid_1's binary_logloss: 0.479139\n",
      "[1600]\ttraining's binary_logloss: 0.438544\tvalid_1's binary_logloss: 0.479128\n",
      "[1700]\ttraining's binary_logloss: 0.438476\tvalid_1's binary_logloss: 0.47911\n",
      "[1800]\ttraining's binary_logloss: 0.438412\tvalid_1's binary_logloss: 0.479094\n",
      "[1900]\ttraining's binary_logloss: 0.438349\tvalid_1's binary_logloss: 0.479077\n",
      "[2000]\ttraining's binary_logloss: 0.438286\tvalid_1's binary_logloss: 0.479062\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.438286\tvalid_1's binary_logloss: 0.479062\n",
      "===== ACCURACY SCORE 0.781447 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509047\tvalid_1's binary_logloss: 0.527283\n",
      "[200]\ttraining's binary_logloss: 0.468588\tvalid_1's binary_logloss: 0.495085\n",
      "[300]\ttraining's binary_logloss: 0.454922\tvalid_1's binary_logloss: 0.488639\n",
      "[400]\ttraining's binary_logloss: 0.448815\tvalid_1's binary_logloss: 0.487659\n",
      "[500]\ttraining's binary_logloss: 0.445395\tvalid_1's binary_logloss: 0.487507\n",
      "[600]\ttraining's binary_logloss: 0.443138\tvalid_1's binary_logloss: 0.487411\n",
      "[700]\ttraining's binary_logloss: 0.441667\tvalid_1's binary_logloss: 0.48746\n",
      "Early stopping, best iteration is:\n",
      "[646]\ttraining's binary_logloss: 0.442386\tvalid_1's binary_logloss: 0.487347\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.442307\tvalid_1's binary_logloss: 0.487349\n",
      "Early stopping, best iteration is:\n",
      "[679]\ttraining's binary_logloss: 0.442337\tvalid_1's binary_logloss: 0.487346\n",
      "===== ACCURACY SCORE 0.778585 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50839\tvalid_1's binary_logloss: 0.528396\n",
      "[200]\ttraining's binary_logloss: 0.467661\tvalid_1's binary_logloss: 0.496989\n",
      "[300]\ttraining's binary_logloss: 0.453871\tvalid_1's binary_logloss: 0.490986\n",
      "[400]\ttraining's binary_logloss: 0.447847\tvalid_1's binary_logloss: 0.490058\n",
      "[500]\ttraining's binary_logloss: 0.444411\tvalid_1's binary_logloss: 0.489926\n",
      "[600]\ttraining's binary_logloss: 0.442123\tvalid_1's binary_logloss: 0.489458\n",
      "[700]\ttraining's binary_logloss: 0.440612\tvalid_1's binary_logloss: 0.489277\n",
      "[800]\ttraining's binary_logloss: 0.439541\tvalid_1's binary_logloss: 0.489162\n",
      "[900]\ttraining's binary_logloss: 0.438661\tvalid_1's binary_logloss: 0.489078\n",
      "[1000]\ttraining's binary_logloss: 0.437923\tvalid_1's binary_logloss: 0.488937\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.437923\tvalid_1's binary_logloss: 0.488937\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.437854\tvalid_1's binary_logloss: 0.488918\n",
      "[1200]\ttraining's binary_logloss: 0.437787\tvalid_1's binary_logloss: 0.488902\n",
      "[1300]\ttraining's binary_logloss: 0.437721\tvalid_1's binary_logloss: 0.488895\n",
      "[1400]\ttraining's binary_logloss: 0.437655\tvalid_1's binary_logloss: 0.488883\n",
      "[1500]\ttraining's binary_logloss: 0.437591\tvalid_1's binary_logloss: 0.488875\n",
      "[1600]\ttraining's binary_logloss: 0.437527\tvalid_1's binary_logloss: 0.488864\n",
      "[1700]\ttraining's binary_logloss: 0.437463\tvalid_1's binary_logloss: 0.488855\n",
      "[1800]\ttraining's binary_logloss: 0.437401\tvalid_1's binary_logloss: 0.48884\n",
      "[1900]\ttraining's binary_logloss: 0.437338\tvalid_1's binary_logloss: 0.488841\n",
      "[2000]\ttraining's binary_logloss: 0.437274\tvalid_1's binary_logloss: 0.488833\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.437274\tvalid_1's binary_logloss: 0.488833\n",
      "===== ACCURACY SCORE 0.783106 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50971\tvalid_1's binary_logloss: 0.528279\n",
      "[200]\ttraining's binary_logloss: 0.469337\tvalid_1's binary_logloss: 0.495479\n",
      "[300]\ttraining's binary_logloss: 0.455554\tvalid_1's binary_logloss: 0.488975\n",
      "[400]\ttraining's binary_logloss: 0.449604\tvalid_1's binary_logloss: 0.487704\n",
      "[500]\ttraining's binary_logloss: 0.446056\tvalid_1's binary_logloss: 0.487444\n",
      "[600]\ttraining's binary_logloss: 0.443717\tvalid_1's binary_logloss: 0.487182\n",
      "[700]\ttraining's binary_logloss: 0.442191\tvalid_1's binary_logloss: 0.487368\n",
      "Early stopping, best iteration is:\n",
      "[620]\ttraining's binary_logloss: 0.443346\tvalid_1's binary_logloss: 0.487126\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.443216\tvalid_1's binary_logloss: 0.487149\n",
      "Early stopping, best iteration is:\n",
      "[621]\ttraining's binary_logloss: 0.443344\tvalid_1's binary_logloss: 0.487127\n",
      "===== ACCURACY SCORE 0.780994 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779210 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.51013\tvalid_1's binary_logloss: 0.526423\n",
      "[200]\ttraining's binary_logloss: 0.470211\tvalid_1's binary_logloss: 0.493948\n",
      "[300]\ttraining's binary_logloss: 0.456734\tvalid_1's binary_logloss: 0.48718\n",
      "[400]\ttraining's binary_logloss: 0.450838\tvalid_1's binary_logloss: 0.485906\n",
      "[500]\ttraining's binary_logloss: 0.447424\tvalid_1's binary_logloss: 0.485304\n",
      "[600]\ttraining's binary_logloss: 0.445196\tvalid_1's binary_logloss: 0.484994\n",
      "[700]\ttraining's binary_logloss: 0.443718\tvalid_1's binary_logloss: 0.48485\n",
      "[800]\ttraining's binary_logloss: 0.442624\tvalid_1's binary_logloss: 0.484729\n",
      "[900]\ttraining's binary_logloss: 0.441794\tvalid_1's binary_logloss: 0.484639\n",
      "[1000]\ttraining's binary_logloss: 0.441081\tvalid_1's binary_logloss: 0.484569\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.441081\tvalid_1's binary_logloss: 0.484569\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.441012\tvalid_1's binary_logloss: 0.48455\n",
      "[1200]\ttraining's binary_logloss: 0.440945\tvalid_1's binary_logloss: 0.48454\n",
      "[1300]\ttraining's binary_logloss: 0.440877\tvalid_1's binary_logloss: 0.484523\n",
      "[1400]\ttraining's binary_logloss: 0.440811\tvalid_1's binary_logloss: 0.484518\n",
      "[1500]\ttraining's binary_logloss: 0.440747\tvalid_1's binary_logloss: 0.484508\n",
      "[1600]\ttraining's binary_logloss: 0.440682\tvalid_1's binary_logloss: 0.484506\n",
      "[1700]\ttraining's binary_logloss: 0.440617\tvalid_1's binary_logloss: 0.484494\n",
      "[1800]\ttraining's binary_logloss: 0.440555\tvalid_1's binary_logloss: 0.484483\n",
      "[1900]\ttraining's binary_logloss: 0.440492\tvalid_1's binary_logloss: 0.484472\n",
      "Early stopping, best iteration is:\n",
      "[1883]\ttraining's binary_logloss: 0.440502\tvalid_1's binary_logloss: 0.484472\n",
      "===== ACCURACY SCORE 0.781500 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509303\tvalid_1's binary_logloss: 0.527344\n",
      "[200]\ttraining's binary_logloss: 0.469083\tvalid_1's binary_logloss: 0.494766\n",
      "[300]\ttraining's binary_logloss: 0.455526\tvalid_1's binary_logloss: 0.488217\n",
      "[400]\ttraining's binary_logloss: 0.449557\tvalid_1's binary_logloss: 0.487023\n",
      "[500]\ttraining's binary_logloss: 0.44605\tvalid_1's binary_logloss: 0.486686\n",
      "[600]\ttraining's binary_logloss: 0.44383\tvalid_1's binary_logloss: 0.486534\n",
      "[700]\ttraining's binary_logloss: 0.442327\tvalid_1's binary_logloss: 0.486556\n",
      "Early stopping, best iteration is:\n",
      "[638]\ttraining's binary_logloss: 0.443209\tvalid_1's binary_logloss: 0.486465\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.443113\tvalid_1's binary_logloss: 0.486462\n",
      "[800]\ttraining's binary_logloss: 0.442966\tvalid_1's binary_logloss: 0.486456\n",
      "[900]\ttraining's binary_logloss: 0.442821\tvalid_1's binary_logloss: 0.486451\n",
      "[1000]\ttraining's binary_logloss: 0.442684\tvalid_1's binary_logloss: 0.486464\n",
      "Early stopping, best iteration is:\n",
      "[906]\ttraining's binary_logloss: 0.442812\tvalid_1's binary_logloss: 0.48645\n",
      "===== ACCURACY SCORE 0.778482 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510131\tvalid_1's binary_logloss: 0.530683\n",
      "[200]\ttraining's binary_logloss: 0.470022\tvalid_1's binary_logloss: 0.499481\n",
      "[300]\ttraining's binary_logloss: 0.456295\tvalid_1's binary_logloss: 0.493163\n",
      "[400]\ttraining's binary_logloss: 0.45029\tvalid_1's binary_logloss: 0.491819\n",
      "[500]\ttraining's binary_logloss: 0.446809\tvalid_1's binary_logloss: 0.491476\n",
      "[600]\ttraining's binary_logloss: 0.444526\tvalid_1's binary_logloss: 0.491045\n",
      "[700]\ttraining's binary_logloss: 0.442985\tvalid_1's binary_logloss: 0.490772\n",
      "[800]\ttraining's binary_logloss: 0.441897\tvalid_1's binary_logloss: 0.490584\n",
      "[900]\ttraining's binary_logloss: 0.441045\tvalid_1's binary_logloss: 0.490441\n",
      "[1000]\ttraining's binary_logloss: 0.44032\tvalid_1's binary_logloss: 0.490228\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.44032\tvalid_1's binary_logloss: 0.490228\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.44025\tvalid_1's binary_logloss: 0.490225\n",
      "[1200]\ttraining's binary_logloss: 0.440182\tvalid_1's binary_logloss: 0.490218\n",
      "[1300]\ttraining's binary_logloss: 0.440117\tvalid_1's binary_logloss: 0.49021\n",
      "[1400]\ttraining's binary_logloss: 0.44005\tvalid_1's binary_logloss: 0.490193\n",
      "[1500]\ttraining's binary_logloss: 0.439985\tvalid_1's binary_logloss: 0.490182\n",
      "[1600]\ttraining's binary_logloss: 0.439921\tvalid_1's binary_logloss: 0.490172\n",
      "[1700]\ttraining's binary_logloss: 0.439858\tvalid_1's binary_logloss: 0.490165\n",
      "[1800]\ttraining's binary_logloss: 0.439794\tvalid_1's binary_logloss: 0.490152\n",
      "[1900]\ttraining's binary_logloss: 0.439731\tvalid_1's binary_logloss: 0.490143\n",
      "[2000]\ttraining's binary_logloss: 0.439668\tvalid_1's binary_logloss: 0.49013\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439668\tvalid_1's binary_logloss: 0.49013\n",
      "===== ACCURACY SCORE 0.776068 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508824\tvalid_1's binary_logloss: 0.523733\n",
      "[200]\ttraining's binary_logloss: 0.46827\tvalid_1's binary_logloss: 0.491538\n",
      "[300]\ttraining's binary_logloss: 0.454611\tvalid_1's binary_logloss: 0.484957\n",
      "[400]\ttraining's binary_logloss: 0.448586\tvalid_1's binary_logloss: 0.483711\n",
      "[500]\ttraining's binary_logloss: 0.445099\tvalid_1's binary_logloss: 0.483459\n",
      "[600]\ttraining's binary_logloss: 0.442793\tvalid_1's binary_logloss: 0.483083\n",
      "[700]\ttraining's binary_logloss: 0.441227\tvalid_1's binary_logloss: 0.482992\n",
      "[800]\ttraining's binary_logloss: 0.440118\tvalid_1's binary_logloss: 0.48288\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's binary_logloss: 0.440786\tvalid_1's binary_logloss: 0.482866\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.440712\tvalid_1's binary_logloss: 0.482866\n",
      "[900]\ttraining's binary_logloss: 0.440599\tvalid_1's binary_logloss: 0.482864\n",
      "Early stopping, best iteration is:\n",
      "[874]\ttraining's binary_logloss: 0.440628\tvalid_1's binary_logloss: 0.482857\n",
      "===== ACCURACY SCORE 0.782500 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508862\tvalid_1's binary_logloss: 0.528145\n",
      "[200]\ttraining's binary_logloss: 0.468419\tvalid_1's binary_logloss: 0.4955\n",
      "[300]\ttraining's binary_logloss: 0.454772\tvalid_1's binary_logloss: 0.488675\n",
      "[400]\ttraining's binary_logloss: 0.44869\tvalid_1's binary_logloss: 0.487288\n",
      "[500]\ttraining's binary_logloss: 0.445145\tvalid_1's binary_logloss: 0.486672\n",
      "[600]\ttraining's binary_logloss: 0.442775\tvalid_1's binary_logloss: 0.486128\n",
      "[700]\ttraining's binary_logloss: 0.441271\tvalid_1's binary_logloss: 0.485964\n",
      "[800]\ttraining's binary_logloss: 0.440163\tvalid_1's binary_logloss: 0.485883\n",
      "Early stopping, best iteration is:\n",
      "[754]\ttraining's binary_logloss: 0.440625\tvalid_1's binary_logloss: 0.485848\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.440576\tvalid_1's binary_logloss: 0.48585\n",
      "[900]\ttraining's binary_logloss: 0.440472\tvalid_1's binary_logloss: 0.485842\n",
      "[1000]\ttraining's binary_logloss: 0.440373\tvalid_1's binary_logloss: 0.485833\n",
      "[1100]\ttraining's binary_logloss: 0.440275\tvalid_1's binary_logloss: 0.485829\n",
      "[1200]\ttraining's binary_logloss: 0.440177\tvalid_1's binary_logloss: 0.485829\n",
      "Early stopping, best iteration is:\n",
      "[1163]\ttraining's binary_logloss: 0.440212\tvalid_1's binary_logloss: 0.485821\n",
      "===== ACCURACY SCORE 0.780969 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508665\tvalid_1's binary_logloss: 0.527764\n",
      "[200]\ttraining's binary_logloss: 0.468187\tvalid_1's binary_logloss: 0.495049\n",
      "[300]\ttraining's binary_logloss: 0.454529\tvalid_1's binary_logloss: 0.488178\n",
      "[400]\ttraining's binary_logloss: 0.448489\tvalid_1's binary_logloss: 0.486716\n",
      "[500]\ttraining's binary_logloss: 0.445054\tvalid_1's binary_logloss: 0.48645\n",
      "[600]\ttraining's binary_logloss: 0.442706\tvalid_1's binary_logloss: 0.48608\n",
      "[700]\ttraining's binary_logloss: 0.44122\tvalid_1's binary_logloss: 0.486004\n",
      "[800]\ttraining's binary_logloss: 0.440127\tvalid_1's binary_logloss: 0.48587\n",
      "[900]\ttraining's binary_logloss: 0.439238\tvalid_1's binary_logloss: 0.485738\n",
      "Early stopping, best iteration is:\n",
      "[892]\ttraining's binary_logloss: 0.439302\tvalid_1's binary_logloss: 0.485729\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[900]\ttraining's binary_logloss: 0.439295\tvalid_1's binary_logloss: 0.485727\n",
      "[1000]\ttraining's binary_logloss: 0.439212\tvalid_1's binary_logloss: 0.485724\n",
      "Early stopping, best iteration is:\n",
      "[980]\ttraining's binary_logloss: 0.439228\tvalid_1's binary_logloss: 0.485722\n",
      "===== ACCURACY SCORE 0.781241 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.511644\tvalid_1's binary_logloss: 0.525159\n",
      "[200]\ttraining's binary_logloss: 0.471914\tvalid_1's binary_logloss: 0.491533\n",
      "[300]\ttraining's binary_logloss: 0.458457\tvalid_1's binary_logloss: 0.484533\n",
      "[400]\ttraining's binary_logloss: 0.452511\tvalid_1's binary_logloss: 0.482884\n",
      "[500]\ttraining's binary_logloss: 0.449053\tvalid_1's binary_logloss: 0.482782\n",
      "[600]\ttraining's binary_logloss: 0.446781\tvalid_1's binary_logloss: 0.482547\n",
      "Early stopping, best iteration is:\n",
      "[566]\ttraining's binary_logloss: 0.447402\tvalid_1's binary_logloss: 0.482461\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.447328\tvalid_1's binary_logloss: 0.482468\n",
      "Early stopping, best iteration is:\n",
      "[567]\ttraining's binary_logloss: 0.4474\tvalid_1's binary_logloss: 0.482461\n",
      "===== ACCURACY SCORE 0.782860 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508255\tvalid_1's binary_logloss: 0.528454\n",
      "[200]\ttraining's binary_logloss: 0.46776\tvalid_1's binary_logloss: 0.496695\n",
      "[300]\ttraining's binary_logloss: 0.454106\tvalid_1's binary_logloss: 0.490661\n",
      "[400]\ttraining's binary_logloss: 0.448104\tvalid_1's binary_logloss: 0.489708\n",
      "[500]\ttraining's binary_logloss: 0.444693\tvalid_1's binary_logloss: 0.48954\n",
      "[600]\ttraining's binary_logloss: 0.442354\tvalid_1's binary_logloss: 0.489429\n",
      "Early stopping, best iteration is:\n",
      "[588]\ttraining's binary_logloss: 0.442576\tvalid_1's binary_logloss: 0.489395\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.442552\tvalid_1's binary_logloss: 0.489398\n",
      "Early stopping, best iteration is:\n",
      "[592]\ttraining's binary_logloss: 0.442567\tvalid_1's binary_logloss: 0.489394\n",
      "===== ACCURACY SCORE 0.779451 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509166\tvalid_1's binary_logloss: 0.526887\n",
      "[200]\ttraining's binary_logloss: 0.468983\tvalid_1's binary_logloss: 0.493424\n",
      "[300]\ttraining's binary_logloss: 0.4556\tvalid_1's binary_logloss: 0.486854\n",
      "[400]\ttraining's binary_logloss: 0.449673\tvalid_1's binary_logloss: 0.485628\n",
      "[500]\ttraining's binary_logloss: 0.446194\tvalid_1's binary_logloss: 0.485097\n",
      "[600]\ttraining's binary_logloss: 0.443928\tvalid_1's binary_logloss: 0.484887\n",
      "[700]\ttraining's binary_logloss: 0.442385\tvalid_1's binary_logloss: 0.484771\n",
      "[800]\ttraining's binary_logloss: 0.441274\tvalid_1's binary_logloss: 0.484738\n",
      "Early stopping, best iteration is:\n",
      "[760]\ttraining's binary_logloss: 0.441674\tvalid_1's binary_logloss: 0.484678\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.44163\tvalid_1's binary_logloss: 0.484674\n",
      "[900]\ttraining's binary_logloss: 0.441528\tvalid_1's binary_logloss: 0.484667\n",
      "[1000]\ttraining's binary_logloss: 0.441427\tvalid_1's binary_logloss: 0.484662\n",
      "[1100]\ttraining's binary_logloss: 0.441327\tvalid_1's binary_logloss: 0.484642\n",
      "[1200]\ttraining's binary_logloss: 0.44123\tvalid_1's binary_logloss: 0.484636\n",
      "[1300]\ttraining's binary_logloss: 0.441138\tvalid_1's binary_logloss: 0.484625\n",
      "[1400]\ttraining's binary_logloss: 0.441047\tvalid_1's binary_logloss: 0.484626\n",
      "Early stopping, best iteration is:\n",
      "[1300]\ttraining's binary_logloss: 0.441138\tvalid_1's binary_logloss: 0.484625\n",
      "===== ACCURACY SCORE 0.778405 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509644\tvalid_1's binary_logloss: 0.536218\n",
      "[200]\ttraining's binary_logloss: 0.469253\tvalid_1's binary_logloss: 0.50637\n",
      "[300]\ttraining's binary_logloss: 0.455689\tvalid_1's binary_logloss: 0.501047\n",
      "[400]\ttraining's binary_logloss: 0.449767\tvalid_1's binary_logloss: 0.50034\n",
      "Early stopping, best iteration is:\n",
      "[388]\ttraining's binary_logloss: 0.450276\tvalid_1's binary_logloss: 0.500282\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.450224\tvalid_1's binary_logloss: 0.500279\n",
      "[500]\ttraining's binary_logloss: 0.449809\tvalid_1's binary_logloss: 0.500258\n",
      "[600]\ttraining's binary_logloss: 0.449407\tvalid_1's binary_logloss: 0.500253\n",
      "Early stopping, best iteration is:\n",
      "[585]\ttraining's binary_logloss: 0.449464\tvalid_1's binary_logloss: 0.500248\n",
      "===== ACCURACY SCORE 0.770196 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779170 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510028\tvalid_1's binary_logloss: 0.526382\n",
      "[200]\ttraining's binary_logloss: 0.469742\tvalid_1's binary_logloss: 0.492538\n",
      "[300]\ttraining's binary_logloss: 0.456077\tvalid_1's binary_logloss: 0.484957\n",
      "[400]\ttraining's binary_logloss: 0.450031\tvalid_1's binary_logloss: 0.483082\n",
      "[500]\ttraining's binary_logloss: 0.446505\tvalid_1's binary_logloss: 0.482535\n",
      "[600]\ttraining's binary_logloss: 0.444157\tvalid_1's binary_logloss: 0.482182\n",
      "[700]\ttraining's binary_logloss: 0.442583\tvalid_1's binary_logloss: 0.48205\n",
      "[800]\ttraining's binary_logloss: 0.441465\tvalid_1's binary_logloss: 0.482014\n",
      "Early stopping, best iteration is:\n",
      "[737]\ttraining's binary_logloss: 0.442128\tvalid_1's binary_logloss: 0.482008\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.442056\tvalid_1's binary_logloss: 0.482004\n",
      "[900]\ttraining's binary_logloss: 0.441943\tvalid_1's binary_logloss: 0.482006\n",
      "Early stopping, best iteration is:\n",
      "[847]\ttraining's binary_logloss: 0.442003\tvalid_1's binary_logloss: 0.481999\n",
      "===== ACCURACY SCORE 0.781166 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509642\tvalid_1's binary_logloss: 0.528822\n",
      "[200]\ttraining's binary_logloss: 0.469274\tvalid_1's binary_logloss: 0.497327\n",
      "[300]\ttraining's binary_logloss: 0.455563\tvalid_1's binary_logloss: 0.490749\n",
      "[400]\ttraining's binary_logloss: 0.449624\tvalid_1's binary_logloss: 0.489402\n",
      "[500]\ttraining's binary_logloss: 0.446109\tvalid_1's binary_logloss: 0.489087\n",
      "[600]\ttraining's binary_logloss: 0.443832\tvalid_1's binary_logloss: 0.488735\n",
      "[700]\ttraining's binary_logloss: 0.442359\tvalid_1's binary_logloss: 0.488719\n",
      "[800]\ttraining's binary_logloss: 0.441225\tvalid_1's binary_logloss: 0.488509\n",
      "[900]\ttraining's binary_logloss: 0.440327\tvalid_1's binary_logloss: 0.488553\n",
      "Early stopping, best iteration is:\n",
      "[808]\ttraining's binary_logloss: 0.441141\tvalid_1's binary_logloss: 0.488481\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[900]\ttraining's binary_logloss: 0.441055\tvalid_1's binary_logloss: 0.488482\n",
      "Early stopping, best iteration is:\n",
      "[871]\ttraining's binary_logloss: 0.441081\tvalid_1's binary_logloss: 0.48848\n",
      "===== ACCURACY SCORE 0.777976 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509859\tvalid_1's binary_logloss: 0.528116\n",
      "[200]\ttraining's binary_logloss: 0.469614\tvalid_1's binary_logloss: 0.496176\n",
      "[300]\ttraining's binary_logloss: 0.455972\tvalid_1's binary_logloss: 0.489992\n",
      "[400]\ttraining's binary_logloss: 0.449882\tvalid_1's binary_logloss: 0.488796\n",
      "[500]\ttraining's binary_logloss: 0.446465\tvalid_1's binary_logloss: 0.488591\n",
      "[600]\ttraining's binary_logloss: 0.444168\tvalid_1's binary_logloss: 0.488376\n",
      "[700]\ttraining's binary_logloss: 0.442689\tvalid_1's binary_logloss: 0.488382\n",
      "Early stopping, best iteration is:\n",
      "[633]\ttraining's binary_logloss: 0.443633\tvalid_1's binary_logloss: 0.488339\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.443529\tvalid_1's binary_logloss: 0.488335\n",
      "Early stopping, best iteration is:\n",
      "[657]\ttraining's binary_logloss: 0.443593\tvalid_1's binary_logloss: 0.488333\n",
      "===== ACCURACY SCORE 0.781816 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509272\tvalid_1's binary_logloss: 0.525654\n",
      "[200]\ttraining's binary_logloss: 0.468802\tvalid_1's binary_logloss: 0.492657\n",
      "[300]\ttraining's binary_logloss: 0.455147\tvalid_1's binary_logloss: 0.485748\n",
      "[400]\ttraining's binary_logloss: 0.449205\tvalid_1's binary_logloss: 0.484281\n",
      "[500]\ttraining's binary_logloss: 0.445733\tvalid_1's binary_logloss: 0.483793\n",
      "[600]\ttraining's binary_logloss: 0.443478\tvalid_1's binary_logloss: 0.483499\n",
      "[700]\ttraining's binary_logloss: 0.442016\tvalid_1's binary_logloss: 0.483492\n",
      "[800]\ttraining's binary_logloss: 0.440964\tvalid_1's binary_logloss: 0.48344\n",
      "Early stopping, best iteration is:\n",
      "[778]\ttraining's binary_logloss: 0.44118\tvalid_1's binary_logloss: 0.483424\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.441158\tvalid_1's binary_logloss: 0.483422\n",
      "[900]\ttraining's binary_logloss: 0.441062\tvalid_1's binary_logloss: 0.48341\n",
      "[1000]\ttraining's binary_logloss: 0.440964\tvalid_1's binary_logloss: 0.483399\n",
      "[1100]\ttraining's binary_logloss: 0.440869\tvalid_1's binary_logloss: 0.483387\n",
      "[1200]\ttraining's binary_logloss: 0.440778\tvalid_1's binary_logloss: 0.483389\n",
      "Early stopping, best iteration is:\n",
      "[1137]\ttraining's binary_logloss: 0.440835\tvalid_1's binary_logloss: 0.483379\n",
      "===== ACCURACY SCORE 0.781023 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508848\tvalid_1's binary_logloss: 0.528895\n",
      "[200]\ttraining's binary_logloss: 0.468386\tvalid_1's binary_logloss: 0.498609\n",
      "[300]\ttraining's binary_logloss: 0.454812\tvalid_1's binary_logloss: 0.493472\n",
      "[400]\ttraining's binary_logloss: 0.448956\tvalid_1's binary_logloss: 0.492977\n",
      "[500]\ttraining's binary_logloss: 0.445524\tvalid_1's binary_logloss: 0.493254\n",
      "Early stopping, best iteration is:\n",
      "[402]\ttraining's binary_logloss: 0.448878\tvalid_1's binary_logloss: 0.492956\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.448491\tvalid_1's binary_logloss: 0.49299\n",
      "Early stopping, best iteration is:\n",
      "[405]\ttraining's binary_logloss: 0.448864\tvalid_1's binary_logloss: 0.492957\n",
      "===== ACCURACY SCORE 0.775630 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509642\tvalid_1's binary_logloss: 0.53772\n",
      "[200]\ttraining's binary_logloss: 0.469392\tvalid_1's binary_logloss: 0.507488\n",
      "[300]\ttraining's binary_logloss: 0.455737\tvalid_1's binary_logloss: 0.501548\n",
      "[400]\ttraining's binary_logloss: 0.449714\tvalid_1's binary_logloss: 0.500199\n",
      "[500]\ttraining's binary_logloss: 0.446265\tvalid_1's binary_logloss: 0.499749\n",
      "[600]\ttraining's binary_logloss: 0.444053\tvalid_1's binary_logloss: 0.499242\n",
      "[700]\ttraining's binary_logloss: 0.442599\tvalid_1's binary_logloss: 0.498896\n",
      "[800]\ttraining's binary_logloss: 0.441535\tvalid_1's binary_logloss: 0.498547\n",
      "[900]\ttraining's binary_logloss: 0.44067\tvalid_1's binary_logloss: 0.498311\n",
      "[1000]\ttraining's binary_logloss: 0.439949\tvalid_1's binary_logloss: 0.498062\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439949\tvalid_1's binary_logloss: 0.498062\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.43988\tvalid_1's binary_logloss: 0.498038\n",
      "[1200]\ttraining's binary_logloss: 0.439813\tvalid_1's binary_logloss: 0.498012\n",
      "[1300]\ttraining's binary_logloss: 0.439746\tvalid_1's binary_logloss: 0.497996\n",
      "[1400]\ttraining's binary_logloss: 0.43968\tvalid_1's binary_logloss: 0.49798\n",
      "[1500]\ttraining's binary_logloss: 0.439614\tvalid_1's binary_logloss: 0.497958\n",
      "[1600]\ttraining's binary_logloss: 0.43955\tvalid_1's binary_logloss: 0.497947\n",
      "[1700]\ttraining's binary_logloss: 0.439486\tvalid_1's binary_logloss: 0.497929\n",
      "[1800]\ttraining's binary_logloss: 0.439422\tvalid_1's binary_logloss: 0.497911\n",
      "[1900]\ttraining's binary_logloss: 0.439362\tvalid_1's binary_logloss: 0.497891\n",
      "[2000]\ttraining's binary_logloss: 0.439301\tvalid_1's binary_logloss: 0.497878\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439301\tvalid_1's binary_logloss: 0.497878\n",
      "===== ACCURACY SCORE 0.773117 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509553\tvalid_1's binary_logloss: 0.526704\n",
      "[200]\ttraining's binary_logloss: 0.469553\tvalid_1's binary_logloss: 0.494298\n",
      "[300]\ttraining's binary_logloss: 0.4561\tvalid_1's binary_logloss: 0.487997\n",
      "[400]\ttraining's binary_logloss: 0.450192\tvalid_1's binary_logloss: 0.486747\n",
      "[500]\ttraining's binary_logloss: 0.446813\tvalid_1's binary_logloss: 0.486431\n",
      "[600]\ttraining's binary_logloss: 0.44452\tvalid_1's binary_logloss: 0.48612\n",
      "Early stopping, best iteration is:\n",
      "[595]\ttraining's binary_logloss: 0.444606\tvalid_1's binary_logloss: 0.486107\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.444597\tvalid_1's binary_logloss: 0.486108\n",
      "[700]\ttraining's binary_logloss: 0.444419\tvalid_1's binary_logloss: 0.486112\n",
      "Early stopping, best iteration is:\n",
      "[622]\ttraining's binary_logloss: 0.444556\tvalid_1's binary_logloss: 0.486103\n",
      "===== ACCURACY SCORE 0.778111 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509601\tvalid_1's binary_logloss: 0.526087\n",
      "[200]\ttraining's binary_logloss: 0.469117\tvalid_1's binary_logloss: 0.493206\n",
      "[300]\ttraining's binary_logloss: 0.455328\tvalid_1's binary_logloss: 0.486835\n",
      "[400]\ttraining's binary_logloss: 0.44928\tvalid_1's binary_logloss: 0.485965\n",
      "[500]\ttraining's binary_logloss: 0.445794\tvalid_1's binary_logloss: 0.485641\n",
      "[600]\ttraining's binary_logloss: 0.443555\tvalid_1's binary_logloss: 0.485611\n",
      "Early stopping, best iteration is:\n",
      "[552]\ttraining's binary_logloss: 0.444492\tvalid_1's binary_logloss: 0.485552\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.444387\tvalid_1's binary_logloss: 0.485549\n",
      "[700]\ttraining's binary_logloss: 0.444177\tvalid_1's binary_logloss: 0.485557\n",
      "Early stopping, best iteration is:\n",
      "[616]\ttraining's binary_logloss: 0.444353\tvalid_1's binary_logloss: 0.485546\n",
      "===== ACCURACY SCORE 0.780406 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509178\tvalid_1's binary_logloss: 0.525773\n",
      "[200]\ttraining's binary_logloss: 0.468796\tvalid_1's binary_logloss: 0.492723\n",
      "[300]\ttraining's binary_logloss: 0.455214\tvalid_1's binary_logloss: 0.485461\n",
      "[400]\ttraining's binary_logloss: 0.449237\tvalid_1's binary_logloss: 0.484071\n",
      "[500]\ttraining's binary_logloss: 0.445847\tvalid_1's binary_logloss: 0.483661\n",
      "[600]\ttraining's binary_logloss: 0.443591\tvalid_1's binary_logloss: 0.48348\n",
      "[700]\ttraining's binary_logloss: 0.442107\tvalid_1's binary_logloss: 0.483358\n",
      "Early stopping, best iteration is:\n",
      "[676]\ttraining's binary_logloss: 0.442413\tvalid_1's binary_logloss: 0.483345\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.442378\tvalid_1's binary_logloss: 0.483349\n",
      "Early stopping, best iteration is:\n",
      "[677]\ttraining's binary_logloss: 0.442412\tvalid_1's binary_logloss: 0.483346\n",
      "===== ACCURACY SCORE 0.779370 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509184\tvalid_1's binary_logloss: 0.527381\n",
      "[200]\ttraining's binary_logloss: 0.468738\tvalid_1's binary_logloss: 0.493524\n",
      "[300]\ttraining's binary_logloss: 0.455039\tvalid_1's binary_logloss: 0.48586\n",
      "[400]\ttraining's binary_logloss: 0.449131\tvalid_1's binary_logloss: 0.484103\n",
      "[500]\ttraining's binary_logloss: 0.445815\tvalid_1's binary_logloss: 0.483416\n",
      "[600]\ttraining's binary_logloss: 0.443557\tvalid_1's binary_logloss: 0.482821\n",
      "[700]\ttraining's binary_logloss: 0.442064\tvalid_1's binary_logloss: 0.482532\n",
      "[800]\ttraining's binary_logloss: 0.440959\tvalid_1's binary_logloss: 0.482406\n",
      "[900]\ttraining's binary_logloss: 0.440112\tvalid_1's binary_logloss: 0.482312\n",
      "[1000]\ttraining's binary_logloss: 0.4394\tvalid_1's binary_logloss: 0.482212\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.4394\tvalid_1's binary_logloss: 0.482212\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439331\tvalid_1's binary_logloss: 0.482204\n",
      "[1200]\ttraining's binary_logloss: 0.439266\tvalid_1's binary_logloss: 0.482198\n",
      "Early stopping, best iteration is:\n",
      "[1136]\ttraining's binary_logloss: 0.439308\tvalid_1's binary_logloss: 0.482194\n",
      "===== ACCURACY SCORE 0.783171 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779180 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509572\tvalid_1's binary_logloss: 0.526933\n",
      "[200]\ttraining's binary_logloss: 0.469207\tvalid_1's binary_logloss: 0.494229\n",
      "[300]\ttraining's binary_logloss: 0.455473\tvalid_1's binary_logloss: 0.487411\n",
      "[400]\ttraining's binary_logloss: 0.449391\tvalid_1's binary_logloss: 0.486108\n",
      "[500]\ttraining's binary_logloss: 0.44594\tvalid_1's binary_logloss: 0.485822\n",
      "[600]\ttraining's binary_logloss: 0.443622\tvalid_1's binary_logloss: 0.485589\n",
      "Early stopping, best iteration is:\n",
      "[574]\ttraining's binary_logloss: 0.444118\tvalid_1's binary_logloss: 0.485548\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.444066\tvalid_1's binary_logloss: 0.485544\n",
      "[700]\ttraining's binary_logloss: 0.443871\tvalid_1's binary_logloss: 0.485535\n",
      "[800]\ttraining's binary_logloss: 0.443682\tvalid_1's binary_logloss: 0.485519\n",
      "[900]\ttraining's binary_logloss: 0.443499\tvalid_1's binary_logloss: 0.485511\n",
      "[1000]\ttraining's binary_logloss: 0.443328\tvalid_1's binary_logloss: 0.485515\n",
      "[1100]\ttraining's binary_logloss: 0.443165\tvalid_1's binary_logloss: 0.4855\n",
      "[1200]\ttraining's binary_logloss: 0.443007\tvalid_1's binary_logloss: 0.485503\n",
      "Early stopping, best iteration is:\n",
      "[1166]\ttraining's binary_logloss: 0.443056\tvalid_1's binary_logloss: 0.485494\n",
      "===== ACCURACY SCORE 0.780708 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509992\tvalid_1's binary_logloss: 0.529384\n",
      "[200]\ttraining's binary_logloss: 0.469852\tvalid_1's binary_logloss: 0.497246\n",
      "[300]\ttraining's binary_logloss: 0.456267\tvalid_1's binary_logloss: 0.490352\n",
      "[400]\ttraining's binary_logloss: 0.450371\tvalid_1's binary_logloss: 0.488642\n",
      "[500]\ttraining's binary_logloss: 0.447015\tvalid_1's binary_logloss: 0.487881\n",
      "[600]\ttraining's binary_logloss: 0.444776\tvalid_1's binary_logloss: 0.487436\n",
      "[700]\ttraining's binary_logloss: 0.443303\tvalid_1's binary_logloss: 0.487257\n",
      "[800]\ttraining's binary_logloss: 0.44225\tvalid_1's binary_logloss: 0.487168\n",
      "[900]\ttraining's binary_logloss: 0.441388\tvalid_1's binary_logloss: 0.487008\n",
      "[1000]\ttraining's binary_logloss: 0.440643\tvalid_1's binary_logloss: 0.486935\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440643\tvalid_1's binary_logloss: 0.486935\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440574\tvalid_1's binary_logloss: 0.486924\n",
      "[1200]\ttraining's binary_logloss: 0.440508\tvalid_1's binary_logloss: 0.486913\n",
      "[1300]\ttraining's binary_logloss: 0.440443\tvalid_1's binary_logloss: 0.486905\n",
      "[1400]\ttraining's binary_logloss: 0.440377\tvalid_1's binary_logloss: 0.486898\n",
      "[1500]\ttraining's binary_logloss: 0.440311\tvalid_1's binary_logloss: 0.486889\n",
      "[1600]\ttraining's binary_logloss: 0.440246\tvalid_1's binary_logloss: 0.486874\n",
      "[1700]\ttraining's binary_logloss: 0.440183\tvalid_1's binary_logloss: 0.486859\n",
      "[1800]\ttraining's binary_logloss: 0.440118\tvalid_1's binary_logloss: 0.48684\n",
      "[1900]\ttraining's binary_logloss: 0.440056\tvalid_1's binary_logloss: 0.486824\n",
      "[2000]\ttraining's binary_logloss: 0.439994\tvalid_1's binary_logloss: 0.486818\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439994\tvalid_1's binary_logloss: 0.486818\n",
      "===== ACCURACY SCORE 0.776347 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50974\tvalid_1's binary_logloss: 0.523298\n",
      "[200]\ttraining's binary_logloss: 0.46942\tvalid_1's binary_logloss: 0.488799\n",
      "[300]\ttraining's binary_logloss: 0.455597\tvalid_1's binary_logloss: 0.481235\n",
      "[400]\ttraining's binary_logloss: 0.44964\tvalid_1's binary_logloss: 0.479508\n",
      "[500]\ttraining's binary_logloss: 0.44621\tvalid_1's binary_logloss: 0.478959\n",
      "[600]\ttraining's binary_logloss: 0.443927\tvalid_1's binary_logloss: 0.478419\n",
      "[700]\ttraining's binary_logloss: 0.442436\tvalid_1's binary_logloss: 0.478192\n",
      "[800]\ttraining's binary_logloss: 0.441369\tvalid_1's binary_logloss: 0.478103\n",
      "[900]\ttraining's binary_logloss: 0.440516\tvalid_1's binary_logloss: 0.478022\n",
      "[1000]\ttraining's binary_logloss: 0.439743\tvalid_1's binary_logloss: 0.477793\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439743\tvalid_1's binary_logloss: 0.477793\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439675\tvalid_1's binary_logloss: 0.477786\n",
      "[1200]\ttraining's binary_logloss: 0.439608\tvalid_1's binary_logloss: 0.477772\n",
      "[1300]\ttraining's binary_logloss: 0.439542\tvalid_1's binary_logloss: 0.477766\n",
      "[1400]\ttraining's binary_logloss: 0.439476\tvalid_1's binary_logloss: 0.477753\n",
      "[1500]\ttraining's binary_logloss: 0.439407\tvalid_1's binary_logloss: 0.477737\n",
      "[1600]\ttraining's binary_logloss: 0.439342\tvalid_1's binary_logloss: 0.477721\n",
      "[1700]\ttraining's binary_logloss: 0.439276\tvalid_1's binary_logloss: 0.477715\n",
      "[1800]\ttraining's binary_logloss: 0.439212\tvalid_1's binary_logloss: 0.477706\n",
      "[1900]\ttraining's binary_logloss: 0.439151\tvalid_1's binary_logloss: 0.477701\n",
      "[2000]\ttraining's binary_logloss: 0.439085\tvalid_1's binary_logloss: 0.477684\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439085\tvalid_1's binary_logloss: 0.477684\n",
      "===== ACCURACY SCORE 0.787384 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509433\tvalid_1's binary_logloss: 0.526521\n",
      "[200]\ttraining's binary_logloss: 0.468766\tvalid_1's binary_logloss: 0.492942\n",
      "[300]\ttraining's binary_logloss: 0.455043\tvalid_1's binary_logloss: 0.486156\n",
      "[400]\ttraining's binary_logloss: 0.44908\tvalid_1's binary_logloss: 0.484932\n",
      "[500]\ttraining's binary_logloss: 0.445616\tvalid_1's binary_logloss: 0.484873\n",
      "Early stopping, best iteration is:\n",
      "[484]\ttraining's binary_logloss: 0.446069\tvalid_1's binary_logloss: 0.484815\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.446022\tvalid_1's binary_logloss: 0.484815\n",
      "[600]\ttraining's binary_logloss: 0.445727\tvalid_1's binary_logloss: 0.4848\n",
      "[700]\ttraining's binary_logloss: 0.445454\tvalid_1's binary_logloss: 0.484791\n",
      "[800]\ttraining's binary_logloss: 0.445188\tvalid_1's binary_logloss: 0.484781\n",
      "Early stopping, best iteration is:\n",
      "[777]\ttraining's binary_logloss: 0.445247\tvalid_1's binary_logloss: 0.484776\n",
      "===== ACCURACY SCORE 0.782449 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509572\tvalid_1's binary_logloss: 0.528366\n",
      "[200]\ttraining's binary_logloss: 0.469189\tvalid_1's binary_logloss: 0.497138\n",
      "[300]\ttraining's binary_logloss: 0.455492\tvalid_1's binary_logloss: 0.491168\n",
      "[400]\ttraining's binary_logloss: 0.449509\tvalid_1's binary_logloss: 0.490389\n",
      "[500]\ttraining's binary_logloss: 0.445957\tvalid_1's binary_logloss: 0.490316\n",
      "[600]\ttraining's binary_logloss: 0.443599\tvalid_1's binary_logloss: 0.490207\n",
      "Early stopping, best iteration is:\n",
      "[583]\ttraining's binary_logloss: 0.443923\tvalid_1's binary_logloss: 0.490133\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.443887\tvalid_1's binary_logloss: 0.490131\n",
      "[700]\ttraining's binary_logloss: 0.443684\tvalid_1's binary_logloss: 0.490129\n",
      "[800]\ttraining's binary_logloss: 0.443495\tvalid_1's binary_logloss: 0.490134\n",
      "Early stopping, best iteration is:\n",
      "[725]\ttraining's binary_logloss: 0.443637\tvalid_1's binary_logloss: 0.490123\n",
      "===== ACCURACY SCORE 0.776897 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510121\tvalid_1's binary_logloss: 0.531272\n",
      "[200]\ttraining's binary_logloss: 0.470217\tvalid_1's binary_logloss: 0.499515\n",
      "[300]\ttraining's binary_logloss: 0.456894\tvalid_1's binary_logloss: 0.493348\n",
      "[400]\ttraining's binary_logloss: 0.451053\tvalid_1's binary_logloss: 0.492475\n",
      "[500]\ttraining's binary_logloss: 0.447702\tvalid_1's binary_logloss: 0.492217\n",
      "[600]\ttraining's binary_logloss: 0.445428\tvalid_1's binary_logloss: 0.491943\n",
      "[700]\ttraining's binary_logloss: 0.443939\tvalid_1's binary_logloss: 0.491926\n",
      "[800]\ttraining's binary_logloss: 0.442843\tvalid_1's binary_logloss: 0.49193\n",
      "Early stopping, best iteration is:\n",
      "[769]\ttraining's binary_logloss: 0.443156\tvalid_1's binary_logloss: 0.491844\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.443123\tvalid_1's binary_logloss: 0.491848\n",
      "Early stopping, best iteration is:\n",
      "[771]\ttraining's binary_logloss: 0.443154\tvalid_1's binary_logloss: 0.491843\n",
      "===== ACCURACY SCORE 0.777992 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510803\tvalid_1's binary_logloss: 0.529758\n",
      "[200]\ttraining's binary_logloss: 0.470719\tvalid_1's binary_logloss: 0.497984\n",
      "[300]\ttraining's binary_logloss: 0.457176\tvalid_1's binary_logloss: 0.491488\n",
      "[400]\ttraining's binary_logloss: 0.451195\tvalid_1's binary_logloss: 0.490283\n",
      "[500]\ttraining's binary_logloss: 0.447679\tvalid_1's binary_logloss: 0.490085\n",
      "[600]\ttraining's binary_logloss: 0.445388\tvalid_1's binary_logloss: 0.489815\n",
      "[700]\ttraining's binary_logloss: 0.443916\tvalid_1's binary_logloss: 0.489877\n",
      "Early stopping, best iteration is:\n",
      "[666]\ttraining's binary_logloss: 0.444354\tvalid_1's binary_logloss: 0.489748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.444306\tvalid_1's binary_logloss: 0.489748\n",
      "[800]\ttraining's binary_logloss: 0.444168\tvalid_1's binary_logloss: 0.489752\n",
      "[900]\ttraining's binary_logloss: 0.444037\tvalid_1's binary_logloss: 0.489744\n",
      "[1000]\ttraining's binary_logloss: 0.443909\tvalid_1's binary_logloss: 0.489741\n",
      "[1100]\ttraining's binary_logloss: 0.443785\tvalid_1's binary_logloss: 0.489739\n",
      "[1200]\ttraining's binary_logloss: 0.443662\tvalid_1's binary_logloss: 0.489738\n",
      "[1300]\ttraining's binary_logloss: 0.443547\tvalid_1's binary_logloss: 0.489729\n",
      "Early stopping, best iteration is:\n",
      "[1290]\ttraining's binary_logloss: 0.443558\tvalid_1's binary_logloss: 0.489727\n",
      "===== ACCURACY SCORE 0.780180 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509642\tvalid_1's binary_logloss: 0.531643\n",
      "[200]\ttraining's binary_logloss: 0.469463\tvalid_1's binary_logloss: 0.501485\n",
      "[300]\ttraining's binary_logloss: 0.455997\tvalid_1's binary_logloss: 0.495427\n",
      "[400]\ttraining's binary_logloss: 0.450086\tvalid_1's binary_logloss: 0.494326\n",
      "[500]\ttraining's binary_logloss: 0.446689\tvalid_1's binary_logloss: 0.493912\n",
      "[600]\ttraining's binary_logloss: 0.444447\tvalid_1's binary_logloss: 0.493311\n",
      "[700]\ttraining's binary_logloss: 0.442973\tvalid_1's binary_logloss: 0.493083\n",
      "[800]\ttraining's binary_logloss: 0.441887\tvalid_1's binary_logloss: 0.492772\n",
      "[900]\ttraining's binary_logloss: 0.441037\tvalid_1's binary_logloss: 0.492685\n",
      "[1000]\ttraining's binary_logloss: 0.440303\tvalid_1's binary_logloss: 0.492524\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440303\tvalid_1's binary_logloss: 0.492524\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440235\tvalid_1's binary_logloss: 0.49252\n",
      "[1200]\ttraining's binary_logloss: 0.440168\tvalid_1's binary_logloss: 0.492505\n",
      "[1300]\ttraining's binary_logloss: 0.440102\tvalid_1's binary_logloss: 0.49249\n",
      "[1400]\ttraining's binary_logloss: 0.440034\tvalid_1's binary_logloss: 0.492476\n",
      "[1500]\ttraining's binary_logloss: 0.439969\tvalid_1's binary_logloss: 0.492469\n",
      "[1600]\ttraining's binary_logloss: 0.439902\tvalid_1's binary_logloss: 0.492458\n",
      "[1700]\ttraining's binary_logloss: 0.439838\tvalid_1's binary_logloss: 0.492447\n",
      "[1800]\ttraining's binary_logloss: 0.439776\tvalid_1's binary_logloss: 0.492432\n",
      "[1900]\ttraining's binary_logloss: 0.439714\tvalid_1's binary_logloss: 0.492418\n",
      "[2000]\ttraining's binary_logloss: 0.439653\tvalid_1's binary_logloss: 0.492403\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439653\tvalid_1's binary_logloss: 0.492403\n",
      "===== ACCURACY SCORE 0.772185 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510637\tvalid_1's binary_logloss: 0.526822\n",
      "[200]\ttraining's binary_logloss: 0.470542\tvalid_1's binary_logloss: 0.493784\n",
      "[300]\ttraining's binary_logloss: 0.457036\tvalid_1's binary_logloss: 0.486819\n",
      "[400]\ttraining's binary_logloss: 0.451016\tvalid_1's binary_logloss: 0.485495\n",
      "[500]\ttraining's binary_logloss: 0.447597\tvalid_1's binary_logloss: 0.485263\n",
      "[600]\ttraining's binary_logloss: 0.445285\tvalid_1's binary_logloss: 0.484998\n",
      "[700]\ttraining's binary_logloss: 0.443792\tvalid_1's binary_logloss: 0.48495\n",
      "Early stopping, best iteration is:\n",
      "[668]\ttraining's binary_logloss: 0.444213\tvalid_1's binary_logloss: 0.484895\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.444168\tvalid_1's binary_logloss: 0.484898\n",
      "Early stopping, best iteration is:\n",
      "[674]\ttraining's binary_logloss: 0.444205\tvalid_1's binary_logloss: 0.484894\n",
      "===== ACCURACY SCORE 0.783182 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509821\tvalid_1's binary_logloss: 0.529545\n",
      "[200]\ttraining's binary_logloss: 0.469692\tvalid_1's binary_logloss: 0.496659\n",
      "[300]\ttraining's binary_logloss: 0.456104\tvalid_1's binary_logloss: 0.489556\n",
      "[400]\ttraining's binary_logloss: 0.450098\tvalid_1's binary_logloss: 0.487903\n",
      "[500]\ttraining's binary_logloss: 0.446681\tvalid_1's binary_logloss: 0.48733\n",
      "[600]\ttraining's binary_logloss: 0.444445\tvalid_1's binary_logloss: 0.486869\n",
      "[700]\ttraining's binary_logloss: 0.442984\tvalid_1's binary_logloss: 0.486841\n",
      "Early stopping, best iteration is:\n",
      "[688]\ttraining's binary_logloss: 0.443124\tvalid_1's binary_logloss: 0.486826\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.443109\tvalid_1's binary_logloss: 0.486824\n",
      "Early stopping, best iteration is:\n",
      "[691]\ttraining's binary_logloss: 0.44312\tvalid_1's binary_logloss: 0.486822\n",
      "===== ACCURACY SCORE 0.779527 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779700 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.507942\tvalid_1's binary_logloss: 0.52619\n",
      "[200]\ttraining's binary_logloss: 0.466991\tvalid_1's binary_logloss: 0.493545\n",
      "[300]\ttraining's binary_logloss: 0.453045\tvalid_1's binary_logloss: 0.486993\n",
      "[400]\ttraining's binary_logloss: 0.446911\tvalid_1's binary_logloss: 0.485953\n",
      "Early stopping, best iteration is:\n",
      "[379]\ttraining's binary_logloss: 0.447874\tvalid_1's binary_logloss: 0.485916\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.447773\tvalid_1's binary_logloss: 0.4859\n",
      "[500]\ttraining's binary_logloss: 0.447308\tvalid_1's binary_logloss: 0.485875\n",
      "[600]\ttraining's binary_logloss: 0.446866\tvalid_1's binary_logloss: 0.485856\n",
      "[700]\ttraining's binary_logloss: 0.446449\tvalid_1's binary_logloss: 0.485834\n",
      "[800]\ttraining's binary_logloss: 0.446049\tvalid_1's binary_logloss: 0.48584\n",
      "Early stopping, best iteration is:\n",
      "[751]\ttraining's binary_logloss: 0.446246\tvalid_1's binary_logloss: 0.485825\n",
      "===== ACCURACY SCORE 0.780831 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510525\tvalid_1's binary_logloss: 0.526051\n",
      "[200]\ttraining's binary_logloss: 0.470297\tvalid_1's binary_logloss: 0.492802\n",
      "[300]\ttraining's binary_logloss: 0.456596\tvalid_1's binary_logloss: 0.485263\n",
      "[400]\ttraining's binary_logloss: 0.45062\tvalid_1's binary_logloss: 0.483365\n",
      "[500]\ttraining's binary_logloss: 0.447191\tvalid_1's binary_logloss: 0.482701\n",
      "[600]\ttraining's binary_logloss: 0.444965\tvalid_1's binary_logloss: 0.482202\n",
      "[700]\ttraining's binary_logloss: 0.443495\tvalid_1's binary_logloss: 0.481884\n",
      "[800]\ttraining's binary_logloss: 0.442416\tvalid_1's binary_logloss: 0.481773\n",
      "[900]\ttraining's binary_logloss: 0.44153\tvalid_1's binary_logloss: 0.481776\n",
      "Early stopping, best iteration is:\n",
      "[861]\ttraining's binary_logloss: 0.441853\tvalid_1's binary_logloss: 0.481731\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[900]\ttraining's binary_logloss: 0.441818\tvalid_1's binary_logloss: 0.48173\n",
      "[1000]\ttraining's binary_logloss: 0.441735\tvalid_1's binary_logloss: 0.481737\n",
      "Early stopping, best iteration is:\n",
      "[913]\ttraining's binary_logloss: 0.441808\tvalid_1's binary_logloss: 0.481728\n",
      "===== ACCURACY SCORE 0.781129 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50897\tvalid_1's binary_logloss: 0.525053\n",
      "[200]\ttraining's binary_logloss: 0.468547\tvalid_1's binary_logloss: 0.491965\n",
      "[300]\ttraining's binary_logloss: 0.455064\tvalid_1's binary_logloss: 0.485149\n",
      "[400]\ttraining's binary_logloss: 0.449116\tvalid_1's binary_logloss: 0.483768\n",
      "[500]\ttraining's binary_logloss: 0.445671\tvalid_1's binary_logloss: 0.483447\n",
      "[600]\ttraining's binary_logloss: 0.443461\tvalid_1's binary_logloss: 0.483304\n",
      "[700]\ttraining's binary_logloss: 0.442032\tvalid_1's binary_logloss: 0.483455\n",
      "Early stopping, best iteration is:\n",
      "[600]\ttraining's binary_logloss: 0.443461\tvalid_1's binary_logloss: 0.483304\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.443292\tvalid_1's binary_logloss: 0.48329\n",
      "[800]\ttraining's binary_logloss: 0.443132\tvalid_1's binary_logloss: 0.483288\n",
      "Early stopping, best iteration is:\n",
      "[786]\ttraining's binary_logloss: 0.443154\tvalid_1's binary_logloss: 0.483285\n",
      "===== ACCURACY SCORE 0.779013 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508356\tvalid_1's binary_logloss: 0.530704\n",
      "[200]\ttraining's binary_logloss: 0.467632\tvalid_1's binary_logloss: 0.500602\n",
      "[300]\ttraining's binary_logloss: 0.453867\tvalid_1's binary_logloss: 0.49486\n",
      "[400]\ttraining's binary_logloss: 0.447827\tvalid_1's binary_logloss: 0.494078\n",
      "[500]\ttraining's binary_logloss: 0.444378\tvalid_1's binary_logloss: 0.494016\n",
      "[600]\ttraining's binary_logloss: 0.442165\tvalid_1's binary_logloss: 0.493925\n",
      "[700]\ttraining's binary_logloss: 0.440717\tvalid_1's binary_logloss: 0.49379\n",
      "[800]\ttraining's binary_logloss: 0.439664\tvalid_1's binary_logloss: 0.493797\n",
      "Early stopping, best iteration is:\n",
      "[759]\ttraining's binary_logloss: 0.440049\tvalid_1's binary_logloss: 0.493755\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.440005\tvalid_1's binary_logloss: 0.493751\n",
      "Early stopping, best iteration is:\n",
      "[780]\ttraining's binary_logloss: 0.440026\tvalid_1's binary_logloss: 0.49375\n",
      "===== ACCURACY SCORE 0.773455 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509026\tvalid_1's binary_logloss: 0.524252\n",
      "[200]\ttraining's binary_logloss: 0.468506\tvalid_1's binary_logloss: 0.489934\n",
      "[300]\ttraining's binary_logloss: 0.454799\tvalid_1's binary_logloss: 0.482044\n",
      "[400]\ttraining's binary_logloss: 0.44881\tvalid_1's binary_logloss: 0.480265\n",
      "[500]\ttraining's binary_logloss: 0.445446\tvalid_1's binary_logloss: 0.479631\n",
      "[600]\ttraining's binary_logloss: 0.443157\tvalid_1's binary_logloss: 0.479165\n",
      "[700]\ttraining's binary_logloss: 0.441646\tvalid_1's binary_logloss: 0.478951\n",
      "[800]\ttraining's binary_logloss: 0.440586\tvalid_1's binary_logloss: 0.478773\n",
      "[900]\ttraining's binary_logloss: 0.439737\tvalid_1's binary_logloss: 0.478685\n",
      "[1000]\ttraining's binary_logloss: 0.439019\tvalid_1's binary_logloss: 0.478646\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439019\tvalid_1's binary_logloss: 0.478646\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.438951\tvalid_1's binary_logloss: 0.478632\n",
      "[1200]\ttraining's binary_logloss: 0.438883\tvalid_1's binary_logloss: 0.478624\n",
      "[1300]\ttraining's binary_logloss: 0.438815\tvalid_1's binary_logloss: 0.478615\n",
      "[1400]\ttraining's binary_logloss: 0.438748\tvalid_1's binary_logloss: 0.478604\n",
      "[1500]\ttraining's binary_logloss: 0.438681\tvalid_1's binary_logloss: 0.478593\n",
      "[1600]\ttraining's binary_logloss: 0.438614\tvalid_1's binary_logloss: 0.478579\n",
      "[1700]\ttraining's binary_logloss: 0.438547\tvalid_1's binary_logloss: 0.478572\n",
      "[1800]\ttraining's binary_logloss: 0.438485\tvalid_1's binary_logloss: 0.478554\n",
      "[1900]\ttraining's binary_logloss: 0.438423\tvalid_1's binary_logloss: 0.478553\n",
      "[2000]\ttraining's binary_logloss: 0.438361\tvalid_1's binary_logloss: 0.478545\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.438361\tvalid_1's binary_logloss: 0.478545\n",
      "===== ACCURACY SCORE 0.782301 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509194\tvalid_1's binary_logloss: 0.52892\n",
      "[200]\ttraining's binary_logloss: 0.468603\tvalid_1's binary_logloss: 0.497072\n",
      "[300]\ttraining's binary_logloss: 0.454932\tvalid_1's binary_logloss: 0.491309\n",
      "[400]\ttraining's binary_logloss: 0.448926\tvalid_1's binary_logloss: 0.490664\n",
      "Early stopping, best iteration is:\n",
      "[363]\ttraining's binary_logloss: 0.450673\tvalid_1's binary_logloss: 0.490597\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.450485\tvalid_1's binary_logloss: 0.490581\n",
      "[500]\ttraining's binary_logloss: 0.449991\tvalid_1's binary_logloss: 0.490553\n",
      "[600]\ttraining's binary_logloss: 0.449514\tvalid_1's binary_logloss: 0.490531\n",
      "Early stopping, best iteration is:\n",
      "[595]\ttraining's binary_logloss: 0.449539\tvalid_1's binary_logloss: 0.49053\n",
      "===== ACCURACY SCORE 0.779833 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508171\tvalid_1's binary_logloss: 0.530915\n",
      "[200]\ttraining's binary_logloss: 0.467564\tvalid_1's binary_logloss: 0.499614\n",
      "[300]\ttraining's binary_logloss: 0.453808\tvalid_1's binary_logloss: 0.49312\n",
      "[400]\ttraining's binary_logloss: 0.447698\tvalid_1's binary_logloss: 0.491919\n",
      "[500]\ttraining's binary_logloss: 0.444198\tvalid_1's binary_logloss: 0.491346\n",
      "[600]\ttraining's binary_logloss: 0.441817\tvalid_1's binary_logloss: 0.490726\n",
      "[700]\ttraining's binary_logloss: 0.440288\tvalid_1's binary_logloss: 0.490519\n",
      "[800]\ttraining's binary_logloss: 0.439141\tvalid_1's binary_logloss: 0.490316\n",
      "[900]\ttraining's binary_logloss: 0.438306\tvalid_1's binary_logloss: 0.490313\n",
      "[1000]\ttraining's binary_logloss: 0.437548\tvalid_1's binary_logloss: 0.490234\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.437548\tvalid_1's binary_logloss: 0.490234\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.437477\tvalid_1's binary_logloss: 0.490216\n",
      "[1200]\ttraining's binary_logloss: 0.437407\tvalid_1's binary_logloss: 0.490201\n",
      "[1300]\ttraining's binary_logloss: 0.437338\tvalid_1's binary_logloss: 0.49019\n",
      "[1400]\ttraining's binary_logloss: 0.437272\tvalid_1's binary_logloss: 0.49018\n",
      "[1500]\ttraining's binary_logloss: 0.437204\tvalid_1's binary_logloss: 0.490164\n",
      "[1600]\ttraining's binary_logloss: 0.437139\tvalid_1's binary_logloss: 0.490161\n",
      "[1700]\ttraining's binary_logloss: 0.437071\tvalid_1's binary_logloss: 0.490156\n",
      "[1800]\ttraining's binary_logloss: 0.437004\tvalid_1's binary_logloss: 0.490146\n",
      "[1900]\ttraining's binary_logloss: 0.436942\tvalid_1's binary_logloss: 0.490129\n",
      "[2000]\ttraining's binary_logloss: 0.436878\tvalid_1's binary_logloss: 0.490118\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.436878\tvalid_1's binary_logloss: 0.490118\n",
      "===== ACCURACY SCORE 0.777855 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509142\tvalid_1's binary_logloss: 0.535998\n",
      "[200]\ttraining's binary_logloss: 0.468731\tvalid_1's binary_logloss: 0.506958\n",
      "[300]\ttraining's binary_logloss: 0.455098\tvalid_1's binary_logloss: 0.502522\n",
      "[400]\ttraining's binary_logloss: 0.449065\tvalid_1's binary_logloss: 0.502329\n",
      "Early stopping, best iteration is:\n",
      "[375]\ttraining's binary_logloss: 0.450162\tvalid_1's binary_logloss: 0.502237\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.450038\tvalid_1's binary_logloss: 0.502244\n",
      "Early stopping, best iteration is:\n",
      "[377]\ttraining's binary_logloss: 0.450152\tvalid_1's binary_logloss: 0.502235\n",
      "===== ACCURACY SCORE 0.768564 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508416\tvalid_1's binary_logloss: 0.529816\n",
      "[200]\ttraining's binary_logloss: 0.467788\tvalid_1's binary_logloss: 0.49813\n",
      "[300]\ttraining's binary_logloss: 0.454029\tvalid_1's binary_logloss: 0.491927\n",
      "[400]\ttraining's binary_logloss: 0.448026\tvalid_1's binary_logloss: 0.491133\n",
      "[500]\ttraining's binary_logloss: 0.444567\tvalid_1's binary_logloss: 0.491037\n",
      "[600]\ttraining's binary_logloss: 0.44235\tvalid_1's binary_logloss: 0.491026\n",
      "[700]\ttraining's binary_logloss: 0.44082\tvalid_1's binary_logloss: 0.490784\n",
      "[800]\ttraining's binary_logloss: 0.439738\tvalid_1's binary_logloss: 0.490604\n",
      "[900]\ttraining's binary_logloss: 0.438869\tvalid_1's binary_logloss: 0.490394\n",
      "[1000]\ttraining's binary_logloss: 0.438146\tvalid_1's binary_logloss: 0.490308\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.438146\tvalid_1's binary_logloss: 0.490308\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.438078\tvalid_1's binary_logloss: 0.490285\n",
      "[1200]\ttraining's binary_logloss: 0.438009\tvalid_1's binary_logloss: 0.490272\n",
      "[1300]\ttraining's binary_logloss: 0.437945\tvalid_1's binary_logloss: 0.490255\n",
      "[1400]\ttraining's binary_logloss: 0.437876\tvalid_1's binary_logloss: 0.490247\n",
      "[1500]\ttraining's binary_logloss: 0.437812\tvalid_1's binary_logloss: 0.490236\n",
      "[1600]\ttraining's binary_logloss: 0.437749\tvalid_1's binary_logloss: 0.490222\n",
      "[1700]\ttraining's binary_logloss: 0.437684\tvalid_1's binary_logloss: 0.490207\n",
      "[1800]\ttraining's binary_logloss: 0.437621\tvalid_1's binary_logloss: 0.490196\n",
      "[1900]\ttraining's binary_logloss: 0.437557\tvalid_1's binary_logloss: 0.490181\n",
      "[2000]\ttraining's binary_logloss: 0.437497\tvalid_1's binary_logloss: 0.490173\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.437497\tvalid_1's binary_logloss: 0.490173\n",
      "===== ACCURACY SCORE 0.779457 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510895\tvalid_1's binary_logloss: 0.523164\n",
      "[200]\ttraining's binary_logloss: 0.470958\tvalid_1's binary_logloss: 0.488252\n",
      "[300]\ttraining's binary_logloss: 0.457417\tvalid_1's binary_logloss: 0.479927\n",
      "[400]\ttraining's binary_logloss: 0.451445\tvalid_1's binary_logloss: 0.477907\n",
      "[500]\ttraining's binary_logloss: 0.447874\tvalid_1's binary_logloss: 0.477353\n",
      "[600]\ttraining's binary_logloss: 0.445569\tvalid_1's binary_logloss: 0.477205\n",
      "Early stopping, best iteration is:\n",
      "[572]\ttraining's binary_logloss: 0.446098\tvalid_1's binary_logloss: 0.477099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.446037\tvalid_1's binary_logloss: 0.477095\n",
      "[700]\ttraining's binary_logloss: 0.445839\tvalid_1's binary_logloss: 0.477078\n",
      "[800]\ttraining's binary_logloss: 0.445652\tvalid_1's binary_logloss: 0.477074\n",
      "[900]\ttraining's binary_logloss: 0.445474\tvalid_1's binary_logloss: 0.477067\n",
      "[1000]\ttraining's binary_logloss: 0.445297\tvalid_1's binary_logloss: 0.477068\n",
      "Early stopping, best iteration is:\n",
      "[947]\ttraining's binary_logloss: 0.445391\tvalid_1's binary_logloss: 0.477059\n",
      "===== ACCURACY SCORE 0.789239 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779160 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510568\tvalid_1's binary_logloss: 0.523467\n",
      "[200]\ttraining's binary_logloss: 0.470642\tvalid_1's binary_logloss: 0.488797\n",
      "[300]\ttraining's binary_logloss: 0.457127\tvalid_1's binary_logloss: 0.480981\n",
      "[400]\ttraining's binary_logloss: 0.451276\tvalid_1's binary_logloss: 0.479282\n",
      "[500]\ttraining's binary_logloss: 0.44787\tvalid_1's binary_logloss: 0.478699\n",
      "[600]\ttraining's binary_logloss: 0.445594\tvalid_1's binary_logloss: 0.47838\n",
      "[700]\ttraining's binary_logloss: 0.444057\tvalid_1's binary_logloss: 0.478308\n",
      "[800]\ttraining's binary_logloss: 0.442955\tvalid_1's binary_logloss: 0.478311\n",
      "Early stopping, best iteration is:\n",
      "[757]\ttraining's binary_logloss: 0.443381\tvalid_1's binary_logloss: 0.478253\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.443335\tvalid_1's binary_logloss: 0.478254\n",
      "[900]\ttraining's binary_logloss: 0.443233\tvalid_1's binary_logloss: 0.478259\n",
      "Early stopping, best iteration is:\n",
      "[844]\ttraining's binary_logloss: 0.44329\tvalid_1's binary_logloss: 0.478251\n",
      "===== ACCURACY SCORE 0.785793 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509954\tvalid_1's binary_logloss: 0.53123\n",
      "[200]\ttraining's binary_logloss: 0.469649\tvalid_1's binary_logloss: 0.500622\n",
      "[300]\ttraining's binary_logloss: 0.456063\tvalid_1's binary_logloss: 0.494607\n",
      "[400]\ttraining's binary_logloss: 0.450215\tvalid_1's binary_logloss: 0.493653\n",
      "[500]\ttraining's binary_logloss: 0.446829\tvalid_1's binary_logloss: 0.493312\n",
      "[600]\ttraining's binary_logloss: 0.444575\tvalid_1's binary_logloss: 0.492958\n",
      "[700]\ttraining's binary_logloss: 0.443137\tvalid_1's binary_logloss: 0.492834\n",
      "[800]\ttraining's binary_logloss: 0.442074\tvalid_1's binary_logloss: 0.492675\n",
      "[900]\ttraining's binary_logloss: 0.441219\tvalid_1's binary_logloss: 0.492651\n",
      "[1000]\ttraining's binary_logloss: 0.440484\tvalid_1's binary_logloss: 0.492531\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440484\tvalid_1's binary_logloss: 0.492531\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440417\tvalid_1's binary_logloss: 0.492517\n",
      "[1200]\ttraining's binary_logloss: 0.440346\tvalid_1's binary_logloss: 0.492503\n",
      "[1300]\ttraining's binary_logloss: 0.440279\tvalid_1's binary_logloss: 0.492494\n",
      "[1400]\ttraining's binary_logloss: 0.440211\tvalid_1's binary_logloss: 0.492487\n",
      "[1500]\ttraining's binary_logloss: 0.440147\tvalid_1's binary_logloss: 0.492471\n",
      "[1600]\ttraining's binary_logloss: 0.440081\tvalid_1's binary_logloss: 0.492458\n",
      "[1700]\ttraining's binary_logloss: 0.440016\tvalid_1's binary_logloss: 0.492441\n",
      "[1800]\ttraining's binary_logloss: 0.439953\tvalid_1's binary_logloss: 0.49243\n",
      "[1900]\ttraining's binary_logloss: 0.439891\tvalid_1's binary_logloss: 0.492424\n",
      "[2000]\ttraining's binary_logloss: 0.439828\tvalid_1's binary_logloss: 0.492412\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439828\tvalid_1's binary_logloss: 0.492412\n",
      "===== ACCURACY SCORE 0.777496 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509536\tvalid_1's binary_logloss: 0.524292\n",
      "[200]\ttraining's binary_logloss: 0.469039\tvalid_1's binary_logloss: 0.49034\n",
      "[300]\ttraining's binary_logloss: 0.455333\tvalid_1's binary_logloss: 0.483041\n",
      "[400]\ttraining's binary_logloss: 0.44944\tvalid_1's binary_logloss: 0.48127\n",
      "[500]\ttraining's binary_logloss: 0.446099\tvalid_1's binary_logloss: 0.480486\n",
      "[600]\ttraining's binary_logloss: 0.443923\tvalid_1's binary_logloss: 0.480169\n",
      "[700]\ttraining's binary_logloss: 0.442462\tvalid_1's binary_logloss: 0.479847\n",
      "[800]\ttraining's binary_logloss: 0.441363\tvalid_1's binary_logloss: 0.479511\n",
      "[900]\ttraining's binary_logloss: 0.440533\tvalid_1's binary_logloss: 0.479166\n",
      "[1000]\ttraining's binary_logloss: 0.439804\tvalid_1's binary_logloss: 0.478973\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439804\tvalid_1's binary_logloss: 0.478973\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439736\tvalid_1's binary_logloss: 0.478957\n",
      "[1200]\ttraining's binary_logloss: 0.43967\tvalid_1's binary_logloss: 0.47894\n",
      "[1300]\ttraining's binary_logloss: 0.439606\tvalid_1's binary_logloss: 0.47892\n",
      "[1400]\ttraining's binary_logloss: 0.43954\tvalid_1's binary_logloss: 0.4789\n",
      "[1500]\ttraining's binary_logloss: 0.439475\tvalid_1's binary_logloss: 0.478878\n",
      "[1600]\ttraining's binary_logloss: 0.439411\tvalid_1's binary_logloss: 0.478874\n",
      "[1700]\ttraining's binary_logloss: 0.439345\tvalid_1's binary_logloss: 0.478864\n",
      "[1800]\ttraining's binary_logloss: 0.43928\tvalid_1's binary_logloss: 0.478841\n",
      "[1900]\ttraining's binary_logloss: 0.439217\tvalid_1's binary_logloss: 0.478826\n",
      "[2000]\ttraining's binary_logloss: 0.439157\tvalid_1's binary_logloss: 0.478812\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439157\tvalid_1's binary_logloss: 0.478812\n",
      "===== ACCURACY SCORE 0.786301 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.5084\tvalid_1's binary_logloss: 0.528928\n",
      "[200]\ttraining's binary_logloss: 0.468003\tvalid_1's binary_logloss: 0.496706\n",
      "[300]\ttraining's binary_logloss: 0.454482\tvalid_1's binary_logloss: 0.490158\n",
      "[400]\ttraining's binary_logloss: 0.448512\tvalid_1's binary_logloss: 0.488765\n",
      "[500]\ttraining's binary_logloss: 0.445071\tvalid_1's binary_logloss: 0.488538\n",
      "[600]\ttraining's binary_logloss: 0.442816\tvalid_1's binary_logloss: 0.488295\n",
      "[700]\ttraining's binary_logloss: 0.441346\tvalid_1's binary_logloss: 0.488284\n",
      "[800]\ttraining's binary_logloss: 0.440246\tvalid_1's binary_logloss: 0.488282\n",
      "Early stopping, best iteration is:\n",
      "[733]\ttraining's binary_logloss: 0.440944\tvalid_1's binary_logloss: 0.488231\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.440866\tvalid_1's binary_logloss: 0.488243\n",
      "Early stopping, best iteration is:\n",
      "[734]\ttraining's binary_logloss: 0.440943\tvalid_1's binary_logloss: 0.488231\n",
      "===== ACCURACY SCORE 0.777756 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508699\tvalid_1's binary_logloss: 0.524255\n",
      "[200]\ttraining's binary_logloss: 0.468142\tvalid_1's binary_logloss: 0.491204\n",
      "[300]\ttraining's binary_logloss: 0.454335\tvalid_1's binary_logloss: 0.484253\n",
      "[400]\ttraining's binary_logloss: 0.448258\tvalid_1's binary_logloss: 0.48275\n",
      "[500]\ttraining's binary_logloss: 0.444833\tvalid_1's binary_logloss: 0.482691\n",
      "[600]\ttraining's binary_logloss: 0.442542\tvalid_1's binary_logloss: 0.482563\n",
      "[700]\ttraining's binary_logloss: 0.441026\tvalid_1's binary_logloss: 0.482584\n",
      "[800]\ttraining's binary_logloss: 0.439906\tvalid_1's binary_logloss: 0.482525\n",
      "[900]\ttraining's binary_logloss: 0.438966\tvalid_1's binary_logloss: 0.482492\n",
      "Early stopping, best iteration is:\n",
      "[890]\ttraining's binary_logloss: 0.439052\tvalid_1's binary_logloss: 0.482482\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[900]\ttraining's binary_logloss: 0.439043\tvalid_1's binary_logloss: 0.482484\n",
      "Early stopping, best iteration is:\n",
      "[892]\ttraining's binary_logloss: 0.43905\tvalid_1's binary_logloss: 0.482482\n",
      "===== ACCURACY SCORE 0.785451 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510222\tvalid_1's binary_logloss: 0.530296\n",
      "[200]\ttraining's binary_logloss: 0.469993\tvalid_1's binary_logloss: 0.498812\n",
      "[300]\ttraining's binary_logloss: 0.456464\tvalid_1's binary_logloss: 0.492661\n",
      "[400]\ttraining's binary_logloss: 0.450559\tvalid_1's binary_logloss: 0.491333\n",
      "[500]\ttraining's binary_logloss: 0.447202\tvalid_1's binary_logloss: 0.491119\n",
      "[600]\ttraining's binary_logloss: 0.444928\tvalid_1's binary_logloss: 0.490795\n",
      "[700]\ttraining's binary_logloss: 0.44346\tvalid_1's binary_logloss: 0.49079\n",
      "[800]\ttraining's binary_logloss: 0.442388\tvalid_1's binary_logloss: 0.490641\n",
      "[900]\ttraining's binary_logloss: 0.441541\tvalid_1's binary_logloss: 0.49064\n",
      "[1000]\ttraining's binary_logloss: 0.440822\tvalid_1's binary_logloss: 0.49051\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440822\tvalid_1's binary_logloss: 0.49051\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440749\tvalid_1's binary_logloss: 0.490503\n",
      "[1200]\ttraining's binary_logloss: 0.440681\tvalid_1's binary_logloss: 0.490501\n",
      "[1300]\ttraining's binary_logloss: 0.440612\tvalid_1's binary_logloss: 0.490491\n",
      "[1400]\ttraining's binary_logloss: 0.440547\tvalid_1's binary_logloss: 0.490493\n",
      "Early stopping, best iteration is:\n",
      "[1310]\ttraining's binary_logloss: 0.440606\tvalid_1's binary_logloss: 0.49049\n",
      "===== ACCURACY SCORE 0.779305 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509576\tvalid_1's binary_logloss: 0.534077\n",
      "[200]\ttraining's binary_logloss: 0.469096\tvalid_1's binary_logloss: 0.504152\n",
      "[300]\ttraining's binary_logloss: 0.455521\tvalid_1's binary_logloss: 0.49867\n",
      "[400]\ttraining's binary_logloss: 0.449517\tvalid_1's binary_logloss: 0.497734\n",
      "[500]\ttraining's binary_logloss: 0.446105\tvalid_1's binary_logloss: 0.497308\n",
      "[600]\ttraining's binary_logloss: 0.443821\tvalid_1's binary_logloss: 0.496965\n",
      "[700]\ttraining's binary_logloss: 0.442329\tvalid_1's binary_logloss: 0.496747\n",
      "[800]\ttraining's binary_logloss: 0.441245\tvalid_1's binary_logloss: 0.496641\n",
      "[900]\ttraining's binary_logloss: 0.4404\tvalid_1's binary_logloss: 0.496381\n",
      "[1000]\ttraining's binary_logloss: 0.43968\tvalid_1's binary_logloss: 0.496214\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.43968\tvalid_1's binary_logloss: 0.496214\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439614\tvalid_1's binary_logloss: 0.496201\n",
      "[1200]\ttraining's binary_logloss: 0.439546\tvalid_1's binary_logloss: 0.496193\n",
      "[1300]\ttraining's binary_logloss: 0.439481\tvalid_1's binary_logloss: 0.496179\n",
      "[1400]\ttraining's binary_logloss: 0.439414\tvalid_1's binary_logloss: 0.496175\n",
      "Early stopping, best iteration is:\n",
      "[1348]\ttraining's binary_logloss: 0.43945\tvalid_1's binary_logloss: 0.49617\n",
      "===== ACCURACY SCORE 0.775058 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509798\tvalid_1's binary_logloss: 0.531477\n",
      "[200]\ttraining's binary_logloss: 0.469541\tvalid_1's binary_logloss: 0.501157\n",
      "[300]\ttraining's binary_logloss: 0.4559\tvalid_1's binary_logloss: 0.495227\n",
      "[400]\ttraining's binary_logloss: 0.449943\tvalid_1's binary_logloss: 0.494233\n",
      "[500]\ttraining's binary_logloss: 0.446446\tvalid_1's binary_logloss: 0.494068\n",
      "[600]\ttraining's binary_logloss: 0.444186\tvalid_1's binary_logloss: 0.494094\n",
      "Early stopping, best iteration is:\n",
      "[534]\ttraining's binary_logloss: 0.445541\tvalid_1's binary_logloss: 0.493981\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.445391\tvalid_1's binary_logloss: 0.493983\n",
      "[700]\ttraining's binary_logloss: 0.44517\tvalid_1's binary_logloss: 0.493967\n",
      "[800]\ttraining's binary_logloss: 0.444946\tvalid_1's binary_logloss: 0.493954\n",
      "[900]\ttraining's binary_logloss: 0.444741\tvalid_1's binary_logloss: 0.493941\n",
      "[1000]\ttraining's binary_logloss: 0.444544\tvalid_1's binary_logloss: 0.493946\n",
      "[1100]\ttraining's binary_logloss: 0.444352\tvalid_1's binary_logloss: 0.493931\n",
      "Early stopping, best iteration is:\n",
      "[1087]\ttraining's binary_logloss: 0.444377\tvalid_1's binary_logloss: 0.493926\n",
      "===== ACCURACY SCORE 0.769589 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508521\tvalid_1's binary_logloss: 0.529989\n",
      "[200]\ttraining's binary_logloss: 0.467664\tvalid_1's binary_logloss: 0.498959\n",
      "[300]\ttraining's binary_logloss: 0.453696\tvalid_1's binary_logloss: 0.493382\n",
      "[400]\ttraining's binary_logloss: 0.447543\tvalid_1's binary_logloss: 0.492845\n",
      "Early stopping, best iteration is:\n",
      "[370]\ttraining's binary_logloss: 0.448941\tvalid_1's binary_logloss: 0.492717\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.448792\tvalid_1's binary_logloss: 0.492712\n",
      "Early stopping, best iteration is:\n",
      "[397]\ttraining's binary_logloss: 0.448807\tvalid_1's binary_logloss: 0.492709\n",
      "===== ACCURACY SCORE 0.777548 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509137\tvalid_1's binary_logloss: 0.523366\n",
      "[200]\ttraining's binary_logloss: 0.468581\tvalid_1's binary_logloss: 0.488327\n",
      "[300]\ttraining's binary_logloss: 0.454867\tvalid_1's binary_logloss: 0.480256\n",
      "[400]\ttraining's binary_logloss: 0.44887\tvalid_1's binary_logloss: 0.478134\n",
      "[500]\ttraining's binary_logloss: 0.445518\tvalid_1's binary_logloss: 0.477265\n",
      "[600]\ttraining's binary_logloss: 0.44325\tvalid_1's binary_logloss: 0.476692\n",
      "[700]\ttraining's binary_logloss: 0.441771\tvalid_1's binary_logloss: 0.476354\n",
      "[800]\ttraining's binary_logloss: 0.440715\tvalid_1's binary_logloss: 0.476151\n",
      "[900]\ttraining's binary_logloss: 0.439885\tvalid_1's binary_logloss: 0.475963\n",
      "[1000]\ttraining's binary_logloss: 0.439167\tvalid_1's binary_logloss: 0.475768\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439167\tvalid_1's binary_logloss: 0.475768\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439102\tvalid_1's binary_logloss: 0.475751\n",
      "[1200]\ttraining's binary_logloss: 0.439039\tvalid_1's binary_logloss: 0.475722\n",
      "[1300]\ttraining's binary_logloss: 0.438973\tvalid_1's binary_logloss: 0.475697\n",
      "[1400]\ttraining's binary_logloss: 0.438908\tvalid_1's binary_logloss: 0.475689\n",
      "[1500]\ttraining's binary_logloss: 0.438843\tvalid_1's binary_logloss: 0.475669\n",
      "[1600]\ttraining's binary_logloss: 0.438781\tvalid_1's binary_logloss: 0.475658\n",
      "[1700]\ttraining's binary_logloss: 0.438719\tvalid_1's binary_logloss: 0.47564\n",
      "[1800]\ttraining's binary_logloss: 0.438657\tvalid_1's binary_logloss: 0.475628\n",
      "[1900]\ttraining's binary_logloss: 0.438598\tvalid_1's binary_logloss: 0.475616\n",
      "[2000]\ttraining's binary_logloss: 0.438536\tvalid_1's binary_logloss: 0.475596\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.438536\tvalid_1's binary_logloss: 0.475596\n",
      "===== ACCURACY SCORE 0.786034 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.780050 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509327\tvalid_1's binary_logloss: 0.529073\n",
      "[200]\ttraining's binary_logloss: 0.469025\tvalid_1's binary_logloss: 0.498784\n",
      "[300]\ttraining's binary_logloss: 0.45526\tvalid_1's binary_logloss: 0.493658\n",
      "[400]\ttraining's binary_logloss: 0.449204\tvalid_1's binary_logloss: 0.493287\n",
      "Early stopping, best iteration is:\n",
      "[374]\ttraining's binary_logloss: 0.450394\tvalid_1's binary_logloss: 0.493197\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.450264\tvalid_1's binary_logloss: 0.493204\n",
      "Early stopping, best iteration is:\n",
      "[375]\ttraining's binary_logloss: 0.450388\tvalid_1's binary_logloss: 0.493196\n",
      "===== ACCURACY SCORE 0.776010 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509663\tvalid_1's binary_logloss: 0.525251\n",
      "[200]\ttraining's binary_logloss: 0.469367\tvalid_1's binary_logloss: 0.491594\n",
      "[300]\ttraining's binary_logloss: 0.455834\tvalid_1's binary_logloss: 0.484141\n",
      "[400]\ttraining's binary_logloss: 0.449824\tvalid_1's binary_logloss: 0.482205\n",
      "[500]\ttraining's binary_logloss: 0.446274\tvalid_1's binary_logloss: 0.481654\n",
      "[600]\ttraining's binary_logloss: 0.444019\tvalid_1's binary_logloss: 0.48134\n",
      "[700]\ttraining's binary_logloss: 0.442508\tvalid_1's binary_logloss: 0.481256\n",
      "[800]\ttraining's binary_logloss: 0.44139\tvalid_1's binary_logloss: 0.481221\n",
      "Early stopping, best iteration is:\n",
      "[743]\ttraining's binary_logloss: 0.441983\tvalid_1's binary_logloss: 0.481167\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.441917\tvalid_1's binary_logloss: 0.481159\n",
      "[900]\ttraining's binary_logloss: 0.441807\tvalid_1's binary_logloss: 0.481156\n",
      "Early stopping, best iteration is:\n",
      "[879]\ttraining's binary_logloss: 0.44183\tvalid_1's binary_logloss: 0.481151\n",
      "===== ACCURACY SCORE 0.784312 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509269\tvalid_1's binary_logloss: 0.531281\n",
      "[200]\ttraining's binary_logloss: 0.468766\tvalid_1's binary_logloss: 0.499783\n",
      "[300]\ttraining's binary_logloss: 0.454993\tvalid_1's binary_logloss: 0.493612\n",
      "[400]\ttraining's binary_logloss: 0.44896\tvalid_1's binary_logloss: 0.492742\n",
      "[500]\ttraining's binary_logloss: 0.445493\tvalid_1's binary_logloss: 0.492555\n",
      "[600]\ttraining's binary_logloss: 0.443255\tvalid_1's binary_logloss: 0.492376\n",
      "Early stopping, best iteration is:\n",
      "[577]\ttraining's binary_logloss: 0.443675\tvalid_1's binary_logloss: 0.492353\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.443629\tvalid_1's binary_logloss: 0.492352\n",
      "[700]\ttraining's binary_logloss: 0.443436\tvalid_1's binary_logloss: 0.492338\n",
      "[800]\ttraining's binary_logloss: 0.443248\tvalid_1's binary_logloss: 0.492343\n",
      "Early stopping, best iteration is:\n",
      "[705]\ttraining's binary_logloss: 0.443426\tvalid_1's binary_logloss: 0.492334\n",
      "===== ACCURACY SCORE 0.776549 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50905\tvalid_1's binary_logloss: 0.528434\n",
      "[200]\ttraining's binary_logloss: 0.468532\tvalid_1's binary_logloss: 0.49595\n",
      "[300]\ttraining's binary_logloss: 0.454709\tvalid_1's binary_logloss: 0.488875\n",
      "[400]\ttraining's binary_logloss: 0.448782\tvalid_1's binary_logloss: 0.487387\n",
      "[500]\ttraining's binary_logloss: 0.445261\tvalid_1's binary_logloss: 0.486744\n",
      "[600]\ttraining's binary_logloss: 0.442967\tvalid_1's binary_logloss: 0.486243\n",
      "[700]\ttraining's binary_logloss: 0.441432\tvalid_1's binary_logloss: 0.486063\n",
      "[800]\ttraining's binary_logloss: 0.44033\tvalid_1's binary_logloss: 0.485822\n",
      "[900]\ttraining's binary_logloss: 0.439445\tvalid_1's binary_logloss: 0.485722\n",
      "[1000]\ttraining's binary_logloss: 0.438707\tvalid_1's binary_logloss: 0.485713\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.438707\tvalid_1's binary_logloss: 0.485713\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.438639\tvalid_1's binary_logloss: 0.485704\n",
      "[1200]\ttraining's binary_logloss: 0.438569\tvalid_1's binary_logloss: 0.485699\n",
      "[1300]\ttraining's binary_logloss: 0.438502\tvalid_1's binary_logloss: 0.485691\n",
      "Early stopping, best iteration is:\n",
      "[1287]\ttraining's binary_logloss: 0.438511\tvalid_1's binary_logloss: 0.485688\n",
      "===== ACCURACY SCORE 0.778834 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510437\tvalid_1's binary_logloss: 0.526714\n",
      "[200]\ttraining's binary_logloss: 0.470228\tvalid_1's binary_logloss: 0.492921\n",
      "[300]\ttraining's binary_logloss: 0.456559\tvalid_1's binary_logloss: 0.485498\n",
      "[400]\ttraining's binary_logloss: 0.450552\tvalid_1's binary_logloss: 0.48369\n",
      "[500]\ttraining's binary_logloss: 0.446986\tvalid_1's binary_logloss: 0.483248\n",
      "[600]\ttraining's binary_logloss: 0.444681\tvalid_1's binary_logloss: 0.482979\n",
      "[700]\ttraining's binary_logloss: 0.443168\tvalid_1's binary_logloss: 0.482906\n",
      "[800]\ttraining's binary_logloss: 0.442051\tvalid_1's binary_logloss: 0.482778\n",
      "[900]\ttraining's binary_logloss: 0.441182\tvalid_1's binary_logloss: 0.482795\n",
      "Early stopping, best iteration is:\n",
      "[830]\ttraining's binary_logloss: 0.441761\tvalid_1's binary_logloss: 0.482744\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[900]\ttraining's binary_logloss: 0.441699\tvalid_1's binary_logloss: 0.482739\n",
      "[1000]\ttraining's binary_logloss: 0.441609\tvalid_1's binary_logloss: 0.482737\n",
      "[1100]\ttraining's binary_logloss: 0.441521\tvalid_1's binary_logloss: 0.482727\n",
      "[1200]\ttraining's binary_logloss: 0.441438\tvalid_1's binary_logloss: 0.482718\n",
      "[1300]\ttraining's binary_logloss: 0.441356\tvalid_1's binary_logloss: 0.48272\n",
      "[1400]\ttraining's binary_logloss: 0.441274\tvalid_1's binary_logloss: 0.482715\n",
      "Early stopping, best iteration is:\n",
      "[1329]\ttraining's binary_logloss: 0.441332\tvalid_1's binary_logloss: 0.482712\n",
      "===== ACCURACY SCORE 0.780456 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50959\tvalid_1's binary_logloss: 0.528749\n",
      "[200]\ttraining's binary_logloss: 0.469382\tvalid_1's binary_logloss: 0.49733\n",
      "[300]\ttraining's binary_logloss: 0.455848\tvalid_1's binary_logloss: 0.491143\n",
      "[400]\ttraining's binary_logloss: 0.449881\tvalid_1's binary_logloss: 0.490027\n",
      "[500]\ttraining's binary_logloss: 0.446482\tvalid_1's binary_logloss: 0.4898\n",
      "[600]\ttraining's binary_logloss: 0.444204\tvalid_1's binary_logloss: 0.489584\n",
      "[700]\ttraining's binary_logloss: 0.442743\tvalid_1's binary_logloss: 0.489562\n",
      "[800]\ttraining's binary_logloss: 0.441649\tvalid_1's binary_logloss: 0.489442\n",
      "[900]\ttraining's binary_logloss: 0.440789\tvalid_1's binary_logloss: 0.489414\n",
      "[1000]\ttraining's binary_logloss: 0.440077\tvalid_1's binary_logloss: 0.489311\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440077\tvalid_1's binary_logloss: 0.489311\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440009\tvalid_1's binary_logloss: 0.489309\n",
      "[1200]\ttraining's binary_logloss: 0.43994\tvalid_1's binary_logloss: 0.489298\n",
      "[1300]\ttraining's binary_logloss: 0.439874\tvalid_1's binary_logloss: 0.489286\n",
      "[1400]\ttraining's binary_logloss: 0.439811\tvalid_1's binary_logloss: 0.489275\n",
      "[1500]\ttraining's binary_logloss: 0.439743\tvalid_1's binary_logloss: 0.489267\n",
      "[1600]\ttraining's binary_logloss: 0.43968\tvalid_1's binary_logloss: 0.48926\n",
      "[1700]\ttraining's binary_logloss: 0.439614\tvalid_1's binary_logloss: 0.489255\n",
      "[1800]\ttraining's binary_logloss: 0.43955\tvalid_1's binary_logloss: 0.489245\n",
      "[1900]\ttraining's binary_logloss: 0.439486\tvalid_1's binary_logloss: 0.489241\n",
      "[2000]\ttraining's binary_logloss: 0.439426\tvalid_1's binary_logloss: 0.489232\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439426\tvalid_1's binary_logloss: 0.489232\n",
      "===== ACCURACY SCORE 0.777577 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509325\tvalid_1's binary_logloss: 0.526597\n",
      "[200]\ttraining's binary_logloss: 0.468667\tvalid_1's binary_logloss: 0.493735\n",
      "[300]\ttraining's binary_logloss: 0.454988\tvalid_1's binary_logloss: 0.486959\n",
      "[400]\ttraining's binary_logloss: 0.44898\tvalid_1's binary_logloss: 0.485619\n",
      "[500]\ttraining's binary_logloss: 0.445487\tvalid_1's binary_logloss: 0.485377\n",
      "[600]\ttraining's binary_logloss: 0.443192\tvalid_1's binary_logloss: 0.485258\n",
      "Early stopping, best iteration is:\n",
      "[575]\ttraining's binary_logloss: 0.443649\tvalid_1's binary_logloss: 0.485198\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.443599\tvalid_1's binary_logloss: 0.485195\n",
      "[700]\ttraining's binary_logloss: 0.443411\tvalid_1's binary_logloss: 0.485194\n",
      "[800]\ttraining's binary_logloss: 0.44323\tvalid_1's binary_logloss: 0.485192\n",
      "[900]\ttraining's binary_logloss: 0.443057\tvalid_1's binary_logloss: 0.485189\n",
      "[1000]\ttraining's binary_logloss: 0.442892\tvalid_1's binary_logloss: 0.485188\n",
      "Early stopping, best iteration is:\n",
      "[975]\ttraining's binary_logloss: 0.442929\tvalid_1's binary_logloss: 0.485183\n",
      "===== ACCURACY SCORE 0.783518 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508848\tvalid_1's binary_logloss: 0.527858\n",
      "[200]\ttraining's binary_logloss: 0.468314\tvalid_1's binary_logloss: 0.494\n",
      "[300]\ttraining's binary_logloss: 0.454732\tvalid_1's binary_logloss: 0.486871\n",
      "[400]\ttraining's binary_logloss: 0.448809\tvalid_1's binary_logloss: 0.48513\n",
      "[500]\ttraining's binary_logloss: 0.44533\tvalid_1's binary_logloss: 0.484624\n",
      "[600]\ttraining's binary_logloss: 0.44306\tvalid_1's binary_logloss: 0.48412\n",
      "[700]\ttraining's binary_logloss: 0.441544\tvalid_1's binary_logloss: 0.483899\n",
      "[800]\ttraining's binary_logloss: 0.440471\tvalid_1's binary_logloss: 0.483721\n",
      "[900]\ttraining's binary_logloss: 0.439607\tvalid_1's binary_logloss: 0.483635\n",
      "[1000]\ttraining's binary_logloss: 0.438891\tvalid_1's binary_logloss: 0.483556\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.438891\tvalid_1's binary_logloss: 0.483556\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.438817\tvalid_1's binary_logloss: 0.483544\n",
      "[1200]\ttraining's binary_logloss: 0.438747\tvalid_1's binary_logloss: 0.483536\n",
      "[1300]\ttraining's binary_logloss: 0.43868\tvalid_1's binary_logloss: 0.483536\n",
      "Early stopping, best iteration is:\n",
      "[1222]\ttraining's binary_logloss: 0.438732\tvalid_1's binary_logloss: 0.483534\n",
      "===== ACCURACY SCORE 0.783979 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509099\tvalid_1's binary_logloss: 0.531944\n",
      "[200]\ttraining's binary_logloss: 0.46838\tvalid_1's binary_logloss: 0.501359\n",
      "[300]\ttraining's binary_logloss: 0.454581\tvalid_1's binary_logloss: 0.496353\n",
      "[400]\ttraining's binary_logloss: 0.448444\tvalid_1's binary_logloss: 0.495895\n",
      "Early stopping, best iteration is:\n",
      "[368]\ttraining's binary_logloss: 0.44997\tvalid_1's binary_logloss: 0.495827\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.4498\tvalid_1's binary_logloss: 0.495819\n",
      "[500]\ttraining's binary_logloss: 0.449303\tvalid_1's binary_logloss: 0.495809\n",
      "[600]\ttraining's binary_logloss: 0.448837\tvalid_1's binary_logloss: 0.495827\n",
      "Early stopping, best iteration is:\n",
      "[520]\ttraining's binary_logloss: 0.449208\tvalid_1's binary_logloss: 0.495803\n",
      "===== ACCURACY SCORE 0.774049 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509641\tvalid_1's binary_logloss: 0.526256\n",
      "[200]\ttraining's binary_logloss: 0.469497\tvalid_1's binary_logloss: 0.493268\n",
      "[300]\ttraining's binary_logloss: 0.456011\tvalid_1's binary_logloss: 0.486517\n",
      "[400]\ttraining's binary_logloss: 0.450112\tvalid_1's binary_logloss: 0.484801\n",
      "[500]\ttraining's binary_logloss: 0.446712\tvalid_1's binary_logloss: 0.484253\n",
      "[600]\ttraining's binary_logloss: 0.444341\tvalid_1's binary_logloss: 0.483853\n",
      "[700]\ttraining's binary_logloss: 0.442797\tvalid_1's binary_logloss: 0.483615\n",
      "[800]\ttraining's binary_logloss: 0.441679\tvalid_1's binary_logloss: 0.483667\n",
      "Early stopping, best iteration is:\n",
      "[726]\ttraining's binary_logloss: 0.442463\tvalid_1's binary_logloss: 0.483581\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.442375\tvalid_1's binary_logloss: 0.483566\n",
      "[900]\ttraining's binary_logloss: 0.442266\tvalid_1's binary_logloss: 0.483567\n",
      "Early stopping, best iteration is:\n",
      "[862]\ttraining's binary_logloss: 0.442306\tvalid_1's binary_logloss: 0.483561\n",
      "===== ACCURACY SCORE 0.778959 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779430 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.507928\tvalid_1's binary_logloss: 0.52676\n",
      "[200]\ttraining's binary_logloss: 0.467267\tvalid_1's binary_logloss: 0.495035\n",
      "[300]\ttraining's binary_logloss: 0.453586\tvalid_1's binary_logloss: 0.488695\n",
      "[400]\ttraining's binary_logloss: 0.447597\tvalid_1's binary_logloss: 0.487606\n",
      "[500]\ttraining's binary_logloss: 0.444218\tvalid_1's binary_logloss: 0.487295\n",
      "[600]\ttraining's binary_logloss: 0.441953\tvalid_1's binary_logloss: 0.486927\n",
      "[700]\ttraining's binary_logloss: 0.440476\tvalid_1's binary_logloss: 0.486705\n",
      "[800]\ttraining's binary_logloss: 0.439386\tvalid_1's binary_logloss: 0.486578\n",
      "[900]\ttraining's binary_logloss: 0.438512\tvalid_1's binary_logloss: 0.486465\n",
      "[1000]\ttraining's binary_logloss: 0.437796\tvalid_1's binary_logloss: 0.486402\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.437796\tvalid_1's binary_logloss: 0.486402\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.437726\tvalid_1's binary_logloss: 0.486388\n",
      "[1200]\ttraining's binary_logloss: 0.437662\tvalid_1's binary_logloss: 0.48638\n",
      "[1300]\ttraining's binary_logloss: 0.437596\tvalid_1's binary_logloss: 0.486367\n",
      "[1400]\ttraining's binary_logloss: 0.437533\tvalid_1's binary_logloss: 0.486372\n",
      "Early stopping, best iteration is:\n",
      "[1308]\ttraining's binary_logloss: 0.437591\tvalid_1's binary_logloss: 0.486365\n",
      "===== ACCURACY SCORE 0.780343 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508912\tvalid_1's binary_logloss: 0.530875\n",
      "[200]\ttraining's binary_logloss: 0.468396\tvalid_1's binary_logloss: 0.499542\n",
      "[300]\ttraining's binary_logloss: 0.454513\tvalid_1's binary_logloss: 0.493272\n",
      "[400]\ttraining's binary_logloss: 0.448404\tvalid_1's binary_logloss: 0.492416\n",
      "[500]\ttraining's binary_logloss: 0.444894\tvalid_1's binary_logloss: 0.492584\n",
      "Early stopping, best iteration is:\n",
      "[400]\ttraining's binary_logloss: 0.448404\tvalid_1's binary_logloss: 0.492416\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.447992\tvalid_1's binary_logloss: 0.492388\n",
      "[600]\ttraining's binary_logloss: 0.4476\tvalid_1's binary_logloss: 0.492396\n",
      "Early stopping, best iteration is:\n",
      "[527]\ttraining's binary_logloss: 0.447883\tvalid_1's binary_logloss: 0.492376\n",
      "===== ACCURACY SCORE 0.776677 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509784\tvalid_1's binary_logloss: 0.52942\n",
      "[200]\ttraining's binary_logloss: 0.46947\tvalid_1's binary_logloss: 0.497004\n",
      "[300]\ttraining's binary_logloss: 0.455687\tvalid_1's binary_logloss: 0.490139\n",
      "[400]\ttraining's binary_logloss: 0.449523\tvalid_1's binary_logloss: 0.488747\n",
      "[500]\ttraining's binary_logloss: 0.445876\tvalid_1's binary_logloss: 0.488258\n",
      "[600]\ttraining's binary_logloss: 0.44357\tvalid_1's binary_logloss: 0.488129\n",
      "[700]\ttraining's binary_logloss: 0.44205\tvalid_1's binary_logloss: 0.488236\n",
      "Early stopping, best iteration is:\n",
      "[613]\ttraining's binary_logloss: 0.443339\tvalid_1's binary_logloss: 0.488102\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.443197\tvalid_1's binary_logloss: 0.488103\n",
      "Early stopping, best iteration is:\n",
      "[639]\ttraining's binary_logloss: 0.443294\tvalid_1's binary_logloss: 0.488094\n",
      "===== ACCURACY SCORE 0.781341 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509093\tvalid_1's binary_logloss: 0.524064\n",
      "[200]\ttraining's binary_logloss: 0.468716\tvalid_1's binary_logloss: 0.48952\n",
      "[300]\ttraining's binary_logloss: 0.455132\tvalid_1's binary_logloss: 0.482214\n",
      "[400]\ttraining's binary_logloss: 0.449211\tvalid_1's binary_logloss: 0.48062\n",
      "[500]\ttraining's binary_logloss: 0.445776\tvalid_1's binary_logloss: 0.480211\n",
      "[600]\ttraining's binary_logloss: 0.443504\tvalid_1's binary_logloss: 0.479977\n",
      "[700]\ttraining's binary_logloss: 0.442022\tvalid_1's binary_logloss: 0.479944\n",
      "[800]\ttraining's binary_logloss: 0.440885\tvalid_1's binary_logloss: 0.479914\n",
      "Early stopping, best iteration is:\n",
      "[718]\ttraining's binary_logloss: 0.441779\tvalid_1's binary_logloss: 0.479849\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.441684\tvalid_1's binary_logloss: 0.479861\n",
      "Early stopping, best iteration is:\n",
      "[730]\ttraining's binary_logloss: 0.441764\tvalid_1's binary_logloss: 0.479844\n",
      "===== ACCURACY SCORE 0.784618 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510402\tvalid_1's binary_logloss: 0.526065\n",
      "[200]\ttraining's binary_logloss: 0.470301\tvalid_1's binary_logloss: 0.49187\n",
      "[300]\ttraining's binary_logloss: 0.456637\tvalid_1's binary_logloss: 0.484049\n",
      "[400]\ttraining's binary_logloss: 0.450618\tvalid_1's binary_logloss: 0.482318\n",
      "[500]\ttraining's binary_logloss: 0.447126\tvalid_1's binary_logloss: 0.481988\n",
      "[600]\ttraining's binary_logloss: 0.444786\tvalid_1's binary_logloss: 0.481694\n",
      "Early stopping, best iteration is:\n",
      "[587]\ttraining's binary_logloss: 0.445023\tvalid_1's binary_logloss: 0.48166\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.444997\tvalid_1's binary_logloss: 0.481658\n",
      "[700]\ttraining's binary_logloss: 0.44482\tvalid_1's binary_logloss: 0.481664\n",
      "Early stopping, best iteration is:\n",
      "[649]\ttraining's binary_logloss: 0.444906\tvalid_1's binary_logloss: 0.481651\n",
      "===== ACCURACY SCORE 0.783006 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509641\tvalid_1's binary_logloss: 0.530676\n",
      "[200]\ttraining's binary_logloss: 0.469422\tvalid_1's binary_logloss: 0.500772\n",
      "[300]\ttraining's binary_logloss: 0.455634\tvalid_1's binary_logloss: 0.495718\n",
      "[400]\ttraining's binary_logloss: 0.449588\tvalid_1's binary_logloss: 0.495211\n",
      "Early stopping, best iteration is:\n",
      "[371]\ttraining's binary_logloss: 0.450904\tvalid_1's binary_logloss: 0.495181\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.450762\tvalid_1's binary_logloss: 0.495184\n",
      "[500]\ttraining's binary_logloss: 0.450293\tvalid_1's binary_logloss: 0.495139\n",
      "[600]\ttraining's binary_logloss: 0.449847\tvalid_1's binary_logloss: 0.495131\n",
      "[700]\ttraining's binary_logloss: 0.449435\tvalid_1's binary_logloss: 0.495139\n",
      "Early stopping, best iteration is:\n",
      "[630]\ttraining's binary_logloss: 0.449722\tvalid_1's binary_logloss: 0.495117\n",
      "===== ACCURACY SCORE 0.779201 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509316\tvalid_1's binary_logloss: 0.522358\n",
      "[200]\ttraining's binary_logloss: 0.469149\tvalid_1's binary_logloss: 0.487613\n",
      "[300]\ttraining's binary_logloss: 0.455519\tvalid_1's binary_logloss: 0.479924\n",
      "[400]\ttraining's binary_logloss: 0.449652\tvalid_1's binary_logloss: 0.478074\n",
      "[500]\ttraining's binary_logloss: 0.446181\tvalid_1's binary_logloss: 0.477317\n",
      "[600]\ttraining's binary_logloss: 0.443957\tvalid_1's binary_logloss: 0.476731\n",
      "[700]\ttraining's binary_logloss: 0.442542\tvalid_1's binary_logloss: 0.476496\n",
      "[800]\ttraining's binary_logloss: 0.441477\tvalid_1's binary_logloss: 0.476447\n",
      "[900]\ttraining's binary_logloss: 0.440632\tvalid_1's binary_logloss: 0.476304\n",
      "[1000]\ttraining's binary_logloss: 0.439911\tvalid_1's binary_logloss: 0.47624\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439911\tvalid_1's binary_logloss: 0.47624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439842\tvalid_1's binary_logloss: 0.476237\n",
      "[1200]\ttraining's binary_logloss: 0.439775\tvalid_1's binary_logloss: 0.476235\n",
      "[1300]\ttraining's binary_logloss: 0.439709\tvalid_1's binary_logloss: 0.476233\n",
      "[1400]\ttraining's binary_logloss: 0.439639\tvalid_1's binary_logloss: 0.476227\n",
      "[1500]\ttraining's binary_logloss: 0.439575\tvalid_1's binary_logloss: 0.476222\n",
      "[1600]\ttraining's binary_logloss: 0.439512\tvalid_1's binary_logloss: 0.476222\n",
      "[1700]\ttraining's binary_logloss: 0.439449\tvalid_1's binary_logloss: 0.476217\n",
      "[1800]\ttraining's binary_logloss: 0.439387\tvalid_1's binary_logloss: 0.476214\n",
      "[1900]\ttraining's binary_logloss: 0.439327\tvalid_1's binary_logloss: 0.476206\n",
      "[2000]\ttraining's binary_logloss: 0.439265\tvalid_1's binary_logloss: 0.476192\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439265\tvalid_1's binary_logloss: 0.476192\n",
      "===== ACCURACY SCORE 0.785145 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509682\tvalid_1's binary_logloss: 0.530576\n",
      "[200]\ttraining's binary_logloss: 0.469285\tvalid_1's binary_logloss: 0.500108\n",
      "[300]\ttraining's binary_logloss: 0.455658\tvalid_1's binary_logloss: 0.494611\n",
      "[400]\ttraining's binary_logloss: 0.449661\tvalid_1's binary_logloss: 0.493647\n",
      "[500]\ttraining's binary_logloss: 0.44617\tvalid_1's binary_logloss: 0.493406\n",
      "[600]\ttraining's binary_logloss: 0.443896\tvalid_1's binary_logloss: 0.493241\n",
      "Early stopping, best iteration is:\n",
      "[587]\ttraining's binary_logloss: 0.444136\tvalid_1's binary_logloss: 0.493215\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.44411\tvalid_1's binary_logloss: 0.493214\n",
      "[700]\ttraining's binary_logloss: 0.443925\tvalid_1's binary_logloss: 0.493211\n",
      "[800]\ttraining's binary_logloss: 0.443743\tvalid_1's binary_logloss: 0.493199\n",
      "Early stopping, best iteration is:\n",
      "[769]\ttraining's binary_logloss: 0.443797\tvalid_1's binary_logloss: 0.493195\n",
      "===== ACCURACY SCORE 0.770777 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509508\tvalid_1's binary_logloss: 0.532239\n",
      "[200]\ttraining's binary_logloss: 0.469351\tvalid_1's binary_logloss: 0.501491\n",
      "[300]\ttraining's binary_logloss: 0.455897\tvalid_1's binary_logloss: 0.49578\n",
      "[400]\ttraining's binary_logloss: 0.449968\tvalid_1's binary_logloss: 0.495231\n",
      "Early stopping, best iteration is:\n",
      "[373]\ttraining's binary_logloss: 0.451192\tvalid_1's binary_logloss: 0.495172\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.451057\tvalid_1's binary_logloss: 0.49517\n",
      "[500]\ttraining's binary_logloss: 0.45059\tvalid_1's binary_logloss: 0.495152\n",
      "[600]\ttraining's binary_logloss: 0.45014\tvalid_1's binary_logloss: 0.495165\n",
      "Early stopping, best iteration is:\n",
      "[510]\ttraining's binary_logloss: 0.450546\tvalid_1's binary_logloss: 0.495147\n",
      "===== ACCURACY SCORE 0.771516 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509047\tvalid_1's binary_logloss: 0.526864\n",
      "[200]\ttraining's binary_logloss: 0.468647\tvalid_1's binary_logloss: 0.494216\n",
      "[300]\ttraining's binary_logloss: 0.454957\tvalid_1's binary_logloss: 0.487045\n",
      "[400]\ttraining's binary_logloss: 0.449032\tvalid_1's binary_logloss: 0.485342\n",
      "[500]\ttraining's binary_logloss: 0.445577\tvalid_1's binary_logloss: 0.484762\n",
      "[600]\ttraining's binary_logloss: 0.443318\tvalid_1's binary_logloss: 0.484286\n",
      "[700]\ttraining's binary_logloss: 0.441814\tvalid_1's binary_logloss: 0.484035\n",
      "[800]\ttraining's binary_logloss: 0.440711\tvalid_1's binary_logloss: 0.483982\n",
      "Early stopping, best iteration is:\n",
      "[776]\ttraining's binary_logloss: 0.440941\tvalid_1's binary_logloss: 0.483938\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.440916\tvalid_1's binary_logloss: 0.483932\n",
      "[900]\ttraining's binary_logloss: 0.440814\tvalid_1's binary_logloss: 0.483926\n",
      "[1000]\ttraining's binary_logloss: 0.440716\tvalid_1's binary_logloss: 0.483921\n",
      "[1100]\ttraining's binary_logloss: 0.440618\tvalid_1's binary_logloss: 0.483904\n",
      "[1200]\ttraining's binary_logloss: 0.440521\tvalid_1's binary_logloss: 0.483898\n",
      "[1300]\ttraining's binary_logloss: 0.440431\tvalid_1's binary_logloss: 0.483896\n",
      "[1400]\ttraining's binary_logloss: 0.440343\tvalid_1's binary_logloss: 0.483891\n",
      "[1500]\ttraining's binary_logloss: 0.440255\tvalid_1's binary_logloss: 0.483884\n",
      "[1600]\ttraining's binary_logloss: 0.44017\tvalid_1's binary_logloss: 0.483885\n",
      "Early stopping, best iteration is:\n",
      "[1524]\ttraining's binary_logloss: 0.440234\tvalid_1's binary_logloss: 0.48388\n",
      "===== ACCURACY SCORE 0.779734 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779210 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510262\tvalid_1's binary_logloss: 0.528855\n",
      "[200]\ttraining's binary_logloss: 0.470364\tvalid_1's binary_logloss: 0.496385\n",
      "[300]\ttraining's binary_logloss: 0.456802\tvalid_1's binary_logloss: 0.489734\n",
      "[400]\ttraining's binary_logloss: 0.450764\tvalid_1's binary_logloss: 0.48854\n",
      "[500]\ttraining's binary_logloss: 0.44726\tvalid_1's binary_logloss: 0.488282\n",
      "[600]\ttraining's binary_logloss: 0.444978\tvalid_1's binary_logloss: 0.488256\n",
      "[700]\ttraining's binary_logloss: 0.44352\tvalid_1's binary_logloss: 0.488289\n",
      "Early stopping, best iteration is:\n",
      "[682]\ttraining's binary_logloss: 0.443754\tvalid_1's binary_logloss: 0.488207\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.443732\tvalid_1's binary_logloss: 0.488202\n",
      "[800]\ttraining's binary_logloss: 0.443603\tvalid_1's binary_logloss: 0.488208\n",
      "Early stopping, best iteration is:\n",
      "[757]\ttraining's binary_logloss: 0.443657\tvalid_1's binary_logloss: 0.488201\n",
      "===== ACCURACY SCORE 0.780327 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509242\tvalid_1's binary_logloss: 0.528933\n",
      "[200]\ttraining's binary_logloss: 0.468766\tvalid_1's binary_logloss: 0.49743\n",
      "[300]\ttraining's binary_logloss: 0.454992\tvalid_1's binary_logloss: 0.491316\n",
      "[400]\ttraining's binary_logloss: 0.448979\tvalid_1's binary_logloss: 0.49008\n",
      "[500]\ttraining's binary_logloss: 0.445469\tvalid_1's binary_logloss: 0.489898\n",
      "[600]\ttraining's binary_logloss: 0.443192\tvalid_1's binary_logloss: 0.489682\n",
      "[700]\ttraining's binary_logloss: 0.441748\tvalid_1's binary_logloss: 0.489603\n",
      "[800]\ttraining's binary_logloss: 0.440626\tvalid_1's binary_logloss: 0.489574\n",
      "[900]\ttraining's binary_logloss: 0.439745\tvalid_1's binary_logloss: 0.489519\n",
      "[1000]\ttraining's binary_logloss: 0.439026\tvalid_1's binary_logloss: 0.489454\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439026\tvalid_1's binary_logloss: 0.489454\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.43896\tvalid_1's binary_logloss: 0.48945\n",
      "[1200]\ttraining's binary_logloss: 0.438894\tvalid_1's binary_logloss: 0.489443\n",
      "Early stopping, best iteration is:\n",
      "[1184]\ttraining's binary_logloss: 0.438903\tvalid_1's binary_logloss: 0.489442\n",
      "===== ACCURACY SCORE 0.780069 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510199\tvalid_1's binary_logloss: 0.530185\n",
      "[200]\ttraining's binary_logloss: 0.469958\tvalid_1's binary_logloss: 0.499846\n",
      "[300]\ttraining's binary_logloss: 0.456174\tvalid_1's binary_logloss: 0.493864\n",
      "[400]\ttraining's binary_logloss: 0.450078\tvalid_1's binary_logloss: 0.493034\n",
      "[500]\ttraining's binary_logloss: 0.446624\tvalid_1's binary_logloss: 0.493006\n",
      "Early stopping, best iteration is:\n",
      "[458]\ttraining's binary_logloss: 0.447916\tvalid_1's binary_logloss: 0.492884\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.447772\tvalid_1's binary_logloss: 0.492889\n",
      "Early stopping, best iteration is:\n",
      "[462]\ttraining's binary_logloss: 0.447901\tvalid_1's binary_logloss: 0.492884\n",
      "===== ACCURACY SCORE 0.771113 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508926\tvalid_1's binary_logloss: 0.531887\n",
      "[200]\ttraining's binary_logloss: 0.468471\tvalid_1's binary_logloss: 0.500614\n",
      "[300]\ttraining's binary_logloss: 0.454898\tvalid_1's binary_logloss: 0.494637\n",
      "[400]\ttraining's binary_logloss: 0.448939\tvalid_1's binary_logloss: 0.493463\n",
      "[500]\ttraining's binary_logloss: 0.445559\tvalid_1's binary_logloss: 0.493278\n",
      "[600]\ttraining's binary_logloss: 0.443361\tvalid_1's binary_logloss: 0.493036\n",
      "[700]\ttraining's binary_logloss: 0.441933\tvalid_1's binary_logloss: 0.492982\n",
      "[800]\ttraining's binary_logloss: 0.440882\tvalid_1's binary_logloss: 0.492827\n",
      "[900]\ttraining's binary_logloss: 0.44003\tvalid_1's binary_logloss: 0.49273\n",
      "[1000]\ttraining's binary_logloss: 0.439319\tvalid_1's binary_logloss: 0.492654\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439319\tvalid_1's binary_logloss: 0.492654\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439252\tvalid_1's binary_logloss: 0.49264\n",
      "[1200]\ttraining's binary_logloss: 0.439187\tvalid_1's binary_logloss: 0.49262\n",
      "[1300]\ttraining's binary_logloss: 0.439123\tvalid_1's binary_logloss: 0.4926\n",
      "[1400]\ttraining's binary_logloss: 0.439059\tvalid_1's binary_logloss: 0.4926\n",
      "Early stopping, best iteration is:\n",
      "[1313]\ttraining's binary_logloss: 0.439114\tvalid_1's binary_logloss: 0.492596\n",
      "===== ACCURACY SCORE 0.775529 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509398\tvalid_1's binary_logloss: 0.527324\n",
      "[200]\ttraining's binary_logloss: 0.46903\tvalid_1's binary_logloss: 0.494874\n",
      "[300]\ttraining's binary_logloss: 0.455591\tvalid_1's binary_logloss: 0.488738\n",
      "[400]\ttraining's binary_logloss: 0.449635\tvalid_1's binary_logloss: 0.487588\n",
      "[500]\ttraining's binary_logloss: 0.446237\tvalid_1's binary_logloss: 0.487353\n",
      "[600]\ttraining's binary_logloss: 0.443938\tvalid_1's binary_logloss: 0.486938\n",
      "[700]\ttraining's binary_logloss: 0.442441\tvalid_1's binary_logloss: 0.486767\n",
      "[800]\ttraining's binary_logloss: 0.441348\tvalid_1's binary_logloss: 0.486589\n",
      "[900]\ttraining's binary_logloss: 0.440478\tvalid_1's binary_logloss: 0.486461\n",
      "[1000]\ttraining's binary_logloss: 0.439735\tvalid_1's binary_logloss: 0.486319\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439735\tvalid_1's binary_logloss: 0.486319\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439664\tvalid_1's binary_logloss: 0.486313\n",
      "[1200]\ttraining's binary_logloss: 0.439595\tvalid_1's binary_logloss: 0.486307\n",
      "[1300]\ttraining's binary_logloss: 0.439528\tvalid_1's binary_logloss: 0.486291\n",
      "[1400]\ttraining's binary_logloss: 0.439462\tvalid_1's binary_logloss: 0.486282\n",
      "[1500]\ttraining's binary_logloss: 0.439394\tvalid_1's binary_logloss: 0.486266\n",
      "[1600]\ttraining's binary_logloss: 0.43933\tvalid_1's binary_logloss: 0.486255\n",
      "[1700]\ttraining's binary_logloss: 0.439265\tvalid_1's binary_logloss: 0.486244\n",
      "[1800]\ttraining's binary_logloss: 0.439203\tvalid_1's binary_logloss: 0.486231\n",
      "[1900]\ttraining's binary_logloss: 0.439139\tvalid_1's binary_logloss: 0.48622\n",
      "[2000]\ttraining's binary_logloss: 0.439077\tvalid_1's binary_logloss: 0.486214\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439077\tvalid_1's binary_logloss: 0.486214\n",
      "===== ACCURACY SCORE 0.779700 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509595\tvalid_1's binary_logloss: 0.527342\n",
      "[200]\ttraining's binary_logloss: 0.469303\tvalid_1's binary_logloss: 0.493668\n",
      "[300]\ttraining's binary_logloss: 0.455775\tvalid_1's binary_logloss: 0.486617\n",
      "[400]\ttraining's binary_logloss: 0.449951\tvalid_1's binary_logloss: 0.485365\n",
      "[500]\ttraining's binary_logloss: 0.446538\tvalid_1's binary_logloss: 0.485227\n",
      "[600]\ttraining's binary_logloss: 0.444321\tvalid_1's binary_logloss: 0.48484\n",
      "[700]\ttraining's binary_logloss: 0.442924\tvalid_1's binary_logloss: 0.484823\n",
      "[800]\ttraining's binary_logloss: 0.441855\tvalid_1's binary_logloss: 0.484705\n",
      "Early stopping, best iteration is:\n",
      "[778]\ttraining's binary_logloss: 0.442056\tvalid_1's binary_logloss: 0.484677\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.442034\tvalid_1's binary_logloss: 0.484669\n",
      "[900]\ttraining's binary_logloss: 0.44194\tvalid_1's binary_logloss: 0.484674\n",
      "Early stopping, best iteration is:\n",
      "[827]\ttraining's binary_logloss: 0.442008\tvalid_1's binary_logloss: 0.484668\n",
      "===== ACCURACY SCORE 0.783152 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509881\tvalid_1's binary_logloss: 0.527304\n",
      "[200]\ttraining's binary_logloss: 0.469734\tvalid_1's binary_logloss: 0.493478\n",
      "[300]\ttraining's binary_logloss: 0.456152\tvalid_1's binary_logloss: 0.486016\n",
      "[400]\ttraining's binary_logloss: 0.450215\tvalid_1's binary_logloss: 0.48435\n",
      "[500]\ttraining's binary_logloss: 0.44678\tvalid_1's binary_logloss: 0.483885\n",
      "[600]\ttraining's binary_logloss: 0.444511\tvalid_1's binary_logloss: 0.483696\n",
      "[700]\ttraining's binary_logloss: 0.443061\tvalid_1's binary_logloss: 0.483593\n",
      "[800]\ttraining's binary_logloss: 0.441981\tvalid_1's binary_logloss: 0.483484\n",
      "[900]\ttraining's binary_logloss: 0.441148\tvalid_1's binary_logloss: 0.483448\n",
      "[1000]\ttraining's binary_logloss: 0.440436\tvalid_1's binary_logloss: 0.483419\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440436\tvalid_1's binary_logloss: 0.483419\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440369\tvalid_1's binary_logloss: 0.483412\n",
      "Early stopping, best iteration is:\n",
      "[1099]\ttraining's binary_logloss: 0.440369\tvalid_1's binary_logloss: 0.483411\n",
      "===== ACCURACY SCORE 0.780498 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509306\tvalid_1's binary_logloss: 0.528539\n",
      "[200]\ttraining's binary_logloss: 0.46876\tvalid_1's binary_logloss: 0.49593\n",
      "[300]\ttraining's binary_logloss: 0.455146\tvalid_1's binary_logloss: 0.489167\n",
      "[400]\ttraining's binary_logloss: 0.44923\tvalid_1's binary_logloss: 0.487663\n",
      "[500]\ttraining's binary_logloss: 0.445864\tvalid_1's binary_logloss: 0.487613\n",
      "[600]\ttraining's binary_logloss: 0.44369\tvalid_1's binary_logloss: 0.487387\n",
      "[700]\ttraining's binary_logloss: 0.442236\tvalid_1's binary_logloss: 0.487204\n",
      "[800]\ttraining's binary_logloss: 0.441141\tvalid_1's binary_logloss: 0.487204\n",
      "Early stopping, best iteration is:\n",
      "[746]\ttraining's binary_logloss: 0.4417\tvalid_1's binary_logloss: 0.487159\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.441641\tvalid_1's binary_logloss: 0.487156\n",
      "[900]\ttraining's binary_logloss: 0.441534\tvalid_1's binary_logloss: 0.487152\n",
      "[1000]\ttraining's binary_logloss: 0.441428\tvalid_1's binary_logloss: 0.487126\n",
      "[1100]\ttraining's binary_logloss: 0.441325\tvalid_1's binary_logloss: 0.487106\n",
      "[1200]\ttraining's binary_logloss: 0.441225\tvalid_1's binary_logloss: 0.487096\n",
      "Early stopping, best iteration is:\n",
      "[1194]\ttraining's binary_logloss: 0.441231\tvalid_1's binary_logloss: 0.487094\n",
      "[100]\ttraining's binary_logloss: 0.509444\tvalid_1's binary_logloss: 0.531113\n",
      "[200]\ttraining's binary_logloss: 0.469222\tvalid_1's binary_logloss: 0.500752\n",
      "[300]\ttraining's binary_logloss: 0.455719\tvalid_1's binary_logloss: 0.495928\n",
      "[400]\ttraining's binary_logloss: 0.449705\tvalid_1's binary_logloss: 0.495804\n",
      "Early stopping, best iteration is:\n",
      "[346]\ttraining's binary_logloss: 0.452428\tvalid_1's binary_logloss: 0.495622\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.452113\tvalid_1's binary_logloss: 0.495602\n",
      "[500]\ttraining's binary_logloss: 0.451567\tvalid_1's binary_logloss: 0.495581\n",
      "Early stopping, best iteration is:\n",
      "[478]\ttraining's binary_logloss: 0.451681\tvalid_1's binary_logloss: 0.495574\n",
      "===== ACCURACY SCORE 0.774736 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509342\tvalid_1's binary_logloss: 0.524852\n",
      "[200]\ttraining's binary_logloss: 0.469014\tvalid_1's binary_logloss: 0.490594\n",
      "[300]\ttraining's binary_logloss: 0.455518\tvalid_1's binary_logloss: 0.482666\n",
      "[400]\ttraining's binary_logloss: 0.449517\tvalid_1's binary_logloss: 0.480769\n",
      "[500]\ttraining's binary_logloss: 0.446174\tvalid_1's binary_logloss: 0.480077\n",
      "[600]\ttraining's binary_logloss: 0.443934\tvalid_1's binary_logloss: 0.479554\n",
      "[700]\ttraining's binary_logloss: 0.442434\tvalid_1's binary_logloss: 0.479236\n",
      "[800]\ttraining's binary_logloss: 0.441298\tvalid_1's binary_logloss: 0.479031\n",
      "[900]\ttraining's binary_logloss: 0.440455\tvalid_1's binary_logloss: 0.478935\n",
      "[1000]\ttraining's binary_logloss: 0.439732\tvalid_1's binary_logloss: 0.478871\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439732\tvalid_1's binary_logloss: 0.478871\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439662\tvalid_1's binary_logloss: 0.478868\n",
      "[1200]\ttraining's binary_logloss: 0.43959\tvalid_1's binary_logloss: 0.478848\n",
      "[1300]\ttraining's binary_logloss: 0.439523\tvalid_1's binary_logloss: 0.478835\n",
      "[1400]\ttraining's binary_logloss: 0.439456\tvalid_1's binary_logloss: 0.478826\n",
      "[1500]\ttraining's binary_logloss: 0.43939\tvalid_1's binary_logloss: 0.478819\n",
      "[1600]\ttraining's binary_logloss: 0.439325\tvalid_1's binary_logloss: 0.478799\n",
      "[1700]\ttraining's binary_logloss: 0.439261\tvalid_1's binary_logloss: 0.478789\n",
      "[1800]\ttraining's binary_logloss: 0.439196\tvalid_1's binary_logloss: 0.478787\n",
      "[1900]\ttraining's binary_logloss: 0.439131\tvalid_1's binary_logloss: 0.478777\n",
      "[2000]\ttraining's binary_logloss: 0.439068\tvalid_1's binary_logloss: 0.478774\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439068\tvalid_1's binary_logloss: 0.478774\n",
      "===== ACCURACY SCORE 0.785343 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509307\tvalid_1's binary_logloss: 0.526443\n",
      "[200]\ttraining's binary_logloss: 0.469009\tvalid_1's binary_logloss: 0.493613\n",
      "[300]\ttraining's binary_logloss: 0.455541\tvalid_1's binary_logloss: 0.486743\n",
      "[400]\ttraining's binary_logloss: 0.44952\tvalid_1's binary_logloss: 0.485301\n",
      "[500]\ttraining's binary_logloss: 0.446103\tvalid_1's binary_logloss: 0.484844\n",
      "[600]\ttraining's binary_logloss: 0.44383\tvalid_1's binary_logloss: 0.484442\n",
      "[700]\ttraining's binary_logloss: 0.442311\tvalid_1's binary_logloss: 0.48418\n",
      "[800]\ttraining's binary_logloss: 0.441213\tvalid_1's binary_logloss: 0.483912\n",
      "[900]\ttraining's binary_logloss: 0.440349\tvalid_1's binary_logloss: 0.483876\n",
      "[1000]\ttraining's binary_logloss: 0.439613\tvalid_1's binary_logloss: 0.483647\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439613\tvalid_1's binary_logloss: 0.483647\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439544\tvalid_1's binary_logloss: 0.483638\n",
      "[1200]\ttraining's binary_logloss: 0.439478\tvalid_1's binary_logloss: 0.483626\n",
      "[1300]\ttraining's binary_logloss: 0.439412\tvalid_1's binary_logloss: 0.48361\n",
      "[1400]\ttraining's binary_logloss: 0.439347\tvalid_1's binary_logloss: 0.483601\n",
      "[1500]\ttraining's binary_logloss: 0.439283\tvalid_1's binary_logloss: 0.483592\n",
      "[1600]\ttraining's binary_logloss: 0.439218\tvalid_1's binary_logloss: 0.483579\n",
      "[1700]\ttraining's binary_logloss: 0.439158\tvalid_1's binary_logloss: 0.483573\n",
      "[1800]\ttraining's binary_logloss: 0.439093\tvalid_1's binary_logloss: 0.483564\n",
      "[1900]\ttraining's binary_logloss: 0.43903\tvalid_1's binary_logloss: 0.483557\n",
      "[2000]\ttraining's binary_logloss: 0.43897\tvalid_1's binary_logloss: 0.483545\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.43897\tvalid_1's binary_logloss: 0.483545\n",
      "===== ACCURACY SCORE 0.782722 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509756\tvalid_1's binary_logloss: 0.535239\n",
      "[200]\ttraining's binary_logloss: 0.469497\tvalid_1's binary_logloss: 0.504552\n",
      "[300]\ttraining's binary_logloss: 0.45601\tvalid_1's binary_logloss: 0.498261\n",
      "[400]\ttraining's binary_logloss: 0.450071\tvalid_1's binary_logloss: 0.496904\n",
      "[500]\ttraining's binary_logloss: 0.446672\tvalid_1's binary_logloss: 0.496521\n",
      "[600]\ttraining's binary_logloss: 0.444395\tvalid_1's binary_logloss: 0.49622\n",
      "[700]\ttraining's binary_logloss: 0.442885\tvalid_1's binary_logloss: 0.496053\n",
      "[800]\ttraining's binary_logloss: 0.441822\tvalid_1's binary_logloss: 0.495914\n",
      "[900]\ttraining's binary_logloss: 0.440978\tvalid_1's binary_logloss: 0.495845\n",
      "[1000]\ttraining's binary_logloss: 0.440229\tvalid_1's binary_logloss: 0.495672\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440229\tvalid_1's binary_logloss: 0.495672\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.44016\tvalid_1's binary_logloss: 0.495656\n",
      "[1200]\ttraining's binary_logloss: 0.440093\tvalid_1's binary_logloss: 0.495634\n",
      "[1300]\ttraining's binary_logloss: 0.440029\tvalid_1's binary_logloss: 0.495634\n",
      "[1400]\ttraining's binary_logloss: 0.439961\tvalid_1's binary_logloss: 0.495625\n",
      "[1500]\ttraining's binary_logloss: 0.439894\tvalid_1's binary_logloss: 0.49562\n",
      "[1600]\ttraining's binary_logloss: 0.43983\tvalid_1's binary_logloss: 0.49562\n",
      "Early stopping, best iteration is:\n",
      "[1512]\ttraining's binary_logloss: 0.439887\tvalid_1's binary_logloss: 0.495616\n",
      "===== ACCURACY SCORE 0.773483 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508785\tvalid_1's binary_logloss: 0.5287\n",
      "[200]\ttraining's binary_logloss: 0.468123\tvalid_1's binary_logloss: 0.496922\n",
      "[300]\ttraining's binary_logloss: 0.454429\tvalid_1's binary_logloss: 0.491013\n",
      "[400]\ttraining's binary_logloss: 0.448477\tvalid_1's binary_logloss: 0.49048\n",
      "Early stopping, best iteration is:\n",
      "[375]\ttraining's binary_logloss: 0.44957\tvalid_1's binary_logloss: 0.490455\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.44945\tvalid_1's binary_logloss: 0.490448\n",
      "[500]\ttraining's binary_logloss: 0.448997\tvalid_1's binary_logloss: 0.490442\n",
      "[600]\ttraining's binary_logloss: 0.448567\tvalid_1's binary_logloss: 0.490444\n",
      "Early stopping, best iteration is:\n",
      "[554]\ttraining's binary_logloss: 0.448767\tvalid_1's binary_logloss: 0.490436\n",
      "===== ACCURACY SCORE 0.781300 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510158\tvalid_1's binary_logloss: 0.52623\n",
      "[200]\ttraining's binary_logloss: 0.46998\tvalid_1's binary_logloss: 0.492204\n",
      "[300]\ttraining's binary_logloss: 0.456514\tvalid_1's binary_logloss: 0.484413\n",
      "[400]\ttraining's binary_logloss: 0.450489\tvalid_1's binary_logloss: 0.482338\n",
      "[500]\ttraining's binary_logloss: 0.447092\tvalid_1's binary_logloss: 0.481651\n",
      "[600]\ttraining's binary_logloss: 0.44483\tvalid_1's binary_logloss: 0.48138\n",
      "[700]\ttraining's binary_logloss: 0.443363\tvalid_1's binary_logloss: 0.481167\n",
      "[800]\ttraining's binary_logloss: 0.442282\tvalid_1's binary_logloss: 0.480998\n",
      "[900]\ttraining's binary_logloss: 0.441417\tvalid_1's binary_logloss: 0.48087\n",
      "[1000]\ttraining's binary_logloss: 0.44066\tvalid_1's binary_logloss: 0.480862\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.44066\tvalid_1's binary_logloss: 0.480862\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.44059\tvalid_1's binary_logloss: 0.480853\n",
      "[1200]\ttraining's binary_logloss: 0.44052\tvalid_1's binary_logloss: 0.480844\n",
      "[1300]\ttraining's binary_logloss: 0.440452\tvalid_1's binary_logloss: 0.480836\n",
      "[1400]\ttraining's binary_logloss: 0.440386\tvalid_1's binary_logloss: 0.480832\n",
      "[1500]\ttraining's binary_logloss: 0.440322\tvalid_1's binary_logloss: 0.480826\n",
      "Early stopping, best iteration is:\n",
      "[1494]\ttraining's binary_logloss: 0.440326\tvalid_1's binary_logloss: 0.480824\n",
      "===== ACCURACY SCORE 0.781434 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509776\tvalid_1's binary_logloss: 0.524068\n",
      "[200]\ttraining's binary_logloss: 0.469632\tvalid_1's binary_logloss: 0.490208\n",
      "[300]\ttraining's binary_logloss: 0.456143\tvalid_1's binary_logloss: 0.48263\n",
      "[400]\ttraining's binary_logloss: 0.450359\tvalid_1's binary_logloss: 0.48073\n",
      "[500]\ttraining's binary_logloss: 0.447042\tvalid_1's binary_logloss: 0.479996\n",
      "[600]\ttraining's binary_logloss: 0.444759\tvalid_1's binary_logloss: 0.479211\n",
      "[700]\ttraining's binary_logloss: 0.443262\tvalid_1's binary_logloss: 0.478878\n",
      "[800]\ttraining's binary_logloss: 0.442165\tvalid_1's binary_logloss: 0.478534\n",
      "[900]\ttraining's binary_logloss: 0.441273\tvalid_1's binary_logloss: 0.478271\n",
      "[1000]\ttraining's binary_logloss: 0.440551\tvalid_1's binary_logloss: 0.478165\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440551\tvalid_1's binary_logloss: 0.478165\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.44048\tvalid_1's binary_logloss: 0.478152\n",
      "[1200]\ttraining's binary_logloss: 0.440411\tvalid_1's binary_logloss: 0.478133\n",
      "[1300]\ttraining's binary_logloss: 0.440341\tvalid_1's binary_logloss: 0.478119\n",
      "[1400]\ttraining's binary_logloss: 0.440275\tvalid_1's binary_logloss: 0.47811\n",
      "[1500]\ttraining's binary_logloss: 0.440211\tvalid_1's binary_logloss: 0.478105\n",
      "[1600]\ttraining's binary_logloss: 0.440145\tvalid_1's binary_logloss: 0.478084\n",
      "[1700]\ttraining's binary_logloss: 0.44008\tvalid_1's binary_logloss: 0.478084\n",
      "[1800]\ttraining's binary_logloss: 0.440013\tvalid_1's binary_logloss: 0.478069\n",
      "[1900]\ttraining's binary_logloss: 0.439952\tvalid_1's binary_logloss: 0.478053\n",
      "[2000]\ttraining's binary_logloss: 0.439889\tvalid_1's binary_logloss: 0.478039\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439889\tvalid_1's binary_logloss: 0.478039\n",
      "===== ACCURACY SCORE 0.782933 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509667\tvalid_1's binary_logloss: 0.529593\n",
      "[200]\ttraining's binary_logloss: 0.46935\tvalid_1's binary_logloss: 0.497903\n",
      "[300]\ttraining's binary_logloss: 0.45589\tvalid_1's binary_logloss: 0.491939\n",
      "[400]\ttraining's binary_logloss: 0.450003\tvalid_1's binary_logloss: 0.490909\n",
      "[500]\ttraining's binary_logloss: 0.446513\tvalid_1's binary_logloss: 0.490631\n",
      "[600]\ttraining's binary_logloss: 0.444224\tvalid_1's binary_logloss: 0.490607\n",
      "[700]\ttraining's binary_logloss: 0.442714\tvalid_1's binary_logloss: 0.490638\n",
      "Early stopping, best iteration is:\n",
      "[619]\ttraining's binary_logloss: 0.443883\tvalid_1's binary_logloss: 0.490536\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.443748\tvalid_1's binary_logloss: 0.49055\n",
      "Early stopping, best iteration is:\n",
      "[634]\ttraining's binary_logloss: 0.443858\tvalid_1's binary_logloss: 0.490531\n",
      "===== ACCURACY SCORE 0.774719 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509647\tvalid_1's binary_logloss: 0.52792\n",
      "[200]\ttraining's binary_logloss: 0.469593\tvalid_1's binary_logloss: 0.496873\n",
      "[300]\ttraining's binary_logloss: 0.455952\tvalid_1's binary_logloss: 0.49088\n",
      "[400]\ttraining's binary_logloss: 0.450045\tvalid_1's binary_logloss: 0.490023\n",
      "[500]\ttraining's binary_logloss: 0.446526\tvalid_1's binary_logloss: 0.489578\n",
      "[600]\ttraining's binary_logloss: 0.444273\tvalid_1's binary_logloss: 0.489327\n",
      "[700]\ttraining's binary_logloss: 0.442814\tvalid_1's binary_logloss: 0.489178\n",
      "[800]\ttraining's binary_logloss: 0.441691\tvalid_1's binary_logloss: 0.488938\n",
      "[900]\ttraining's binary_logloss: 0.440831\tvalid_1's binary_logloss: 0.488763\n",
      "[1000]\ttraining's binary_logloss: 0.440119\tvalid_1's binary_logloss: 0.488733\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440119\tvalid_1's binary_logloss: 0.488733\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440052\tvalid_1's binary_logloss: 0.488719\n",
      "[1200]\ttraining's binary_logloss: 0.439987\tvalid_1's binary_logloss: 0.488716\n",
      "[1300]\ttraining's binary_logloss: 0.439922\tvalid_1's binary_logloss: 0.488704\n",
      "[1400]\ttraining's binary_logloss: 0.439856\tvalid_1's binary_logloss: 0.488694\n",
      "[1500]\ttraining's binary_logloss: 0.439792\tvalid_1's binary_logloss: 0.488686\n",
      "[1600]\ttraining's binary_logloss: 0.439728\tvalid_1's binary_logloss: 0.488673\n",
      "[1700]\ttraining's binary_logloss: 0.439664\tvalid_1's binary_logloss: 0.48866\n",
      "[1800]\ttraining's binary_logloss: 0.439604\tvalid_1's binary_logloss: 0.488647\n",
      "[1900]\ttraining's binary_logloss: 0.43954\tvalid_1's binary_logloss: 0.488628\n",
      "[2000]\ttraining's binary_logloss: 0.439478\tvalid_1's binary_logloss: 0.488624\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439478\tvalid_1's binary_logloss: 0.488624\n",
      "===== ACCURACY SCORE 0.781407 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510022\tvalid_1's binary_logloss: 0.527674\n",
      "[200]\ttraining's binary_logloss: 0.46991\tvalid_1's binary_logloss: 0.494909\n",
      "[300]\ttraining's binary_logloss: 0.456561\tvalid_1's binary_logloss: 0.488232\n",
      "[400]\ttraining's binary_logloss: 0.450577\tvalid_1's binary_logloss: 0.486635\n",
      "[500]\ttraining's binary_logloss: 0.447033\tvalid_1's binary_logloss: 0.486163\n",
      "[600]\ttraining's binary_logloss: 0.444797\tvalid_1's binary_logloss: 0.485927\n",
      "[700]\ttraining's binary_logloss: 0.443298\tvalid_1's binary_logloss: 0.485855\n",
      "[800]\ttraining's binary_logloss: 0.442242\tvalid_1's binary_logloss: 0.485949\n",
      "Early stopping, best iteration is:\n",
      "[735]\ttraining's binary_logloss: 0.442881\tvalid_1's binary_logloss: 0.485796\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.442812\tvalid_1's binary_logloss: 0.485795\n",
      "Early stopping, best iteration is:\n",
      "[780]\ttraining's binary_logloss: 0.442834\tvalid_1's binary_logloss: 0.485793\n",
      "===== ACCURACY SCORE 0.776087 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779420 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.511213\tvalid_1's binary_logloss: 0.530446\n",
      "[200]\ttraining's binary_logloss: 0.471344\tvalid_1's binary_logloss: 0.49888\n",
      "[300]\ttraining's binary_logloss: 0.457734\tvalid_1's binary_logloss: 0.492412\n",
      "[400]\ttraining's binary_logloss: 0.451802\tvalid_1's binary_logloss: 0.491087\n",
      "[500]\ttraining's binary_logloss: 0.448265\tvalid_1's binary_logloss: 0.490466\n",
      "[600]\ttraining's binary_logloss: 0.446008\tvalid_1's binary_logloss: 0.49029\n",
      "[700]\ttraining's binary_logloss: 0.444458\tvalid_1's binary_logloss: 0.490176\n",
      "[800]\ttraining's binary_logloss: 0.443342\tvalid_1's binary_logloss: 0.490143\n",
      "[900]\ttraining's binary_logloss: 0.442476\tvalid_1's binary_logloss: 0.490049\n",
      "[1000]\ttraining's binary_logloss: 0.441724\tvalid_1's binary_logloss: 0.48997\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.441724\tvalid_1's binary_logloss: 0.48997\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.441653\tvalid_1's binary_logloss: 0.489973\n",
      "Early stopping, best iteration is:\n",
      "[1007]\ttraining's binary_logloss: 0.441719\tvalid_1's binary_logloss: 0.489969\n",
      "===== ACCURACY SCORE 0.779060 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509846\tvalid_1's binary_logloss: 0.522727\n",
      "[200]\ttraining's binary_logloss: 0.469437\tvalid_1's binary_logloss: 0.489063\n",
      "[300]\ttraining's binary_logloss: 0.455659\tvalid_1's binary_logloss: 0.481906\n",
      "[400]\ttraining's binary_logloss: 0.449435\tvalid_1's binary_logloss: 0.480346\n",
      "[500]\ttraining's binary_logloss: 0.445828\tvalid_1's binary_logloss: 0.479979\n",
      "[600]\ttraining's binary_logloss: 0.443513\tvalid_1's binary_logloss: 0.479626\n",
      "[700]\ttraining's binary_logloss: 0.441932\tvalid_1's binary_logloss: 0.479644\n",
      "Early stopping, best iteration is:\n",
      "[674]\ttraining's binary_logloss: 0.442302\tvalid_1's binary_logloss: 0.479602\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.442263\tvalid_1's binary_logloss: 0.479602\n",
      "[800]\ttraining's binary_logloss: 0.442123\tvalid_1's binary_logloss: 0.479586\n",
      "[900]\ttraining's binary_logloss: 0.441988\tvalid_1's binary_logloss: 0.479578\n",
      "[1000]\ttraining's binary_logloss: 0.441857\tvalid_1's binary_logloss: 0.479564\n",
      "[1100]\ttraining's binary_logloss: 0.441729\tvalid_1's binary_logloss: 0.479558\n",
      "[1200]\ttraining's binary_logloss: 0.441603\tvalid_1's binary_logloss: 0.479553\n",
      "[1300]\ttraining's binary_logloss: 0.441487\tvalid_1's binary_logloss: 0.479559\n",
      "Early stopping, best iteration is:\n",
      "[1206]\ttraining's binary_logloss: 0.441595\tvalid_1's binary_logloss: 0.479551\n",
      "===== ACCURACY SCORE 0.783468 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508527\tvalid_1's binary_logloss: 0.529869\n",
      "[200]\ttraining's binary_logloss: 0.467887\tvalid_1's binary_logloss: 0.498685\n",
      "[300]\ttraining's binary_logloss: 0.454103\tvalid_1's binary_logloss: 0.492524\n",
      "[400]\ttraining's binary_logloss: 0.448102\tvalid_1's binary_logloss: 0.4916\n",
      "[500]\ttraining's binary_logloss: 0.444661\tvalid_1's binary_logloss: 0.49145\n",
      "[600]\ttraining's binary_logloss: 0.442379\tvalid_1's binary_logloss: 0.491343\n",
      "Early stopping, best iteration is:\n",
      "[557]\ttraining's binary_logloss: 0.443203\tvalid_1's binary_logloss: 0.491232\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.443114\tvalid_1's binary_logloss: 0.491247\n",
      "Early stopping, best iteration is:\n",
      "[558]\ttraining's binary_logloss: 0.443201\tvalid_1's binary_logloss: 0.491231\n",
      "===== ACCURACY SCORE 0.773533 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508738\tvalid_1's binary_logloss: 0.528791\n",
      "[200]\ttraining's binary_logloss: 0.468297\tvalid_1's binary_logloss: 0.495788\n",
      "[300]\ttraining's binary_logloss: 0.454685\tvalid_1's binary_logloss: 0.489077\n",
      "[400]\ttraining's binary_logloss: 0.4487\tvalid_1's binary_logloss: 0.487497\n",
      "[500]\ttraining's binary_logloss: 0.445223\tvalid_1's binary_logloss: 0.486888\n",
      "[600]\ttraining's binary_logloss: 0.442979\tvalid_1's binary_logloss: 0.486401\n",
      "[700]\ttraining's binary_logloss: 0.441455\tvalid_1's binary_logloss: 0.48594\n",
      "[800]\ttraining's binary_logloss: 0.440319\tvalid_1's binary_logloss: 0.485667\n",
      "[900]\ttraining's binary_logloss: 0.439466\tvalid_1's binary_logloss: 0.485518\n",
      "[1000]\ttraining's binary_logloss: 0.438732\tvalid_1's binary_logloss: 0.485434\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.438732\tvalid_1's binary_logloss: 0.485434\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.438666\tvalid_1's binary_logloss: 0.485413\n",
      "[1200]\ttraining's binary_logloss: 0.4386\tvalid_1's binary_logloss: 0.485397\n",
      "[1300]\ttraining's binary_logloss: 0.438536\tvalid_1's binary_logloss: 0.485391\n",
      "[1400]\ttraining's binary_logloss: 0.43847\tvalid_1's binary_logloss: 0.485386\n",
      "[1500]\ttraining's binary_logloss: 0.438405\tvalid_1's binary_logloss: 0.485382\n",
      "[1600]\ttraining's binary_logloss: 0.43834\tvalid_1's binary_logloss: 0.485371\n",
      "[1700]\ttraining's binary_logloss: 0.438275\tvalid_1's binary_logloss: 0.485355\n",
      "[1800]\ttraining's binary_logloss: 0.438211\tvalid_1's binary_logloss: 0.48535\n",
      "Early stopping, best iteration is:\n",
      "[1766]\ttraining's binary_logloss: 0.438231\tvalid_1's binary_logloss: 0.485346\n",
      "===== ACCURACY SCORE 0.779879 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509651\tvalid_1's binary_logloss: 0.526874\n",
      "[200]\ttraining's binary_logloss: 0.469478\tvalid_1's binary_logloss: 0.493262\n",
      "[300]\ttraining's binary_logloss: 0.455936\tvalid_1's binary_logloss: 0.485883\n",
      "[400]\ttraining's binary_logloss: 0.450126\tvalid_1's binary_logloss: 0.484\n",
      "[500]\ttraining's binary_logloss: 0.446677\tvalid_1's binary_logloss: 0.482967\n",
      "[600]\ttraining's binary_logloss: 0.444465\tvalid_1's binary_logloss: 0.482432\n",
      "[700]\ttraining's binary_logloss: 0.442976\tvalid_1's binary_logloss: 0.482048\n",
      "[800]\ttraining's binary_logloss: 0.44192\tvalid_1's binary_logloss: 0.481994\n",
      "[900]\ttraining's binary_logloss: 0.441065\tvalid_1's binary_logloss: 0.48192\n",
      "[1000]\ttraining's binary_logloss: 0.440351\tvalid_1's binary_logloss: 0.481856\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440351\tvalid_1's binary_logloss: 0.481856\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440279\tvalid_1's binary_logloss: 0.481846\n",
      "[1200]\ttraining's binary_logloss: 0.44021\tvalid_1's binary_logloss: 0.481833\n",
      "[1300]\ttraining's binary_logloss: 0.440143\tvalid_1's binary_logloss: 0.481832\n",
      "[1400]\ttraining's binary_logloss: 0.440077\tvalid_1's binary_logloss: 0.481829\n",
      "[1500]\ttraining's binary_logloss: 0.440011\tvalid_1's binary_logloss: 0.481821\n",
      "[1600]\ttraining's binary_logloss: 0.439945\tvalid_1's binary_logloss: 0.481815\n",
      "[1700]\ttraining's binary_logloss: 0.439879\tvalid_1's binary_logloss: 0.481806\n",
      "[1800]\ttraining's binary_logloss: 0.439819\tvalid_1's binary_logloss: 0.4818\n",
      "[1900]\ttraining's binary_logloss: 0.439756\tvalid_1's binary_logloss: 0.481794\n",
      "[2000]\ttraining's binary_logloss: 0.439696\tvalid_1's binary_logloss: 0.481787\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439696\tvalid_1's binary_logloss: 0.481787\n",
      "===== ACCURACY SCORE 0.780648 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510723\tvalid_1's binary_logloss: 0.529022\n",
      "[200]\ttraining's binary_logloss: 0.470736\tvalid_1's binary_logloss: 0.497059\n",
      "[300]\ttraining's binary_logloss: 0.457157\tvalid_1's binary_logloss: 0.490709\n",
      "[400]\ttraining's binary_logloss: 0.451148\tvalid_1's binary_logloss: 0.489748\n",
      "[500]\ttraining's binary_logloss: 0.447714\tvalid_1's binary_logloss: 0.489541\n",
      "[600]\ttraining's binary_logloss: 0.445407\tvalid_1's binary_logloss: 0.489393\n",
      "[700]\ttraining's binary_logloss: 0.443923\tvalid_1's binary_logloss: 0.489345\n",
      "[800]\ttraining's binary_logloss: 0.442845\tvalid_1's binary_logloss: 0.489322\n",
      "Early stopping, best iteration is:\n",
      "[758]\ttraining's binary_logloss: 0.443252\tvalid_1's binary_logloss: 0.489268\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.443206\tvalid_1's binary_logloss: 0.489268\n",
      "[900]\ttraining's binary_logloss: 0.443102\tvalid_1's binary_logloss: 0.489274\n",
      "Early stopping, best iteration is:\n",
      "[822]\ttraining's binary_logloss: 0.443182\tvalid_1's binary_logloss: 0.489266\n",
      "===== ACCURACY SCORE 0.779946 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509581\tvalid_1's binary_logloss: 0.525461\n",
      "[200]\ttraining's binary_logloss: 0.469198\tvalid_1's binary_logloss: 0.492461\n",
      "[300]\ttraining's binary_logloss: 0.455458\tvalid_1's binary_logloss: 0.48602\n",
      "[400]\ttraining's binary_logloss: 0.449442\tvalid_1's binary_logloss: 0.485045\n",
      "[500]\ttraining's binary_logloss: 0.445919\tvalid_1's binary_logloss: 0.485283\n",
      "Early stopping, best iteration is:\n",
      "[407]\ttraining's binary_logloss: 0.449128\tvalid_1's binary_logloss: 0.484985\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.44876\tvalid_1's binary_logloss: 0.484996\n",
      "Early stopping, best iteration is:\n",
      "[420]\ttraining's binary_logloss: 0.449074\tvalid_1's binary_logloss: 0.484981\n",
      "===== ACCURACY SCORE 0.781767 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50999\tvalid_1's binary_logloss: 0.52886\n",
      "[200]\ttraining's binary_logloss: 0.469698\tvalid_1's binary_logloss: 0.497552\n",
      "[300]\ttraining's binary_logloss: 0.456139\tvalid_1's binary_logloss: 0.491732\n",
      "[400]\ttraining's binary_logloss: 0.450165\tvalid_1's binary_logloss: 0.491101\n",
      "Early stopping, best iteration is:\n",
      "[394]\ttraining's binary_logloss: 0.450417\tvalid_1's binary_logloss: 0.491042\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.450392\tvalid_1's binary_logloss: 0.491043\n",
      "[500]\ttraining's binary_logloss: 0.449981\tvalid_1's binary_logloss: 0.49103\n",
      "[600]\ttraining's binary_logloss: 0.449587\tvalid_1's binary_logloss: 0.491035\n",
      "Early stopping, best iteration is:\n",
      "[550]\ttraining's binary_logloss: 0.449785\tvalid_1's binary_logloss: 0.491022\n",
      "===== ACCURACY SCORE 0.775664 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508426\tvalid_1's binary_logloss: 0.530571\n",
      "[200]\ttraining's binary_logloss: 0.467777\tvalid_1's binary_logloss: 0.499046\n",
      "[300]\ttraining's binary_logloss: 0.454189\tvalid_1's binary_logloss: 0.493126\n",
      "[400]\ttraining's binary_logloss: 0.448346\tvalid_1's binary_logloss: 0.492022\n",
      "[500]\ttraining's binary_logloss: 0.444974\tvalid_1's binary_logloss: 0.49145\n",
      "[600]\ttraining's binary_logloss: 0.442778\tvalid_1's binary_logloss: 0.491044\n",
      "[700]\ttraining's binary_logloss: 0.441313\tvalid_1's binary_logloss: 0.490963\n",
      "[800]\ttraining's binary_logloss: 0.440224\tvalid_1's binary_logloss: 0.490811\n",
      "[900]\ttraining's binary_logloss: 0.439364\tvalid_1's binary_logloss: 0.490702\n",
      "[1000]\ttraining's binary_logloss: 0.438643\tvalid_1's binary_logloss: 0.490621\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.438643\tvalid_1's binary_logloss: 0.490621\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.438568\tvalid_1's binary_logloss: 0.490609\n",
      "[1200]\ttraining's binary_logloss: 0.4385\tvalid_1's binary_logloss: 0.49059\n",
      "[1300]\ttraining's binary_logloss: 0.438433\tvalid_1's binary_logloss: 0.490585\n",
      "[1400]\ttraining's binary_logloss: 0.438365\tvalid_1's binary_logloss: 0.49057\n",
      "[1500]\ttraining's binary_logloss: 0.438299\tvalid_1's binary_logloss: 0.490554\n",
      "[1600]\ttraining's binary_logloss: 0.438234\tvalid_1's binary_logloss: 0.490544\n",
      "[1700]\ttraining's binary_logloss: 0.43817\tvalid_1's binary_logloss: 0.490532\n",
      "[1800]\ttraining's binary_logloss: 0.438101\tvalid_1's binary_logloss: 0.490518\n",
      "[1900]\ttraining's binary_logloss: 0.438037\tvalid_1's binary_logloss: 0.490503\n",
      "[2000]\ttraining's binary_logloss: 0.437972\tvalid_1's binary_logloss: 0.490495\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.437972\tvalid_1's binary_logloss: 0.490495\n",
      "===== ACCURACY SCORE 0.777722 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510414\tvalid_1's binary_logloss: 0.529873\n",
      "[200]\ttraining's binary_logloss: 0.470218\tvalid_1's binary_logloss: 0.496613\n",
      "[300]\ttraining's binary_logloss: 0.456642\tvalid_1's binary_logloss: 0.489305\n",
      "[400]\ttraining's binary_logloss: 0.450693\tvalid_1's binary_logloss: 0.487408\n",
      "[500]\ttraining's binary_logloss: 0.447302\tvalid_1's binary_logloss: 0.486701\n",
      "[600]\ttraining's binary_logloss: 0.445136\tvalid_1's binary_logloss: 0.486225\n",
      "[700]\ttraining's binary_logloss: 0.443688\tvalid_1's binary_logloss: 0.48604\n",
      "[800]\ttraining's binary_logloss: 0.442642\tvalid_1's binary_logloss: 0.485888\n",
      "[900]\ttraining's binary_logloss: 0.441807\tvalid_1's binary_logloss: 0.485688\n",
      "[1000]\ttraining's binary_logloss: 0.441115\tvalid_1's binary_logloss: 0.485589\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.441115\tvalid_1's binary_logloss: 0.485589\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.441046\tvalid_1's binary_logloss: 0.48558\n",
      "[1200]\ttraining's binary_logloss: 0.440978\tvalid_1's binary_logloss: 0.48557\n",
      "[1300]\ttraining's binary_logloss: 0.440911\tvalid_1's binary_logloss: 0.485557\n",
      "[1400]\ttraining's binary_logloss: 0.440844\tvalid_1's binary_logloss: 0.485549\n",
      "[1500]\ttraining's binary_logloss: 0.440781\tvalid_1's binary_logloss: 0.485536\n",
      "[1600]\ttraining's binary_logloss: 0.440718\tvalid_1's binary_logloss: 0.48552\n",
      "[1700]\ttraining's binary_logloss: 0.440658\tvalid_1's binary_logloss: 0.485515\n",
      "[1800]\ttraining's binary_logloss: 0.440594\tvalid_1's binary_logloss: 0.485502\n",
      "[1900]\ttraining's binary_logloss: 0.440533\tvalid_1's binary_logloss: 0.485479\n",
      "[2000]\ttraining's binary_logloss: 0.440472\tvalid_1's binary_logloss: 0.485465\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.440472\tvalid_1's binary_logloss: 0.485465\n",
      "===== ACCURACY SCORE 0.780662 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779250 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508628\tvalid_1's binary_logloss: 0.525369\n",
      "[200]\ttraining's binary_logloss: 0.468161\tvalid_1's binary_logloss: 0.491662\n",
      "[300]\ttraining's binary_logloss: 0.454472\tvalid_1's binary_logloss: 0.484143\n",
      "[400]\ttraining's binary_logloss: 0.448553\tvalid_1's binary_logloss: 0.482257\n",
      "[500]\ttraining's binary_logloss: 0.445171\tvalid_1's binary_logloss: 0.481836\n",
      "[600]\ttraining's binary_logloss: 0.44286\tvalid_1's binary_logloss: 0.481303\n",
      "[700]\ttraining's binary_logloss: 0.441334\tvalid_1's binary_logloss: 0.48117\n",
      "[800]\ttraining's binary_logloss: 0.440253\tvalid_1's binary_logloss: 0.481088\n",
      "[900]\ttraining's binary_logloss: 0.43935\tvalid_1's binary_logloss: 0.480908\n",
      "[1000]\ttraining's binary_logloss: 0.438642\tvalid_1's binary_logloss: 0.480845\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.438642\tvalid_1's binary_logloss: 0.480845\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.438573\tvalid_1's binary_logloss: 0.480837\n",
      "[1200]\ttraining's binary_logloss: 0.438507\tvalid_1's binary_logloss: 0.480832\n",
      "[1300]\ttraining's binary_logloss: 0.438438\tvalid_1's binary_logloss: 0.480813\n",
      "[1400]\ttraining's binary_logloss: 0.438372\tvalid_1's binary_logloss: 0.480804\n",
      "[1500]\ttraining's binary_logloss: 0.43831\tvalid_1's binary_logloss: 0.480804\n",
      "[1600]\ttraining's binary_logloss: 0.438245\tvalid_1's binary_logloss: 0.480798\n",
      "[1700]\ttraining's binary_logloss: 0.438177\tvalid_1's binary_logloss: 0.480788\n",
      "[1800]\ttraining's binary_logloss: 0.438113\tvalid_1's binary_logloss: 0.480777\n",
      "[1900]\ttraining's binary_logloss: 0.438048\tvalid_1's binary_logloss: 0.480773\n",
      "[2000]\ttraining's binary_logloss: 0.437985\tvalid_1's binary_logloss: 0.480769\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.437985\tvalid_1's binary_logloss: 0.480769\n",
      "===== ACCURACY SCORE 0.784451 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509798\tvalid_1's binary_logloss: 0.526185\n",
      "[200]\ttraining's binary_logloss: 0.469689\tvalid_1's binary_logloss: 0.492222\n",
      "[300]\ttraining's binary_logloss: 0.456062\tvalid_1's binary_logloss: 0.484487\n",
      "[400]\ttraining's binary_logloss: 0.450032\tvalid_1's binary_logloss: 0.482665\n",
      "[500]\ttraining's binary_logloss: 0.44653\tvalid_1's binary_logloss: 0.481886\n",
      "[600]\ttraining's binary_logloss: 0.444285\tvalid_1's binary_logloss: 0.481365\n",
      "[700]\ttraining's binary_logloss: 0.442769\tvalid_1's binary_logloss: 0.481043\n",
      "[800]\ttraining's binary_logloss: 0.44169\tvalid_1's binary_logloss: 0.480892\n",
      "[900]\ttraining's binary_logloss: 0.440826\tvalid_1's binary_logloss: 0.48073\n",
      "[1000]\ttraining's binary_logloss: 0.440086\tvalid_1's binary_logloss: 0.480538\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440086\tvalid_1's binary_logloss: 0.480538\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440019\tvalid_1's binary_logloss: 0.480536\n",
      "Early stopping, best iteration is:\n",
      "[1089]\ttraining's binary_logloss: 0.440026\tvalid_1's binary_logloss: 0.480535\n",
      "===== ACCURACY SCORE 0.784357 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510129\tvalid_1's binary_logloss: 0.523155\n",
      "[200]\ttraining's binary_logloss: 0.469939\tvalid_1's binary_logloss: 0.488254\n",
      "[300]\ttraining's binary_logloss: 0.456329\tvalid_1's binary_logloss: 0.4804\n",
      "[400]\ttraining's binary_logloss: 0.450458\tvalid_1's binary_logloss: 0.478664\n",
      "[500]\ttraining's binary_logloss: 0.44709\tvalid_1's binary_logloss: 0.478203\n",
      "[600]\ttraining's binary_logloss: 0.444882\tvalid_1's binary_logloss: 0.477704\n",
      "[700]\ttraining's binary_logloss: 0.443429\tvalid_1's binary_logloss: 0.47754\n",
      "[800]\ttraining's binary_logloss: 0.442373\tvalid_1's binary_logloss: 0.477478\n",
      "[900]\ttraining's binary_logloss: 0.441549\tvalid_1's binary_logloss: 0.477422\n",
      "[1000]\ttraining's binary_logloss: 0.440864\tvalid_1's binary_logloss: 0.477365\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440864\tvalid_1's binary_logloss: 0.477365\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440795\tvalid_1's binary_logloss: 0.477345\n",
      "[1200]\ttraining's binary_logloss: 0.440725\tvalid_1's binary_logloss: 0.477329\n",
      "[1300]\ttraining's binary_logloss: 0.440657\tvalid_1's binary_logloss: 0.477318\n",
      "[1400]\ttraining's binary_logloss: 0.44059\tvalid_1's binary_logloss: 0.477309\n",
      "[1500]\ttraining's binary_logloss: 0.440526\tvalid_1's binary_logloss: 0.477298\n",
      "[1600]\ttraining's binary_logloss: 0.440461\tvalid_1's binary_logloss: 0.47729\n",
      "[1700]\ttraining's binary_logloss: 0.440395\tvalid_1's binary_logloss: 0.47728\n",
      "[1800]\ttraining's binary_logloss: 0.440332\tvalid_1's binary_logloss: 0.477275\n",
      "[1900]\ttraining's binary_logloss: 0.440271\tvalid_1's binary_logloss: 0.477273\n",
      "[2000]\ttraining's binary_logloss: 0.440213\tvalid_1's binary_logloss: 0.477263\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.440213\tvalid_1's binary_logloss: 0.477263\n",
      "===== ACCURACY SCORE 0.783404 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509246\tvalid_1's binary_logloss: 0.533428\n",
      "[200]\ttraining's binary_logloss: 0.468806\tvalid_1's binary_logloss: 0.502744\n",
      "[300]\ttraining's binary_logloss: 0.455126\tvalid_1's binary_logloss: 0.496999\n",
      "[400]\ttraining's binary_logloss: 0.449098\tvalid_1's binary_logloss: 0.496119\n",
      "[500]\ttraining's binary_logloss: 0.445566\tvalid_1's binary_logloss: 0.495926\n",
      "[600]\ttraining's binary_logloss: 0.443286\tvalid_1's binary_logloss: 0.495853\n",
      "[700]\ttraining's binary_logloss: 0.44176\tvalid_1's binary_logloss: 0.495748\n",
      "Early stopping, best iteration is:\n",
      "[672]\ttraining's binary_logloss: 0.442135\tvalid_1's binary_logloss: 0.495691\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.442097\tvalid_1's binary_logloss: 0.495693\n",
      "[800]\ttraining's binary_logloss: 0.441961\tvalid_1's binary_logloss: 0.495676\n",
      "[900]\ttraining's binary_logloss: 0.44183\tvalid_1's binary_logloss: 0.495678\n",
      "Early stopping, best iteration is:\n",
      "[804]\ttraining's binary_logloss: 0.441956\tvalid_1's binary_logloss: 0.495675\n",
      "===== ACCURACY SCORE 0.773686 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508825\tvalid_1's binary_logloss: 0.52765\n",
      "[200]\ttraining's binary_logloss: 0.468225\tvalid_1's binary_logloss: 0.495598\n",
      "[300]\ttraining's binary_logloss: 0.45443\tvalid_1's binary_logloss: 0.489308\n",
      "[400]\ttraining's binary_logloss: 0.448434\tvalid_1's binary_logloss: 0.488211\n",
      "[500]\ttraining's binary_logloss: 0.444957\tvalid_1's binary_logloss: 0.487958\n",
      "[600]\ttraining's binary_logloss: 0.442718\tvalid_1's binary_logloss: 0.488021\n",
      "Early stopping, best iteration is:\n",
      "[562]\ttraining's binary_logloss: 0.443429\tvalid_1's binary_logloss: 0.487833\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.44335\tvalid_1's binary_logloss: 0.48784\n",
      "[700]\ttraining's binary_logloss: 0.44315\tvalid_1's binary_logloss: 0.48785\n",
      "Early stopping, best iteration is:\n",
      "[635]\ttraining's binary_logloss: 0.443278\tvalid_1's binary_logloss: 0.487833\n",
      "===== ACCURACY SCORE 0.775504 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509524\tvalid_1's binary_logloss: 0.527205\n",
      "[200]\ttraining's binary_logloss: 0.469157\tvalid_1's binary_logloss: 0.494429\n",
      "[300]\ttraining's binary_logloss: 0.455497\tvalid_1's binary_logloss: 0.487439\n",
      "[400]\ttraining's binary_logloss: 0.44944\tvalid_1's binary_logloss: 0.485726\n",
      "[500]\ttraining's binary_logloss: 0.445831\tvalid_1's binary_logloss: 0.484996\n",
      "[600]\ttraining's binary_logloss: 0.44351\tvalid_1's binary_logloss: 0.484491\n",
      "[700]\ttraining's binary_logloss: 0.442007\tvalid_1's binary_logloss: 0.484383\n",
      "[800]\ttraining's binary_logloss: 0.440904\tvalid_1's binary_logloss: 0.484229\n",
      "[900]\ttraining's binary_logloss: 0.440047\tvalid_1's binary_logloss: 0.484146\n",
      "[1000]\ttraining's binary_logloss: 0.439328\tvalid_1's binary_logloss: 0.484147\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439328\tvalid_1's binary_logloss: 0.484147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439257\tvalid_1's binary_logloss: 0.48413\n",
      "[1200]\ttraining's binary_logloss: 0.439189\tvalid_1's binary_logloss: 0.484117\n",
      "[1300]\ttraining's binary_logloss: 0.439122\tvalid_1's binary_logloss: 0.484106\n",
      "[1400]\ttraining's binary_logloss: 0.439056\tvalid_1's binary_logloss: 0.4841\n",
      "[1500]\ttraining's binary_logloss: 0.438991\tvalid_1's binary_logloss: 0.484093\n",
      "[1600]\ttraining's binary_logloss: 0.438923\tvalid_1's binary_logloss: 0.484083\n",
      "[1700]\ttraining's binary_logloss: 0.438857\tvalid_1's binary_logloss: 0.48407\n",
      "[1800]\ttraining's binary_logloss: 0.43879\tvalid_1's binary_logloss: 0.48406\n",
      "[1900]\ttraining's binary_logloss: 0.438728\tvalid_1's binary_logloss: 0.484049\n",
      "[2000]\ttraining's binary_logloss: 0.438667\tvalid_1's binary_logloss: 0.48404\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.438667\tvalid_1's binary_logloss: 0.48404\n",
      "===== ACCURACY SCORE 0.780944 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509148\tvalid_1's binary_logloss: 0.529884\n",
      "[200]\ttraining's binary_logloss: 0.468764\tvalid_1's binary_logloss: 0.499166\n",
      "[300]\ttraining's binary_logloss: 0.455054\tvalid_1's binary_logloss: 0.493348\n",
      "[400]\ttraining's binary_logloss: 0.44907\tvalid_1's binary_logloss: 0.492872\n",
      "Early stopping, best iteration is:\n",
      "[372]\ttraining's binary_logloss: 0.45035\tvalid_1's binary_logloss: 0.49278\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.450206\tvalid_1's binary_logloss: 0.492783\n",
      "Early stopping, best iteration is:\n",
      "[388]\ttraining's binary_logloss: 0.450268\tvalid_1's binary_logloss: 0.492777\n",
      "===== ACCURACY SCORE 0.778729 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.5104\tvalid_1's binary_logloss: 0.531601\n",
      "[200]\ttraining's binary_logloss: 0.4704\tvalid_1's binary_logloss: 0.499643\n",
      "[300]\ttraining's binary_logloss: 0.456842\tvalid_1's binary_logloss: 0.49315\n",
      "[400]\ttraining's binary_logloss: 0.450928\tvalid_1's binary_logloss: 0.491862\n",
      "[500]\ttraining's binary_logloss: 0.447407\tvalid_1's binary_logloss: 0.4917\n",
      "[600]\ttraining's binary_logloss: 0.445148\tvalid_1's binary_logloss: 0.49166\n",
      "Early stopping, best iteration is:\n",
      "[591]\ttraining's binary_logloss: 0.445307\tvalid_1's binary_logloss: 0.49163\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.445291\tvalid_1's binary_logloss: 0.491634\n",
      "[700]\ttraining's binary_logloss: 0.445112\tvalid_1's binary_logloss: 0.491628\n",
      "[800]\ttraining's binary_logloss: 0.444937\tvalid_1's binary_logloss: 0.491626\n",
      "Early stopping, best iteration is:\n",
      "[783]\ttraining's binary_logloss: 0.444966\tvalid_1's binary_logloss: 0.491619\n",
      "===== ACCURACY SCORE 0.775141 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509496\tvalid_1's binary_logloss: 0.52971\n",
      "[200]\ttraining's binary_logloss: 0.469049\tvalid_1's binary_logloss: 0.499077\n",
      "[300]\ttraining's binary_logloss: 0.455243\tvalid_1's binary_logloss: 0.493904\n",
      "[400]\ttraining's binary_logloss: 0.449153\tvalid_1's binary_logloss: 0.493445\n",
      "Early stopping, best iteration is:\n",
      "[370]\ttraining's binary_logloss: 0.450545\tvalid_1's binary_logloss: 0.493355\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.450396\tvalid_1's binary_logloss: 0.493346\n",
      "[500]\ttraining's binary_logloss: 0.449917\tvalid_1's binary_logloss: 0.493334\n",
      "Early stopping, best iteration is:\n",
      "[491]\ttraining's binary_logloss: 0.449957\tvalid_1's binary_logloss: 0.493332\n",
      "===== ACCURACY SCORE 0.775464 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509583\tvalid_1's binary_logloss: 0.527934\n",
      "[200]\ttraining's binary_logloss: 0.469233\tvalid_1's binary_logloss: 0.495296\n",
      "[300]\ttraining's binary_logloss: 0.455757\tvalid_1's binary_logloss: 0.488661\n",
      "[400]\ttraining's binary_logloss: 0.449997\tvalid_1's binary_logloss: 0.48733\n",
      "[500]\ttraining's binary_logloss: 0.44663\tvalid_1's binary_logloss: 0.487014\n",
      "[600]\ttraining's binary_logloss: 0.444384\tvalid_1's binary_logloss: 0.486846\n",
      "[700]\ttraining's binary_logloss: 0.442928\tvalid_1's binary_logloss: 0.486849\n",
      "[800]\ttraining's binary_logloss: 0.441851\tvalid_1's binary_logloss: 0.486853\n",
      "Early stopping, best iteration is:\n",
      "[750]\ttraining's binary_logloss: 0.442368\tvalid_1's binary_logloss: 0.486779\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.442315\tvalid_1's binary_logloss: 0.486783\n",
      "[900]\ttraining's binary_logloss: 0.442211\tvalid_1's binary_logloss: 0.486787\n",
      "Early stopping, best iteration is:\n",
      "[832]\ttraining's binary_logloss: 0.44228\tvalid_1's binary_logloss: 0.486775\n",
      "===== ACCURACY SCORE 0.780415 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779200 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509722\tvalid_1's binary_logloss: 0.521645\n",
      "[200]\ttraining's binary_logloss: 0.469454\tvalid_1's binary_logloss: 0.485837\n",
      "[300]\ttraining's binary_logloss: 0.455819\tvalid_1's binary_logloss: 0.477217\n",
      "[400]\ttraining's binary_logloss: 0.449789\tvalid_1's binary_logloss: 0.474692\n",
      "[500]\ttraining's binary_logloss: 0.446324\tvalid_1's binary_logloss: 0.473757\n",
      "[600]\ttraining's binary_logloss: 0.444015\tvalid_1's binary_logloss: 0.472946\n",
      "[700]\ttraining's binary_logloss: 0.44248\tvalid_1's binary_logloss: 0.472558\n",
      "[800]\ttraining's binary_logloss: 0.441352\tvalid_1's binary_logloss: 0.472272\n",
      "[900]\ttraining's binary_logloss: 0.440435\tvalid_1's binary_logloss: 0.471942\n",
      "[1000]\ttraining's binary_logloss: 0.439711\tvalid_1's binary_logloss: 0.471796\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439711\tvalid_1's binary_logloss: 0.471796\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.43964\tvalid_1's binary_logloss: 0.471791\n",
      "[1200]\ttraining's binary_logloss: 0.439571\tvalid_1's binary_logloss: 0.471775\n",
      "[1300]\ttraining's binary_logloss: 0.439502\tvalid_1's binary_logloss: 0.471763\n",
      "[1400]\ttraining's binary_logloss: 0.439435\tvalid_1's binary_logloss: 0.471748\n",
      "[1500]\ttraining's binary_logloss: 0.439369\tvalid_1's binary_logloss: 0.471738\n",
      "[1600]\ttraining's binary_logloss: 0.439303\tvalid_1's binary_logloss: 0.471721\n",
      "[1700]\ttraining's binary_logloss: 0.439238\tvalid_1's binary_logloss: 0.47171\n",
      "[1800]\ttraining's binary_logloss: 0.439175\tvalid_1's binary_logloss: 0.471699\n",
      "[1900]\ttraining's binary_logloss: 0.43911\tvalid_1's binary_logloss: 0.471678\n",
      "[2000]\ttraining's binary_logloss: 0.439046\tvalid_1's binary_logloss: 0.47167\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439046\tvalid_1's binary_logloss: 0.47167\n",
      "===== ACCURACY SCORE 0.788874 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509409\tvalid_1's binary_logloss: 0.532439\n",
      "[200]\ttraining's binary_logloss: 0.468975\tvalid_1's binary_logloss: 0.502788\n",
      "[300]\ttraining's binary_logloss: 0.45532\tvalid_1's binary_logloss: 0.49748\n",
      "[400]\ttraining's binary_logloss: 0.449422\tvalid_1's binary_logloss: 0.49702\n",
      "Early stopping, best iteration is:\n",
      "[368]\ttraining's binary_logloss: 0.450844\tvalid_1's binary_logloss: 0.49697\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.450683\tvalid_1's binary_logloss: 0.496973\n",
      "Early stopping, best iteration is:\n",
      "[371]\ttraining's binary_logloss: 0.450827\tvalid_1's binary_logloss: 0.496967\n",
      "===== ACCURACY SCORE 0.775615 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509405\tvalid_1's binary_logloss: 0.530297\n",
      "[200]\ttraining's binary_logloss: 0.469072\tvalid_1's binary_logloss: 0.499155\n",
      "[300]\ttraining's binary_logloss: 0.455353\tvalid_1's binary_logloss: 0.493108\n",
      "[400]\ttraining's binary_logloss: 0.449318\tvalid_1's binary_logloss: 0.492311\n",
      "Early stopping, best iteration is:\n",
      "[392]\ttraining's binary_logloss: 0.449655\tvalid_1's binary_logloss: 0.492276\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.44962\tvalid_1's binary_logloss: 0.492276\n",
      "[500]\ttraining's binary_logloss: 0.449203\tvalid_1's binary_logloss: 0.49228\n",
      "Early stopping, best iteration is:\n",
      "[442]\ttraining's binary_logloss: 0.44944\tvalid_1's binary_logloss: 0.492265\n",
      "===== ACCURACY SCORE 0.776052 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50883\tvalid_1's binary_logloss: 0.526306\n",
      "[200]\ttraining's binary_logloss: 0.468489\tvalid_1's binary_logloss: 0.493052\n",
      "[300]\ttraining's binary_logloss: 0.454836\tvalid_1's binary_logloss: 0.485818\n",
      "[400]\ttraining's binary_logloss: 0.44887\tvalid_1's binary_logloss: 0.484051\n",
      "[500]\ttraining's binary_logloss: 0.445386\tvalid_1's binary_logloss: 0.483095\n",
      "[600]\ttraining's binary_logloss: 0.443116\tvalid_1's binary_logloss: 0.48242\n",
      "[700]\ttraining's binary_logloss: 0.441633\tvalid_1's binary_logloss: 0.482082\n",
      "[800]\ttraining's binary_logloss: 0.440553\tvalid_1's binary_logloss: 0.481794\n",
      "[900]\ttraining's binary_logloss: 0.439705\tvalid_1's binary_logloss: 0.481498\n",
      "[1000]\ttraining's binary_logloss: 0.43901\tvalid_1's binary_logloss: 0.481411\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.43901\tvalid_1's binary_logloss: 0.481411\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.438943\tvalid_1's binary_logloss: 0.481406\n",
      "[1200]\ttraining's binary_logloss: 0.438877\tvalid_1's binary_logloss: 0.48139\n",
      "[1300]\ttraining's binary_logloss: 0.438811\tvalid_1's binary_logloss: 0.481384\n",
      "[1400]\ttraining's binary_logloss: 0.438746\tvalid_1's binary_logloss: 0.48138\n",
      "[1500]\ttraining's binary_logloss: 0.438681\tvalid_1's binary_logloss: 0.481366\n",
      "[1600]\ttraining's binary_logloss: 0.438615\tvalid_1's binary_logloss: 0.481353\n",
      "[1700]\ttraining's binary_logloss: 0.438549\tvalid_1's binary_logloss: 0.481342\n",
      "[1800]\ttraining's binary_logloss: 0.438485\tvalid_1's binary_logloss: 0.481328\n",
      "[1900]\ttraining's binary_logloss: 0.438422\tvalid_1's binary_logloss: 0.481317\n",
      "[2000]\ttraining's binary_logloss: 0.438362\tvalid_1's binary_logloss: 0.481313\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.438362\tvalid_1's binary_logloss: 0.481313\n",
      "===== ACCURACY SCORE 0.780838 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508871\tvalid_1's binary_logloss: 0.528865\n",
      "[200]\ttraining's binary_logloss: 0.468363\tvalid_1's binary_logloss: 0.497753\n",
      "[300]\ttraining's binary_logloss: 0.454648\tvalid_1's binary_logloss: 0.491958\n",
      "[400]\ttraining's binary_logloss: 0.448752\tvalid_1's binary_logloss: 0.491053\n",
      "[500]\ttraining's binary_logloss: 0.445444\tvalid_1's binary_logloss: 0.491043\n",
      "[600]\ttraining's binary_logloss: 0.443183\tvalid_1's binary_logloss: 0.490717\n",
      "[700]\ttraining's binary_logloss: 0.441698\tvalid_1's binary_logloss: 0.49063\n",
      "[800]\ttraining's binary_logloss: 0.440602\tvalid_1's binary_logloss: 0.490488\n",
      "[900]\ttraining's binary_logloss: 0.439735\tvalid_1's binary_logloss: 0.490483\n",
      "[1000]\ttraining's binary_logloss: 0.439009\tvalid_1's binary_logloss: 0.49047\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439009\tvalid_1's binary_logloss: 0.49047\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.438938\tvalid_1's binary_logloss: 0.490473\n",
      "Early stopping, best iteration is:\n",
      "[1071]\ttraining's binary_logloss: 0.438959\tvalid_1's binary_logloss: 0.490466\n",
      "===== ACCURACY SCORE 0.775109 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510099\tvalid_1's binary_logloss: 0.524102\n",
      "[200]\ttraining's binary_logloss: 0.470081\tvalid_1's binary_logloss: 0.490019\n",
      "[300]\ttraining's binary_logloss: 0.456442\tvalid_1's binary_logloss: 0.482296\n",
      "[400]\ttraining's binary_logloss: 0.450422\tvalid_1's binary_logloss: 0.480284\n",
      "[500]\ttraining's binary_logloss: 0.446919\tvalid_1's binary_logloss: 0.479781\n",
      "[600]\ttraining's binary_logloss: 0.444683\tvalid_1's binary_logloss: 0.479678\n",
      "[700]\ttraining's binary_logloss: 0.443165\tvalid_1's binary_logloss: 0.479572\n",
      "[800]\ttraining's binary_logloss: 0.442094\tvalid_1's binary_logloss: 0.479493\n",
      "Early stopping, best iteration is:\n",
      "[742]\ttraining's binary_logloss: 0.442671\tvalid_1's binary_logloss: 0.479464\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.442611\tvalid_1's binary_logloss: 0.479472\n",
      "Early stopping, best iteration is:\n",
      "[764]\ttraining's binary_logloss: 0.442647\tvalid_1's binary_logloss: 0.479464\n",
      "===== ACCURACY SCORE 0.784009 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509387\tvalid_1's binary_logloss: 0.526474\n",
      "[200]\ttraining's binary_logloss: 0.469136\tvalid_1's binary_logloss: 0.492864\n",
      "[300]\ttraining's binary_logloss: 0.45562\tvalid_1's binary_logloss: 0.485974\n",
      "[400]\ttraining's binary_logloss: 0.449663\tvalid_1's binary_logloss: 0.484728\n",
      "[500]\ttraining's binary_logloss: 0.446159\tvalid_1's binary_logloss: 0.484677\n",
      "[600]\ttraining's binary_logloss: 0.443843\tvalid_1's binary_logloss: 0.484651\n",
      "Early stopping, best iteration is:\n",
      "[532]\ttraining's binary_logloss: 0.445282\tvalid_1's binary_logloss: 0.484623\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.445111\tvalid_1's binary_logloss: 0.484621\n",
      "Early stopping, best iteration is:\n",
      "[560]\ttraining's binary_logloss: 0.44521\tvalid_1's binary_logloss: 0.484615\n",
      "===== ACCURACY SCORE 0.780441 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50952\tvalid_1's binary_logloss: 0.533933\n",
      "[200]\ttraining's binary_logloss: 0.46892\tvalid_1's binary_logloss: 0.504453\n",
      "[300]\ttraining's binary_logloss: 0.455111\tvalid_1's binary_logloss: 0.49949\n",
      "[400]\ttraining's binary_logloss: 0.449081\tvalid_1's binary_logloss: 0.498911\n",
      "Early stopping, best iteration is:\n",
      "[375]\ttraining's binary_logloss: 0.450204\tvalid_1's binary_logloss: 0.498827\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.450083\tvalid_1's binary_logloss: 0.498813\n",
      "[500]\ttraining's binary_logloss: 0.449619\tvalid_1's binary_logloss: 0.498773\n",
      "[600]\ttraining's binary_logloss: 0.449182\tvalid_1's binary_logloss: 0.498761\n",
      "[700]\ttraining's binary_logloss: 0.448767\tvalid_1's binary_logloss: 0.49874\n",
      "Early stopping, best iteration is:\n",
      "[688]\ttraining's binary_logloss: 0.448814\tvalid_1's binary_logloss: 0.498737\n",
      "===== ACCURACY SCORE 0.769788 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509632\tvalid_1's binary_logloss: 0.528943\n",
      "[200]\ttraining's binary_logloss: 0.469346\tvalid_1's binary_logloss: 0.497802\n",
      "[300]\ttraining's binary_logloss: 0.455813\tvalid_1's binary_logloss: 0.491859\n",
      "[400]\ttraining's binary_logloss: 0.449955\tvalid_1's binary_logloss: 0.490866\n",
      "[500]\ttraining's binary_logloss: 0.446542\tvalid_1's binary_logloss: 0.490812\n",
      "Early stopping, best iteration is:\n",
      "[463]\ttraining's binary_logloss: 0.447703\tvalid_1's binary_logloss: 0.490751\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.447577\tvalid_1's binary_logloss: 0.490754\n",
      "Early stopping, best iteration is:\n",
      "[468]\ttraining's binary_logloss: 0.447683\tvalid_1's binary_logloss: 0.490747\n",
      "===== ACCURACY SCORE 0.775958 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508789\tvalid_1's binary_logloss: 0.527179\n",
      "[200]\ttraining's binary_logloss: 0.46848\tvalid_1's binary_logloss: 0.494286\n",
      "[300]\ttraining's binary_logloss: 0.454886\tvalid_1's binary_logloss: 0.487137\n",
      "[400]\ttraining's binary_logloss: 0.448877\tvalid_1's binary_logloss: 0.485396\n",
      "[500]\ttraining's binary_logloss: 0.445324\tvalid_1's binary_logloss: 0.484736\n",
      "[600]\ttraining's binary_logloss: 0.443046\tvalid_1's binary_logloss: 0.484312\n",
      "[700]\ttraining's binary_logloss: 0.44154\tvalid_1's binary_logloss: 0.483765\n",
      "[800]\ttraining's binary_logloss: 0.440427\tvalid_1's binary_logloss: 0.483441\n",
      "[900]\ttraining's binary_logloss: 0.439557\tvalid_1's binary_logloss: 0.48326\n",
      "[1000]\ttraining's binary_logloss: 0.438827\tvalid_1's binary_logloss: 0.483164\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.438827\tvalid_1's binary_logloss: 0.483164\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.438759\tvalid_1's binary_logloss: 0.483157\n",
      "[1200]\ttraining's binary_logloss: 0.438692\tvalid_1's binary_logloss: 0.483143\n",
      "[1300]\ttraining's binary_logloss: 0.438627\tvalid_1's binary_logloss: 0.483131\n",
      "[1400]\ttraining's binary_logloss: 0.43856\tvalid_1's binary_logloss: 0.483125\n",
      "[1500]\ttraining's binary_logloss: 0.438494\tvalid_1's binary_logloss: 0.483114\n",
      "[1600]\ttraining's binary_logloss: 0.43843\tvalid_1's binary_logloss: 0.483111\n",
      "[1700]\ttraining's binary_logloss: 0.438366\tvalid_1's binary_logloss: 0.483097\n",
      "[1800]\ttraining's binary_logloss: 0.438301\tvalid_1's binary_logloss: 0.483096\n",
      "Early stopping, best iteration is:\n",
      "[1726]\ttraining's binary_logloss: 0.43835\tvalid_1's binary_logloss: 0.483094\n",
      "===== ACCURACY SCORE 0.781601 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778840 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510023\tvalid_1's binary_logloss: 0.529993\n",
      "[200]\ttraining's binary_logloss: 0.469964\tvalid_1's binary_logloss: 0.498156\n",
      "[300]\ttraining's binary_logloss: 0.456256\tvalid_1's binary_logloss: 0.492024\n",
      "[400]\ttraining's binary_logloss: 0.450275\tvalid_1's binary_logloss: 0.491063\n",
      "[500]\ttraining's binary_logloss: 0.446673\tvalid_1's binary_logloss: 0.49105\n",
      "Early stopping, best iteration is:\n",
      "[458]\ttraining's binary_logloss: 0.448026\tvalid_1's binary_logloss: 0.491007\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.447893\tvalid_1's binary_logloss: 0.491024\n",
      "Early stopping, best iteration is:\n",
      "[459]\ttraining's binary_logloss: 0.448024\tvalid_1's binary_logloss: 0.491008\n",
      "===== ACCURACY SCORE 0.778526 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509187\tvalid_1's binary_logloss: 0.527484\n",
      "[200]\ttraining's binary_logloss: 0.468871\tvalid_1's binary_logloss: 0.494772\n",
      "[300]\ttraining's binary_logloss: 0.455243\tvalid_1's binary_logloss: 0.488035\n",
      "[400]\ttraining's binary_logloss: 0.44931\tvalid_1's binary_logloss: 0.486619\n",
      "[500]\ttraining's binary_logloss: 0.445943\tvalid_1's binary_logloss: 0.48608\n",
      "[600]\ttraining's binary_logloss: 0.443708\tvalid_1's binary_logloss: 0.485508\n",
      "[700]\ttraining's binary_logloss: 0.442255\tvalid_1's binary_logloss: 0.485097\n",
      "[800]\ttraining's binary_logloss: 0.441165\tvalid_1's binary_logloss: 0.484925\n",
      "[900]\ttraining's binary_logloss: 0.440316\tvalid_1's binary_logloss: 0.48483\n",
      "[1000]\ttraining's binary_logloss: 0.439559\tvalid_1's binary_logloss: 0.484838\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439559\tvalid_1's binary_logloss: 0.484838\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439489\tvalid_1's binary_logloss: 0.484839\n",
      "[1200]\ttraining's binary_logloss: 0.439421\tvalid_1's binary_logloss: 0.484839\n",
      "Early stopping, best iteration is:\n",
      "[1147]\ttraining's binary_logloss: 0.439457\tvalid_1's binary_logloss: 0.484835\n",
      "===== ACCURACY SCORE 0.781392 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509579\tvalid_1's binary_logloss: 0.527429\n",
      "[200]\ttraining's binary_logloss: 0.469064\tvalid_1's binary_logloss: 0.494971\n",
      "[300]\ttraining's binary_logloss: 0.455341\tvalid_1's binary_logloss: 0.487973\n",
      "[400]\ttraining's binary_logloss: 0.449388\tvalid_1's binary_logloss: 0.486382\n",
      "[500]\ttraining's binary_logloss: 0.445905\tvalid_1's binary_logloss: 0.485817\n",
      "[600]\ttraining's binary_logloss: 0.443698\tvalid_1's binary_logloss: 0.48531\n",
      "[700]\ttraining's binary_logloss: 0.44222\tvalid_1's binary_logloss: 0.48506\n",
      "[800]\ttraining's binary_logloss: 0.441161\tvalid_1's binary_logloss: 0.484979\n",
      "[900]\ttraining's binary_logloss: 0.440351\tvalid_1's binary_logloss: 0.484851\n",
      "[1000]\ttraining's binary_logloss: 0.43964\tvalid_1's binary_logloss: 0.484679\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.43964\tvalid_1's binary_logloss: 0.484679\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439576\tvalid_1's binary_logloss: 0.484667\n",
      "[1200]\ttraining's binary_logloss: 0.43951\tvalid_1's binary_logloss: 0.484655\n",
      "[1300]\ttraining's binary_logloss: 0.439445\tvalid_1's binary_logloss: 0.48464\n",
      "[1400]\ttraining's binary_logloss: 0.439382\tvalid_1's binary_logloss: 0.484623\n",
      "[1500]\ttraining's binary_logloss: 0.439322\tvalid_1's binary_logloss: 0.484615\n",
      "[1600]\ttraining's binary_logloss: 0.439263\tvalid_1's binary_logloss: 0.484612\n",
      "[1700]\ttraining's binary_logloss: 0.439201\tvalid_1's binary_logloss: 0.484609\n",
      "[1800]\ttraining's binary_logloss: 0.439137\tvalid_1's binary_logloss: 0.484602\n",
      "[1900]\ttraining's binary_logloss: 0.439078\tvalid_1's binary_logloss: 0.484585\n",
      "[2000]\ttraining's binary_logloss: 0.439018\tvalid_1's binary_logloss: 0.484571\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439018\tvalid_1's binary_logloss: 0.484571\n",
      "===== ACCURACY SCORE 0.777977 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509784\tvalid_1's binary_logloss: 0.524014\n",
      "[200]\ttraining's binary_logloss: 0.469659\tvalid_1's binary_logloss: 0.48975\n",
      "[300]\ttraining's binary_logloss: 0.456042\tvalid_1's binary_logloss: 0.482224\n",
      "[400]\ttraining's binary_logloss: 0.449956\tvalid_1's binary_logloss: 0.480308\n",
      "[500]\ttraining's binary_logloss: 0.446397\tvalid_1's binary_logloss: 0.479616\n",
      "[600]\ttraining's binary_logloss: 0.444076\tvalid_1's binary_logloss: 0.479192\n",
      "[700]\ttraining's binary_logloss: 0.442575\tvalid_1's binary_logloss: 0.479194\n",
      "[800]\ttraining's binary_logloss: 0.441499\tvalid_1's binary_logloss: 0.479205\n",
      "Early stopping, best iteration is:\n",
      "[742]\ttraining's binary_logloss: 0.442078\tvalid_1's binary_logloss: 0.479144\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.442017\tvalid_1's binary_logloss: 0.479149\n",
      "Early stopping, best iteration is:\n",
      "[751]\ttraining's binary_logloss: 0.442069\tvalid_1's binary_logloss: 0.479143\n",
      "===== ACCURACY SCORE 0.784944 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509531\tvalid_1's binary_logloss: 0.53017\n",
      "[200]\ttraining's binary_logloss: 0.469056\tvalid_1's binary_logloss: 0.497699\n",
      "[300]\ttraining's binary_logloss: 0.455275\tvalid_1's binary_logloss: 0.491204\n",
      "[400]\ttraining's binary_logloss: 0.449367\tvalid_1's binary_logloss: 0.489939\n",
      "[500]\ttraining's binary_logloss: 0.445877\tvalid_1's binary_logloss: 0.489603\n",
      "[600]\ttraining's binary_logloss: 0.443638\tvalid_1's binary_logloss: 0.489536\n",
      "Early stopping, best iteration is:\n",
      "[593]\ttraining's binary_logloss: 0.443763\tvalid_1's binary_logloss: 0.489495\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.443749\tvalid_1's binary_logloss: 0.489493\n",
      "Early stopping, best iteration is:\n",
      "[599]\ttraining's binary_logloss: 0.44375\tvalid_1's binary_logloss: 0.489493\n",
      "===== ACCURACY SCORE 0.775057 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509606\tvalid_1's binary_logloss: 0.528338\n",
      "[200]\ttraining's binary_logloss: 0.469578\tvalid_1's binary_logloss: 0.495071\n",
      "[300]\ttraining's binary_logloss: 0.455987\tvalid_1's binary_logloss: 0.488027\n",
      "[400]\ttraining's binary_logloss: 0.450118\tvalid_1's binary_logloss: 0.486497\n",
      "[500]\ttraining's binary_logloss: 0.446719\tvalid_1's binary_logloss: 0.486077\n",
      "[600]\ttraining's binary_logloss: 0.4445\tvalid_1's binary_logloss: 0.486049\n",
      "Early stopping, best iteration is:\n",
      "[517]\ttraining's binary_logloss: 0.446258\tvalid_1's binary_logloss: 0.485946\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.44605\tvalid_1's binary_logloss: 0.485952\n",
      "Early stopping, best iteration is:\n",
      "[521]\ttraining's binary_logloss: 0.446248\tvalid_1's binary_logloss: 0.485945\n",
      "===== ACCURACY SCORE 0.780433 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50861\tvalid_1's binary_logloss: 0.531298\n",
      "[200]\ttraining's binary_logloss: 0.467795\tvalid_1's binary_logloss: 0.502007\n",
      "[300]\ttraining's binary_logloss: 0.453833\tvalid_1's binary_logloss: 0.496851\n",
      "[400]\ttraining's binary_logloss: 0.4477\tvalid_1's binary_logloss: 0.496343\n",
      "Early stopping, best iteration is:\n",
      "[381]\ttraining's binary_logloss: 0.448565\tvalid_1's binary_logloss: 0.496338\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.448476\tvalid_1's binary_logloss: 0.496338\n",
      "Early stopping, best iteration is:\n",
      "[385]\ttraining's binary_logloss: 0.448546\tvalid_1's binary_logloss: 0.496337\n",
      "===== ACCURACY SCORE 0.772373 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509078\tvalid_1's binary_logloss: 0.524405\n",
      "[200]\ttraining's binary_logloss: 0.468667\tvalid_1's binary_logloss: 0.490783\n",
      "[300]\ttraining's binary_logloss: 0.455218\tvalid_1's binary_logloss: 0.48358\n",
      "[400]\ttraining's binary_logloss: 0.449291\tvalid_1's binary_logloss: 0.481969\n",
      "[500]\ttraining's binary_logloss: 0.445949\tvalid_1's binary_logloss: 0.481409\n",
      "[600]\ttraining's binary_logloss: 0.443647\tvalid_1's binary_logloss: 0.480936\n",
      "[700]\ttraining's binary_logloss: 0.442197\tvalid_1's binary_logloss: 0.48072\n",
      "[800]\ttraining's binary_logloss: 0.441099\tvalid_1's binary_logloss: 0.480602\n",
      "[900]\ttraining's binary_logloss: 0.440215\tvalid_1's binary_logloss: 0.480435\n",
      "[1000]\ttraining's binary_logloss: 0.439508\tvalid_1's binary_logloss: 0.480314\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439508\tvalid_1's binary_logloss: 0.480314\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439438\tvalid_1's binary_logloss: 0.48031\n",
      "[1200]\ttraining's binary_logloss: 0.439368\tvalid_1's binary_logloss: 0.480306\n",
      "[1300]\ttraining's binary_logloss: 0.439301\tvalid_1's binary_logloss: 0.480301\n",
      "Early stopping, best iteration is:\n",
      "[1252]\ttraining's binary_logloss: 0.439333\tvalid_1's binary_logloss: 0.480298\n",
      "===== ACCURACY SCORE 0.783713 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510259\tvalid_1's binary_logloss: 0.529907\n",
      "[200]\ttraining's binary_logloss: 0.47009\tvalid_1's binary_logloss: 0.498473\n",
      "[300]\ttraining's binary_logloss: 0.45659\tvalid_1's binary_logloss: 0.492145\n",
      "[400]\ttraining's binary_logloss: 0.450594\tvalid_1's binary_logloss: 0.491006\n",
      "[500]\ttraining's binary_logloss: 0.447183\tvalid_1's binary_logloss: 0.490796\n",
      "[600]\ttraining's binary_logloss: 0.444882\tvalid_1's binary_logloss: 0.490718\n",
      "Early stopping, best iteration is:\n",
      "[552]\ttraining's binary_logloss: 0.445826\tvalid_1's binary_logloss: 0.490673\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.445725\tvalid_1's binary_logloss: 0.490678\n",
      "Early stopping, best iteration is:\n",
      "[553]\ttraining's binary_logloss: 0.445823\tvalid_1's binary_logloss: 0.490672\n",
      "===== ACCURACY SCORE 0.780808 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509944\tvalid_1's binary_logloss: 0.527424\n",
      "[200]\ttraining's binary_logloss: 0.469518\tvalid_1's binary_logloss: 0.495541\n",
      "[300]\ttraining's binary_logloss: 0.455843\tvalid_1's binary_logloss: 0.489981\n",
      "[400]\ttraining's binary_logloss: 0.449852\tvalid_1's binary_logloss: 0.489206\n",
      "[500]\ttraining's binary_logloss: 0.446425\tvalid_1's binary_logloss: 0.489101\n",
      "[600]\ttraining's binary_logloss: 0.444196\tvalid_1's binary_logloss: 0.48902\n",
      "Early stopping, best iteration is:\n",
      "[589]\ttraining's binary_logloss: 0.444383\tvalid_1's binary_logloss: 0.48897\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.444362\tvalid_1's binary_logloss: 0.488971\n",
      "[700]\ttraining's binary_logloss: 0.444187\tvalid_1's binary_logloss: 0.488956\n",
      "[800]\ttraining's binary_logloss: 0.444025\tvalid_1's binary_logloss: 0.48896\n",
      "[900]\ttraining's binary_logloss: 0.443864\tvalid_1's binary_logloss: 0.48895\n",
      "Early stopping, best iteration is:\n",
      "[845]\ttraining's binary_logloss: 0.443947\tvalid_1's binary_logloss: 0.488944\n",
      "===== ACCURACY SCORE 0.777286 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779240 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509669\tvalid_1's binary_logloss: 0.523307\n",
      "[200]\ttraining's binary_logloss: 0.469689\tvalid_1's binary_logloss: 0.487893\n",
      "[300]\ttraining's binary_logloss: 0.456286\tvalid_1's binary_logloss: 0.47947\n",
      "[400]\ttraining's binary_logloss: 0.450353\tvalid_1's binary_logloss: 0.477203\n",
      "[500]\ttraining's binary_logloss: 0.446881\tvalid_1's binary_logloss: 0.476289\n",
      "[600]\ttraining's binary_logloss: 0.4446\tvalid_1's binary_logloss: 0.475888\n",
      "[700]\ttraining's binary_logloss: 0.443141\tvalid_1's binary_logloss: 0.475855\n",
      "[800]\ttraining's binary_logloss: 0.44205\tvalid_1's binary_logloss: 0.475628\n",
      "Early stopping, best iteration is:\n",
      "[799]\ttraining's binary_logloss: 0.442058\tvalid_1's binary_logloss: 0.475624\n",
      "[800]\ttraining's binary_logloss: 0.442057\tvalid_1's binary_logloss: 0.475623\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[900]\ttraining's binary_logloss: 0.441965\tvalid_1's binary_logloss: 0.475618\n",
      "[1000]\ttraining's binary_logloss: 0.441874\tvalid_1's binary_logloss: 0.475615\n",
      "[1100]\ttraining's binary_logloss: 0.441783\tvalid_1's binary_logloss: 0.475608\n",
      "[1200]\ttraining's binary_logloss: 0.441695\tvalid_1's binary_logloss: 0.475611\n",
      "Early stopping, best iteration is:\n",
      "[1108]\ttraining's binary_logloss: 0.441775\tvalid_1's binary_logloss: 0.475605\n",
      "===== ACCURACY SCORE 0.785528 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509858\tvalid_1's binary_logloss: 0.526123\n",
      "[200]\ttraining's binary_logloss: 0.469519\tvalid_1's binary_logloss: 0.492371\n",
      "[300]\ttraining's binary_logloss: 0.455944\tvalid_1's binary_logloss: 0.484774\n",
      "[400]\ttraining's binary_logloss: 0.450026\tvalid_1's binary_logloss: 0.482981\n",
      "[500]\ttraining's binary_logloss: 0.446614\tvalid_1's binary_logloss: 0.482293\n",
      "[600]\ttraining's binary_logloss: 0.44439\tvalid_1's binary_logloss: 0.481843\n",
      "[700]\ttraining's binary_logloss: 0.442944\tvalid_1's binary_logloss: 0.481538\n",
      "[800]\ttraining's binary_logloss: 0.44185\tvalid_1's binary_logloss: 0.481305\n",
      "[900]\ttraining's binary_logloss: 0.441004\tvalid_1's binary_logloss: 0.481162\n",
      "[1000]\ttraining's binary_logloss: 0.440258\tvalid_1's binary_logloss: 0.48104\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440258\tvalid_1's binary_logloss: 0.48104\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440191\tvalid_1's binary_logloss: 0.481037\n",
      "[1200]\ttraining's binary_logloss: 0.440123\tvalid_1's binary_logloss: 0.481021\n",
      "[1300]\ttraining's binary_logloss: 0.440054\tvalid_1's binary_logloss: 0.481017\n",
      "Early stopping, best iteration is:\n",
      "[1232]\ttraining's binary_logloss: 0.4401\tvalid_1's binary_logloss: 0.481013\n",
      "===== ACCURACY SCORE 0.781427 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50935\tvalid_1's binary_logloss: 0.53017\n",
      "[200]\ttraining's binary_logloss: 0.469117\tvalid_1's binary_logloss: 0.498679\n",
      "[300]\ttraining's binary_logloss: 0.455569\tvalid_1's binary_logloss: 0.492628\n",
      "[400]\ttraining's binary_logloss: 0.449632\tvalid_1's binary_logloss: 0.491452\n",
      "[500]\ttraining's binary_logloss: 0.446242\tvalid_1's binary_logloss: 0.49111\n",
      "[600]\ttraining's binary_logloss: 0.443991\tvalid_1's binary_logloss: 0.490716\n",
      "[700]\ttraining's binary_logloss: 0.442463\tvalid_1's binary_logloss: 0.490581\n",
      "[800]\ttraining's binary_logloss: 0.441383\tvalid_1's binary_logloss: 0.49049\n",
      "Early stopping, best iteration is:\n",
      "[730]\ttraining's binary_logloss: 0.442094\tvalid_1's binary_logloss: 0.490446\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.442017\tvalid_1's binary_logloss: 0.49044\n",
      "[900]\ttraining's binary_logloss: 0.441908\tvalid_1's binary_logloss: 0.490434\n",
      "[1000]\ttraining's binary_logloss: 0.441799\tvalid_1's binary_logloss: 0.490432\n",
      "Early stopping, best iteration is:\n",
      "[971]\ttraining's binary_logloss: 0.441831\tvalid_1's binary_logloss: 0.490428\n",
      "===== ACCURACY SCORE 0.778638 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509894\tvalid_1's binary_logloss: 0.530743\n",
      "[200]\ttraining's binary_logloss: 0.4694\tvalid_1's binary_logloss: 0.500345\n",
      "[300]\ttraining's binary_logloss: 0.455731\tvalid_1's binary_logloss: 0.495052\n",
      "[400]\ttraining's binary_logloss: 0.449692\tvalid_1's binary_logloss: 0.494567\n",
      "Early stopping, best iteration is:\n",
      "[399]\ttraining's binary_logloss: 0.449732\tvalid_1's binary_logloss: 0.494556\n",
      "[400]\ttraining's binary_logloss: 0.449728\tvalid_1's binary_logloss: 0.494555\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.449321\tvalid_1's binary_logloss: 0.494568\n",
      "Early stopping, best iteration is:\n",
      "[414]\ttraining's binary_logloss: 0.449668\tvalid_1's binary_logloss: 0.494551\n",
      "===== ACCURACY SCORE 0.775419 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508307\tvalid_1's binary_logloss: 0.532262\n",
      "[200]\ttraining's binary_logloss: 0.467807\tvalid_1's binary_logloss: 0.501852\n",
      "[300]\ttraining's binary_logloss: 0.454047\tvalid_1's binary_logloss: 0.496704\n",
      "[400]\ttraining's binary_logloss: 0.44805\tvalid_1's binary_logloss: 0.49633\n",
      "Early stopping, best iteration is:\n",
      "[378]\ttraining's binary_logloss: 0.448994\tvalid_1's binary_logloss: 0.496303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.448892\tvalid_1's binary_logloss: 0.496299\n",
      "Early stopping, best iteration is:\n",
      "[394]\ttraining's binary_logloss: 0.44892\tvalid_1's binary_logloss: 0.496296\n",
      "===== ACCURACY SCORE 0.772804 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510547\tvalid_1's binary_logloss: 0.530717\n",
      "[200]\ttraining's binary_logloss: 0.470462\tvalid_1's binary_logloss: 0.500007\n",
      "[300]\ttraining's binary_logloss: 0.456949\tvalid_1's binary_logloss: 0.494284\n",
      "[400]\ttraining's binary_logloss: 0.450984\tvalid_1's binary_logloss: 0.493561\n",
      "[500]\ttraining's binary_logloss: 0.447568\tvalid_1's binary_logloss: 0.493541\n",
      "[600]\ttraining's binary_logloss: 0.445307\tvalid_1's binary_logloss: 0.493595\n",
      "Early stopping, best iteration is:\n",
      "[526]\ttraining's binary_logloss: 0.446859\tvalid_1's binary_logloss: 0.493477\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.44668\tvalid_1's binary_logloss: 0.493479\n",
      "Early stopping, best iteration is:\n",
      "[541]\ttraining's binary_logloss: 0.446823\tvalid_1's binary_logloss: 0.493475\n",
      "===== ACCURACY SCORE 0.776589 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509522\tvalid_1's binary_logloss: 0.522493\n",
      "[200]\ttraining's binary_logloss: 0.469143\tvalid_1's binary_logloss: 0.487631\n",
      "[300]\ttraining's binary_logloss: 0.455401\tvalid_1's binary_logloss: 0.479714\n",
      "[400]\ttraining's binary_logloss: 0.449376\tvalid_1's binary_logloss: 0.477881\n",
      "[500]\ttraining's binary_logloss: 0.445857\tvalid_1's binary_logloss: 0.477326\n",
      "[600]\ttraining's binary_logloss: 0.443555\tvalid_1's binary_logloss: 0.477185\n",
      "Early stopping, best iteration is:\n",
      "[574]\ttraining's binary_logloss: 0.444038\tvalid_1's binary_logloss: 0.4771\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.443989\tvalid_1's binary_logloss: 0.477104\n",
      "Early stopping, best iteration is:\n",
      "[580]\ttraining's binary_logloss: 0.444027\tvalid_1's binary_logloss: 0.4771\n",
      "===== ACCURACY SCORE 0.788038 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509605\tvalid_1's binary_logloss: 0.530018\n",
      "[200]\ttraining's binary_logloss: 0.469313\tvalid_1's binary_logloss: 0.498083\n",
      "[300]\ttraining's binary_logloss: 0.455751\tvalid_1's binary_logloss: 0.491841\n",
      "[400]\ttraining's binary_logloss: 0.449989\tvalid_1's binary_logloss: 0.490582\n",
      "[500]\ttraining's binary_logloss: 0.446609\tvalid_1's binary_logloss: 0.490506\n",
      "[600]\ttraining's binary_logloss: 0.444367\tvalid_1's binary_logloss: 0.490293\n",
      "Early stopping, best iteration is:\n",
      "[585]\ttraining's binary_logloss: 0.444644\tvalid_1's binary_logloss: 0.490265\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.444616\tvalid_1's binary_logloss: 0.490268\n",
      "Early stopping, best iteration is:\n",
      "[586]\ttraining's binary_logloss: 0.444643\tvalid_1's binary_logloss: 0.490265\n",
      "===== ACCURACY SCORE 0.775603 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508938\tvalid_1's binary_logloss: 0.52864\n",
      "[200]\ttraining's binary_logloss: 0.468504\tvalid_1's binary_logloss: 0.496117\n",
      "[300]\ttraining's binary_logloss: 0.454795\tvalid_1's binary_logloss: 0.48928\n",
      "[400]\ttraining's binary_logloss: 0.448789\tvalid_1's binary_logloss: 0.487727\n",
      "[500]\ttraining's binary_logloss: 0.445339\tvalid_1's binary_logloss: 0.487158\n",
      "[600]\ttraining's binary_logloss: 0.443112\tvalid_1's binary_logloss: 0.486894\n",
      "[700]\ttraining's binary_logloss: 0.441621\tvalid_1's binary_logloss: 0.486695\n",
      "[800]\ttraining's binary_logloss: 0.440524\tvalid_1's binary_logloss: 0.486538\n",
      "[900]\ttraining's binary_logloss: 0.439684\tvalid_1's binary_logloss: 0.486482\n",
      "[1000]\ttraining's binary_logloss: 0.438935\tvalid_1's binary_logloss: 0.486368\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.438935\tvalid_1's binary_logloss: 0.486368\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.438865\tvalid_1's binary_logloss: 0.486355\n",
      "[1200]\ttraining's binary_logloss: 0.438796\tvalid_1's binary_logloss: 0.486339\n",
      "[1300]\ttraining's binary_logloss: 0.438725\tvalid_1's binary_logloss: 0.486326\n",
      "[1400]\ttraining's binary_logloss: 0.438657\tvalid_1's binary_logloss: 0.486318\n",
      "[1500]\ttraining's binary_logloss: 0.43859\tvalid_1's binary_logloss: 0.486307\n",
      "[1600]\ttraining's binary_logloss: 0.438522\tvalid_1's binary_logloss: 0.486296\n",
      "[1700]\ttraining's binary_logloss: 0.438456\tvalid_1's binary_logloss: 0.486297\n",
      "Early stopping, best iteration is:\n",
      "[1658]\ttraining's binary_logloss: 0.438484\tvalid_1's binary_logloss: 0.486291\n",
      "===== ACCURACY SCORE 0.778433 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509244\tvalid_1's binary_logloss: 0.527926\n",
      "[200]\ttraining's binary_logloss: 0.4688\tvalid_1's binary_logloss: 0.495967\n",
      "[300]\ttraining's binary_logloss: 0.45518\tvalid_1's binary_logloss: 0.489913\n",
      "[400]\ttraining's binary_logloss: 0.449291\tvalid_1's binary_logloss: 0.488967\n",
      "[500]\ttraining's binary_logloss: 0.445862\tvalid_1's binary_logloss: 0.488886\n",
      "[600]\ttraining's binary_logloss: 0.443605\tvalid_1's binary_logloss: 0.488714\n",
      "[700]\ttraining's binary_logloss: 0.44213\tvalid_1's binary_logloss: 0.488613\n",
      "[800]\ttraining's binary_logloss: 0.441068\tvalid_1's binary_logloss: 0.488511\n",
      "Early stopping, best iteration is:\n",
      "[779]\ttraining's binary_logloss: 0.441266\tvalid_1's binary_logloss: 0.488477\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.441244\tvalid_1's binary_logloss: 0.488469\n",
      "[900]\ttraining's binary_logloss: 0.44115\tvalid_1's binary_logloss: 0.488473\n",
      "Early stopping, best iteration is:\n",
      "[881]\ttraining's binary_logloss: 0.441166\tvalid_1's binary_logloss: 0.488468\n",
      "===== ACCURACY SCORE 0.777130 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778950 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508978\tvalid_1's binary_logloss: 0.524799\n",
      "[200]\ttraining's binary_logloss: 0.468478\tvalid_1's binary_logloss: 0.490899\n",
      "[300]\ttraining's binary_logloss: 0.45491\tvalid_1's binary_logloss: 0.483493\n",
      "[400]\ttraining's binary_logloss: 0.448879\tvalid_1's binary_logloss: 0.482\n",
      "[500]\ttraining's binary_logloss: 0.445441\tvalid_1's binary_logloss: 0.48179\n",
      "[600]\ttraining's binary_logloss: 0.443111\tvalid_1's binary_logloss: 0.481819\n",
      "Early stopping, best iteration is:\n",
      "[520]\ttraining's binary_logloss: 0.44486\tvalid_1's binary_logloss: 0.481727\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.444656\tvalid_1's binary_logloss: 0.481722\n",
      "[700]\ttraining's binary_logloss: 0.444414\tvalid_1's binary_logloss: 0.48172\n",
      "Early stopping, best iteration is:\n",
      "[643]\ttraining's binary_logloss: 0.444547\tvalid_1's binary_logloss: 0.481714\n",
      "===== ACCURACY SCORE 0.783626 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509207\tvalid_1's binary_logloss: 0.522349\n",
      "[200]\ttraining's binary_logloss: 0.468747\tvalid_1's binary_logloss: 0.489115\n",
      "[300]\ttraining's binary_logloss: 0.455215\tvalid_1's binary_logloss: 0.482055\n",
      "[400]\ttraining's binary_logloss: 0.449271\tvalid_1's binary_logloss: 0.480375\n",
      "[500]\ttraining's binary_logloss: 0.445913\tvalid_1's binary_logloss: 0.480121\n",
      "[600]\ttraining's binary_logloss: 0.443697\tvalid_1's binary_logloss: 0.479806\n",
      "[700]\ttraining's binary_logloss: 0.442208\tvalid_1's binary_logloss: 0.47948\n",
      "[800]\ttraining's binary_logloss: 0.441122\tvalid_1's binary_logloss: 0.479221\n",
      "[900]\ttraining's binary_logloss: 0.440246\tvalid_1's binary_logloss: 0.479082\n",
      "[1000]\ttraining's binary_logloss: 0.439507\tvalid_1's binary_logloss: 0.479051\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439507\tvalid_1's binary_logloss: 0.479051\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439437\tvalid_1's binary_logloss: 0.479038\n",
      "[1200]\ttraining's binary_logloss: 0.439369\tvalid_1's binary_logloss: 0.47904\n",
      "Early stopping, best iteration is:\n",
      "[1104]\ttraining's binary_logloss: 0.439434\tvalid_1's binary_logloss: 0.479038\n",
      "===== ACCURACY SCORE 0.785536 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510463\tvalid_1's binary_logloss: 0.523483\n",
      "[200]\ttraining's binary_logloss: 0.470388\tvalid_1's binary_logloss: 0.488913\n",
      "[300]\ttraining's binary_logloss: 0.456891\tvalid_1's binary_logloss: 0.481091\n",
      "[400]\ttraining's binary_logloss: 0.451021\tvalid_1's binary_logloss: 0.479252\n",
      "[500]\ttraining's binary_logloss: 0.447555\tvalid_1's binary_logloss: 0.478736\n",
      "[600]\ttraining's binary_logloss: 0.44537\tvalid_1's binary_logloss: 0.478653\n",
      "[700]\ttraining's binary_logloss: 0.443864\tvalid_1's binary_logloss: 0.478425\n",
      "[800]\ttraining's binary_logloss: 0.442804\tvalid_1's binary_logloss: 0.478339\n",
      "[900]\ttraining's binary_logloss: 0.441948\tvalid_1's binary_logloss: 0.478247\n",
      "[1000]\ttraining's binary_logloss: 0.441218\tvalid_1's binary_logloss: 0.478197\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.441218\tvalid_1's binary_logloss: 0.478197\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.44115\tvalid_1's binary_logloss: 0.478182\n",
      "[1200]\ttraining's binary_logloss: 0.441084\tvalid_1's binary_logloss: 0.478173\n",
      "[1300]\ttraining's binary_logloss: 0.441018\tvalid_1's binary_logloss: 0.478154\n",
      "[1400]\ttraining's binary_logloss: 0.440953\tvalid_1's binary_logloss: 0.478145\n",
      "[1500]\ttraining's binary_logloss: 0.44089\tvalid_1's binary_logloss: 0.478136\n",
      "Early stopping, best iteration is:\n",
      "[1468]\ttraining's binary_logloss: 0.440909\tvalid_1's binary_logloss: 0.478132\n",
      "===== ACCURACY SCORE 0.783878 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508519\tvalid_1's binary_logloss: 0.529067\n",
      "[200]\ttraining's binary_logloss: 0.468107\tvalid_1's binary_logloss: 0.497145\n",
      "[300]\ttraining's binary_logloss: 0.454452\tvalid_1's binary_logloss: 0.490752\n",
      "[400]\ttraining's binary_logloss: 0.448433\tvalid_1's binary_logloss: 0.489422\n",
      "[500]\ttraining's binary_logloss: 0.4449\tvalid_1's binary_logloss: 0.488989\n",
      "[600]\ttraining's binary_logloss: 0.44266\tvalid_1's binary_logloss: 0.488606\n",
      "[700]\ttraining's binary_logloss: 0.441142\tvalid_1's binary_logloss: 0.488475\n",
      "[800]\ttraining's binary_logloss: 0.439993\tvalid_1's binary_logloss: 0.488308\n",
      "Early stopping, best iteration is:\n",
      "[794]\ttraining's binary_logloss: 0.44005\tvalid_1's binary_logloss: 0.488276\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.440044\tvalid_1's binary_logloss: 0.488273\n",
      "[900]\ttraining's binary_logloss: 0.439945\tvalid_1's binary_logloss: 0.488282\n",
      "Early stopping, best iteration is:\n",
      "[802]\ttraining's binary_logloss: 0.440042\tvalid_1's binary_logloss: 0.488271\n",
      "===== ACCURACY SCORE 0.776386 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508626\tvalid_1's binary_logloss: 0.532383\n",
      "[200]\ttraining's binary_logloss: 0.468027\tvalid_1's binary_logloss: 0.502454\n",
      "[300]\ttraining's binary_logloss: 0.454414\tvalid_1's binary_logloss: 0.496919\n",
      "[400]\ttraining's binary_logloss: 0.448527\tvalid_1's binary_logloss: 0.495914\n",
      "[500]\ttraining's binary_logloss: 0.445124\tvalid_1's binary_logloss: 0.495516\n",
      "[600]\ttraining's binary_logloss: 0.443011\tvalid_1's binary_logloss: 0.495272\n",
      "[700]\ttraining's binary_logloss: 0.441555\tvalid_1's binary_logloss: 0.495034\n",
      "[800]\ttraining's binary_logloss: 0.440506\tvalid_1's binary_logloss: 0.494809\n",
      "[900]\ttraining's binary_logloss: 0.439678\tvalid_1's binary_logloss: 0.494611\n",
      "[1000]\ttraining's binary_logloss: 0.438967\tvalid_1's binary_logloss: 0.494454\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.438967\tvalid_1's binary_logloss: 0.494454\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.4389\tvalid_1's binary_logloss: 0.494439\n",
      "[1200]\ttraining's binary_logloss: 0.438834\tvalid_1's binary_logloss: 0.494427\n",
      "[1300]\ttraining's binary_logloss: 0.438767\tvalid_1's binary_logloss: 0.49441\n",
      "[1400]\ttraining's binary_logloss: 0.438699\tvalid_1's binary_logloss: 0.494397\n",
      "[1500]\ttraining's binary_logloss: 0.438634\tvalid_1's binary_logloss: 0.494373\n",
      "[1600]\ttraining's binary_logloss: 0.438568\tvalid_1's binary_logloss: 0.494358\n",
      "[1700]\ttraining's binary_logloss: 0.438504\tvalid_1's binary_logloss: 0.494342\n",
      "[1800]\ttraining's binary_logloss: 0.438439\tvalid_1's binary_logloss: 0.494333\n",
      "[1900]\ttraining's binary_logloss: 0.438379\tvalid_1's binary_logloss: 0.494327\n",
      "[2000]\ttraining's binary_logloss: 0.438318\tvalid_1's binary_logloss: 0.49432\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.438318\tvalid_1's binary_logloss: 0.49432\n",
      "===== ACCURACY SCORE 0.774203 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509202\tvalid_1's binary_logloss: 0.528466\n",
      "[200]\ttraining's binary_logloss: 0.469068\tvalid_1's binary_logloss: 0.495889\n",
      "[300]\ttraining's binary_logloss: 0.455537\tvalid_1's binary_logloss: 0.489157\n",
      "[400]\ttraining's binary_logloss: 0.4498\tvalid_1's binary_logloss: 0.487486\n",
      "[500]\ttraining's binary_logloss: 0.446555\tvalid_1's binary_logloss: 0.486907\n",
      "[600]\ttraining's binary_logloss: 0.444402\tvalid_1's binary_logloss: 0.486334\n",
      "[700]\ttraining's binary_logloss: 0.442954\tvalid_1's binary_logloss: 0.485952\n",
      "[800]\ttraining's binary_logloss: 0.441898\tvalid_1's binary_logloss: 0.485784\n",
      "[900]\ttraining's binary_logloss: 0.441069\tvalid_1's binary_logloss: 0.485745\n",
      "[1000]\ttraining's binary_logloss: 0.440354\tvalid_1's binary_logloss: 0.485638\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440354\tvalid_1's binary_logloss: 0.485638\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440289\tvalid_1's binary_logloss: 0.485633\n",
      "[1200]\ttraining's binary_logloss: 0.440224\tvalid_1's binary_logloss: 0.485617\n",
      "[1300]\ttraining's binary_logloss: 0.44016\tvalid_1's binary_logloss: 0.485609\n",
      "[1400]\ttraining's binary_logloss: 0.440096\tvalid_1's binary_logloss: 0.485599\n",
      "[1500]\ttraining's binary_logloss: 0.440034\tvalid_1's binary_logloss: 0.4856\n",
      "[1600]\ttraining's binary_logloss: 0.439972\tvalid_1's binary_logloss: 0.485596\n",
      "[1700]\ttraining's binary_logloss: 0.439909\tvalid_1's binary_logloss: 0.485584\n",
      "[1800]\ttraining's binary_logloss: 0.439847\tvalid_1's binary_logloss: 0.485574\n",
      "[1900]\ttraining's binary_logloss: 0.439784\tvalid_1's binary_logloss: 0.485572\n",
      "[2000]\ttraining's binary_logloss: 0.439724\tvalid_1's binary_logloss: 0.48556\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439724\tvalid_1's binary_logloss: 0.48556\n",
      "===== ACCURACY SCORE 0.779201 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509059\tvalid_1's binary_logloss: 0.533085\n",
      "[200]\ttraining's binary_logloss: 0.468454\tvalid_1's binary_logloss: 0.502912\n",
      "[300]\ttraining's binary_logloss: 0.454638\tvalid_1's binary_logloss: 0.498085\n",
      "[400]\ttraining's binary_logloss: 0.448642\tvalid_1's binary_logloss: 0.497646\n",
      "Early stopping, best iteration is:\n",
      "[393]\ttraining's binary_logloss: 0.448931\tvalid_1's binary_logloss: 0.497625\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.448902\tvalid_1's binary_logloss: 0.497624\n",
      "Early stopping, best iteration is:\n",
      "[397]\ttraining's binary_logloss: 0.448915\tvalid_1's binary_logloss: 0.497623\n",
      "===== ACCURACY SCORE 0.775580 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50994\tvalid_1's binary_logloss: 0.532426\n",
      "[200]\ttraining's binary_logloss: 0.469653\tvalid_1's binary_logloss: 0.501646\n",
      "[300]\ttraining's binary_logloss: 0.456145\tvalid_1's binary_logloss: 0.495852\n",
      "[400]\ttraining's binary_logloss: 0.450264\tvalid_1's binary_logloss: 0.495145\n",
      "[500]\ttraining's binary_logloss: 0.446839\tvalid_1's binary_logloss: 0.495139\n",
      "Early stopping, best iteration is:\n",
      "[424]\ttraining's binary_logloss: 0.449323\tvalid_1's binary_logloss: 0.495075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.449048\tvalid_1's binary_logloss: 0.495073\n",
      "[600]\ttraining's binary_logloss: 0.448705\tvalid_1's binary_logloss: 0.495074\n",
      "[700]\ttraining's binary_logloss: 0.448355\tvalid_1's binary_logloss: 0.495068\n",
      "Early stopping, best iteration is:\n",
      "[644]\ttraining's binary_logloss: 0.448546\tvalid_1's binary_logloss: 0.495042\n",
      "===== ACCURACY SCORE 0.772226 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509364\tvalid_1's binary_logloss: 0.524591\n",
      "[200]\ttraining's binary_logloss: 0.469105\tvalid_1's binary_logloss: 0.491107\n",
      "[300]\ttraining's binary_logloss: 0.455518\tvalid_1's binary_logloss: 0.484258\n",
      "[400]\ttraining's binary_logloss: 0.449482\tvalid_1's binary_logloss: 0.482941\n",
      "[500]\ttraining's binary_logloss: 0.445941\tvalid_1's binary_logloss: 0.482722\n",
      "[600]\ttraining's binary_logloss: 0.443599\tvalid_1's binary_logloss: 0.482697\n",
      "[700]\ttraining's binary_logloss: 0.442053\tvalid_1's binary_logloss: 0.482812\n",
      "Early stopping, best iteration is:\n",
      "[600]\ttraining's binary_logloss: 0.443599\tvalid_1's binary_logloss: 0.482697\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.443414\tvalid_1's binary_logloss: 0.482701\n",
      "Early stopping, best iteration is:\n",
      "[601]\ttraining's binary_logloss: 0.443597\tvalid_1's binary_logloss: 0.482697\n",
      "===== ACCURACY SCORE 0.778552 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510373\tvalid_1's binary_logloss: 0.529603\n",
      "[200]\ttraining's binary_logloss: 0.470205\tvalid_1's binary_logloss: 0.497672\n",
      "[300]\ttraining's binary_logloss: 0.456538\tvalid_1's binary_logloss: 0.491252\n",
      "[400]\ttraining's binary_logloss: 0.450438\tvalid_1's binary_logloss: 0.489853\n",
      "[500]\ttraining's binary_logloss: 0.446862\tvalid_1's binary_logloss: 0.489357\n",
      "[600]\ttraining's binary_logloss: 0.444576\tvalid_1's binary_logloss: 0.489138\n",
      "[700]\ttraining's binary_logloss: 0.443017\tvalid_1's binary_logloss: 0.488968\n",
      "[800]\ttraining's binary_logloss: 0.441905\tvalid_1's binary_logloss: 0.488822\n",
      "[900]\ttraining's binary_logloss: 0.441011\tvalid_1's binary_logloss: 0.488817\n",
      "[1000]\ttraining's binary_logloss: 0.440269\tvalid_1's binary_logloss: 0.488682\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440269\tvalid_1's binary_logloss: 0.488682\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440195\tvalid_1's binary_logloss: 0.488672\n",
      "[1200]\ttraining's binary_logloss: 0.440126\tvalid_1's binary_logloss: 0.488653\n",
      "[1300]\ttraining's binary_logloss: 0.440058\tvalid_1's binary_logloss: 0.488641\n",
      "[1400]\ttraining's binary_logloss: 0.43999\tvalid_1's binary_logloss: 0.488635\n",
      "[1500]\ttraining's binary_logloss: 0.43992\tvalid_1's binary_logloss: 0.488632\n",
      "[1600]\ttraining's binary_logloss: 0.439853\tvalid_1's binary_logloss: 0.488628\n",
      "[1700]\ttraining's binary_logloss: 0.439785\tvalid_1's binary_logloss: 0.488615\n",
      "[1800]\ttraining's binary_logloss: 0.439716\tvalid_1's binary_logloss: 0.488615\n",
      "Early stopping, best iteration is:\n",
      "[1736]\ttraining's binary_logloss: 0.439759\tvalid_1's binary_logloss: 0.48861\n",
      "===== ACCURACY SCORE 0.780046 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778910 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509955\tvalid_1's binary_logloss: 0.527403\n",
      "[200]\ttraining's binary_logloss: 0.469669\tvalid_1's binary_logloss: 0.493746\n",
      "[300]\ttraining's binary_logloss: 0.456081\tvalid_1's binary_logloss: 0.486721\n",
      "[400]\ttraining's binary_logloss: 0.450035\tvalid_1's binary_logloss: 0.485222\n",
      "[500]\ttraining's binary_logloss: 0.446585\tvalid_1's binary_logloss: 0.485173\n",
      "[600]\ttraining's binary_logloss: 0.444251\tvalid_1's binary_logloss: 0.485039\n",
      "Early stopping, best iteration is:\n",
      "[550]\ttraining's binary_logloss: 0.445247\tvalid_1's binary_logloss: 0.484995\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.445142\tvalid_1's binary_logloss: 0.485007\n",
      "Early stopping, best iteration is:\n",
      "[553]\ttraining's binary_logloss: 0.44524\tvalid_1's binary_logloss: 0.484994\n",
      "===== ACCURACY SCORE 0.781313 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50867\tvalid_1's binary_logloss: 0.528018\n",
      "[200]\ttraining's binary_logloss: 0.468417\tvalid_1's binary_logloss: 0.495506\n",
      "[300]\ttraining's binary_logloss: 0.45498\tvalid_1's binary_logloss: 0.488755\n",
      "[400]\ttraining's binary_logloss: 0.449057\tvalid_1's binary_logloss: 0.487741\n",
      "[500]\ttraining's binary_logloss: 0.445747\tvalid_1's binary_logloss: 0.487585\n",
      "[600]\ttraining's binary_logloss: 0.443578\tvalid_1's binary_logloss: 0.487291\n",
      "[700]\ttraining's binary_logloss: 0.442144\tvalid_1's binary_logloss: 0.487142\n",
      "[800]\ttraining's binary_logloss: 0.441084\tvalid_1's binary_logloss: 0.487045\n",
      "[900]\ttraining's binary_logloss: 0.440278\tvalid_1's binary_logloss: 0.487036\n",
      "Early stopping, best iteration is:\n",
      "[838]\ttraining's binary_logloss: 0.440761\tvalid_1's binary_logloss: 0.487016\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[900]\ttraining's binary_logloss: 0.440708\tvalid_1's binary_logloss: 0.487008\n",
      "[1000]\ttraining's binary_logloss: 0.440627\tvalid_1's binary_logloss: 0.487003\n",
      "Early stopping, best iteration is:\n",
      "[999]\ttraining's binary_logloss: 0.440628\tvalid_1's binary_logloss: 0.487003\n",
      "===== ACCURACY SCORE 0.776482 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508685\tvalid_1's binary_logloss: 0.5324\n",
      "[200]\ttraining's binary_logloss: 0.468197\tvalid_1's binary_logloss: 0.502536\n",
      "[300]\ttraining's binary_logloss: 0.454529\tvalid_1's binary_logloss: 0.496933\n",
      "[400]\ttraining's binary_logloss: 0.448567\tvalid_1's binary_logloss: 0.495865\n",
      "[500]\ttraining's binary_logloss: 0.44517\tvalid_1's binary_logloss: 0.495443\n",
      "[600]\ttraining's binary_logloss: 0.44289\tvalid_1's binary_logloss: 0.494993\n",
      "[700]\ttraining's binary_logloss: 0.441437\tvalid_1's binary_logloss: 0.494832\n",
      "[800]\ttraining's binary_logloss: 0.440338\tvalid_1's binary_logloss: 0.494644\n",
      "[900]\ttraining's binary_logloss: 0.439507\tvalid_1's binary_logloss: 0.494547\n",
      "[1000]\ttraining's binary_logloss: 0.43877\tvalid_1's binary_logloss: 0.494407\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.43877\tvalid_1's binary_logloss: 0.494407\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.4387\tvalid_1's binary_logloss: 0.4944\n",
      "[1200]\ttraining's binary_logloss: 0.438632\tvalid_1's binary_logloss: 0.49439\n",
      "[1300]\ttraining's binary_logloss: 0.438568\tvalid_1's binary_logloss: 0.494392\n",
      "Early stopping, best iteration is:\n",
      "[1217]\ttraining's binary_logloss: 0.438621\tvalid_1's binary_logloss: 0.494388\n",
      "===== ACCURACY SCORE 0.774075 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510763\tvalid_1's binary_logloss: 0.5263\n",
      "[200]\ttraining's binary_logloss: 0.470778\tvalid_1's binary_logloss: 0.492147\n",
      "[300]\ttraining's binary_logloss: 0.457271\tvalid_1's binary_logloss: 0.484713\n",
      "[400]\ttraining's binary_logloss: 0.451324\tvalid_1's binary_logloss: 0.482905\n",
      "[500]\ttraining's binary_logloss: 0.447941\tvalid_1's binary_logloss: 0.482505\n",
      "[600]\ttraining's binary_logloss: 0.445736\tvalid_1's binary_logloss: 0.482357\n",
      "[700]\ttraining's binary_logloss: 0.444308\tvalid_1's binary_logloss: 0.482164\n",
      "[800]\ttraining's binary_logloss: 0.44325\tvalid_1's binary_logloss: 0.481922\n",
      "[900]\ttraining's binary_logloss: 0.442395\tvalid_1's binary_logloss: 0.481727\n",
      "[1000]\ttraining's binary_logloss: 0.441669\tvalid_1's binary_logloss: 0.48161\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.441669\tvalid_1's binary_logloss: 0.48161\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.441601\tvalid_1's binary_logloss: 0.481596\n",
      "[1200]\ttraining's binary_logloss: 0.441533\tvalid_1's binary_logloss: 0.481585\n",
      "[1300]\ttraining's binary_logloss: 0.441468\tvalid_1's binary_logloss: 0.481573\n",
      "[1400]\ttraining's binary_logloss: 0.441402\tvalid_1's binary_logloss: 0.481561\n",
      "[1500]\ttraining's binary_logloss: 0.441337\tvalid_1's binary_logloss: 0.481549\n",
      "[1600]\ttraining's binary_logloss: 0.441272\tvalid_1's binary_logloss: 0.48154\n",
      "[1700]\ttraining's binary_logloss: 0.441212\tvalid_1's binary_logloss: 0.481522\n",
      "[1800]\ttraining's binary_logloss: 0.44115\tvalid_1's binary_logloss: 0.481501\n",
      "[1900]\ttraining's binary_logloss: 0.441089\tvalid_1's binary_logloss: 0.481489\n",
      "[2000]\ttraining's binary_logloss: 0.441028\tvalid_1's binary_logloss: 0.481477\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.441028\tvalid_1's binary_logloss: 0.481477\n",
      "===== ACCURACY SCORE 0.783994 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509511\tvalid_1's binary_logloss: 0.528226\n",
      "[200]\ttraining's binary_logloss: 0.46915\tvalid_1's binary_logloss: 0.496192\n",
      "[300]\ttraining's binary_logloss: 0.455528\tvalid_1's binary_logloss: 0.490014\n",
      "[400]\ttraining's binary_logloss: 0.449507\tvalid_1's binary_logloss: 0.488969\n",
      "[500]\ttraining's binary_logloss: 0.446054\tvalid_1's binary_logloss: 0.488614\n",
      "[600]\ttraining's binary_logloss: 0.443778\tvalid_1's binary_logloss: 0.488378\n",
      "[700]\ttraining's binary_logloss: 0.442279\tvalid_1's binary_logloss: 0.488344\n",
      "Early stopping, best iteration is:\n",
      "[620]\ttraining's binary_logloss: 0.443437\tvalid_1's binary_logloss: 0.488318\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.443303\tvalid_1's binary_logloss: 0.488302\n",
      "[800]\ttraining's binary_logloss: 0.443144\tvalid_1's binary_logloss: 0.488296\n",
      "Early stopping, best iteration is:\n",
      "[768]\ttraining's binary_logloss: 0.443193\tvalid_1's binary_logloss: 0.488288\n",
      "===== ACCURACY SCORE 0.778935 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508944\tvalid_1's binary_logloss: 0.527401\n",
      "[200]\ttraining's binary_logloss: 0.468747\tvalid_1's binary_logloss: 0.496219\n",
      "[300]\ttraining's binary_logloss: 0.455091\tvalid_1's binary_logloss: 0.49044\n",
      "[400]\ttraining's binary_logloss: 0.449124\tvalid_1's binary_logloss: 0.489499\n",
      "Early stopping, best iteration is:\n",
      "[394]\ttraining's binary_logloss: 0.449373\tvalid_1's binary_logloss: 0.48948\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.449346\tvalid_1's binary_logloss: 0.489477\n",
      "[500]\ttraining's binary_logloss: 0.448932\tvalid_1's binary_logloss: 0.489459\n",
      "[600]\ttraining's binary_logloss: 0.448539\tvalid_1's binary_logloss: 0.489444\n",
      "[700]\ttraining's binary_logloss: 0.448165\tvalid_1's binary_logloss: 0.48944\n",
      "Early stopping, best iteration is:\n",
      "[652]\ttraining's binary_logloss: 0.44834\tvalid_1's binary_logloss: 0.489434\n",
      "===== ACCURACY SCORE 0.778167 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509012\tvalid_1's binary_logloss: 0.527761\n",
      "[200]\ttraining's binary_logloss: 0.468526\tvalid_1's binary_logloss: 0.49554\n",
      "[300]\ttraining's binary_logloss: 0.454803\tvalid_1's binary_logloss: 0.489153\n",
      "[400]\ttraining's binary_logloss: 0.448904\tvalid_1's binary_logloss: 0.487879\n",
      "[500]\ttraining's binary_logloss: 0.445419\tvalid_1's binary_logloss: 0.487487\n",
      "[600]\ttraining's binary_logloss: 0.443133\tvalid_1's binary_logloss: 0.487287\n",
      "[700]\ttraining's binary_logloss: 0.441574\tvalid_1's binary_logloss: 0.487169\n",
      "[800]\ttraining's binary_logloss: 0.440456\tvalid_1's binary_logloss: 0.487084\n",
      "[900]\ttraining's binary_logloss: 0.439548\tvalid_1's binary_logloss: 0.487088\n",
      "Early stopping, best iteration is:\n",
      "[832]\ttraining's binary_logloss: 0.44014\tvalid_1's binary_logloss: 0.487036\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[900]\ttraining's binary_logloss: 0.440076\tvalid_1's binary_logloss: 0.487031\n",
      "[1000]\ttraining's binary_logloss: 0.439983\tvalid_1's binary_logloss: 0.487026\n",
      "[1100]\ttraining's binary_logloss: 0.439894\tvalid_1's binary_logloss: 0.487032\n",
      "Early stopping, best iteration is:\n",
      "[1006]\ttraining's binary_logloss: 0.439978\tvalid_1's binary_logloss: 0.487023\n",
      "===== ACCURACY SCORE 0.782543 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509584\tvalid_1's binary_logloss: 0.525716\n",
      "[200]\ttraining's binary_logloss: 0.469226\tvalid_1's binary_logloss: 0.492408\n",
      "[300]\ttraining's binary_logloss: 0.455687\tvalid_1's binary_logloss: 0.485539\n",
      "[400]\ttraining's binary_logloss: 0.449646\tvalid_1's binary_logloss: 0.484159\n",
      "[500]\ttraining's binary_logloss: 0.446155\tvalid_1's binary_logloss: 0.483813\n",
      "[600]\ttraining's binary_logloss: 0.443877\tvalid_1's binary_logloss: 0.48364\n",
      "[700]\ttraining's binary_logloss: 0.442386\tvalid_1's binary_logloss: 0.483744\n",
      "Early stopping, best iteration is:\n",
      "[620]\ttraining's binary_logloss: 0.443537\tvalid_1's binary_logloss: 0.483609\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.443402\tvalid_1's binary_logloss: 0.483628\n",
      "Early stopping, best iteration is:\n",
      "[621]\ttraining's binary_logloss: 0.443536\tvalid_1's binary_logloss: 0.48361\n",
      "===== ACCURACY SCORE 0.779641 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510446\tvalid_1's binary_logloss: 0.529379\n",
      "[200]\ttraining's binary_logloss: 0.47056\tvalid_1's binary_logloss: 0.496608\n",
      "[300]\ttraining's binary_logloss: 0.45695\tvalid_1's binary_logloss: 0.489228\n",
      "[400]\ttraining's binary_logloss: 0.450982\tvalid_1's binary_logloss: 0.487398\n",
      "[500]\ttraining's binary_logloss: 0.447552\tvalid_1's binary_logloss: 0.48686\n",
      "[600]\ttraining's binary_logloss: 0.445209\tvalid_1's binary_logloss: 0.486473\n",
      "[700]\ttraining's binary_logloss: 0.443658\tvalid_1's binary_logloss: 0.486263\n",
      "[800]\ttraining's binary_logloss: 0.442539\tvalid_1's binary_logloss: 0.486165\n",
      "[900]\ttraining's binary_logloss: 0.441683\tvalid_1's binary_logloss: 0.48603\n",
      "[1000]\ttraining's binary_logloss: 0.440964\tvalid_1's binary_logloss: 0.485944\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440964\tvalid_1's binary_logloss: 0.485944\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440891\tvalid_1's binary_logloss: 0.485938\n",
      "Early stopping, best iteration is:\n",
      "[1077]\ttraining's binary_logloss: 0.440907\tvalid_1's binary_logloss: 0.485937\n",
      "===== ACCURACY SCORE 0.778852 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509272\tvalid_1's binary_logloss: 0.529602\n",
      "[200]\ttraining's binary_logloss: 0.469037\tvalid_1's binary_logloss: 0.499093\n",
      "[300]\ttraining's binary_logloss: 0.455506\tvalid_1's binary_logloss: 0.49332\n",
      "[400]\ttraining's binary_logloss: 0.449491\tvalid_1's binary_logloss: 0.492316\n",
      "[500]\ttraining's binary_logloss: 0.446062\tvalid_1's binary_logloss: 0.49218\n",
      "[600]\ttraining's binary_logloss: 0.443815\tvalid_1's binary_logloss: 0.492031\n",
      "[700]\ttraining's binary_logloss: 0.442315\tvalid_1's binary_logloss: 0.492047\n",
      "Early stopping, best iteration is:\n",
      "[600]\ttraining's binary_logloss: 0.443815\tvalid_1's binary_logloss: 0.492031\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.44364\tvalid_1's binary_logloss: 0.492043\n",
      "Early stopping, best iteration is:\n",
      "[628]\ttraining's binary_logloss: 0.443763\tvalid_1's binary_logloss: 0.492026\n",
      "===== ACCURACY SCORE 0.775672 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778960 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509289\tvalid_1's binary_logloss: 0.531544\n",
      "[200]\ttraining's binary_logloss: 0.46886\tvalid_1's binary_logloss: 0.500188\n",
      "[300]\ttraining's binary_logloss: 0.455181\tvalid_1's binary_logloss: 0.494045\n",
      "[400]\ttraining's binary_logloss: 0.449151\tvalid_1's binary_logloss: 0.493113\n",
      "[500]\ttraining's binary_logloss: 0.445747\tvalid_1's binary_logloss: 0.493112\n",
      "[600]\ttraining's binary_logloss: 0.443517\tvalid_1's binary_logloss: 0.493029\n",
      "[700]\ttraining's binary_logloss: 0.441971\tvalid_1's binary_logloss: 0.492998\n",
      "Early stopping, best iteration is:\n",
      "[644]\ttraining's binary_logloss: 0.44277\tvalid_1's binary_logloss: 0.492973\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.442686\tvalid_1's binary_logloss: 0.492972\n",
      "[800]\ttraining's binary_logloss: 0.442539\tvalid_1's binary_logloss: 0.492961\n",
      "[900]\ttraining's binary_logloss: 0.44239\tvalid_1's binary_logloss: 0.492954\n",
      "Early stopping, best iteration is:\n",
      "[852]\ttraining's binary_logloss: 0.442463\tvalid_1's binary_logloss: 0.49295\n",
      "===== ACCURACY SCORE 0.778305 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510488\tvalid_1's binary_logloss: 0.523483\n",
      "[200]\ttraining's binary_logloss: 0.470606\tvalid_1's binary_logloss: 0.488934\n",
      "[300]\ttraining's binary_logloss: 0.457114\tvalid_1's binary_logloss: 0.480965\n",
      "[400]\ttraining's binary_logloss: 0.451137\tvalid_1's binary_logloss: 0.478981\n",
      "[500]\ttraining's binary_logloss: 0.447698\tvalid_1's binary_logloss: 0.47857\n",
      "[600]\ttraining's binary_logloss: 0.445459\tvalid_1's binary_logloss: 0.478194\n",
      "[700]\ttraining's binary_logloss: 0.443946\tvalid_1's binary_logloss: 0.478113\n",
      "[800]\ttraining's binary_logloss: 0.442853\tvalid_1's binary_logloss: 0.477965\n",
      "[900]\ttraining's binary_logloss: 0.441992\tvalid_1's binary_logloss: 0.477901\n",
      "[1000]\ttraining's binary_logloss: 0.44124\tvalid_1's binary_logloss: 0.477835\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.44124\tvalid_1's binary_logloss: 0.477835\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.441171\tvalid_1's binary_logloss: 0.477831\n",
      "[1200]\ttraining's binary_logloss: 0.441103\tvalid_1's binary_logloss: 0.477825\n",
      "[1300]\ttraining's binary_logloss: 0.441038\tvalid_1's binary_logloss: 0.47782\n",
      "[1400]\ttraining's binary_logloss: 0.44097\tvalid_1's binary_logloss: 0.477818\n",
      "[1500]\ttraining's binary_logloss: 0.440905\tvalid_1's binary_logloss: 0.477813\n",
      "[1600]\ttraining's binary_logloss: 0.440842\tvalid_1's binary_logloss: 0.477801\n",
      "[1700]\ttraining's binary_logloss: 0.440779\tvalid_1's binary_logloss: 0.477793\n",
      "[1800]\ttraining's binary_logloss: 0.440714\tvalid_1's binary_logloss: 0.477787\n",
      "[1900]\ttraining's binary_logloss: 0.440651\tvalid_1's binary_logloss: 0.477785\n",
      "[2000]\ttraining's binary_logloss: 0.440589\tvalid_1's binary_logloss: 0.477785\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.440589\tvalid_1's binary_logloss: 0.477785\n",
      "===== ACCURACY SCORE 0.783218 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510264\tvalid_1's binary_logloss: 0.527278\n",
      "[200]\ttraining's binary_logloss: 0.470184\tvalid_1's binary_logloss: 0.494548\n",
      "[300]\ttraining's binary_logloss: 0.456712\tvalid_1's binary_logloss: 0.487413\n",
      "[400]\ttraining's binary_logloss: 0.450816\tvalid_1's binary_logloss: 0.486186\n",
      "[500]\ttraining's binary_logloss: 0.447424\tvalid_1's binary_logloss: 0.485957\n",
      "[600]\ttraining's binary_logloss: 0.445141\tvalid_1's binary_logloss: 0.485824\n",
      "[700]\ttraining's binary_logloss: 0.443645\tvalid_1's binary_logloss: 0.485822\n",
      "[800]\ttraining's binary_logloss: 0.442576\tvalid_1's binary_logloss: 0.48588\n",
      "Early stopping, best iteration is:\n",
      "[730]\ttraining's binary_logloss: 0.443299\tvalid_1's binary_logloss: 0.485781\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.443221\tvalid_1's binary_logloss: 0.485779\n",
      "Early stopping, best iteration is:\n",
      "[783]\ttraining's binary_logloss: 0.443241\tvalid_1's binary_logloss: 0.485777\n",
      "===== ACCURACY SCORE 0.777520 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509608\tvalid_1's binary_logloss: 0.528815\n",
      "[200]\ttraining's binary_logloss: 0.469478\tvalid_1's binary_logloss: 0.497984\n",
      "[300]\ttraining's binary_logloss: 0.455819\tvalid_1's binary_logloss: 0.491728\n",
      "[400]\ttraining's binary_logloss: 0.449805\tvalid_1's binary_logloss: 0.490872\n",
      "[500]\ttraining's binary_logloss: 0.446295\tvalid_1's binary_logloss: 0.49052\n",
      "Early stopping, best iteration is:\n",
      "[498]\ttraining's binary_logloss: 0.446346\tvalid_1's binary_logloss: 0.490511\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.44634\tvalid_1's binary_logloss: 0.490511\n",
      "Early stopping, best iteration is:\n",
      "[499]\ttraining's binary_logloss: 0.446342\tvalid_1's binary_logloss: 0.490509\n",
      "===== ACCURACY SCORE 0.774995 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510503\tvalid_1's binary_logloss: 0.527691\n",
      "[200]\ttraining's binary_logloss: 0.47065\tvalid_1's binary_logloss: 0.495095\n",
      "[300]\ttraining's binary_logloss: 0.457245\tvalid_1's binary_logloss: 0.488175\n",
      "[400]\ttraining's binary_logloss: 0.451284\tvalid_1's binary_logloss: 0.48671\n",
      "[500]\ttraining's binary_logloss: 0.447898\tvalid_1's binary_logloss: 0.486208\n",
      "[600]\ttraining's binary_logloss: 0.445628\tvalid_1's binary_logloss: 0.485726\n",
      "[700]\ttraining's binary_logloss: 0.444166\tvalid_1's binary_logloss: 0.485535\n",
      "[800]\ttraining's binary_logloss: 0.443086\tvalid_1's binary_logloss: 0.485291\n",
      "[900]\ttraining's binary_logloss: 0.442235\tvalid_1's binary_logloss: 0.485223\n",
      "[1000]\ttraining's binary_logloss: 0.441522\tvalid_1's binary_logloss: 0.485147\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.441522\tvalid_1's binary_logloss: 0.485147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.441454\tvalid_1's binary_logloss: 0.485139\n",
      "[1200]\ttraining's binary_logloss: 0.441385\tvalid_1's binary_logloss: 0.485126\n",
      "[1300]\ttraining's binary_logloss: 0.441319\tvalid_1's binary_logloss: 0.485115\n",
      "[1400]\ttraining's binary_logloss: 0.441254\tvalid_1's binary_logloss: 0.485102\n",
      "[1500]\ttraining's binary_logloss: 0.441189\tvalid_1's binary_logloss: 0.485093\n",
      "[1600]\ttraining's binary_logloss: 0.441124\tvalid_1's binary_logloss: 0.485077\n",
      "[1700]\ttraining's binary_logloss: 0.441059\tvalid_1's binary_logloss: 0.485072\n",
      "[1800]\ttraining's binary_logloss: 0.440993\tvalid_1's binary_logloss: 0.485061\n",
      "[1900]\ttraining's binary_logloss: 0.44093\tvalid_1's binary_logloss: 0.48505\n",
      "[2000]\ttraining's binary_logloss: 0.440871\tvalid_1's binary_logloss: 0.485042\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.440871\tvalid_1's binary_logloss: 0.485042\n",
      "===== ACCURACY SCORE 0.780231 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509042\tvalid_1's binary_logloss: 0.524139\n",
      "[200]\ttraining's binary_logloss: 0.468468\tvalid_1's binary_logloss: 0.490472\n",
      "[300]\ttraining's binary_logloss: 0.454766\tvalid_1's binary_logloss: 0.483354\n",
      "[400]\ttraining's binary_logloss: 0.44877\tvalid_1's binary_logloss: 0.482032\n",
      "[500]\ttraining's binary_logloss: 0.445364\tvalid_1's binary_logloss: 0.481628\n",
      "[600]\ttraining's binary_logloss: 0.443071\tvalid_1's binary_logloss: 0.481359\n",
      "[700]\ttraining's binary_logloss: 0.44152\tvalid_1's binary_logloss: 0.481163\n",
      "[800]\ttraining's binary_logloss: 0.440367\tvalid_1's binary_logloss: 0.481126\n",
      "[900]\ttraining's binary_logloss: 0.439482\tvalid_1's binary_logloss: 0.481084\n",
      "[1000]\ttraining's binary_logloss: 0.438729\tvalid_1's binary_logloss: 0.480988\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.438729\tvalid_1's binary_logloss: 0.480988\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.438658\tvalid_1's binary_logloss: 0.480983\n",
      "[1200]\ttraining's binary_logloss: 0.438589\tvalid_1's binary_logloss: 0.480974\n",
      "[1300]\ttraining's binary_logloss: 0.438518\tvalid_1's binary_logloss: 0.48097\n",
      "Early stopping, best iteration is:\n",
      "[1285]\ttraining's binary_logloss: 0.438528\tvalid_1's binary_logloss: 0.480966\n",
      "===== ACCURACY SCORE 0.783963 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.507614\tvalid_1's binary_logloss: 0.528002\n",
      "[200]\ttraining's binary_logloss: 0.466923\tvalid_1's binary_logloss: 0.496865\n",
      "[300]\ttraining's binary_logloss: 0.453253\tvalid_1's binary_logloss: 0.490879\n",
      "[400]\ttraining's binary_logloss: 0.44734\tvalid_1's binary_logloss: 0.489903\n",
      "[500]\ttraining's binary_logloss: 0.443912\tvalid_1's binary_logloss: 0.489591\n",
      "[600]\ttraining's binary_logloss: 0.441702\tvalid_1's binary_logloss: 0.489396\n",
      "[700]\ttraining's binary_logloss: 0.44021\tvalid_1's binary_logloss: 0.489276\n",
      "[800]\ttraining's binary_logloss: 0.439144\tvalid_1's binary_logloss: 0.489065\n",
      "[900]\ttraining's binary_logloss: 0.438311\tvalid_1's binary_logloss: 0.488994\n",
      "[1000]\ttraining's binary_logloss: 0.437573\tvalid_1's binary_logloss: 0.488858\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.437573\tvalid_1's binary_logloss: 0.488858\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.437507\tvalid_1's binary_logloss: 0.488847\n",
      "[1200]\ttraining's binary_logloss: 0.437444\tvalid_1's binary_logloss: 0.488849\n",
      "Early stopping, best iteration is:\n",
      "[1130]\ttraining's binary_logloss: 0.437488\tvalid_1's binary_logloss: 0.488846\n",
      "===== ACCURACY SCORE 0.780960 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.5105\tvalid_1's binary_logloss: 0.535497\n",
      "[200]\ttraining's binary_logloss: 0.470225\tvalid_1's binary_logloss: 0.504571\n",
      "[300]\ttraining's binary_logloss: 0.456633\tvalid_1's binary_logloss: 0.498539\n",
      "[400]\ttraining's binary_logloss: 0.450657\tvalid_1's binary_logloss: 0.497399\n",
      "[500]\ttraining's binary_logloss: 0.447139\tvalid_1's binary_logloss: 0.496856\n",
      "[600]\ttraining's binary_logloss: 0.444841\tvalid_1's binary_logloss: 0.496539\n",
      "[700]\ttraining's binary_logloss: 0.443326\tvalid_1's binary_logloss: 0.496435\n",
      "[800]\ttraining's binary_logloss: 0.442227\tvalid_1's binary_logloss: 0.496351\n",
      "[900]\ttraining's binary_logloss: 0.441387\tvalid_1's binary_logloss: 0.4963\n",
      "[1000]\ttraining's binary_logloss: 0.440652\tvalid_1's binary_logloss: 0.496295\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440652\tvalid_1's binary_logloss: 0.496295\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440585\tvalid_1's binary_logloss: 0.496302\n",
      "Early stopping, best iteration is:\n",
      "[1007]\ttraining's binary_logloss: 0.440648\tvalid_1's binary_logloss: 0.496294\n",
      "===== ACCURACY SCORE 0.775785 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50989\tvalid_1's binary_logloss: 0.526053\n",
      "[200]\ttraining's binary_logloss: 0.469533\tvalid_1's binary_logloss: 0.492837\n",
      "[300]\ttraining's binary_logloss: 0.455891\tvalid_1's binary_logloss: 0.485568\n",
      "[400]\ttraining's binary_logloss: 0.449928\tvalid_1's binary_logloss: 0.48412\n",
      "[500]\ttraining's binary_logloss: 0.446425\tvalid_1's binary_logloss: 0.483829\n",
      "[600]\ttraining's binary_logloss: 0.444175\tvalid_1's binary_logloss: 0.483702\n",
      "[700]\ttraining's binary_logloss: 0.442712\tvalid_1's binary_logloss: 0.48359\n",
      "[800]\ttraining's binary_logloss: 0.441624\tvalid_1's binary_logloss: 0.4834\n",
      "[900]\ttraining's binary_logloss: 0.440758\tvalid_1's binary_logloss: 0.483186\n",
      "Early stopping, best iteration is:\n",
      "[886]\ttraining's binary_logloss: 0.440868\tvalid_1's binary_logloss: 0.483172\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[900]\ttraining's binary_logloss: 0.440858\tvalid_1's binary_logloss: 0.483168\n",
      "[1000]\ttraining's binary_logloss: 0.440778\tvalid_1's binary_logloss: 0.483169\n",
      "[1100]\ttraining's binary_logloss: 0.440699\tvalid_1's binary_logloss: 0.483159\n",
      "[1200]\ttraining's binary_logloss: 0.440621\tvalid_1's binary_logloss: 0.483152\n",
      "Early stopping, best iteration is:\n",
      "[1191]\ttraining's binary_logloss: 0.440627\tvalid_1's binary_logloss: 0.48315\n",
      "===== ACCURACY SCORE 0.780975 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508194\tvalid_1's binary_logloss: 0.529355\n",
      "[200]\ttraining's binary_logloss: 0.467536\tvalid_1's binary_logloss: 0.497984\n",
      "[300]\ttraining's binary_logloss: 0.453744\tvalid_1's binary_logloss: 0.491843\n",
      "[400]\ttraining's binary_logloss: 0.447733\tvalid_1's binary_logloss: 0.490938\n",
      "[500]\ttraining's binary_logloss: 0.444242\tvalid_1's binary_logloss: 0.490778\n",
      "[600]\ttraining's binary_logloss: 0.441897\tvalid_1's binary_logloss: 0.490489\n",
      "[700]\ttraining's binary_logloss: 0.440388\tvalid_1's binary_logloss: 0.490594\n",
      "Early stopping, best iteration is:\n",
      "[608]\ttraining's binary_logloss: 0.441764\tvalid_1's binary_logloss: 0.490484\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.441609\tvalid_1's binary_logloss: 0.490486\n",
      "Early stopping, best iteration is:\n",
      "[634]\ttraining's binary_logloss: 0.441719\tvalid_1's binary_logloss: 0.490481\n",
      "===== ACCURACY SCORE 0.778042 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779400 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509225\tvalid_1's binary_logloss: 0.534495\n",
      "[200]\ttraining's binary_logloss: 0.468762\tvalid_1's binary_logloss: 0.50499\n",
      "[300]\ttraining's binary_logloss: 0.455187\tvalid_1's binary_logloss: 0.500118\n",
      "[400]\ttraining's binary_logloss: 0.449135\tvalid_1's binary_logloss: 0.499922\n",
      "Early stopping, best iteration is:\n",
      "[365]\ttraining's binary_logloss: 0.450741\tvalid_1's binary_logloss: 0.499787\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.450551\tvalid_1's binary_logloss: 0.499793\n",
      "Early stopping, best iteration is:\n",
      "[367]\ttraining's binary_logloss: 0.45073\tvalid_1's binary_logloss: 0.499787\n",
      "===== ACCURACY SCORE 0.770557 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.51141\tvalid_1's binary_logloss: 0.522638\n",
      "[200]\ttraining's binary_logloss: 0.471426\tvalid_1's binary_logloss: 0.486352\n",
      "[300]\ttraining's binary_logloss: 0.458011\tvalid_1's binary_logloss: 0.477535\n",
      "[400]\ttraining's binary_logloss: 0.452086\tvalid_1's binary_logloss: 0.475195\n",
      "[500]\ttraining's binary_logloss: 0.44867\tvalid_1's binary_logloss: 0.474394\n",
      "[600]\ttraining's binary_logloss: 0.446321\tvalid_1's binary_logloss: 0.473959\n",
      "[700]\ttraining's binary_logloss: 0.444845\tvalid_1's binary_logloss: 0.473727\n",
      "[800]\ttraining's binary_logloss: 0.443732\tvalid_1's binary_logloss: 0.473517\n",
      "[900]\ttraining's binary_logloss: 0.442859\tvalid_1's binary_logloss: 0.473364\n",
      "[1000]\ttraining's binary_logloss: 0.442119\tvalid_1's binary_logloss: 0.4733\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.442119\tvalid_1's binary_logloss: 0.4733\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.442051\tvalid_1's binary_logloss: 0.473297\n",
      "[1200]\ttraining's binary_logloss: 0.441982\tvalid_1's binary_logloss: 0.473292\n",
      "[1300]\ttraining's binary_logloss: 0.441915\tvalid_1's binary_logloss: 0.473281\n",
      "[1400]\ttraining's binary_logloss: 0.441848\tvalid_1's binary_logloss: 0.473278\n",
      "Early stopping, best iteration is:\n",
      "[1364]\ttraining's binary_logloss: 0.441872\tvalid_1's binary_logloss: 0.473273\n",
      "===== ACCURACY SCORE 0.790407 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50978\tvalid_1's binary_logloss: 0.528843\n",
      "[200]\ttraining's binary_logloss: 0.469553\tvalid_1's binary_logloss: 0.496879\n",
      "[300]\ttraining's binary_logloss: 0.455834\tvalid_1's binary_logloss: 0.490437\n",
      "[400]\ttraining's binary_logloss: 0.449784\tvalid_1's binary_logloss: 0.489115\n",
      "[500]\ttraining's binary_logloss: 0.446135\tvalid_1's binary_logloss: 0.488567\n",
      "[600]\ttraining's binary_logloss: 0.443855\tvalid_1's binary_logloss: 0.48828\n",
      "[700]\ttraining's binary_logloss: 0.442361\tvalid_1's binary_logloss: 0.488097\n",
      "[800]\ttraining's binary_logloss: 0.441277\tvalid_1's binary_logloss: 0.48783\n",
      "[900]\ttraining's binary_logloss: 0.440397\tvalid_1's binary_logloss: 0.487732\n",
      "[1000]\ttraining's binary_logloss: 0.439659\tvalid_1's binary_logloss: 0.487529\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439659\tvalid_1's binary_logloss: 0.487529\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439587\tvalid_1's binary_logloss: 0.487513\n",
      "[1200]\ttraining's binary_logloss: 0.43952\tvalid_1's binary_logloss: 0.487493\n",
      "[1300]\ttraining's binary_logloss: 0.439453\tvalid_1's binary_logloss: 0.487477\n",
      "[1400]\ttraining's binary_logloss: 0.439387\tvalid_1's binary_logloss: 0.487472\n",
      "[1500]\ttraining's binary_logloss: 0.439325\tvalid_1's binary_logloss: 0.487468\n",
      "[1600]\ttraining's binary_logloss: 0.43926\tvalid_1's binary_logloss: 0.487459\n",
      "[1700]\ttraining's binary_logloss: 0.439196\tvalid_1's binary_logloss: 0.487452\n",
      "[1800]\ttraining's binary_logloss: 0.439131\tvalid_1's binary_logloss: 0.48745\n",
      "Early stopping, best iteration is:\n",
      "[1751]\ttraining's binary_logloss: 0.439163\tvalid_1's binary_logloss: 0.487447\n",
      "===== ACCURACY SCORE 0.776380 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509395\tvalid_1's binary_logloss: 0.527425\n",
      "[200]\ttraining's binary_logloss: 0.46902\tvalid_1's binary_logloss: 0.495953\n",
      "[300]\ttraining's binary_logloss: 0.455361\tvalid_1's binary_logloss: 0.489662\n",
      "[400]\ttraining's binary_logloss: 0.449409\tvalid_1's binary_logloss: 0.488517\n",
      "[500]\ttraining's binary_logloss: 0.445986\tvalid_1's binary_logloss: 0.487966\n",
      "[600]\ttraining's binary_logloss: 0.443679\tvalid_1's binary_logloss: 0.487421\n",
      "[700]\ttraining's binary_logloss: 0.442221\tvalid_1's binary_logloss: 0.487177\n",
      "[800]\ttraining's binary_logloss: 0.441137\tvalid_1's binary_logloss: 0.487139\n",
      "Early stopping, best iteration is:\n",
      "[749]\ttraining's binary_logloss: 0.44165\tvalid_1's binary_logloss: 0.487083\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.441597\tvalid_1's binary_logloss: 0.48708\n",
      "[900]\ttraining's binary_logloss: 0.441495\tvalid_1's binary_logloss: 0.487074\n",
      "[1000]\ttraining's binary_logloss: 0.441393\tvalid_1's binary_logloss: 0.487068\n",
      "[1100]\ttraining's binary_logloss: 0.441295\tvalid_1's binary_logloss: 0.487061\n",
      "[1200]\ttraining's binary_logloss: 0.441197\tvalid_1's binary_logloss: 0.487049\n",
      "[1300]\ttraining's binary_logloss: 0.441103\tvalid_1's binary_logloss: 0.487046\n",
      "[1400]\ttraining's binary_logloss: 0.441011\tvalid_1's binary_logloss: 0.487041\n",
      "[1500]\ttraining's binary_logloss: 0.440921\tvalid_1's binary_logloss: 0.487025\n",
      "Early stopping, best iteration is:\n",
      "[1476]\ttraining's binary_logloss: 0.440941\tvalid_1's binary_logloss: 0.487024\n",
      "===== ACCURACY SCORE 0.778969 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509373\tvalid_1's binary_logloss: 0.528491\n",
      "[200]\ttraining's binary_logloss: 0.468976\tvalid_1's binary_logloss: 0.495459\n",
      "[300]\ttraining's binary_logloss: 0.455435\tvalid_1's binary_logloss: 0.488486\n",
      "[400]\ttraining's binary_logloss: 0.449538\tvalid_1's binary_logloss: 0.487296\n",
      "[500]\ttraining's binary_logloss: 0.446132\tvalid_1's binary_logloss: 0.487149\n",
      "[600]\ttraining's binary_logloss: 0.443896\tvalid_1's binary_logloss: 0.486962\n",
      "[700]\ttraining's binary_logloss: 0.442442\tvalid_1's binary_logloss: 0.486934\n",
      "[800]\ttraining's binary_logloss: 0.44138\tvalid_1's binary_logloss: 0.486985\n",
      "Early stopping, best iteration is:\n",
      "[724]\ttraining's binary_logloss: 0.442148\tvalid_1's binary_logloss: 0.486844\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.442064\tvalid_1's binary_logloss: 0.486857\n",
      "Early stopping, best iteration is:\n",
      "[741]\ttraining's binary_logloss: 0.442129\tvalid_1's binary_logloss: 0.486842\n",
      "===== ACCURACY SCORE 0.780326 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509024\tvalid_1's binary_logloss: 0.524834\n",
      "[200]\ttraining's binary_logloss: 0.468526\tvalid_1's binary_logloss: 0.491806\n",
      "[300]\ttraining's binary_logloss: 0.454841\tvalid_1's binary_logloss: 0.48489\n",
      "[400]\ttraining's binary_logloss: 0.448826\tvalid_1's binary_logloss: 0.483649\n",
      "[500]\ttraining's binary_logloss: 0.445322\tvalid_1's binary_logloss: 0.483457\n",
      "[600]\ttraining's binary_logloss: 0.443027\tvalid_1's binary_logloss: 0.483238\n",
      "[700]\ttraining's binary_logloss: 0.4416\tvalid_1's binary_logloss: 0.483356\n",
      "Early stopping, best iteration is:\n",
      "[626]\ttraining's binary_logloss: 0.442607\tvalid_1's binary_logloss: 0.483235\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.442492\tvalid_1's binary_logloss: 0.483243\n",
      "[800]\ttraining's binary_logloss: 0.44234\tvalid_1's binary_logloss: 0.483224\n",
      "[900]\ttraining's binary_logloss: 0.442188\tvalid_1's binary_logloss: 0.483208\n",
      "[1000]\ttraining's binary_logloss: 0.442046\tvalid_1's binary_logloss: 0.483209\n",
      "Early stopping, best iteration is:\n",
      "[958]\ttraining's binary_logloss: 0.442106\tvalid_1's binary_logloss: 0.483205\n",
      "===== ACCURACY SCORE 0.784459 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508463\tvalid_1's binary_logloss: 0.530617\n",
      "[200]\ttraining's binary_logloss: 0.468003\tvalid_1's binary_logloss: 0.500599\n",
      "[300]\ttraining's binary_logloss: 0.454367\tvalid_1's binary_logloss: 0.495382\n",
      "[400]\ttraining's binary_logloss: 0.448364\tvalid_1's binary_logloss: 0.49521\n",
      "Early stopping, best iteration is:\n",
      "[337]\ttraining's binary_logloss: 0.451599\tvalid_1's binary_logloss: 0.495003\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.451212\tvalid_1's binary_logloss: 0.494994\n",
      "Early stopping, best iteration is:\n",
      "[394]\ttraining's binary_logloss: 0.451249\tvalid_1's binary_logloss: 0.494991\n",
      "===== ACCURACY SCORE 0.772677 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509096\tvalid_1's binary_logloss: 0.530398\n",
      "[200]\ttraining's binary_logloss: 0.468489\tvalid_1's binary_logloss: 0.500107\n",
      "[300]\ttraining's binary_logloss: 0.454773\tvalid_1's binary_logloss: 0.494441\n",
      "[400]\ttraining's binary_logloss: 0.448814\tvalid_1's binary_logloss: 0.493553\n",
      "[500]\ttraining's binary_logloss: 0.445369\tvalid_1's binary_logloss: 0.493273\n",
      "[600]\ttraining's binary_logloss: 0.443037\tvalid_1's binary_logloss: 0.49292\n",
      "[700]\ttraining's binary_logloss: 0.441527\tvalid_1's binary_logloss: 0.492767\n",
      "Early stopping, best iteration is:\n",
      "[685]\ttraining's binary_logloss: 0.441714\tvalid_1's binary_logloss: 0.492678\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.441693\tvalid_1's binary_logloss: 0.492677\n",
      "[800]\ttraining's binary_logloss: 0.441561\tvalid_1's binary_logloss: 0.492672\n",
      "[900]\ttraining's binary_logloss: 0.441434\tvalid_1's binary_logloss: 0.492678\n",
      "Early stopping, best iteration is:\n",
      "[806]\ttraining's binary_logloss: 0.441554\tvalid_1's binary_logloss: 0.492666\n",
      "===== ACCURACY SCORE 0.775426 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510678\tvalid_1's binary_logloss: 0.524731\n",
      "[200]\ttraining's binary_logloss: 0.470634\tvalid_1's binary_logloss: 0.490769\n",
      "[300]\ttraining's binary_logloss: 0.457071\tvalid_1's binary_logloss: 0.483064\n",
      "[400]\ttraining's binary_logloss: 0.451126\tvalid_1's binary_logloss: 0.481041\n",
      "[500]\ttraining's binary_logloss: 0.447641\tvalid_1's binary_logloss: 0.48016\n",
      "[600]\ttraining's binary_logloss: 0.445424\tvalid_1's binary_logloss: 0.479573\n",
      "[700]\ttraining's binary_logloss: 0.443923\tvalid_1's binary_logloss: 0.479173\n",
      "[800]\ttraining's binary_logloss: 0.442876\tvalid_1's binary_logloss: 0.478916\n",
      "[900]\ttraining's binary_logloss: 0.442028\tvalid_1's binary_logloss: 0.478729\n",
      "[1000]\ttraining's binary_logloss: 0.441309\tvalid_1's binary_logloss: 0.478726\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.441309\tvalid_1's binary_logloss: 0.478726\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.441239\tvalid_1's binary_logloss: 0.478711\n",
      "[1200]\ttraining's binary_logloss: 0.441166\tvalid_1's binary_logloss: 0.478696\n",
      "[1300]\ttraining's binary_logloss: 0.441098\tvalid_1's binary_logloss: 0.478681\n",
      "[1400]\ttraining's binary_logloss: 0.44103\tvalid_1's binary_logloss: 0.478666\n",
      "[1500]\ttraining's binary_logloss: 0.440964\tvalid_1's binary_logloss: 0.478663\n",
      "[1600]\ttraining's binary_logloss: 0.440898\tvalid_1's binary_logloss: 0.478647\n",
      "[1700]\ttraining's binary_logloss: 0.440834\tvalid_1's binary_logloss: 0.478635\n",
      "[1800]\ttraining's binary_logloss: 0.440772\tvalid_1's binary_logloss: 0.478629\n",
      "[1900]\ttraining's binary_logloss: 0.440711\tvalid_1's binary_logloss: 0.478627\n",
      "[2000]\ttraining's binary_logloss: 0.440648\tvalid_1's binary_logloss: 0.478624\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.440648\tvalid_1's binary_logloss: 0.478624\n",
      "===== ACCURACY SCORE 0.784224 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508696\tvalid_1's binary_logloss: 0.529286\n",
      "[200]\ttraining's binary_logloss: 0.468302\tvalid_1's binary_logloss: 0.496608\n",
      "[300]\ttraining's binary_logloss: 0.454641\tvalid_1's binary_logloss: 0.48953\n",
      "[400]\ttraining's binary_logloss: 0.448612\tvalid_1's binary_logloss: 0.487839\n",
      "[500]\ttraining's binary_logloss: 0.445109\tvalid_1's binary_logloss: 0.48705\n",
      "[600]\ttraining's binary_logloss: 0.44282\tvalid_1's binary_logloss: 0.486682\n",
      "[700]\ttraining's binary_logloss: 0.441307\tvalid_1's binary_logloss: 0.486397\n",
      "[800]\ttraining's binary_logloss: 0.44019\tvalid_1's binary_logloss: 0.486142\n",
      "[900]\ttraining's binary_logloss: 0.439295\tvalid_1's binary_logloss: 0.486031\n",
      "[1000]\ttraining's binary_logloss: 0.438522\tvalid_1's binary_logloss: 0.485875\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.438522\tvalid_1's binary_logloss: 0.485875\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.438451\tvalid_1's binary_logloss: 0.485865\n",
      "[1200]\ttraining's binary_logloss: 0.438383\tvalid_1's binary_logloss: 0.485851\n",
      "[1300]\ttraining's binary_logloss: 0.438315\tvalid_1's binary_logloss: 0.485845\n",
      "[1400]\ttraining's binary_logloss: 0.438246\tvalid_1's binary_logloss: 0.48584\n",
      "[1500]\ttraining's binary_logloss: 0.438177\tvalid_1's binary_logloss: 0.485835\n",
      "[1600]\ttraining's binary_logloss: 0.438111\tvalid_1's binary_logloss: 0.485829\n",
      "[1700]\ttraining's binary_logloss: 0.438044\tvalid_1's binary_logloss: 0.48582\n",
      "[1800]\ttraining's binary_logloss: 0.43798\tvalid_1's binary_logloss: 0.485817\n",
      "[1900]\ttraining's binary_logloss: 0.437914\tvalid_1's binary_logloss: 0.485806\n",
      "[2000]\ttraining's binary_logloss: 0.437849\tvalid_1's binary_logloss: 0.485794\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.437849\tvalid_1's binary_logloss: 0.485794\n",
      "===== ACCURACY SCORE 0.780886 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779420 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510502\tvalid_1's binary_logloss: 0.529438\n",
      "[200]\ttraining's binary_logloss: 0.470341\tvalid_1's binary_logloss: 0.497296\n",
      "[300]\ttraining's binary_logloss: 0.456775\tvalid_1's binary_logloss: 0.490497\n",
      "[400]\ttraining's binary_logloss: 0.450775\tvalid_1's binary_logloss: 0.488898\n",
      "[500]\ttraining's binary_logloss: 0.447274\tvalid_1's binary_logloss: 0.488292\n",
      "[600]\ttraining's binary_logloss: 0.445042\tvalid_1's binary_logloss: 0.487921\n",
      "[700]\ttraining's binary_logloss: 0.44353\tvalid_1's binary_logloss: 0.487682\n",
      "[800]\ttraining's binary_logloss: 0.442464\tvalid_1's binary_logloss: 0.487574\n",
      "Early stopping, best iteration is:\n",
      "[773]\ttraining's binary_logloss: 0.442709\tvalid_1's binary_logloss: 0.487536\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.442682\tvalid_1's binary_logloss: 0.487532\n",
      "[900]\ttraining's binary_logloss: 0.442587\tvalid_1's binary_logloss: 0.487533\n",
      "[1000]\ttraining's binary_logloss: 0.442493\tvalid_1's binary_logloss: 0.487531\n",
      "[1100]\ttraining's binary_logloss: 0.442399\tvalid_1's binary_logloss: 0.487517\n",
      "[1200]\ttraining's binary_logloss: 0.442307\tvalid_1's binary_logloss: 0.487514\n",
      "[1300]\ttraining's binary_logloss: 0.442218\tvalid_1's binary_logloss: 0.487505\n",
      "[1400]\ttraining's binary_logloss: 0.442127\tvalid_1's binary_logloss: 0.487501\n",
      "[1500]\ttraining's binary_logloss: 0.442037\tvalid_1's binary_logloss: 0.487494\n",
      "[1600]\ttraining's binary_logloss: 0.441954\tvalid_1's binary_logloss: 0.487492\n",
      "Early stopping, best iteration is:\n",
      "[1565]\ttraining's binary_logloss: 0.441984\tvalid_1's binary_logloss: 0.487486\n",
      "===== ACCURACY SCORE 0.777465 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508683\tvalid_1's binary_logloss: 0.524336\n",
      "[200]\ttraining's binary_logloss: 0.468322\tvalid_1's binary_logloss: 0.490493\n",
      "[300]\ttraining's binary_logloss: 0.454743\tvalid_1's binary_logloss: 0.48318\n",
      "[400]\ttraining's binary_logloss: 0.448828\tvalid_1's binary_logloss: 0.481668\n",
      "[500]\ttraining's binary_logloss: 0.445371\tvalid_1's binary_logloss: 0.481314\n",
      "[600]\ttraining's binary_logloss: 0.443082\tvalid_1's binary_logloss: 0.48125\n",
      "Early stopping, best iteration is:\n",
      "[567]\ttraining's binary_logloss: 0.443704\tvalid_1's binary_logloss: 0.481204\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.443636\tvalid_1's binary_logloss: 0.4812\n",
      "[700]\ttraining's binary_logloss: 0.443442\tvalid_1's binary_logloss: 0.48119\n",
      "[800]\ttraining's binary_logloss: 0.443244\tvalid_1's binary_logloss: 0.481174\n",
      "[900]\ttraining's binary_logloss: 0.443064\tvalid_1's binary_logloss: 0.481156\n",
      "[1000]\ttraining's binary_logloss: 0.442888\tvalid_1's binary_logloss: 0.481159\n",
      "Early stopping, best iteration is:\n",
      "[905]\ttraining's binary_logloss: 0.443055\tvalid_1's binary_logloss: 0.481154\n",
      "===== ACCURACY SCORE 0.784990 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509675\tvalid_1's binary_logloss: 0.531667\n",
      "[200]\ttraining's binary_logloss: 0.469204\tvalid_1's binary_logloss: 0.501218\n",
      "[300]\ttraining's binary_logloss: 0.455591\tvalid_1's binary_logloss: 0.495493\n",
      "[400]\ttraining's binary_logloss: 0.449625\tvalid_1's binary_logloss: 0.494703\n",
      "[500]\ttraining's binary_logloss: 0.446117\tvalid_1's binary_logloss: 0.494593\n",
      "[600]\ttraining's binary_logloss: 0.443821\tvalid_1's binary_logloss: 0.494059\n",
      "[700]\ttraining's binary_logloss: 0.442373\tvalid_1's binary_logloss: 0.493869\n",
      "[800]\ttraining's binary_logloss: 0.44125\tvalid_1's binary_logloss: 0.493695\n",
      "[900]\ttraining's binary_logloss: 0.440373\tvalid_1's binary_logloss: 0.493557\n",
      "[1000]\ttraining's binary_logloss: 0.439647\tvalid_1's binary_logloss: 0.493473\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439647\tvalid_1's binary_logloss: 0.493473\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439578\tvalid_1's binary_logloss: 0.493459\n",
      "[1200]\ttraining's binary_logloss: 0.439509\tvalid_1's binary_logloss: 0.493444\n",
      "[1300]\ttraining's binary_logloss: 0.439442\tvalid_1's binary_logloss: 0.493438\n",
      "[1400]\ttraining's binary_logloss: 0.439376\tvalid_1's binary_logloss: 0.493431\n",
      "Early stopping, best iteration is:\n",
      "[1354]\ttraining's binary_logloss: 0.439406\tvalid_1's binary_logloss: 0.493428\n",
      "===== ACCURACY SCORE 0.774403 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509227\tvalid_1's binary_logloss: 0.529775\n",
      "[200]\ttraining's binary_logloss: 0.46883\tvalid_1's binary_logloss: 0.498143\n",
      "[300]\ttraining's binary_logloss: 0.455261\tvalid_1's binary_logloss: 0.491687\n",
      "[400]\ttraining's binary_logloss: 0.449235\tvalid_1's binary_logloss: 0.490592\n",
      "[500]\ttraining's binary_logloss: 0.4457\tvalid_1's binary_logloss: 0.490407\n",
      "[600]\ttraining's binary_logloss: 0.443357\tvalid_1's binary_logloss: 0.4902\n",
      "[700]\ttraining's binary_logloss: 0.441827\tvalid_1's binary_logloss: 0.490007\n",
      "[800]\ttraining's binary_logloss: 0.440728\tvalid_1's binary_logloss: 0.490059\n",
      "Early stopping, best iteration is:\n",
      "[705]\ttraining's binary_logloss: 0.44176\tvalid_1's binary_logloss: 0.489988\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.441646\tvalid_1's binary_logloss: 0.489987\n",
      "Early stopping, best iteration is:\n",
      "[738]\ttraining's binary_logloss: 0.441719\tvalid_1's binary_logloss: 0.489978\n",
      "===== ACCURACY SCORE 0.780607 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509118\tvalid_1's binary_logloss: 0.528372\n",
      "[200]\ttraining's binary_logloss: 0.468579\tvalid_1's binary_logloss: 0.495748\n",
      "[300]\ttraining's binary_logloss: 0.454728\tvalid_1's binary_logloss: 0.488672\n",
      "[400]\ttraining's binary_logloss: 0.448682\tvalid_1's binary_logloss: 0.487125\n",
      "[500]\ttraining's binary_logloss: 0.445169\tvalid_1's binary_logloss: 0.486629\n",
      "[600]\ttraining's binary_logloss: 0.442927\tvalid_1's binary_logloss: 0.486355\n",
      "[700]\ttraining's binary_logloss: 0.441497\tvalid_1's binary_logloss: 0.486239\n",
      "[800]\ttraining's binary_logloss: 0.440411\tvalid_1's binary_logloss: 0.486184\n",
      "[900]\ttraining's binary_logloss: 0.439569\tvalid_1's binary_logloss: 0.486156\n",
      "Early stopping, best iteration is:\n",
      "[822]\ttraining's binary_logloss: 0.440208\tvalid_1's binary_logloss: 0.486139\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[900]\ttraining's binary_logloss: 0.440137\tvalid_1's binary_logloss: 0.48614\n",
      "Early stopping, best iteration is:\n",
      "[880]\ttraining's binary_logloss: 0.440155\tvalid_1's binary_logloss: 0.486138\n",
      "===== ACCURACY SCORE 0.779369 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508101\tvalid_1's binary_logloss: 0.531282\n",
      "[200]\ttraining's binary_logloss: 0.467213\tvalid_1's binary_logloss: 0.500146\n",
      "[300]\ttraining's binary_logloss: 0.453453\tvalid_1's binary_logloss: 0.494238\n",
      "[400]\ttraining's binary_logloss: 0.447559\tvalid_1's binary_logloss: 0.493557\n",
      "[500]\ttraining's binary_logloss: 0.444224\tvalid_1's binary_logloss: 0.493674\n",
      "Early stopping, best iteration is:\n",
      "[403]\ttraining's binary_logloss: 0.447432\tvalid_1's binary_logloss: 0.493537\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.447057\tvalid_1's binary_logloss: 0.493548\n",
      "Early stopping, best iteration is:\n",
      "[451]\ttraining's binary_logloss: 0.447244\tvalid_1's binary_logloss: 0.49353\n",
      "===== ACCURACY SCORE 0.774145 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510607\tvalid_1's binary_logloss: 0.5209\n",
      "[200]\ttraining's binary_logloss: 0.47039\tvalid_1's binary_logloss: 0.48566\n",
      "[300]\ttraining's binary_logloss: 0.456807\tvalid_1's binary_logloss: 0.477437\n",
      "[400]\ttraining's binary_logloss: 0.450881\tvalid_1's binary_logloss: 0.475268\n",
      "[500]\ttraining's binary_logloss: 0.447556\tvalid_1's binary_logloss: 0.474626\n",
      "[600]\ttraining's binary_logloss: 0.445316\tvalid_1's binary_logloss: 0.474099\n",
      "[700]\ttraining's binary_logloss: 0.443848\tvalid_1's binary_logloss: 0.473825\n",
      "[800]\ttraining's binary_logloss: 0.442739\tvalid_1's binary_logloss: 0.473663\n",
      "[900]\ttraining's binary_logloss: 0.441884\tvalid_1's binary_logloss: 0.473534\n",
      "[1000]\ttraining's binary_logloss: 0.441168\tvalid_1's binary_logloss: 0.473539\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.441168\tvalid_1's binary_logloss: 0.473539\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.441101\tvalid_1's binary_logloss: 0.473531\n",
      "[1200]\ttraining's binary_logloss: 0.441033\tvalid_1's binary_logloss: 0.473527\n",
      "[1300]\ttraining's binary_logloss: 0.44097\tvalid_1's binary_logloss: 0.473525\n",
      "Early stopping, best iteration is:\n",
      "[1292]\ttraining's binary_logloss: 0.440976\tvalid_1's binary_logloss: 0.473522\n",
      "===== ACCURACY SCORE 0.787170 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508752\tvalid_1's binary_logloss: 0.526263\n",
      "[200]\ttraining's binary_logloss: 0.468293\tvalid_1's binary_logloss: 0.494224\n",
      "[300]\ttraining's binary_logloss: 0.454553\tvalid_1's binary_logloss: 0.488284\n",
      "[400]\ttraining's binary_logloss: 0.448517\tvalid_1's binary_logloss: 0.487781\n",
      "Early stopping, best iteration is:\n",
      "[359]\ttraining's binary_logloss: 0.450435\tvalid_1's binary_logloss: 0.487748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.45022\tvalid_1's binary_logloss: 0.487742\n",
      "[500]\ttraining's binary_logloss: 0.449723\tvalid_1's binary_logloss: 0.487722\n",
      "Early stopping, best iteration is:\n",
      "[497]\ttraining's binary_logloss: 0.449738\tvalid_1's binary_logloss: 0.48772\n",
      "===== ACCURACY SCORE 0.778076 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508889\tvalid_1's binary_logloss: 0.529788\n",
      "[200]\ttraining's binary_logloss: 0.46837\tvalid_1's binary_logloss: 0.499142\n",
      "[300]\ttraining's binary_logloss: 0.454968\tvalid_1's binary_logloss: 0.49391\n",
      "[400]\ttraining's binary_logloss: 0.449064\tvalid_1's binary_logloss: 0.49359\n",
      "Early stopping, best iteration is:\n",
      "[372]\ttraining's binary_logloss: 0.450321\tvalid_1's binary_logloss: 0.493528\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.450184\tvalid_1's binary_logloss: 0.493532\n",
      "Early stopping, best iteration is:\n",
      "[393]\ttraining's binary_logloss: 0.450217\tvalid_1's binary_logloss: 0.493527\n",
      "===== ACCURACY SCORE 0.778213 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510789\tvalid_1's binary_logloss: 0.526698\n",
      "[200]\ttraining's binary_logloss: 0.470438\tvalid_1's binary_logloss: 0.493737\n",
      "[300]\ttraining's binary_logloss: 0.456785\tvalid_1's binary_logloss: 0.486785\n",
      "[400]\ttraining's binary_logloss: 0.450798\tvalid_1's binary_logloss: 0.485269\n",
      "[500]\ttraining's binary_logloss: 0.447273\tvalid_1's binary_logloss: 0.484883\n",
      "[600]\ttraining's binary_logloss: 0.444927\tvalid_1's binary_logloss: 0.484738\n",
      "[700]\ttraining's binary_logloss: 0.443443\tvalid_1's binary_logloss: 0.484688\n",
      "[800]\ttraining's binary_logloss: 0.442373\tvalid_1's binary_logloss: 0.484605\n",
      "Early stopping, best iteration is:\n",
      "[769]\ttraining's binary_logloss: 0.442686\tvalid_1's binary_logloss: 0.484569\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.442653\tvalid_1's binary_logloss: 0.484564\n",
      "[900]\ttraining's binary_logloss: 0.442551\tvalid_1's binary_logloss: 0.48456\n",
      "[1000]\ttraining's binary_logloss: 0.442452\tvalid_1's binary_logloss: 0.484562\n",
      "[1100]\ttraining's binary_logloss: 0.442355\tvalid_1's binary_logloss: 0.484553\n",
      "[1200]\ttraining's binary_logloss: 0.442258\tvalid_1's binary_logloss: 0.484553\n",
      "Early stopping, best iteration is:\n",
      "[1166]\ttraining's binary_logloss: 0.44229\tvalid_1's binary_logloss: 0.484549\n",
      "===== ACCURACY SCORE 0.779988 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779440 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509333\tvalid_1's binary_logloss: 0.52945\n",
      "[200]\ttraining's binary_logloss: 0.469041\tvalid_1's binary_logloss: 0.498189\n",
      "[300]\ttraining's binary_logloss: 0.455426\tvalid_1's binary_logloss: 0.49199\n",
      "[400]\ttraining's binary_logloss: 0.449483\tvalid_1's binary_logloss: 0.490908\n",
      "[500]\ttraining's binary_logloss: 0.4461\tvalid_1's binary_logloss: 0.490782\n",
      "[600]\ttraining's binary_logloss: 0.443857\tvalid_1's binary_logloss: 0.490507\n",
      "[700]\ttraining's binary_logloss: 0.442361\tvalid_1's binary_logloss: 0.490275\n",
      "[800]\ttraining's binary_logloss: 0.441274\tvalid_1's binary_logloss: 0.490255\n",
      "[900]\ttraining's binary_logloss: 0.440429\tvalid_1's binary_logloss: 0.490206\n",
      "[1000]\ttraining's binary_logloss: 0.439723\tvalid_1's binary_logloss: 0.490187\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439723\tvalid_1's binary_logloss: 0.490187\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439656\tvalid_1's binary_logloss: 0.490198\n",
      "Early stopping, best iteration is:\n",
      "[1001]\ttraining's binary_logloss: 0.439722\tvalid_1's binary_logloss: 0.490188\n",
      "===== ACCURACY SCORE 0.776845 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509397\tvalid_1's binary_logloss: 0.526285\n",
      "[200]\ttraining's binary_logloss: 0.468982\tvalid_1's binary_logloss: 0.493601\n",
      "[300]\ttraining's binary_logloss: 0.455414\tvalid_1's binary_logloss: 0.486812\n",
      "[400]\ttraining's binary_logloss: 0.449454\tvalid_1's binary_logloss: 0.485391\n",
      "[500]\ttraining's binary_logloss: 0.445994\tvalid_1's binary_logloss: 0.485035\n",
      "[600]\ttraining's binary_logloss: 0.443703\tvalid_1's binary_logloss: 0.484693\n",
      "[700]\ttraining's binary_logloss: 0.442191\tvalid_1's binary_logloss: 0.48436\n",
      "[800]\ttraining's binary_logloss: 0.441096\tvalid_1's binary_logloss: 0.484087\n",
      "[900]\ttraining's binary_logloss: 0.440202\tvalid_1's binary_logloss: 0.483882\n",
      "[1000]\ttraining's binary_logloss: 0.439443\tvalid_1's binary_logloss: 0.483717\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439443\tvalid_1's binary_logloss: 0.483717\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439372\tvalid_1's binary_logloss: 0.48371\n",
      "[1200]\ttraining's binary_logloss: 0.439302\tvalid_1's binary_logloss: 0.483696\n",
      "[1300]\ttraining's binary_logloss: 0.439236\tvalid_1's binary_logloss: 0.483683\n",
      "[1400]\ttraining's binary_logloss: 0.439168\tvalid_1's binary_logloss: 0.483678\n",
      "[1500]\ttraining's binary_logloss: 0.439102\tvalid_1's binary_logloss: 0.483671\n",
      "[1600]\ttraining's binary_logloss: 0.439037\tvalid_1's binary_logloss: 0.483658\n",
      "[1700]\ttraining's binary_logloss: 0.43897\tvalid_1's binary_logloss: 0.483644\n",
      "[1800]\ttraining's binary_logloss: 0.438907\tvalid_1's binary_logloss: 0.483636\n",
      "[1900]\ttraining's binary_logloss: 0.438844\tvalid_1's binary_logloss: 0.483626\n",
      "[2000]\ttraining's binary_logloss: 0.438779\tvalid_1's binary_logloss: 0.483616\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.438779\tvalid_1's binary_logloss: 0.483616\n",
      "===== ACCURACY SCORE 0.782635 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509452\tvalid_1's binary_logloss: 0.525627\n",
      "[200]\ttraining's binary_logloss: 0.469224\tvalid_1's binary_logloss: 0.490969\n",
      "[300]\ttraining's binary_logloss: 0.455679\tvalid_1's binary_logloss: 0.483985\n",
      "[400]\ttraining's binary_logloss: 0.449719\tvalid_1's binary_logloss: 0.482727\n",
      "[500]\ttraining's binary_logloss: 0.446328\tvalid_1's binary_logloss: 0.48235\n",
      "[600]\ttraining's binary_logloss: 0.444082\tvalid_1's binary_logloss: 0.48197\n",
      "[700]\ttraining's binary_logloss: 0.442591\tvalid_1's binary_logloss: 0.481932\n",
      "[800]\ttraining's binary_logloss: 0.441559\tvalid_1's binary_logloss: 0.481981\n",
      "Early stopping, best iteration is:\n",
      "[724]\ttraining's binary_logloss: 0.442307\tvalid_1's binary_logloss: 0.481897\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.442222\tvalid_1's binary_logloss: 0.481899\n",
      "[900]\ttraining's binary_logloss: 0.442111\tvalid_1's binary_logloss: 0.481909\n",
      "Early stopping, best iteration is:\n",
      "[821]\ttraining's binary_logloss: 0.442198\tvalid_1's binary_logloss: 0.481893\n",
      "===== ACCURACY SCORE 0.783297 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510228\tvalid_1's binary_logloss: 0.529363\n",
      "[200]\ttraining's binary_logloss: 0.470072\tvalid_1's binary_logloss: 0.4969\n",
      "[300]\ttraining's binary_logloss: 0.45665\tvalid_1's binary_logloss: 0.490399\n",
      "[400]\ttraining's binary_logloss: 0.450783\tvalid_1's binary_logloss: 0.48918\n",
      "[500]\ttraining's binary_logloss: 0.447424\tvalid_1's binary_logloss: 0.48895\n",
      "[600]\ttraining's binary_logloss: 0.445247\tvalid_1's binary_logloss: 0.488811\n",
      "[700]\ttraining's binary_logloss: 0.443786\tvalid_1's binary_logloss: 0.488739\n",
      "[800]\ttraining's binary_logloss: 0.442725\tvalid_1's binary_logloss: 0.488614\n",
      "[900]\ttraining's binary_logloss: 0.441875\tvalid_1's binary_logloss: 0.488544\n",
      "[1000]\ttraining's binary_logloss: 0.441144\tvalid_1's binary_logloss: 0.488467\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.441144\tvalid_1's binary_logloss: 0.488467\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.441076\tvalid_1's binary_logloss: 0.488469\n",
      "[1200]\ttraining's binary_logloss: 0.441009\tvalid_1's binary_logloss: 0.488469\n",
      "Early stopping, best iteration is:\n",
      "[1128]\ttraining's binary_logloss: 0.441056\tvalid_1's binary_logloss: 0.488461\n",
      "===== ACCURACY SCORE 0.778391 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509413\tvalid_1's binary_logloss: 0.528611\n",
      "[200]\ttraining's binary_logloss: 0.468958\tvalid_1's binary_logloss: 0.496438\n",
      "[300]\ttraining's binary_logloss: 0.455253\tvalid_1's binary_logloss: 0.490145\n",
      "[400]\ttraining's binary_logloss: 0.449305\tvalid_1's binary_logloss: 0.489145\n",
      "[500]\ttraining's binary_logloss: 0.445803\tvalid_1's binary_logloss: 0.489235\n",
      "Early stopping, best iteration is:\n",
      "[404]\ttraining's binary_logloss: 0.449156\tvalid_1's binary_logloss: 0.489132\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.448775\tvalid_1's binary_logloss: 0.489126\n",
      "[600]\ttraining's binary_logloss: 0.448392\tvalid_1's binary_logloss: 0.489118\n",
      "[700]\ttraining's binary_logloss: 0.448016\tvalid_1's binary_logloss: 0.489112\n",
      "[800]\ttraining's binary_logloss: 0.447658\tvalid_1's binary_logloss: 0.489107\n",
      "Early stopping, best iteration is:\n",
      "[780]\ttraining's binary_logloss: 0.447728\tvalid_1's binary_logloss: 0.489101\n",
      "===== ACCURACY SCORE 0.777856 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510016\tvalid_1's binary_logloss: 0.524887\n",
      "[200]\ttraining's binary_logloss: 0.469794\tvalid_1's binary_logloss: 0.492575\n",
      "[300]\ttraining's binary_logloss: 0.456259\tvalid_1's binary_logloss: 0.485835\n",
      "[400]\ttraining's binary_logloss: 0.450302\tvalid_1's binary_logloss: 0.484464\n",
      "[500]\ttraining's binary_logloss: 0.446877\tvalid_1's binary_logloss: 0.483584\n",
      "[600]\ttraining's binary_logloss: 0.444661\tvalid_1's binary_logloss: 0.483306\n",
      "[700]\ttraining's binary_logloss: 0.443142\tvalid_1's binary_logloss: 0.482923\n",
      "[800]\ttraining's binary_logloss: 0.442084\tvalid_1's binary_logloss: 0.48261\n",
      "[900]\ttraining's binary_logloss: 0.441224\tvalid_1's binary_logloss: 0.482493\n",
      "[1000]\ttraining's binary_logloss: 0.440483\tvalid_1's binary_logloss: 0.482322\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440483\tvalid_1's binary_logloss: 0.482322\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440416\tvalid_1's binary_logloss: 0.482322\n",
      "Early stopping, best iteration is:\n",
      "[1076]\ttraining's binary_logloss: 0.440432\tvalid_1's binary_logloss: 0.482318\n",
      "===== ACCURACY SCORE 0.779543 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510517\tvalid_1's binary_logloss: 0.52781\n",
      "[200]\ttraining's binary_logloss: 0.470367\tvalid_1's binary_logloss: 0.494835\n",
      "[300]\ttraining's binary_logloss: 0.456846\tvalid_1's binary_logloss: 0.487897\n",
      "[400]\ttraining's binary_logloss: 0.450928\tvalid_1's binary_logloss: 0.486371\n",
      "[500]\ttraining's binary_logloss: 0.447573\tvalid_1's binary_logloss: 0.48609\n",
      "[600]\ttraining's binary_logloss: 0.445288\tvalid_1's binary_logloss: 0.485848\n",
      "Early stopping, best iteration is:\n",
      "[548]\ttraining's binary_logloss: 0.446289\tvalid_1's binary_logloss: 0.485766\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.446178\tvalid_1's binary_logloss: 0.485758\n",
      "[700]\ttraining's binary_logloss: 0.445971\tvalid_1's binary_logloss: 0.48576\n",
      "[800]\ttraining's binary_logloss: 0.445763\tvalid_1's binary_logloss: 0.485731\n",
      "[900]\ttraining's binary_logloss: 0.44556\tvalid_1's binary_logloss: 0.485721\n",
      "[1000]\ttraining's binary_logloss: 0.44537\tvalid_1's binary_logloss: 0.485729\n",
      "Early stopping, best iteration is:\n",
      "[906]\ttraining's binary_logloss: 0.445549\tvalid_1's binary_logloss: 0.485719\n",
      "===== ACCURACY SCORE 0.779297 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510818\tvalid_1's binary_logloss: 0.530671\n",
      "[200]\ttraining's binary_logloss: 0.470665\tvalid_1's binary_logloss: 0.499431\n",
      "[300]\ttraining's binary_logloss: 0.456874\tvalid_1's binary_logloss: 0.493112\n",
      "[400]\ttraining's binary_logloss: 0.450855\tvalid_1's binary_logloss: 0.492046\n",
      "[500]\ttraining's binary_logloss: 0.447328\tvalid_1's binary_logloss: 0.491795\n",
      "[600]\ttraining's binary_logloss: 0.445033\tvalid_1's binary_logloss: 0.491587\n",
      "[700]\ttraining's binary_logloss: 0.443498\tvalid_1's binary_logloss: 0.491561\n",
      "[800]\ttraining's binary_logloss: 0.442377\tvalid_1's binary_logloss: 0.491472\n",
      "[900]\ttraining's binary_logloss: 0.441501\tvalid_1's binary_logloss: 0.491517\n",
      "Early stopping, best iteration is:\n",
      "[809]\ttraining's binary_logloss: 0.442278\tvalid_1's binary_logloss: 0.491448\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[900]\ttraining's binary_logloss: 0.442193\tvalid_1's binary_logloss: 0.491456\n",
      "Early stopping, best iteration is:\n",
      "[826]\ttraining's binary_logloss: 0.442262\tvalid_1's binary_logloss: 0.491448\n",
      "===== ACCURACY SCORE 0.777021 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509809\tvalid_1's binary_logloss: 0.528433\n",
      "[200]\ttraining's binary_logloss: 0.469498\tvalid_1's binary_logloss: 0.49639\n",
      "[300]\ttraining's binary_logloss: 0.455855\tvalid_1's binary_logloss: 0.489993\n",
      "[400]\ttraining's binary_logloss: 0.44986\tvalid_1's binary_logloss: 0.48851\n",
      "[500]\ttraining's binary_logloss: 0.446409\tvalid_1's binary_logloss: 0.488383\n",
      "[600]\ttraining's binary_logloss: 0.444118\tvalid_1's binary_logloss: 0.488221\n",
      "[700]\ttraining's binary_logloss: 0.442638\tvalid_1's binary_logloss: 0.488187\n",
      "Early stopping, best iteration is:\n",
      "[633]\ttraining's binary_logloss: 0.443569\tvalid_1's binary_logloss: 0.488118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.443463\tvalid_1's binary_logloss: 0.488124\n",
      "Early stopping, best iteration is:\n",
      "[634]\ttraining's binary_logloss: 0.443567\tvalid_1's binary_logloss: 0.488118\n",
      "===== ACCURACY SCORE 0.780444 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509446\tvalid_1's binary_logloss: 0.531033\n",
      "[200]\ttraining's binary_logloss: 0.469276\tvalid_1's binary_logloss: 0.499264\n",
      "[300]\ttraining's binary_logloss: 0.455804\tvalid_1's binary_logloss: 0.493019\n",
      "[400]\ttraining's binary_logloss: 0.44997\tvalid_1's binary_logloss: 0.492078\n",
      "[500]\ttraining's binary_logloss: 0.446652\tvalid_1's binary_logloss: 0.491799\n",
      "[600]\ttraining's binary_logloss: 0.444359\tvalid_1's binary_logloss: 0.491452\n",
      "[700]\ttraining's binary_logloss: 0.442862\tvalid_1's binary_logloss: 0.491198\n",
      "[800]\ttraining's binary_logloss: 0.441787\tvalid_1's binary_logloss: 0.491149\n",
      "Early stopping, best iteration is:\n",
      "[768]\ttraining's binary_logloss: 0.442087\tvalid_1's binary_logloss: 0.49109\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.442055\tvalid_1's binary_logloss: 0.491094\n",
      "Early stopping, best iteration is:\n",
      "[769]\ttraining's binary_logloss: 0.442086\tvalid_1's binary_logloss: 0.491089\n",
      "===== ACCURACY SCORE 0.776732 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779210 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.507465\tvalid_1's binary_logloss: 0.529993\n",
      "[200]\ttraining's binary_logloss: 0.46667\tvalid_1's binary_logloss: 0.499982\n",
      "[300]\ttraining's binary_logloss: 0.452841\tvalid_1's binary_logloss: 0.494504\n",
      "[400]\ttraining's binary_logloss: 0.446718\tvalid_1's binary_logloss: 0.49361\n",
      "[500]\ttraining's binary_logloss: 0.443133\tvalid_1's binary_logloss: 0.49318\n",
      "[600]\ttraining's binary_logloss: 0.440816\tvalid_1's binary_logloss: 0.49299\n",
      "[700]\ttraining's binary_logloss: 0.439273\tvalid_1's binary_logloss: 0.492884\n",
      "[800]\ttraining's binary_logloss: 0.438176\tvalid_1's binary_logloss: 0.49277\n",
      "[900]\ttraining's binary_logloss: 0.437317\tvalid_1's binary_logloss: 0.492623\n",
      "[1000]\ttraining's binary_logloss: 0.436578\tvalid_1's binary_logloss: 0.492501\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.436578\tvalid_1's binary_logloss: 0.492501\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.43651\tvalid_1's binary_logloss: 0.492492\n",
      "[1200]\ttraining's binary_logloss: 0.436441\tvalid_1's binary_logloss: 0.492486\n",
      "[1300]\ttraining's binary_logloss: 0.436373\tvalid_1's binary_logloss: 0.492482\n",
      "[1400]\ttraining's binary_logloss: 0.436304\tvalid_1's binary_logloss: 0.492476\n",
      "[1500]\ttraining's binary_logloss: 0.436239\tvalid_1's binary_logloss: 0.492466\n",
      "[1600]\ttraining's binary_logloss: 0.436178\tvalid_1's binary_logloss: 0.492461\n",
      "[1700]\ttraining's binary_logloss: 0.43611\tvalid_1's binary_logloss: 0.492449\n",
      "[1800]\ttraining's binary_logloss: 0.436044\tvalid_1's binary_logloss: 0.492434\n",
      "[1900]\ttraining's binary_logloss: 0.435982\tvalid_1's binary_logloss: 0.492427\n",
      "[2000]\ttraining's binary_logloss: 0.435919\tvalid_1's binary_logloss: 0.492413\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.435919\tvalid_1's binary_logloss: 0.492413\n",
      "===== ACCURACY SCORE 0.770613 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508235\tvalid_1's binary_logloss: 0.531362\n",
      "[200]\ttraining's binary_logloss: 0.467603\tvalid_1's binary_logloss: 0.499716\n",
      "[300]\ttraining's binary_logloss: 0.453902\tvalid_1's binary_logloss: 0.49326\n",
      "[400]\ttraining's binary_logloss: 0.447899\tvalid_1's binary_logloss: 0.492293\n",
      "[500]\ttraining's binary_logloss: 0.444346\tvalid_1's binary_logloss: 0.49197\n",
      "[600]\ttraining's binary_logloss: 0.442076\tvalid_1's binary_logloss: 0.491844\n",
      "Early stopping, best iteration is:\n",
      "[586]\ttraining's binary_logloss: 0.442317\tvalid_1's binary_logloss: 0.491779\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.442291\tvalid_1's binary_logloss: 0.491782\n",
      "[700]\ttraining's binary_logloss: 0.442112\tvalid_1's binary_logloss: 0.491782\n",
      "[800]\ttraining's binary_logloss: 0.441936\tvalid_1's binary_logloss: 0.491764\n",
      "[900]\ttraining's binary_logloss: 0.441761\tvalid_1's binary_logloss: 0.491749\n",
      "Early stopping, best iteration is:\n",
      "[892]\ttraining's binary_logloss: 0.441774\tvalid_1's binary_logloss: 0.491746\n",
      "===== ACCURACY SCORE 0.775208 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509275\tvalid_1's binary_logloss: 0.527271\n",
      "[200]\ttraining's binary_logloss: 0.469046\tvalid_1's binary_logloss: 0.493727\n",
      "[300]\ttraining's binary_logloss: 0.455453\tvalid_1's binary_logloss: 0.486524\n",
      "[400]\ttraining's binary_logloss: 0.449485\tvalid_1's binary_logloss: 0.484759\n",
      "[500]\ttraining's binary_logloss: 0.446065\tvalid_1's binary_logloss: 0.484291\n",
      "[600]\ttraining's binary_logloss: 0.443739\tvalid_1's binary_logloss: 0.483977\n",
      "[700]\ttraining's binary_logloss: 0.44223\tvalid_1's binary_logloss: 0.483809\n",
      "[800]\ttraining's binary_logloss: 0.441114\tvalid_1's binary_logloss: 0.483739\n",
      "[900]\ttraining's binary_logloss: 0.440252\tvalid_1's binary_logloss: 0.483711\n",
      "[1000]\ttraining's binary_logloss: 0.439494\tvalid_1's binary_logloss: 0.48362\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439494\tvalid_1's binary_logloss: 0.48362\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439423\tvalid_1's binary_logloss: 0.48362\n",
      "[1200]\ttraining's binary_logloss: 0.439355\tvalid_1's binary_logloss: 0.483624\n",
      "Early stopping, best iteration is:\n",
      "[1118]\ttraining's binary_logloss: 0.43941\tvalid_1's binary_logloss: 0.483616\n",
      "===== ACCURACY SCORE 0.785779 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509951\tvalid_1's binary_logloss: 0.525212\n",
      "[200]\ttraining's binary_logloss: 0.469925\tvalid_1's binary_logloss: 0.49096\n",
      "[300]\ttraining's binary_logloss: 0.456407\tvalid_1's binary_logloss: 0.483241\n",
      "[400]\ttraining's binary_logloss: 0.450315\tvalid_1's binary_logloss: 0.481426\n",
      "[500]\ttraining's binary_logloss: 0.446785\tvalid_1's binary_logloss: 0.481059\n",
      "[600]\ttraining's binary_logloss: 0.444547\tvalid_1's binary_logloss: 0.481092\n",
      "Early stopping, best iteration is:\n",
      "[551]\ttraining's binary_logloss: 0.445509\tvalid_1's binary_logloss: 0.480933\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.445402\tvalid_1's binary_logloss: 0.480949\n",
      "Early stopping, best iteration is:\n",
      "[552]\ttraining's binary_logloss: 0.445506\tvalid_1's binary_logloss: 0.480933\n",
      "===== ACCURACY SCORE 0.783337 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508788\tvalid_1's binary_logloss: 0.530065\n",
      "[200]\ttraining's binary_logloss: 0.468443\tvalid_1's binary_logloss: 0.499042\n",
      "[300]\ttraining's binary_logloss: 0.454681\tvalid_1's binary_logloss: 0.493379\n",
      "[400]\ttraining's binary_logloss: 0.448742\tvalid_1's binary_logloss: 0.49267\n",
      "[500]\ttraining's binary_logloss: 0.445202\tvalid_1's binary_logloss: 0.492901\n",
      "Early stopping, best iteration is:\n",
      "[406]\ttraining's binary_logloss: 0.448512\tvalid_1's binary_logloss: 0.492631\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.448143\tvalid_1's binary_logloss: 0.492632\n",
      "Early stopping, best iteration is:\n",
      "[422]\ttraining's binary_logloss: 0.448448\tvalid_1's binary_logloss: 0.492626\n",
      "===== ACCURACY SCORE 0.775704 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509473\tvalid_1's binary_logloss: 0.523144\n",
      "[200]\ttraining's binary_logloss: 0.468969\tvalid_1's binary_logloss: 0.48813\n",
      "[300]\ttraining's binary_logloss: 0.455146\tvalid_1's binary_logloss: 0.479958\n",
      "[400]\ttraining's binary_logloss: 0.449128\tvalid_1's binary_logloss: 0.477887\n",
      "[500]\ttraining's binary_logloss: 0.445693\tvalid_1's binary_logloss: 0.477326\n",
      "[600]\ttraining's binary_logloss: 0.443426\tvalid_1's binary_logloss: 0.476876\n",
      "[700]\ttraining's binary_logloss: 0.441932\tvalid_1's binary_logloss: 0.47655\n",
      "[800]\ttraining's binary_logloss: 0.440895\tvalid_1's binary_logloss: 0.476344\n",
      "[900]\ttraining's binary_logloss: 0.44002\tvalid_1's binary_logloss: 0.476157\n",
      "[1000]\ttraining's binary_logloss: 0.439299\tvalid_1's binary_logloss: 0.475964\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439299\tvalid_1's binary_logloss: 0.475964\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439229\tvalid_1's binary_logloss: 0.475946\n",
      "[1200]\ttraining's binary_logloss: 0.439159\tvalid_1's binary_logloss: 0.475926\n",
      "[1300]\ttraining's binary_logloss: 0.439091\tvalid_1's binary_logloss: 0.4759\n",
      "[1400]\ttraining's binary_logloss: 0.439023\tvalid_1's binary_logloss: 0.475882\n",
      "[1500]\ttraining's binary_logloss: 0.438956\tvalid_1's binary_logloss: 0.475875\n",
      "[1600]\ttraining's binary_logloss: 0.438889\tvalid_1's binary_logloss: 0.475852\n",
      "[1700]\ttraining's binary_logloss: 0.438823\tvalid_1's binary_logloss: 0.475829\n",
      "[1800]\ttraining's binary_logloss: 0.438759\tvalid_1's binary_logloss: 0.475809\n",
      "[1900]\ttraining's binary_logloss: 0.438697\tvalid_1's binary_logloss: 0.475796\n",
      "[2000]\ttraining's binary_logloss: 0.438635\tvalid_1's binary_logloss: 0.475782\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.438635\tvalid_1's binary_logloss: 0.475782\n",
      "===== ACCURACY SCORE 0.786759 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509717\tvalid_1's binary_logloss: 0.528758\n",
      "[200]\ttraining's binary_logloss: 0.46955\tvalid_1's binary_logloss: 0.496959\n",
      "[300]\ttraining's binary_logloss: 0.456013\tvalid_1's binary_logloss: 0.490757\n",
      "[400]\ttraining's binary_logloss: 0.450098\tvalid_1's binary_logloss: 0.489926\n",
      "[500]\ttraining's binary_logloss: 0.446734\tvalid_1's binary_logloss: 0.489841\n",
      "[600]\ttraining's binary_logloss: 0.444531\tvalid_1's binary_logloss: 0.48974\n",
      "[700]\ttraining's binary_logloss: 0.4431\tvalid_1's binary_logloss: 0.489741\n",
      "Early stopping, best iteration is:\n",
      "[672]\ttraining's binary_logloss: 0.443466\tvalid_1's binary_logloss: 0.489653\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.443429\tvalid_1's binary_logloss: 0.489662\n",
      "Early stopping, best iteration is:\n",
      "[673]\ttraining's binary_logloss: 0.443465\tvalid_1's binary_logloss: 0.489653\n",
      "===== ACCURACY SCORE 0.779841 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.507856\tvalid_1's binary_logloss: 0.534057\n",
      "[200]\ttraining's binary_logloss: 0.467353\tvalid_1's binary_logloss: 0.504115\n",
      "[300]\ttraining's binary_logloss: 0.453718\tvalid_1's binary_logloss: 0.49878\n",
      "[400]\ttraining's binary_logloss: 0.44774\tvalid_1's binary_logloss: 0.497996\n",
      "[500]\ttraining's binary_logloss: 0.444317\tvalid_1's binary_logloss: 0.49794\n",
      "[600]\ttraining's binary_logloss: 0.442043\tvalid_1's binary_logloss: 0.497609\n",
      "[700]\ttraining's binary_logloss: 0.440535\tvalid_1's binary_logloss: 0.497599\n",
      "Early stopping, best iteration is:\n",
      "[666]\ttraining's binary_logloss: 0.440985\tvalid_1's binary_logloss: 0.497507\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.440937\tvalid_1's binary_logloss: 0.497508\n",
      "[800]\ttraining's binary_logloss: 0.440802\tvalid_1's binary_logloss: 0.497498\n",
      "[900]\ttraining's binary_logloss: 0.440669\tvalid_1's binary_logloss: 0.4975\n",
      "[1000]\ttraining's binary_logloss: 0.440541\tvalid_1's binary_logloss: 0.49749\n",
      "Early stopping, best iteration is:\n",
      "[970]\ttraining's binary_logloss: 0.440579\tvalid_1's binary_logloss: 0.497488\n",
      "===== ACCURACY SCORE 0.773359 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508237\tvalid_1's binary_logloss: 0.525224\n",
      "[200]\ttraining's binary_logloss: 0.46778\tvalid_1's binary_logloss: 0.493239\n",
      "[300]\ttraining's binary_logloss: 0.454396\tvalid_1's binary_logloss: 0.487019\n",
      "[400]\ttraining's binary_logloss: 0.448453\tvalid_1's binary_logloss: 0.485852\n",
      "[500]\ttraining's binary_logloss: 0.445083\tvalid_1's binary_logloss: 0.485705\n",
      "Early stopping, best iteration is:\n",
      "[490]\ttraining's binary_logloss: 0.445357\tvalid_1's binary_logloss: 0.485685\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.445327\tvalid_1's binary_logloss: 0.48568\n",
      "[600]\ttraining's binary_logloss: 0.445053\tvalid_1's binary_logloss: 0.485667\n",
      "[700]\ttraining's binary_logloss: 0.444782\tvalid_1's binary_logloss: 0.485662\n",
      "[800]\ttraining's binary_logloss: 0.444532\tvalid_1's binary_logloss: 0.485653\n",
      "[900]\ttraining's binary_logloss: 0.444281\tvalid_1's binary_logloss: 0.485644\n",
      "[1000]\ttraining's binary_logloss: 0.444048\tvalid_1's binary_logloss: 0.485642\n",
      "[1100]\ttraining's binary_logloss: 0.443827\tvalid_1's binary_logloss: 0.485646\n",
      "Early stopping, best iteration is:\n",
      "[1004]\ttraining's binary_logloss: 0.444038\tvalid_1's binary_logloss: 0.485638\n",
      "===== ACCURACY SCORE 0.780186 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509861\tvalid_1's binary_logloss: 0.526723\n",
      "[200]\ttraining's binary_logloss: 0.469557\tvalid_1's binary_logloss: 0.493862\n",
      "[300]\ttraining's binary_logloss: 0.455895\tvalid_1's binary_logloss: 0.486546\n",
      "[400]\ttraining's binary_logloss: 0.449972\tvalid_1's binary_logloss: 0.484621\n",
      "[500]\ttraining's binary_logloss: 0.446555\tvalid_1's binary_logloss: 0.48375\n",
      "[600]\ttraining's binary_logloss: 0.444304\tvalid_1's binary_logloss: 0.482841\n",
      "[700]\ttraining's binary_logloss: 0.442827\tvalid_1's binary_logloss: 0.482329\n",
      "[800]\ttraining's binary_logloss: 0.441795\tvalid_1's binary_logloss: 0.481903\n",
      "[900]\ttraining's binary_logloss: 0.440962\tvalid_1's binary_logloss: 0.481681\n",
      "[1000]\ttraining's binary_logloss: 0.440241\tvalid_1's binary_logloss: 0.481473\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440241\tvalid_1's binary_logloss: 0.481473\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440174\tvalid_1's binary_logloss: 0.481449\n",
      "[1200]\ttraining's binary_logloss: 0.44011\tvalid_1's binary_logloss: 0.481434\n",
      "[1300]\ttraining's binary_logloss: 0.440044\tvalid_1's binary_logloss: 0.481419\n",
      "[1400]\ttraining's binary_logloss: 0.439981\tvalid_1's binary_logloss: 0.481402\n",
      "[1500]\ttraining's binary_logloss: 0.439918\tvalid_1's binary_logloss: 0.481386\n",
      "[1600]\ttraining's binary_logloss: 0.439854\tvalid_1's binary_logloss: 0.481374\n",
      "[1700]\ttraining's binary_logloss: 0.439792\tvalid_1's binary_logloss: 0.481365\n",
      "[1800]\ttraining's binary_logloss: 0.439731\tvalid_1's binary_logloss: 0.481349\n",
      "[1900]\ttraining's binary_logloss: 0.43967\tvalid_1's binary_logloss: 0.481332\n",
      "[2000]\ttraining's binary_logloss: 0.439609\tvalid_1's binary_logloss: 0.481317\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439609\tvalid_1's binary_logloss: 0.481317\n",
      "===== ACCURACY SCORE 0.785592 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779630 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509882\tvalid_1's binary_logloss: 0.532569\n",
      "[200]\ttraining's binary_logloss: 0.469587\tvalid_1's binary_logloss: 0.503052\n",
      "[300]\ttraining's binary_logloss: 0.455934\tvalid_1's binary_logloss: 0.497607\n",
      "[400]\ttraining's binary_logloss: 0.449846\tvalid_1's binary_logloss: 0.496709\n",
      "[500]\ttraining's binary_logloss: 0.446408\tvalid_1's binary_logloss: 0.496407\n",
      "[600]\ttraining's binary_logloss: 0.444131\tvalid_1's binary_logloss: 0.496298\n",
      "[700]\ttraining's binary_logloss: 0.442662\tvalid_1's binary_logloss: 0.496187\n",
      "[800]\ttraining's binary_logloss: 0.441572\tvalid_1's binary_logloss: 0.496239\n",
      "Early stopping, best iteration is:\n",
      "[720]\ttraining's binary_logloss: 0.44242\tvalid_1's binary_logloss: 0.496155\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.442325\tvalid_1's binary_logloss: 0.496163\n",
      "Early stopping, best iteration is:\n",
      "[724]\ttraining's binary_logloss: 0.442414\tvalid_1's binary_logloss: 0.496154\n",
      "===== ACCURACY SCORE 0.770303 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510088\tvalid_1's binary_logloss: 0.52812\n",
      "[200]\ttraining's binary_logloss: 0.469783\tvalid_1's binary_logloss: 0.495435\n",
      "[300]\ttraining's binary_logloss: 0.456016\tvalid_1's binary_logloss: 0.488461\n",
      "[400]\ttraining's binary_logloss: 0.450052\tvalid_1's binary_logloss: 0.487006\n",
      "[500]\ttraining's binary_logloss: 0.446561\tvalid_1's binary_logloss: 0.486518\n",
      "[600]\ttraining's binary_logloss: 0.444252\tvalid_1's binary_logloss: 0.486294\n",
      "[700]\ttraining's binary_logloss: 0.44266\tvalid_1's binary_logloss: 0.486119\n",
      "Early stopping, best iteration is:\n",
      "[681]\ttraining's binary_logloss: 0.442911\tvalid_1's binary_logloss: 0.486078\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.442886\tvalid_1's binary_logloss: 0.486077\n",
      "[800]\ttraining's binary_logloss: 0.442752\tvalid_1's binary_logloss: 0.486078\n",
      "Early stopping, best iteration is:\n",
      "[760]\ttraining's binary_logloss: 0.442804\tvalid_1's binary_logloss: 0.486074\n",
      "===== ACCURACY SCORE 0.780437 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509392\tvalid_1's binary_logloss: 0.52722\n",
      "[200]\ttraining's binary_logloss: 0.469151\tvalid_1's binary_logloss: 0.494179\n",
      "[300]\ttraining's binary_logloss: 0.455618\tvalid_1's binary_logloss: 0.487114\n",
      "[400]\ttraining's binary_logloss: 0.449498\tvalid_1's binary_logloss: 0.485734\n",
      "[500]\ttraining's binary_logloss: 0.446039\tvalid_1's binary_logloss: 0.485566\n",
      "[600]\ttraining's binary_logloss: 0.443752\tvalid_1's binary_logloss: 0.485352\n",
      "[700]\ttraining's binary_logloss: 0.442235\tvalid_1's binary_logloss: 0.48533\n",
      "Early stopping, best iteration is:\n",
      "[646]\ttraining's binary_logloss: 0.442986\tvalid_1's binary_logloss: 0.48525\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.442904\tvalid_1's binary_logloss: 0.48525\n",
      "Early stopping, best iteration is:\n",
      "[659]\ttraining's binary_logloss: 0.442965\tvalid_1's binary_logloss: 0.485247\n",
      "===== ACCURACY SCORE 0.783814 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508856\tvalid_1's binary_logloss: 0.525509\n",
      "[200]\ttraining's binary_logloss: 0.468532\tvalid_1's binary_logloss: 0.492555\n",
      "[300]\ttraining's binary_logloss: 0.454919\tvalid_1's binary_logloss: 0.485374\n",
      "[400]\ttraining's binary_logloss: 0.448973\tvalid_1's binary_logloss: 0.483667\n",
      "[500]\ttraining's binary_logloss: 0.445504\tvalid_1's binary_logloss: 0.483138\n",
      "[600]\ttraining's binary_logloss: 0.443252\tvalid_1's binary_logloss: 0.483035\n",
      "Early stopping, best iteration is:\n",
      "[564]\ttraining's binary_logloss: 0.443934\tvalid_1's binary_logloss: 0.482964\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[600]\ttraining's binary_logloss: 0.443862\tvalid_1's binary_logloss: 0.482958\n",
      "[700]\ttraining's binary_logloss: 0.44366\tvalid_1's binary_logloss: 0.482945\n",
      "[800]\ttraining's binary_logloss: 0.443465\tvalid_1's binary_logloss: 0.482935\n",
      "[900]\ttraining's binary_logloss: 0.443279\tvalid_1's binary_logloss: 0.482933\n",
      "[1000]\ttraining's binary_logloss: 0.4431\tvalid_1's binary_logloss: 0.48293\n",
      "[1100]\ttraining's binary_logloss: 0.442926\tvalid_1's binary_logloss: 0.482927\n",
      "Early stopping, best iteration is:\n",
      "[1078]\ttraining's binary_logloss: 0.442964\tvalid_1's binary_logloss: 0.482924\n",
      "===== ACCURACY SCORE 0.779685 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509864\tvalid_1's binary_logloss: 0.523867\n",
      "[200]\ttraining's binary_logloss: 0.469568\tvalid_1's binary_logloss: 0.489474\n",
      "[300]\ttraining's binary_logloss: 0.455992\tvalid_1's binary_logloss: 0.481841\n",
      "[400]\ttraining's binary_logloss: 0.450035\tvalid_1's binary_logloss: 0.48003\n",
      "[500]\ttraining's binary_logloss: 0.446552\tvalid_1's binary_logloss: 0.479341\n",
      "[600]\ttraining's binary_logloss: 0.444309\tvalid_1's binary_logloss: 0.479094\n",
      "[700]\ttraining's binary_logloss: 0.442789\tvalid_1's binary_logloss: 0.47878\n",
      "[800]\ttraining's binary_logloss: 0.44165\tvalid_1's binary_logloss: 0.47861\n",
      "[900]\ttraining's binary_logloss: 0.440798\tvalid_1's binary_logloss: 0.478524\n",
      "[1000]\ttraining's binary_logloss: 0.440063\tvalid_1's binary_logloss: 0.478485\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440063\tvalid_1's binary_logloss: 0.478485\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439995\tvalid_1's binary_logloss: 0.478472\n",
      "[1200]\ttraining's binary_logloss: 0.439926\tvalid_1's binary_logloss: 0.47847\n",
      "[1300]\ttraining's binary_logloss: 0.439857\tvalid_1's binary_logloss: 0.478456\n",
      "[1400]\ttraining's binary_logloss: 0.439794\tvalid_1's binary_logloss: 0.478451\n",
      "[1500]\ttraining's binary_logloss: 0.439729\tvalid_1's binary_logloss: 0.478441\n",
      "[1600]\ttraining's binary_logloss: 0.43966\tvalid_1's binary_logloss: 0.478434\n",
      "[1700]\ttraining's binary_logloss: 0.439595\tvalid_1's binary_logloss: 0.478431\n",
      "[1800]\ttraining's binary_logloss: 0.439529\tvalid_1's binary_logloss: 0.478418\n",
      "[1900]\ttraining's binary_logloss: 0.439468\tvalid_1's binary_logloss: 0.478417\n",
      "Early stopping, best iteration is:\n",
      "[1864]\ttraining's binary_logloss: 0.43949\tvalid_1's binary_logloss: 0.478416\n",
      "===== ACCURACY SCORE 0.785123 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509157\tvalid_1's binary_logloss: 0.531187\n",
      "[200]\ttraining's binary_logloss: 0.468874\tvalid_1's binary_logloss: 0.500441\n",
      "[300]\ttraining's binary_logloss: 0.455154\tvalid_1's binary_logloss: 0.494854\n",
      "[400]\ttraining's binary_logloss: 0.449186\tvalid_1's binary_logloss: 0.494344\n",
      "[500]\ttraining's binary_logloss: 0.44575\tvalid_1's binary_logloss: 0.494261\n",
      "[600]\ttraining's binary_logloss: 0.443454\tvalid_1's binary_logloss: 0.494099\n",
      "[700]\ttraining's binary_logloss: 0.441953\tvalid_1's binary_logloss: 0.494045\n",
      "Early stopping, best iteration is:\n",
      "[649]\ttraining's binary_logloss: 0.442642\tvalid_1's binary_logloss: 0.49401\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.442565\tvalid_1's binary_logloss: 0.494013\n",
      "Early stopping, best iteration is:\n",
      "[665]\ttraining's binary_logloss: 0.442616\tvalid_1's binary_logloss: 0.494004\n",
      "===== ACCURACY SCORE 0.777568 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509192\tvalid_1's binary_logloss: 0.525176\n",
      "[200]\ttraining's binary_logloss: 0.468779\tvalid_1's binary_logloss: 0.492424\n",
      "[300]\ttraining's binary_logloss: 0.455266\tvalid_1's binary_logloss: 0.485744\n",
      "[400]\ttraining's binary_logloss: 0.449391\tvalid_1's binary_logloss: 0.484631\n",
      "[500]\ttraining's binary_logloss: 0.44599\tvalid_1's binary_logloss: 0.48465\n",
      "Early stopping, best iteration is:\n",
      "[440]\ttraining's binary_logloss: 0.447884\tvalid_1's binary_logloss: 0.48456\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.447688\tvalid_1's binary_logloss: 0.484584\n",
      "Early stopping, best iteration is:\n",
      "[443]\ttraining's binary_logloss: 0.447874\tvalid_1's binary_logloss: 0.484558\n",
      "===== ACCURACY SCORE 0.778781 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510229\tvalid_1's binary_logloss: 0.529576\n",
      "[200]\ttraining's binary_logloss: 0.470088\tvalid_1's binary_logloss: 0.495998\n",
      "[300]\ttraining's binary_logloss: 0.456473\tvalid_1's binary_logloss: 0.48844\n",
      "[400]\ttraining's binary_logloss: 0.450484\tvalid_1's binary_logloss: 0.486241\n",
      "[500]\ttraining's binary_logloss: 0.446997\tvalid_1's binary_logloss: 0.485304\n",
      "[600]\ttraining's binary_logloss: 0.444723\tvalid_1's binary_logloss: 0.484803\n",
      "[700]\ttraining's binary_logloss: 0.443208\tvalid_1's binary_logloss: 0.484339\n",
      "[800]\ttraining's binary_logloss: 0.442098\tvalid_1's binary_logloss: 0.484148\n",
      "[900]\ttraining's binary_logloss: 0.44124\tvalid_1's binary_logloss: 0.483993\n",
      "[1000]\ttraining's binary_logloss: 0.440516\tvalid_1's binary_logloss: 0.483944\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440516\tvalid_1's binary_logloss: 0.483944\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440446\tvalid_1's binary_logloss: 0.483937\n",
      "[1200]\ttraining's binary_logloss: 0.440377\tvalid_1's binary_logloss: 0.483931\n",
      "[1300]\ttraining's binary_logloss: 0.440309\tvalid_1's binary_logloss: 0.483922\n",
      "Early stopping, best iteration is:\n",
      "[1293]\ttraining's binary_logloss: 0.440314\tvalid_1's binary_logloss: 0.483919\n",
      "===== ACCURACY SCORE 0.779196 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509746\tvalid_1's binary_logloss: 0.528322\n",
      "[200]\ttraining's binary_logloss: 0.469618\tvalid_1's binary_logloss: 0.495924\n",
      "[300]\ttraining's binary_logloss: 0.456169\tvalid_1's binary_logloss: 0.489012\n",
      "[400]\ttraining's binary_logloss: 0.450333\tvalid_1's binary_logloss: 0.487329\n",
      "[500]\ttraining's binary_logloss: 0.446987\tvalid_1's binary_logloss: 0.486425\n",
      "[600]\ttraining's binary_logloss: 0.444716\tvalid_1's binary_logloss: 0.485653\n",
      "[700]\ttraining's binary_logloss: 0.443273\tvalid_1's binary_logloss: 0.4853\n",
      "[800]\ttraining's binary_logloss: 0.44223\tvalid_1's binary_logloss: 0.485013\n",
      "[900]\ttraining's binary_logloss: 0.441394\tvalid_1's binary_logloss: 0.484803\n",
      "[1000]\ttraining's binary_logloss: 0.440716\tvalid_1's binary_logloss: 0.484718\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440716\tvalid_1's binary_logloss: 0.484718\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440651\tvalid_1's binary_logloss: 0.484706\n",
      "[1200]\ttraining's binary_logloss: 0.440585\tvalid_1's binary_logloss: 0.484698\n",
      "[1300]\ttraining's binary_logloss: 0.44052\tvalid_1's binary_logloss: 0.48469\n",
      "[1400]\ttraining's binary_logloss: 0.440456\tvalid_1's binary_logloss: 0.484682\n",
      "[1500]\ttraining's binary_logloss: 0.440392\tvalid_1's binary_logloss: 0.484674\n",
      "[1600]\ttraining's binary_logloss: 0.440327\tvalid_1's binary_logloss: 0.484664\n",
      "[1700]\ttraining's binary_logloss: 0.440264\tvalid_1's binary_logloss: 0.484655\n",
      "[1800]\ttraining's binary_logloss: 0.440203\tvalid_1's binary_logloss: 0.484644\n",
      "[1900]\ttraining's binary_logloss: 0.440141\tvalid_1's binary_logloss: 0.484623\n",
      "[2000]\ttraining's binary_logloss: 0.440082\tvalid_1's binary_logloss: 0.484616\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.440082\tvalid_1's binary_logloss: 0.484616\n",
      "===== ACCURACY SCORE 0.781067 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508589\tvalid_1's binary_logloss: 0.531002\n",
      "[200]\ttraining's binary_logloss: 0.467859\tvalid_1's binary_logloss: 0.499755\n",
      "[300]\ttraining's binary_logloss: 0.453963\tvalid_1's binary_logloss: 0.493985\n",
      "[400]\ttraining's binary_logloss: 0.447925\tvalid_1's binary_logloss: 0.493301\n",
      "[500]\ttraining's binary_logloss: 0.444439\tvalid_1's binary_logloss: 0.493596\n",
      "Early stopping, best iteration is:\n",
      "[402]\ttraining's binary_logloss: 0.447847\tvalid_1's binary_logloss: 0.493289\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's binary_logloss: 0.447459\tvalid_1's binary_logloss: 0.493326\n",
      "Early stopping, best iteration is:\n",
      "[405]\ttraining's binary_logloss: 0.447834\tvalid_1's binary_logloss: 0.493288\n",
      "===== ACCURACY SCORE 0.777899 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779400 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509392\tvalid_1's binary_logloss: 0.530249\n",
      "[200]\ttraining's binary_logloss: 0.468944\tvalid_1's binary_logloss: 0.497846\n",
      "[300]\ttraining's binary_logloss: 0.455104\tvalid_1's binary_logloss: 0.49139\n",
      "[400]\ttraining's binary_logloss: 0.449109\tvalid_1's binary_logloss: 0.49009\n",
      "[500]\ttraining's binary_logloss: 0.445538\tvalid_1's binary_logloss: 0.489719\n",
      "[600]\ttraining's binary_logloss: 0.443212\tvalid_1's binary_logloss: 0.489544\n",
      "[700]\ttraining's binary_logloss: 0.441681\tvalid_1's binary_logloss: 0.489429\n",
      "[800]\ttraining's binary_logloss: 0.440577\tvalid_1's binary_logloss: 0.489348\n",
      "[900]\ttraining's binary_logloss: 0.439731\tvalid_1's binary_logloss: 0.489301\n",
      "[1000]\ttraining's binary_logloss: 0.438992\tvalid_1's binary_logloss: 0.489223\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.438992\tvalid_1's binary_logloss: 0.489223\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.438927\tvalid_1's binary_logloss: 0.489213\n",
      "[1200]\ttraining's binary_logloss: 0.438858\tvalid_1's binary_logloss: 0.489197\n",
      "[1300]\ttraining's binary_logloss: 0.438792\tvalid_1's binary_logloss: 0.489187\n",
      "[1400]\ttraining's binary_logloss: 0.438725\tvalid_1's binary_logloss: 0.489179\n",
      "[1500]\ttraining's binary_logloss: 0.438658\tvalid_1's binary_logloss: 0.489156\n",
      "[1600]\ttraining's binary_logloss: 0.438593\tvalid_1's binary_logloss: 0.489145\n",
      "[1700]\ttraining's binary_logloss: 0.438526\tvalid_1's binary_logloss: 0.48913\n",
      "[1800]\ttraining's binary_logloss: 0.438463\tvalid_1's binary_logloss: 0.489122\n",
      "[1900]\ttraining's binary_logloss: 0.438402\tvalid_1's binary_logloss: 0.489119\n",
      "[2000]\ttraining's binary_logloss: 0.438338\tvalid_1's binary_logloss: 0.489119\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.438338\tvalid_1's binary_logloss: 0.489119\n",
      "===== ACCURACY SCORE 0.780240 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.50915\tvalid_1's binary_logloss: 0.526317\n",
      "[200]\ttraining's binary_logloss: 0.468657\tvalid_1's binary_logloss: 0.493281\n",
      "[300]\ttraining's binary_logloss: 0.455213\tvalid_1's binary_logloss: 0.486217\n",
      "[400]\ttraining's binary_logloss: 0.449278\tvalid_1's binary_logloss: 0.484656\n",
      "[500]\ttraining's binary_logloss: 0.445915\tvalid_1's binary_logloss: 0.484128\n",
      "[600]\ttraining's binary_logloss: 0.443661\tvalid_1's binary_logloss: 0.483587\n",
      "[700]\ttraining's binary_logloss: 0.442175\tvalid_1's binary_logloss: 0.483213\n",
      "[800]\ttraining's binary_logloss: 0.441106\tvalid_1's binary_logloss: 0.483024\n",
      "[900]\ttraining's binary_logloss: 0.440214\tvalid_1's binary_logloss: 0.482908\n",
      "[1000]\ttraining's binary_logloss: 0.439497\tvalid_1's binary_logloss: 0.48279\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439497\tvalid_1's binary_logloss: 0.48279\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439426\tvalid_1's binary_logloss: 0.482776\n",
      "[1200]\ttraining's binary_logloss: 0.43936\tvalid_1's binary_logloss: 0.482759\n",
      "[1300]\ttraining's binary_logloss: 0.439292\tvalid_1's binary_logloss: 0.482746\n",
      "[1400]\ttraining's binary_logloss: 0.439223\tvalid_1's binary_logloss: 0.482732\n",
      "[1500]\ttraining's binary_logloss: 0.439154\tvalid_1's binary_logloss: 0.482722\n",
      "[1600]\ttraining's binary_logloss: 0.439089\tvalid_1's binary_logloss: 0.482702\n",
      "[1700]\ttraining's binary_logloss: 0.439019\tvalid_1's binary_logloss: 0.48269\n",
      "[1800]\ttraining's binary_logloss: 0.438954\tvalid_1's binary_logloss: 0.48268\n",
      "[1900]\ttraining's binary_logloss: 0.43889\tvalid_1's binary_logloss: 0.482666\n",
      "[2000]\ttraining's binary_logloss: 0.438829\tvalid_1's binary_logloss: 0.482665\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.438829\tvalid_1's binary_logloss: 0.482665\n",
      "===== ACCURACY SCORE 0.782092 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509495\tvalid_1's binary_logloss: 0.525348\n",
      "[200]\ttraining's binary_logloss: 0.469436\tvalid_1's binary_logloss: 0.492036\n",
      "[300]\ttraining's binary_logloss: 0.455893\tvalid_1's binary_logloss: 0.484986\n",
      "[400]\ttraining's binary_logloss: 0.449939\tvalid_1's binary_logloss: 0.483579\n",
      "[500]\ttraining's binary_logloss: 0.44647\tvalid_1's binary_logloss: 0.482957\n",
      "[600]\ttraining's binary_logloss: 0.444179\tvalid_1's binary_logloss: 0.482476\n",
      "[700]\ttraining's binary_logloss: 0.4427\tvalid_1's binary_logloss: 0.482195\n",
      "[800]\ttraining's binary_logloss: 0.441617\tvalid_1's binary_logloss: 0.482015\n",
      "[900]\ttraining's binary_logloss: 0.440795\tvalid_1's binary_logloss: 0.481959\n",
      "[1000]\ttraining's binary_logloss: 0.440054\tvalid_1's binary_logloss: 0.481885\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440054\tvalid_1's binary_logloss: 0.481885\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439987\tvalid_1's binary_logloss: 0.481888\n",
      "[1200]\ttraining's binary_logloss: 0.439918\tvalid_1's binary_logloss: 0.481883\n",
      "Early stopping, best iteration is:\n",
      "[1124]\ttraining's binary_logloss: 0.43997\tvalid_1's binary_logloss: 0.481881\n",
      "===== ACCURACY SCORE 0.778918 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510436\tvalid_1's binary_logloss: 0.525967\n",
      "[200]\ttraining's binary_logloss: 0.470305\tvalid_1's binary_logloss: 0.493008\n",
      "[300]\ttraining's binary_logloss: 0.456712\tvalid_1's binary_logloss: 0.485964\n",
      "[400]\ttraining's binary_logloss: 0.45076\tvalid_1's binary_logloss: 0.48466\n",
      "[500]\ttraining's binary_logloss: 0.447329\tvalid_1's binary_logloss: 0.484499\n",
      "[600]\ttraining's binary_logloss: 0.445022\tvalid_1's binary_logloss: 0.484272\n",
      "[700]\ttraining's binary_logloss: 0.443469\tvalid_1's binary_logloss: 0.484185\n",
      "[800]\ttraining's binary_logloss: 0.442356\tvalid_1's binary_logloss: 0.48415\n",
      "Early stopping, best iteration is:\n",
      "[782]\ttraining's binary_logloss: 0.442538\tvalid_1's binary_logloss: 0.484121\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.442519\tvalid_1's binary_logloss: 0.484122\n",
      "Early stopping, best iteration is:\n",
      "[786]\ttraining's binary_logloss: 0.442534\tvalid_1's binary_logloss: 0.48412\n",
      "===== ACCURACY SCORE 0.779976 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.51058\tvalid_1's binary_logloss: 0.523739\n",
      "[200]\ttraining's binary_logloss: 0.470817\tvalid_1's binary_logloss: 0.489771\n",
      "[300]\ttraining's binary_logloss: 0.457341\tvalid_1's binary_logloss: 0.482238\n",
      "[400]\ttraining's binary_logloss: 0.451416\tvalid_1's binary_logloss: 0.480535\n",
      "[500]\ttraining's binary_logloss: 0.447961\tvalid_1's binary_logloss: 0.480121\n",
      "[600]\ttraining's binary_logloss: 0.44571\tvalid_1's binary_logloss: 0.479892\n",
      "[700]\ttraining's binary_logloss: 0.444251\tvalid_1's binary_logloss: 0.479814\n",
      "[800]\ttraining's binary_logloss: 0.443183\tvalid_1's binary_logloss: 0.479815\n",
      "[900]\ttraining's binary_logloss: 0.44228\tvalid_1's binary_logloss: 0.479716\n",
      "[1000]\ttraining's binary_logloss: 0.441526\tvalid_1's binary_logloss: 0.479652\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.441526\tvalid_1's binary_logloss: 0.479652\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.441456\tvalid_1's binary_logloss: 0.479658\n",
      "Early stopping, best iteration is:\n",
      "[1008]\ttraining's binary_logloss: 0.44152\tvalid_1's binary_logloss: 0.479651\n",
      "===== ACCURACY SCORE 0.785907 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510459\tvalid_1's binary_logloss: 0.528444\n",
      "[200]\ttraining's binary_logloss: 0.470439\tvalid_1's binary_logloss: 0.495717\n",
      "[300]\ttraining's binary_logloss: 0.456936\tvalid_1's binary_logloss: 0.488619\n",
      "[400]\ttraining's binary_logloss: 0.451042\tvalid_1's binary_logloss: 0.487128\n",
      "[500]\ttraining's binary_logloss: 0.447675\tvalid_1's binary_logloss: 0.486845\n",
      "[600]\ttraining's binary_logloss: 0.445415\tvalid_1's binary_logloss: 0.486678\n",
      "[700]\ttraining's binary_logloss: 0.443877\tvalid_1's binary_logloss: 0.486697\n",
      "Early stopping, best iteration is:\n",
      "[639]\ttraining's binary_logloss: 0.444754\tvalid_1's binary_logloss: 0.486605\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.444654\tvalid_1's binary_logloss: 0.486599\n",
      "Early stopping, best iteration is:\n",
      "[676]\ttraining's binary_logloss: 0.444692\tvalid_1's binary_logloss: 0.486593\n",
      "===== ACCURACY SCORE 0.779810 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508842\tvalid_1's binary_logloss: 0.529799\n",
      "[200]\ttraining's binary_logloss: 0.468374\tvalid_1's binary_logloss: 0.497273\n",
      "[300]\ttraining's binary_logloss: 0.454704\tvalid_1's binary_logloss: 0.490422\n",
      "[400]\ttraining's binary_logloss: 0.448774\tvalid_1's binary_logloss: 0.488991\n",
      "[500]\ttraining's binary_logloss: 0.445353\tvalid_1's binary_logloss: 0.488715\n",
      "[600]\ttraining's binary_logloss: 0.443076\tvalid_1's binary_logloss: 0.488427\n",
      "[700]\ttraining's binary_logloss: 0.441565\tvalid_1's binary_logloss: 0.488434\n",
      "Early stopping, best iteration is:\n",
      "[634]\ttraining's binary_logloss: 0.442493\tvalid_1's binary_logloss: 0.488359\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.442389\tvalid_1's binary_logloss: 0.48835\n",
      "[800]\ttraining's binary_logloss: 0.44224\tvalid_1's binary_logloss: 0.488336\n",
      "Early stopping, best iteration is:\n",
      "[791]\ttraining's binary_logloss: 0.442254\tvalid_1's binary_logloss: 0.488333\n",
      "===== ACCURACY SCORE 0.777487 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510456\tvalid_1's binary_logloss: 0.526363\n",
      "[200]\ttraining's binary_logloss: 0.470323\tvalid_1's binary_logloss: 0.492217\n",
      "[300]\ttraining's binary_logloss: 0.456769\tvalid_1's binary_logloss: 0.484604\n",
      "[400]\ttraining's binary_logloss: 0.450765\tvalid_1's binary_logloss: 0.482775\n",
      "[500]\ttraining's binary_logloss: 0.447342\tvalid_1's binary_logloss: 0.482428\n",
      "[600]\ttraining's binary_logloss: 0.445087\tvalid_1's binary_logloss: 0.482112\n",
      "[700]\ttraining's binary_logloss: 0.443615\tvalid_1's binary_logloss: 0.482005\n",
      "Early stopping, best iteration is:\n",
      "[683]\ttraining's binary_logloss: 0.443829\tvalid_1's binary_logloss: 0.481992\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.443807\tvalid_1's binary_logloss: 0.481997\n",
      "Early stopping, best iteration is:\n",
      "[684]\ttraining's binary_logloss: 0.443828\tvalid_1's binary_logloss: 0.481992\n",
      "===== ACCURACY SCORE 0.785893 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508825\tvalid_1's binary_logloss: 0.535775\n",
      "[200]\ttraining's binary_logloss: 0.468312\tvalid_1's binary_logloss: 0.507783\n",
      "[300]\ttraining's binary_logloss: 0.454704\tvalid_1's binary_logloss: 0.503405\n",
      "[400]\ttraining's binary_logloss: 0.448814\tvalid_1's binary_logloss: 0.503452\n",
      "Early stopping, best iteration is:\n",
      "[339]\ttraining's binary_logloss: 0.451884\tvalid_1's binary_logloss: 0.50318\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.451507\tvalid_1's binary_logloss: 0.503182\n",
      "Early stopping, best iteration is:\n",
      "[371]\ttraining's binary_logloss: 0.451682\tvalid_1's binary_logloss: 0.503177\n",
      "===== ACCURACY SCORE 0.767125 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509621\tvalid_1's binary_logloss: 0.532121\n",
      "[200]\ttraining's binary_logloss: 0.469258\tvalid_1's binary_logloss: 0.501609\n",
      "[300]\ttraining's binary_logloss: 0.455714\tvalid_1's binary_logloss: 0.495647\n",
      "[400]\ttraining's binary_logloss: 0.449659\tvalid_1's binary_logloss: 0.494503\n",
      "[500]\ttraining's binary_logloss: 0.446144\tvalid_1's binary_logloss: 0.494201\n",
      "[600]\ttraining's binary_logloss: 0.44386\tvalid_1's binary_logloss: 0.494041\n",
      "[700]\ttraining's binary_logloss: 0.442314\tvalid_1's binary_logloss: 0.493982\n",
      "[800]\ttraining's binary_logloss: 0.441186\tvalid_1's binary_logloss: 0.49395\n",
      "Early stopping, best iteration is:\n",
      "[748]\ttraining's binary_logloss: 0.441734\tvalid_1's binary_logloss: 0.493915\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[800]\ttraining's binary_logloss: 0.441676\tvalid_1's binary_logloss: 0.493921\n",
      "Early stopping, best iteration is:\n",
      "[753]\ttraining's binary_logloss: 0.441728\tvalid_1's binary_logloss: 0.493912\n",
      "===== ACCURACY SCORE 0.771673 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778910 =====\n",
      "===== FOLD 0 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.51051\tvalid_1's binary_logloss: 0.52841\n",
      "[200]\ttraining's binary_logloss: 0.470367\tvalid_1's binary_logloss: 0.496015\n",
      "[300]\ttraining's binary_logloss: 0.456798\tvalid_1's binary_logloss: 0.488403\n",
      "[400]\ttraining's binary_logloss: 0.450874\tvalid_1's binary_logloss: 0.48641\n",
      "[500]\ttraining's binary_logloss: 0.447397\tvalid_1's binary_logloss: 0.48542\n",
      "[600]\ttraining's binary_logloss: 0.445086\tvalid_1's binary_logloss: 0.484709\n",
      "[700]\ttraining's binary_logloss: 0.443553\tvalid_1's binary_logloss: 0.484339\n",
      "[800]\ttraining's binary_logloss: 0.442453\tvalid_1's binary_logloss: 0.484179\n",
      "[900]\ttraining's binary_logloss: 0.441574\tvalid_1's binary_logloss: 0.484024\n",
      "[1000]\ttraining's binary_logloss: 0.440832\tvalid_1's binary_logloss: 0.483839\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440832\tvalid_1's binary_logloss: 0.483839\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440767\tvalid_1's binary_logloss: 0.483824\n",
      "[1200]\ttraining's binary_logloss: 0.440702\tvalid_1's binary_logloss: 0.483817\n",
      "[1300]\ttraining's binary_logloss: 0.440639\tvalid_1's binary_logloss: 0.483812\n",
      "[1400]\ttraining's binary_logloss: 0.440577\tvalid_1's binary_logloss: 0.483797\n",
      "[1500]\ttraining's binary_logloss: 0.440514\tvalid_1's binary_logloss: 0.483787\n",
      "[1600]\ttraining's binary_logloss: 0.440452\tvalid_1's binary_logloss: 0.483774\n",
      "[1700]\ttraining's binary_logloss: 0.440389\tvalid_1's binary_logloss: 0.483762\n",
      "[1800]\ttraining's binary_logloss: 0.440326\tvalid_1's binary_logloss: 0.483757\n",
      "[1900]\ttraining's binary_logloss: 0.440265\tvalid_1's binary_logloss: 0.483758\n",
      "Early stopping, best iteration is:\n",
      "[1830]\ttraining's binary_logloss: 0.440309\tvalid_1's binary_logloss: 0.483755\n",
      "===== ACCURACY SCORE 0.781247 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509959\tvalid_1's binary_logloss: 0.523766\n",
      "[200]\ttraining's binary_logloss: 0.46952\tvalid_1's binary_logloss: 0.489745\n",
      "[300]\ttraining's binary_logloss: 0.45589\tvalid_1's binary_logloss: 0.482451\n",
      "[400]\ttraining's binary_logloss: 0.449899\tvalid_1's binary_logloss: 0.480688\n",
      "[500]\ttraining's binary_logloss: 0.44635\tvalid_1's binary_logloss: 0.48009\n",
      "[600]\ttraining's binary_logloss: 0.444125\tvalid_1's binary_logloss: 0.479956\n",
      "[700]\ttraining's binary_logloss: 0.442601\tvalid_1's binary_logloss: 0.479875\n",
      "Early stopping, best iteration is:\n",
      "[655]\ttraining's binary_logloss: 0.443198\tvalid_1's binary_logloss: 0.479843\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.443132\tvalid_1's binary_logloss: 0.479839\n",
      "[800]\ttraining's binary_logloss: 0.44299\tvalid_1's binary_logloss: 0.479824\n",
      "Early stopping, best iteration is:\n",
      "[782]\ttraining's binary_logloss: 0.443015\tvalid_1's binary_logloss: 0.479822\n",
      "===== ACCURACY SCORE 0.785311 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509028\tvalid_1's binary_logloss: 0.528508\n",
      "[200]\ttraining's binary_logloss: 0.468867\tvalid_1's binary_logloss: 0.49577\n",
      "[300]\ttraining's binary_logloss: 0.455514\tvalid_1's binary_logloss: 0.48888\n",
      "[400]\ttraining's binary_logloss: 0.44972\tvalid_1's binary_logloss: 0.487132\n",
      "[500]\ttraining's binary_logloss: 0.44636\tvalid_1's binary_logloss: 0.486377\n",
      "[600]\ttraining's binary_logloss: 0.444014\tvalid_1's binary_logloss: 0.485524\n",
      "[700]\ttraining's binary_logloss: 0.442518\tvalid_1's binary_logloss: 0.485276\n",
      "[800]\ttraining's binary_logloss: 0.44143\tvalid_1's binary_logloss: 0.485039\n",
      "[900]\ttraining's binary_logloss: 0.440566\tvalid_1's binary_logloss: 0.484937\n",
      "[1000]\ttraining's binary_logloss: 0.439817\tvalid_1's binary_logloss: 0.484849\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439817\tvalid_1's binary_logloss: 0.484849\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439748\tvalid_1's binary_logloss: 0.484841\n",
      "[1200]\ttraining's binary_logloss: 0.43968\tvalid_1's binary_logloss: 0.484835\n",
      "[1300]\ttraining's binary_logloss: 0.439614\tvalid_1's binary_logloss: 0.484828\n",
      "[1400]\ttraining's binary_logloss: 0.439547\tvalid_1's binary_logloss: 0.484827\n",
      "[1500]\ttraining's binary_logloss: 0.439481\tvalid_1's binary_logloss: 0.484825\n",
      "[1600]\ttraining's binary_logloss: 0.439415\tvalid_1's binary_logloss: 0.484805\n",
      "[1700]\ttraining's binary_logloss: 0.439348\tvalid_1's binary_logloss: 0.484794\n",
      "[1800]\ttraining's binary_logloss: 0.439285\tvalid_1's binary_logloss: 0.484777\n",
      "[1900]\ttraining's binary_logloss: 0.439223\tvalid_1's binary_logloss: 0.484769\n",
      "[2000]\ttraining's binary_logloss: 0.439159\tvalid_1's binary_logloss: 0.484756\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.439159\tvalid_1's binary_logloss: 0.484756\n",
      "===== ACCURACY SCORE 0.781852 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.508506\tvalid_1's binary_logloss: 0.530443\n",
      "[200]\ttraining's binary_logloss: 0.467827\tvalid_1's binary_logloss: 0.499558\n",
      "[300]\ttraining's binary_logloss: 0.453793\tvalid_1's binary_logloss: 0.493235\n",
      "[400]\ttraining's binary_logloss: 0.447719\tvalid_1's binary_logloss: 0.49208\n",
      "[500]\ttraining's binary_logloss: 0.444246\tvalid_1's binary_logloss: 0.491879\n",
      "[600]\ttraining's binary_logloss: 0.44192\tvalid_1's binary_logloss: 0.49152\n",
      "[700]\ttraining's binary_logloss: 0.440412\tvalid_1's binary_logloss: 0.491451\n",
      "[800]\ttraining's binary_logloss: 0.439302\tvalid_1's binary_logloss: 0.491289\n",
      "[900]\ttraining's binary_logloss: 0.438428\tvalid_1's binary_logloss: 0.491138\n",
      "[1000]\ttraining's binary_logloss: 0.437709\tvalid_1's binary_logloss: 0.491101\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.437709\tvalid_1's binary_logloss: 0.491101\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.43764\tvalid_1's binary_logloss: 0.491103\n",
      "Early stopping, best iteration is:\n",
      "[1020]\ttraining's binary_logloss: 0.437695\tvalid_1's binary_logloss: 0.4911\n",
      "===== ACCURACY SCORE 0.772937 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509441\tvalid_1's binary_logloss: 0.529352\n",
      "[200]\ttraining's binary_logloss: 0.469103\tvalid_1's binary_logloss: 0.497937\n",
      "[300]\ttraining's binary_logloss: 0.455469\tvalid_1's binary_logloss: 0.491728\n",
      "[400]\ttraining's binary_logloss: 0.44943\tvalid_1's binary_logloss: 0.490624\n",
      "[500]\ttraining's binary_logloss: 0.446047\tvalid_1's binary_logloss: 0.490583\n",
      "[600]\ttraining's binary_logloss: 0.44377\tvalid_1's binary_logloss: 0.490213\n",
      "[700]\ttraining's binary_logloss: 0.442226\tvalid_1's binary_logloss: 0.490006\n",
      "[800]\ttraining's binary_logloss: 0.441117\tvalid_1's binary_logloss: 0.489856\n",
      "[900]\ttraining's binary_logloss: 0.440244\tvalid_1's binary_logloss: 0.489824\n",
      "[1000]\ttraining's binary_logloss: 0.439505\tvalid_1's binary_logloss: 0.489676\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.439505\tvalid_1's binary_logloss: 0.489676\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.439437\tvalid_1's binary_logloss: 0.489679\n",
      "Early stopping, best iteration is:\n",
      "[1042]\ttraining's binary_logloss: 0.439476\tvalid_1's binary_logloss: 0.489674\n",
      "===== ACCURACY SCORE 0.776455 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509489\tvalid_1's binary_logloss: 0.529162\n",
      "[200]\ttraining's binary_logloss: 0.469357\tvalid_1's binary_logloss: 0.497493\n",
      "[300]\ttraining's binary_logloss: 0.455667\tvalid_1's binary_logloss: 0.491201\n",
      "[400]\ttraining's binary_logloss: 0.449698\tvalid_1's binary_logloss: 0.490219\n",
      "[500]\ttraining's binary_logloss: 0.446287\tvalid_1's binary_logloss: 0.49007\n",
      "[600]\ttraining's binary_logloss: 0.44401\tvalid_1's binary_logloss: 0.489897\n",
      "[700]\ttraining's binary_logloss: 0.442482\tvalid_1's binary_logloss: 0.489936\n",
      "Early stopping, best iteration is:\n",
      "[619]\ttraining's binary_logloss: 0.443681\tvalid_1's binary_logloss: 0.489848\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[700]\ttraining's binary_logloss: 0.443547\tvalid_1's binary_logloss: 0.489849\n",
      "Early stopping, best iteration is:\n",
      "[622]\ttraining's binary_logloss: 0.443676\tvalid_1's binary_logloss: 0.489846\n",
      "===== ACCURACY SCORE 0.777890 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509417\tvalid_1's binary_logloss: 0.528343\n",
      "[200]\ttraining's binary_logloss: 0.469264\tvalid_1's binary_logloss: 0.49729\n",
      "[300]\ttraining's binary_logloss: 0.455675\tvalid_1's binary_logloss: 0.491738\n",
      "[400]\ttraining's binary_logloss: 0.449652\tvalid_1's binary_logloss: 0.491158\n",
      "Early stopping, best iteration is:\n",
      "[359]\ttraining's binary_logloss: 0.451624\tvalid_1's binary_logloss: 0.491064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.451399\tvalid_1's binary_logloss: 0.491059\n",
      "[500]\ttraining's binary_logloss: 0.450887\tvalid_1's binary_logloss: 0.491028\n",
      "[600]\ttraining's binary_logloss: 0.450404\tvalid_1's binary_logloss: 0.491045\n",
      "Early stopping, best iteration is:\n",
      "[511]\ttraining's binary_logloss: 0.450834\tvalid_1's binary_logloss: 0.491023\n",
      "===== ACCURACY SCORE 0.777176 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509865\tvalid_1's binary_logloss: 0.528132\n",
      "[200]\ttraining's binary_logloss: 0.469598\tvalid_1's binary_logloss: 0.496175\n",
      "[300]\ttraining's binary_logloss: 0.456006\tvalid_1's binary_logloss: 0.490344\n",
      "[400]\ttraining's binary_logloss: 0.449992\tvalid_1's binary_logloss: 0.489557\n",
      "Early stopping, best iteration is:\n",
      "[375]\ttraining's binary_logloss: 0.451113\tvalid_1's binary_logloss: 0.489515\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.450993\tvalid_1's binary_logloss: 0.489511\n",
      "[500]\ttraining's binary_logloss: 0.450532\tvalid_1's binary_logloss: 0.48947\n",
      "[600]\ttraining's binary_logloss: 0.450087\tvalid_1's binary_logloss: 0.489474\n",
      "Early stopping, best iteration is:\n",
      "[550]\ttraining's binary_logloss: 0.450315\tvalid_1's binary_logloss: 0.489464\n",
      "===== ACCURACY SCORE 0.778655 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.510148\tvalid_1's binary_logloss: 0.525713\n",
      "[200]\ttraining's binary_logloss: 0.47001\tvalid_1's binary_logloss: 0.491548\n",
      "[300]\ttraining's binary_logloss: 0.456467\tvalid_1's binary_logloss: 0.484004\n",
      "[400]\ttraining's binary_logloss: 0.450459\tvalid_1's binary_logloss: 0.482187\n",
      "[500]\ttraining's binary_logloss: 0.447014\tvalid_1's binary_logloss: 0.481452\n",
      "[600]\ttraining's binary_logloss: 0.444801\tvalid_1's binary_logloss: 0.480725\n",
      "[700]\ttraining's binary_logloss: 0.443338\tvalid_1's binary_logloss: 0.480337\n",
      "[800]\ttraining's binary_logloss: 0.442262\tvalid_1's binary_logloss: 0.480047\n",
      "[900]\ttraining's binary_logloss: 0.441418\tvalid_1's binary_logloss: 0.479899\n",
      "[1000]\ttraining's binary_logloss: 0.440717\tvalid_1's binary_logloss: 0.479663\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.440717\tvalid_1's binary_logloss: 0.479663\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1100]\ttraining's binary_logloss: 0.440647\tvalid_1's binary_logloss: 0.47966\n",
      "[1200]\ttraining's binary_logloss: 0.440581\tvalid_1's binary_logloss: 0.479645\n",
      "[1300]\ttraining's binary_logloss: 0.440517\tvalid_1's binary_logloss: 0.479638\n",
      "[1400]\ttraining's binary_logloss: 0.440453\tvalid_1's binary_logloss: 0.479631\n",
      "[1500]\ttraining's binary_logloss: 0.440389\tvalid_1's binary_logloss: 0.479621\n",
      "[1600]\ttraining's binary_logloss: 0.440325\tvalid_1's binary_logloss: 0.479609\n",
      "[1700]\ttraining's binary_logloss: 0.440265\tvalid_1's binary_logloss: 0.479603\n",
      "[1800]\ttraining's binary_logloss: 0.440203\tvalid_1's binary_logloss: 0.479599\n",
      "[1900]\ttraining's binary_logloss: 0.440142\tvalid_1's binary_logloss: 0.479597\n",
      "[2000]\ttraining's binary_logloss: 0.440083\tvalid_1's binary_logloss: 0.479578\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's binary_logloss: 0.440083\tvalid_1's binary_logloss: 0.479578\n",
      "===== ACCURACY SCORE 0.781587 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.509856\tvalid_1's binary_logloss: 0.530598\n",
      "[200]\ttraining's binary_logloss: 0.469454\tvalid_1's binary_logloss: 0.499223\n",
      "[300]\ttraining's binary_logloss: 0.45579\tvalid_1's binary_logloss: 0.493481\n",
      "[400]\ttraining's binary_logloss: 0.449796\tvalid_1's binary_logloss: 0.493018\n",
      "Early stopping, best iteration is:\n",
      "[371]\ttraining's binary_logloss: 0.451113\tvalid_1's binary_logloss: 0.49296\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.450963\tvalid_1's binary_logloss: 0.492949\n",
      "Early stopping, best iteration is:\n",
      "[384]\ttraining's binary_logloss: 0.451044\tvalid_1's binary_logloss: 0.492947\n",
      "===== ACCURACY SCORE 0.777844 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779110 =====\n"
     ]
    }
   ],
   "source": [
    "lgb_full_preds = []\n",
    "for SEED in range(N_ITERS):\n",
    "    lgb_oof = np.zeros(train_df.shape[0])\n",
    "    lgb_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importances = pd.DataFrame()\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(all_df, all_df[TARGET])):\n",
    "        print(f\"===== FOLD {fold} =====\")\n",
    "        oof_idx = np.array([idx for idx in valid_idx if idx < train_df.shape[0]])\n",
    "        preds_idx = np.array([idx for idx in valid_idx if idx >= train_df.shape[0]])\n",
    "\n",
    "        X_train, y_train = all_df.iloc[train_idx].drop(TARGET, axis=1), all_df.iloc[train_idx][TARGET]\n",
    "        X_train = apply_noise(X_train)\n",
    "        X_valid, y_valid = all_df.iloc[oof_idx].drop(TARGET, axis=1), all_df.iloc[oof_idx][TARGET]\n",
    "        X_test = all_df.iloc[preds_idx].drop(TARGET, axis=1)\n",
    "\n",
    "        pre_model = lgb.LGBMRegressor(**params)\n",
    "        pre_model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train),(X_valid, y_valid)],\n",
    "            early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "            verbose=VERBOSE\n",
    "        )\n",
    "\n",
    "        params2 = params.copy()\n",
    "        params2['learning_rate'] = params['learning_rate'] * 0.1\n",
    "        model = lgb.LGBMRegressor(**params2)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train),(X_valid, y_valid)],\n",
    "            early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "            verbose=VERBOSE,\n",
    "            init_model=pre_model\n",
    "        )\n",
    "\n",
    "        fi_tmp = pd.DataFrame()\n",
    "        fi_tmp[\"feature\"] = model.feature_name_\n",
    "        fi_tmp[\"importance\"] = model.feature_importances_\n",
    "        fi_tmp[\"fold\"] = fold\n",
    "        fi_tmp[\"seed\"] = SEED\n",
    "        feature_importances = feature_importances.append(fi_tmp)\n",
    "\n",
    "        lgb_oof[oof_idx] = model.predict(X_valid)\n",
    "        lgb_preds[preds_idx-train_df.shape[0]] = model.predict(X_test)\n",
    "\n",
    "        acc_score = accuracy_score(y_valid, np.where(lgb_oof[oof_idx]>0.5, 1, 0))\n",
    "        print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\\n\")\n",
    "\n",
    "    acc_score = accuracy_score(all_df[:train_df.shape[0]][TARGET], np.where(lgb_oof>0.5, 1, 0))\n",
    "    print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\")\n",
    "    lgb_full_preds.append(lgb_preds)\n",
    "lgb_full_preds = np.stack(lgb_full_preds, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T06:53:55.912277Z",
     "start_time": "2021-04-05T06:53:55.664403Z"
    },
    "_cell_guid": "cc478b5a-29c0-4f5e-8cec-e4d67ddac008",
    "_uuid": "fe9b90d5-c826-4870-9560-43b4fd9631f9",
    "execution": {
     "iopub.execute_input": "2023-03-24T09:39:41.216953Z",
     "iopub.status.busy": "2023-03-24T09:39:41.216619Z",
     "iopub.status.idle": "2023-03-24T09:39:42.051938Z",
     "shell.execute_reply": "2023-03-24T09:39:42.051079Z",
     "shell.execute_reply.started": "2023-03-24T09:39:41.216923Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# just to get ideas to improve\n",
    "order = list(feature_importances.groupby(\"feature\").mean().sort_values(\"importance\", ascending=False).index)\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=feature_importances, order=order)\n",
    "plt.title(\"{} importance\".format(\"LGBMRegressor\"))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T09:39:56.464938Z",
     "iopub.status.busy": "2023-03-24T09:39:56.464609Z",
     "iopub.status.idle": "2023-03-24T09:39:56.471917Z",
     "shell.execute_reply": "2023-03-24T09:39:56.470982Z",
     "shell.execute_reply.started": "2023-03-24T09:39:56.464908Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'bootstrap_type': 'Poisson',\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'Logloss',\n",
    "    'random_seed': SEED,\n",
    "    'task_type': 'GPU',\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.01,\n",
    "    'n_estimators': N_ESTIMATORS,\n",
    "    'max_bin': 280,\n",
    "    'min_data_in_leaf': 64,\n",
    "    'l2_leaf_reg': 0.01,\n",
    "    'subsample': 0.8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T09:40:09.073983Z",
     "iopub.status.busy": "2023-03-24T09:40:09.073659Z",
     "iopub.status.idle": "2023-03-24T10:40:48.916994Z",
     "shell.execute_reply": "2023-03-24T10:40:48.916218Z",
     "shell.execute_reply.started": "2023-03-24T09:40:09.073951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6878762\ttest: 0.6881359\tbest: 0.6881359 (0)\ttotal: 26.6ms\tremaining: 26.5s\n",
      "100:\tlearn: 0.4830511\ttest: 0.5064645\tbest: 0.5064645 (100)\ttotal: 1.57s\tremaining: 14s\n",
      "200:\tlearn: 0.4547739\ttest: 0.4925269\tbest: 0.4925269 (200)\ttotal: 3.4s\tremaining: 13.5s\n",
      "300:\tlearn: 0.4468870\ttest: 0.4915453\tbest: 0.4915160 (293)\ttotal: 4.88s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4428716\ttest: 0.4919337\tbest: 0.4915130 (307)\ttotal: 6.39s\tremaining: 9.55s\n",
      "bestTest = 0.4915130015\n",
      "bestIteration = 307\n",
      "Shrink model to first 308 iterations.\n",
      "===== ACCURACY SCORE 0.775492 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6878566\ttest: 0.6881792\tbest: 0.6881792 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4834072\ttest: 0.5071738\tbest: 0.5071738 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4554784\ttest: 0.4925115\tbest: 0.4925115 (200)\ttotal: 2.94s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4476588\ttest: 0.4913804\tbest: 0.4913804 (300)\ttotal: 4.4s\tremaining: 10.2s\n",
      "400:\tlearn: 0.4437202\ttest: 0.4912121\tbest: 0.4911785 (375)\ttotal: 6.09s\tremaining: 9.1s\n",
      "500:\tlearn: 0.4409495\ttest: 0.4910609\tbest: 0.4910595 (498)\ttotal: 7.7s\tremaining: 7.67s\n",
      "600:\tlearn: 0.4388294\ttest: 0.4909361\tbest: 0.4909171 (550)\ttotal: 10s\tremaining: 6.66s\n",
      "700:\tlearn: 0.4369021\ttest: 0.4907890\tbest: 0.4907518 (669)\ttotal: 11.5s\tremaining: 4.9s\n",
      "bestTest = 0.4907518496\n",
      "bestIteration = 669\n",
      "Shrink model to first 670 iterations.\n",
      "===== ACCURACY SCORE 0.776845 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6879391\ttest: 0.6881245\tbest: 0.6881245 (0)\ttotal: 14.2ms\tremaining: 14.2s\n",
      "100:\tlearn: 0.4843577\ttest: 0.5015778\tbest: 0.5015778 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4562475\ttest: 0.4846629\tbest: 0.4846629 (200)\ttotal: 3.06s\tremaining: 12.2s\n",
      "300:\tlearn: 0.4485176\ttest: 0.4827072\tbest: 0.4827004 (299)\ttotal: 4.83s\tremaining: 11.2s\n",
      "400:\tlearn: 0.4444809\ttest: 0.4825028\tbest: 0.4825028 (400)\ttotal: 6.29s\tremaining: 9.4s\n",
      "500:\tlearn: 0.4417380\ttest: 0.4824407\tbest: 0.4823492 (453)\ttotal: 7.81s\tremaining: 7.78s\n",
      "600:\tlearn: 0.4396193\ttest: 0.4822735\tbest: 0.4822516 (539)\ttotal: 9.37s\tremaining: 6.22s\n",
      "700:\tlearn: 0.4378247\ttest: 0.4821109\tbest: 0.4820948 (683)\ttotal: 10.8s\tremaining: 4.62s\n",
      "800:\tlearn: 0.4362214\ttest: 0.4821522\tbest: 0.4820920 (758)\ttotal: 12.3s\tremaining: 3.06s\n",
      "bestTest = 0.4820920462\n",
      "bestIteration = 758\n",
      "Shrink model to first 759 iterations.\n",
      "===== ACCURACY SCORE 0.779465 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6878869\ttest: 0.6881434\tbest: 0.6881434 (0)\ttotal: 53.5ms\tremaining: 53.5s\n",
      "100:\tlearn: 0.4842220\ttest: 0.5060511\tbest: 0.5060511 (100)\ttotal: 1.76s\tremaining: 15.7s\n",
      "200:\tlearn: 0.4562207\ttest: 0.4904957\tbest: 0.4904957 (200)\ttotal: 3.23s\tremaining: 12.8s\n",
      "300:\tlearn: 0.4482744\ttest: 0.4889607\tbest: 0.4889607 (300)\ttotal: 4.68s\tremaining: 10.9s\n",
      "400:\tlearn: 0.4443020\ttest: 0.4887529\tbest: 0.4887148 (390)\ttotal: 6.15s\tremaining: 9.18s\n",
      "500:\tlearn: 0.4416922\ttest: 0.4887082\tbest: 0.4886897 (416)\ttotal: 7.62s\tremaining: 7.59s\n",
      "bestTest = 0.4886897146\n",
      "bestIteration = 416\n",
      "Shrink model to first 417 iterations.\n",
      "===== ACCURACY SCORE 0.776079 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6879200\ttest: 0.6880735\tbest: 0.6880735 (0)\ttotal: 16ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4848487\ttest: 0.4976859\tbest: 0.4976859 (100)\ttotal: 1.59s\tremaining: 14.2s\n",
      "200:\tlearn: 0.4570902\ttest: 0.4793717\tbest: 0.4793717 (200)\ttotal: 3.37s\tremaining: 13.4s\n",
      "300:\tlearn: 0.4492321\ttest: 0.4769809\tbest: 0.4769791 (299)\ttotal: 5.62s\tremaining: 13.1s\n",
      "400:\tlearn: 0.4452813\ttest: 0.4763363\tbest: 0.4763363 (400)\ttotal: 7.08s\tremaining: 10.6s\n",
      "500:\tlearn: 0.4426126\ttest: 0.4757848\tbest: 0.4757846 (499)\ttotal: 8.54s\tremaining: 8.5s\n",
      "600:\tlearn: 0.4404647\ttest: 0.4756948\tbest: 0.4756948 (600)\ttotal: 10s\tremaining: 6.64s\n",
      "700:\tlearn: 0.4385753\ttest: 0.4754766\tbest: 0.4754542 (697)\ttotal: 11.5s\tremaining: 4.9s\n",
      "800:\tlearn: 0.4369269\ttest: 0.4753868\tbest: 0.4753833 (799)\ttotal: 13.1s\tremaining: 3.25s\n",
      "900:\tlearn: 0.4353879\ttest: 0.4753931\tbest: 0.4753423 (879)\ttotal: 14.8s\tremaining: 1.62s\n",
      "bestTest = 0.4753423345\n",
      "bestIteration = 879\n",
      "Shrink model to first 880 iterations.\n",
      "===== ACCURACY SCORE 0.790090 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6879396\ttest: 0.6882067\tbest: 0.6882067 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4850739\ttest: 0.5069253\tbest: 0.5069253 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4569148\ttest: 0.4917710\tbest: 0.4917710 (200)\ttotal: 2.98s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4490715\ttest: 0.4904621\tbest: 0.4904621 (300)\ttotal: 4.45s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4451444\ttest: 0.4903448\tbest: 0.4902599 (370)\ttotal: 5.97s\tremaining: 8.92s\n",
      "500:\tlearn: 0.4425607\ttest: 0.4903080\tbest: 0.4902251 (446)\ttotal: 7.77s\tremaining: 7.74s\n",
      "bestTest = 0.4902251365\n",
      "bestIteration = 446\n",
      "Shrink model to first 447 iterations.\n",
      "===== ACCURACY SCORE 0.777435 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6878849\ttest: 0.6881019\tbest: 0.6881019 (0)\ttotal: 16.5ms\tremaining: 16.5s\n",
      "100:\tlearn: 0.4837404\ttest: 0.5052827\tbest: 0.5052827 (100)\ttotal: 1.47s\tremaining: 13.1s\n",
      "200:\tlearn: 0.4555452\ttest: 0.4901337\tbest: 0.4901337 (200)\ttotal: 2.95s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4477044\ttest: 0.4886649\tbest: 0.4886508 (299)\ttotal: 4.42s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4436387\ttest: 0.4886082\tbest: 0.4885316 (328)\ttotal: 5.91s\tremaining: 8.82s\n",
      "bestTest = 0.4885315606\n",
      "bestIteration = 328\n",
      "Shrink model to first 329 iterations.\n",
      "===== ACCURACY SCORE 0.779343 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6879232\ttest: 0.6881813\tbest: 0.6881813 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4851557\ttest: 0.5026452\tbest: 0.5026452 (100)\ttotal: 1.82s\tremaining: 16.2s\n",
      "200:\tlearn: 0.4570581\ttest: 0.4855916\tbest: 0.4855916 (200)\ttotal: 4.04s\tremaining: 16.1s\n",
      "300:\tlearn: 0.4492786\ttest: 0.4835593\tbest: 0.4835593 (300)\ttotal: 5.51s\tremaining: 12.8s\n",
      "400:\tlearn: 0.4453015\ttest: 0.4830686\tbest: 0.4830649 (399)\ttotal: 6.96s\tremaining: 10.4s\n",
      "500:\tlearn: 0.4425507\ttest: 0.4828282\tbest: 0.4828110 (496)\ttotal: 8.43s\tremaining: 8.39s\n",
      "600:\tlearn: 0.4404385\ttest: 0.4826599\tbest: 0.4826573 (593)\ttotal: 9.9s\tremaining: 6.57s\n",
      "700:\tlearn: 0.4385651\ttest: 0.4826184\tbest: 0.4825464 (677)\ttotal: 11.4s\tremaining: 4.86s\n",
      "bestTest = 0.4825463901\n",
      "bestIteration = 677\n",
      "Shrink model to first 678 iterations.\n",
      "===== ACCURACY SCORE 0.781876 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6879207\ttest: 0.6881968\tbest: 0.6881968 (0)\ttotal: 16.4ms\tremaining: 16.4s\n",
      "100:\tlearn: 0.4851037\ttest: 0.5059241\tbest: 0.5059241 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4571388\ttest: 0.4897870\tbest: 0.4897870 (200)\ttotal: 2.94s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4494174\ttest: 0.4880690\tbest: 0.4880660 (299)\ttotal: 4.41s\tremaining: 10.2s\n",
      "400:\tlearn: 0.4455201\ttest: 0.4876820\tbest: 0.4876809 (399)\ttotal: 5.87s\tremaining: 8.77s\n",
      "500:\tlearn: 0.4428670\ttest: 0.4875828\tbest: 0.4875739 (497)\ttotal: 7.32s\tremaining: 7.29s\n",
      "600:\tlearn: 0.4408088\ttest: 0.4872844\tbest: 0.4872844 (600)\ttotal: 8.88s\tremaining: 5.89s\n",
      "700:\tlearn: 0.4389568\ttest: 0.4870853\tbest: 0.4870853 (700)\ttotal: 10.6s\tremaining: 4.52s\n",
      "800:\tlearn: 0.4372466\ttest: 0.4869948\tbest: 0.4869835 (790)\ttotal: 12.1s\tremaining: 3s\n",
      "900:\tlearn: 0.4357614\ttest: 0.4868466\tbest: 0.4868249 (893)\ttotal: 13.5s\tremaining: 1.49s\n",
      "999:\tlearn: 0.4343870\ttest: 0.4868022\tbest: 0.4867708 (972)\ttotal: 15s\tremaining: 0us\n",
      "bestTest = 0.4867708229\n",
      "bestIteration = 972\n",
      "Shrink model to first 973 iterations.\n",
      "===== ACCURACY SCORE 0.780466 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6878717\ttest: 0.6881823\tbest: 0.6881823 (0)\ttotal: 16.6ms\tremaining: 16.6s\n",
      "100:\tlearn: 0.4832943\ttest: 0.5079123\tbest: 0.5079123 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4552221\ttest: 0.4939593\tbest: 0.4939593 (200)\ttotal: 2.98s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4472973\ttest: 0.4930866\tbest: 0.4930866 (300)\ttotal: 5.56s\tremaining: 12.9s\n",
      "400:\tlearn: 0.4432485\ttest: 0.4930685\tbest: 0.4930298 (389)\ttotal: 7.02s\tremaining: 10.5s\n",
      "500:\tlearn: 0.4405053\ttest: 0.4928705\tbest: 0.4928628 (461)\ttotal: 8.5s\tremaining: 8.46s\n",
      "600:\tlearn: 0.4383331\ttest: 0.4928418\tbest: 0.4927822 (554)\ttotal: 9.95s\tremaining: 6.61s\n",
      "700:\tlearn: 0.4364697\ttest: 0.4925923\tbest: 0.4925899 (675)\ttotal: 11.4s\tremaining: 4.87s\n",
      "800:\tlearn: 0.4348232\ttest: 0.4924385\tbest: 0.4924122 (787)\ttotal: 12.9s\tremaining: 3.2s\n",
      "900:\tlearn: 0.4333217\ttest: 0.4923867\tbest: 0.4923867 (900)\ttotal: 14.4s\tremaining: 1.59s\n",
      "999:\tlearn: 0.4319923\ttest: 0.4921517\tbest: 0.4921509 (996)\ttotal: 16.3s\tremaining: 0us\n",
      "bestTest = 0.49215094\n",
      "bestIteration = 996\n",
      "Shrink model to first 997 iterations.\n",
      "===== ACCURACY SCORE 0.775275 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779240 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6878908\ttest: 0.6881826\tbest: 0.6881826 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4846520\ttest: 0.5034488\tbest: 0.5034488 (100)\ttotal: 1.54s\tremaining: 13.7s\n",
      "200:\tlearn: 0.4568057\ttest: 0.4868487\tbest: 0.4868487 (200)\ttotal: 3.01s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4491391\ttest: 0.4849307\tbest: 0.4849307 (300)\ttotal: 4.48s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4452287\ttest: 0.4842552\tbest: 0.4842346 (399)\ttotal: 5.95s\tremaining: 8.89s\n",
      "500:\tlearn: 0.4425571\ttest: 0.4840140\tbest: 0.4839534 (474)\ttotal: 7.43s\tremaining: 7.41s\n",
      "600:\tlearn: 0.4403912\ttest: 0.4840273\tbest: 0.4839227 (534)\ttotal: 9.15s\tremaining: 6.07s\n",
      "bestTest = 0.4839227247\n",
      "bestIteration = 534\n",
      "Shrink model to first 535 iterations.\n",
      "===== ACCURACY SCORE 0.782186 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6878907\ttest: 0.6880729\tbest: 0.6880729 (0)\ttotal: 16.9ms\tremaining: 16.9s\n",
      "100:\tlearn: 0.4841166\ttest: 0.5006542\tbest: 0.5006542 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4561729\ttest: 0.4837035\tbest: 0.4837035 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4484329\ttest: 0.4818923\tbest: 0.4818923 (300)\ttotal: 4.41s\tremaining: 10.2s\n",
      "400:\tlearn: 0.4445130\ttest: 0.4813817\tbest: 0.4813817 (400)\ttotal: 5.88s\tremaining: 8.78s\n",
      "500:\tlearn: 0.4418477\ttest: 0.4808823\tbest: 0.4808745 (495)\ttotal: 7.58s\tremaining: 7.55s\n",
      "600:\tlearn: 0.4397268\ttest: 0.4807450\tbest: 0.4807240 (573)\ttotal: 9.97s\tremaining: 6.62s\n",
      "700:\tlearn: 0.4379079\ttest: 0.4805422\tbest: 0.4805391 (687)\ttotal: 11.4s\tremaining: 4.88s\n",
      "800:\tlearn: 0.4362987\ttest: 0.4804419\tbest: 0.4803983 (763)\ttotal: 12.9s\tremaining: 3.2s\n",
      "bestTest = 0.4803983192\n",
      "bestIteration = 763\n",
      "Shrink model to first 764 iterations.\n",
      "===== ACCURACY SCORE 0.785813 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6878756\ttest: 0.6882451\tbest: 0.6882451 (0)\ttotal: 15.6ms\tremaining: 15.6s\n",
      "100:\tlearn: 0.4834982\ttest: 0.5110141\tbest: 0.5110141 (100)\ttotal: 1.51s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4553333\ttest: 0.4976156\tbest: 0.4976156 (200)\ttotal: 2.99s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4473949\ttest: 0.4970250\tbest: 0.4969369 (265)\ttotal: 4.5s\tremaining: 10.4s\n",
      "bestTest = 0.4969369106\n",
      "bestIteration = 265\n",
      "Shrink model to first 266 iterations.\n",
      "===== ACCURACY SCORE 0.773606 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6878737\ttest: 0.6881917\tbest: 0.6881917 (0)\ttotal: 16.6ms\tremaining: 16.6s\n",
      "100:\tlearn: 0.4831093\ttest: 0.5058362\tbest: 0.5058362 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4548020\ttest: 0.4900388\tbest: 0.4900388 (200)\ttotal: 2.95s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4468183\ttest: 0.4883855\tbest: 0.4883855 (300)\ttotal: 4.41s\tremaining: 10.2s\n",
      "400:\tlearn: 0.4428250\ttest: 0.4882132\tbest: 0.4881953 (390)\ttotal: 5.88s\tremaining: 8.79s\n",
      "500:\tlearn: 0.4401433\ttest: 0.4883824\tbest: 0.4881688 (419)\ttotal: 7.35s\tremaining: 7.32s\n",
      "bestTest = 0.488168773\n",
      "bestIteration = 419\n",
      "Shrink model to first 420 iterations.\n",
      "===== ACCURACY SCORE 0.777767 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6879539\ttest: 0.6881032\tbest: 0.6881032 (0)\ttotal: 14.3ms\tremaining: 14.3s\n",
      "100:\tlearn: 0.4845765\ttest: 0.4984453\tbest: 0.4984453 (100)\ttotal: 1.87s\tremaining: 16.6s\n",
      "200:\tlearn: 0.4566102\ttest: 0.4802947\tbest: 0.4802947 (200)\ttotal: 3.33s\tremaining: 13.2s\n",
      "300:\tlearn: 0.4487333\ttest: 0.4778670\tbest: 0.4778670 (300)\ttotal: 4.79s\tremaining: 11.1s\n",
      "400:\tlearn: 0.4447584\ttest: 0.4774229\tbest: 0.4774229 (400)\ttotal: 6.24s\tremaining: 9.31s\n",
      "500:\tlearn: 0.4420169\ttest: 0.4771079\tbest: 0.4770939 (479)\ttotal: 7.69s\tremaining: 7.66s\n",
      "600:\tlearn: 0.4398936\ttest: 0.4767889\tbest: 0.4767792 (578)\ttotal: 9.61s\tremaining: 6.38s\n",
      "700:\tlearn: 0.4380721\ttest: 0.4765735\tbest: 0.4765735 (700)\ttotal: 11.8s\tremaining: 5.03s\n",
      "800:\tlearn: 0.4364770\ttest: 0.4762562\tbest: 0.4762562 (800)\ttotal: 13.6s\tremaining: 3.38s\n",
      "900:\tlearn: 0.4349924\ttest: 0.4761370\tbest: 0.4761347 (894)\ttotal: 15s\tremaining: 1.65s\n",
      "999:\tlearn: 0.4335922\ttest: 0.4759271\tbest: 0.4759150 (993)\ttotal: 16.5s\tremaining: 0us\n",
      "bestTest = 0.4759150062\n",
      "bestIteration = 993\n",
      "Shrink model to first 994 iterations.\n",
      "===== ACCURACY SCORE 0.784337 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6879612\ttest: 0.6881490\tbest: 0.6881490 (0)\ttotal: 15.6ms\tremaining: 15.6s\n",
      "100:\tlearn: 0.4862817\ttest: 0.5029259\tbest: 0.5029259 (100)\ttotal: 1.47s\tremaining: 13.1s\n",
      "200:\tlearn: 0.4580221\ttest: 0.4864073\tbest: 0.4864073 (200)\ttotal: 3s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4500139\ttest: 0.4848488\tbest: 0.4848488 (300)\ttotal: 4.51s\tremaining: 10.5s\n",
      "400:\tlearn: 0.4459421\ttest: 0.4848014\tbest: 0.4846770 (340)\ttotal: 6.29s\tremaining: 9.4s\n",
      "bestTest = 0.4846770347\n",
      "bestIteration = 340\n",
      "Shrink model to first 341 iterations.\n",
      "===== ACCURACY SCORE 0.777756 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6878002\ttest: 0.6880394\tbest: 0.6880394 (0)\ttotal: 16ms\tremaining: 16s\n",
      "100:\tlearn: 0.4830879\ttest: 0.5108432\tbest: 0.5108432 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4548497\ttest: 0.4982683\tbest: 0.4982608 (198)\ttotal: 2.94s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4468503\ttest: 0.4979163\tbest: 0.4977325 (245)\ttotal: 4.41s\tremaining: 10.2s\n",
      "bestTest = 0.4977324995\n",
      "bestIteration = 245\n",
      "Shrink model to first 246 iterations.\n",
      "===== ACCURACY SCORE 0.773508 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878999\ttest: 0.6880961\tbest: 0.6880961 (0)\ttotal: 16.1ms\tremaining: 16s\n",
      "100:\tlearn: 0.4843428\ttest: 0.5034964\tbest: 0.5034964 (100)\ttotal: 1.55s\tremaining: 13.8s\n",
      "200:\tlearn: 0.4563161\ttest: 0.4880040\tbest: 0.4880040 (200)\ttotal: 3.28s\tremaining: 13.1s\n",
      "300:\tlearn: 0.4484519\ttest: 0.4861890\tbest: 0.4861860 (299)\ttotal: 4.74s\tremaining: 11s\n",
      "400:\tlearn: 0.4445141\ttest: 0.4857494\tbest: 0.4856949 (386)\ttotal: 6.19s\tremaining: 9.24s\n",
      "500:\tlearn: 0.4418469\ttest: 0.4855715\tbest: 0.4855715 (500)\ttotal: 7.64s\tremaining: 7.61s\n",
      "600:\tlearn: 0.4397014\ttest: 0.4854652\tbest: 0.4854652 (600)\ttotal: 9.12s\tremaining: 6.05s\n",
      "700:\tlearn: 0.4379269\ttest: 0.4855201\tbest: 0.4854652 (600)\ttotal: 11.6s\tremaining: 4.97s\n",
      "bestTest = 0.485465155\n",
      "bestIteration = 600\n",
      "Shrink model to first 601 iterations.\n",
      "===== ACCURACY SCORE 0.778904 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6879253\ttest: 0.6881487\tbest: 0.6881487 (0)\ttotal: 38.7ms\tremaining: 38.6s\n",
      "100:\tlearn: 0.4850190\ttest: 0.5041298\tbest: 0.5041298 (100)\ttotal: 1.77s\tremaining: 15.8s\n",
      "200:\tlearn: 0.4568661\ttest: 0.4877176\tbest: 0.4877176 (200)\ttotal: 3.25s\tremaining: 12.9s\n",
      "300:\tlearn: 0.4489769\ttest: 0.4854107\tbest: 0.4854107 (300)\ttotal: 4.71s\tremaining: 10.9s\n",
      "400:\tlearn: 0.4449137\ttest: 0.4844797\tbest: 0.4844796 (399)\ttotal: 6.19s\tremaining: 9.24s\n",
      "500:\tlearn: 0.4421127\ttest: 0.4841483\tbest: 0.4841363 (491)\ttotal: 7.66s\tremaining: 7.63s\n",
      "600:\tlearn: 0.4399438\ttest: 0.4840862\tbest: 0.4840810 (593)\ttotal: 9.13s\tremaining: 6.06s\n",
      "700:\tlearn: 0.4381517\ttest: 0.4838950\tbest: 0.4838872 (698)\ttotal: 10.6s\tremaining: 4.54s\n",
      "800:\tlearn: 0.4364914\ttest: 0.4838093\tbest: 0.4838093 (800)\ttotal: 12.4s\tremaining: 3.08s\n",
      "900:\tlearn: 0.4349901\ttest: 0.4837491\tbest: 0.4837033 (870)\ttotal: 13.9s\tremaining: 1.53s\n",
      "999:\tlearn: 0.4336105\ttest: 0.4836957\tbest: 0.4836500 (952)\ttotal: 15.4s\tremaining: 0us\n",
      "bestTest = 0.4836499557\n",
      "bestIteration = 952\n",
      "Shrink model to first 953 iterations.\n",
      "===== ACCURACY SCORE 0.781390 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6878668\ttest: 0.6881787\tbest: 0.6881787 (0)\ttotal: 16.6ms\tremaining: 16.6s\n",
      "100:\tlearn: 0.4838087\ttest: 0.5072357\tbest: 0.5072357 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4556384\ttest: 0.4929149\tbest: 0.4929149 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4477126\ttest: 0.4921428\tbest: 0.4920307 (264)\ttotal: 4.44s\tremaining: 10.3s\n",
      "bestTest = 0.4920307309\n",
      "bestIteration = 264\n",
      "Shrink model to first 265 iterations.\n",
      "===== ACCURACY SCORE 0.773521 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778880 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6878408\ttest: 0.6881450\tbest: 0.6881450 (0)\ttotal: 20ms\tremaining: 20s\n",
      "100:\tlearn: 0.4822444\ttest: 0.5042096\tbest: 0.5042096 (100)\ttotal: 1.66s\tremaining: 14.8s\n",
      "200:\tlearn: 0.4542194\ttest: 0.4880142\tbest: 0.4880142 (200)\ttotal: 3.14s\tremaining: 12.5s\n",
      "300:\tlearn: 0.4463171\ttest: 0.4862603\tbest: 0.4862577 (299)\ttotal: 4.61s\tremaining: 10.7s\n",
      "400:\tlearn: 0.4423625\ttest: 0.4858260\tbest: 0.4858040 (394)\ttotal: 6.85s\tremaining: 10.2s\n",
      "500:\tlearn: 0.4396746\ttest: 0.4855594\tbest: 0.4855594 (500)\ttotal: 8.4s\tremaining: 8.37s\n",
      "600:\tlearn: 0.4375977\ttest: 0.4853127\tbest: 0.4853042 (597)\ttotal: 9.93s\tremaining: 6.59s\n",
      "700:\tlearn: 0.4358090\ttest: 0.4851326\tbest: 0.4851263 (696)\ttotal: 11.8s\tremaining: 5.02s\n",
      "800:\tlearn: 0.4342249\ttest: 0.4850118\tbest: 0.4850118 (794)\ttotal: 13.3s\tremaining: 3.31s\n",
      "900:\tlearn: 0.4327053\ttest: 0.4849606\tbest: 0.4849407 (893)\ttotal: 14.8s\tremaining: 1.62s\n",
      "999:\tlearn: 0.4313401\ttest: 0.4849072\tbest: 0.4849072 (999)\ttotal: 16.2s\tremaining: 0us\n",
      "bestTest = 0.4849072236\n",
      "bestIteration = 999\n",
      "===== ACCURACY SCORE 0.781642 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6878819\ttest: 0.6881743\tbest: 0.6881743 (0)\ttotal: 15.8ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4845462\ttest: 0.5036342\tbest: 0.5036342 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4564127\ttest: 0.4867329\tbest: 0.4867329 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4485198\ttest: 0.4847607\tbest: 0.4847607 (300)\ttotal: 4.67s\tremaining: 10.8s\n",
      "400:\tlearn: 0.4443973\ttest: 0.4845382\tbest: 0.4844742 (390)\ttotal: 6.26s\tremaining: 9.35s\n",
      "500:\tlearn: 0.4416428\ttest: 0.4845011\tbest: 0.4844165 (431)\ttotal: 7.73s\tremaining: 7.7s\n",
      "bestTest = 0.4844165352\n",
      "bestIteration = 431\n",
      "Shrink model to first 432 iterations.\n",
      "===== ACCURACY SCORE 0.776806 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6879144\ttest: 0.6882581\tbest: 0.6882581 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4843373\ttest: 0.5105007\tbest: 0.5105007 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4561789\ttest: 0.4961175\tbest: 0.4961175 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4482882\ttest: 0.4949902\tbest: 0.4949902 (300)\ttotal: 4.42s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4442697\ttest: 0.4946445\tbest: 0.4946439 (398)\ttotal: 5.99s\tremaining: 8.95s\n",
      "500:\tlearn: 0.4415609\ttest: 0.4945686\tbest: 0.4944581 (477)\ttotal: 7.76s\tremaining: 7.73s\n",
      "600:\tlearn: 0.4394141\ttest: 0.4944157\tbest: 0.4944157 (600)\ttotal: 9.22s\tremaining: 6.12s\n",
      "700:\tlearn: 0.4375657\ttest: 0.4942879\tbest: 0.4942694 (649)\ttotal: 10.7s\tremaining: 4.56s\n",
      "800:\tlearn: 0.4359626\ttest: 0.4941456\tbest: 0.4941456 (800)\ttotal: 13s\tremaining: 3.22s\n",
      "900:\tlearn: 0.4344591\ttest: 0.4939431\tbest: 0.4939420 (896)\ttotal: 14.4s\tremaining: 1.58s\n",
      "999:\tlearn: 0.4330733\ttest: 0.4937287\tbest: 0.4937251 (998)\ttotal: 15.9s\tremaining: 0us\n",
      "bestTest = 0.4937250937\n",
      "bestIteration = 998\n",
      "Shrink model to first 999 iterations.\n",
      "===== ACCURACY SCORE 0.772782 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6879329\ttest: 0.6882825\tbest: 0.6882825 (0)\ttotal: 17.1ms\tremaining: 17.1s\n",
      "100:\tlearn: 0.4852090\ttest: 0.5105782\tbest: 0.5105782 (100)\ttotal: 1.8s\tremaining: 16s\n",
      "200:\tlearn: 0.4571851\ttest: 0.4964249\tbest: 0.4964249 (200)\ttotal: 3.26s\tremaining: 13s\n",
      "300:\tlearn: 0.4493472\ttest: 0.4954028\tbest: 0.4953710 (286)\ttotal: 4.73s\tremaining: 11s\n",
      "400:\tlearn: 0.4453569\ttest: 0.4953876\tbest: 0.4952789 (355)\ttotal: 6.21s\tremaining: 9.28s\n",
      "bestTest = 0.4952788968\n",
      "bestIteration = 355\n",
      "Shrink model to first 356 iterations.\n",
      "===== ACCURACY SCORE 0.774470 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6879376\ttest: 0.6881284\tbest: 0.6881284 (0)\ttotal: 14ms\tremaining: 14s\n",
      "100:\tlearn: 0.4846592\ttest: 0.5045337\tbest: 0.5045337 (100)\ttotal: 1.52s\tremaining: 13.6s\n",
      "200:\tlearn: 0.4568299\ttest: 0.4897511\tbest: 0.4897511 (200)\ttotal: 3.07s\tremaining: 12.2s\n",
      "300:\tlearn: 0.4490805\ttest: 0.4890473\tbest: 0.4890473 (300)\ttotal: 4.76s\tremaining: 11s\n",
      "400:\tlearn: 0.4450854\ttest: 0.4893471\tbest: 0.4890290 (302)\ttotal: 6.22s\tremaining: 9.29s\n",
      "bestTest = 0.48902903\n",
      "bestIteration = 302\n",
      "Shrink model to first 303 iterations.\n",
      "===== ACCURACY SCORE 0.779333 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6879046\ttest: 0.6880697\tbest: 0.6880697 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4838882\ttest: 0.5016887\tbest: 0.5016887 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4556965\ttest: 0.4854891\tbest: 0.4854891 (200)\ttotal: 2.98s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4478437\ttest: 0.4836445\tbest: 0.4836445 (300)\ttotal: 4.47s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4438551\ttest: 0.4829695\tbest: 0.4829690 (399)\ttotal: 6s\tremaining: 8.96s\n",
      "500:\tlearn: 0.4410831\ttest: 0.4824379\tbest: 0.4824203 (495)\ttotal: 7.79s\tremaining: 7.76s\n",
      "600:\tlearn: 0.4389685\ttest: 0.4820374\tbest: 0.4820286 (599)\ttotal: 9.25s\tremaining: 6.14s\n",
      "700:\tlearn: 0.4372020\ttest: 0.4817196\tbest: 0.4817196 (685)\ttotal: 11.2s\tremaining: 4.77s\n",
      "800:\tlearn: 0.4355480\ttest: 0.4813583\tbest: 0.4813583 (800)\ttotal: 13.1s\tremaining: 3.25s\n",
      "900:\tlearn: 0.4340369\ttest: 0.4810252\tbest: 0.4810252 (900)\ttotal: 14.6s\tremaining: 1.6s\n",
      "999:\tlearn: 0.4326574\ttest: 0.4808817\tbest: 0.4808655 (970)\ttotal: 16s\tremaining: 0us\n",
      "bestTest = 0.4808654937\n",
      "bestIteration = 970\n",
      "Shrink model to first 971 iterations.\n",
      "===== ACCURACY SCORE 0.781650 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6878974\ttest: 0.6881190\tbest: 0.6881190 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4845265\ttest: 0.5039400\tbest: 0.5039400 (100)\ttotal: 1.85s\tremaining: 16.5s\n",
      "200:\tlearn: 0.4565004\ttest: 0.4878346\tbest: 0.4878346 (200)\ttotal: 3.3s\tremaining: 13.1s\n",
      "300:\tlearn: 0.4486987\ttest: 0.4858256\tbest: 0.4858256 (300)\ttotal: 4.75s\tremaining: 11s\n",
      "400:\tlearn: 0.4446898\ttest: 0.4855256\tbest: 0.4855035 (398)\ttotal: 6.25s\tremaining: 9.33s\n",
      "500:\tlearn: 0.4419661\ttest: 0.4853924\tbest: 0.4853487 (478)\ttotal: 7.73s\tremaining: 7.7s\n",
      "600:\tlearn: 0.4398727\ttest: 0.4854094\tbest: 0.4853107 (554)\ttotal: 9.2s\tremaining: 6.11s\n",
      "bestTest = 0.4853106975\n",
      "bestIteration = 554\n",
      "Shrink model to first 555 iterations.\n",
      "===== ACCURACY SCORE 0.781154 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6879154\ttest: 0.6881546\tbest: 0.6881546 (0)\ttotal: 16.5ms\tremaining: 16.5s\n",
      "100:\tlearn: 0.4846496\ttest: 0.5023484\tbest: 0.5023484 (100)\ttotal: 1.82s\tremaining: 16.2s\n",
      "200:\tlearn: 0.4565275\ttest: 0.4857608\tbest: 0.4857608 (200)\ttotal: 3.27s\tremaining: 13s\n",
      "300:\tlearn: 0.4485969\ttest: 0.4840640\tbest: 0.4840640 (300)\ttotal: 4.73s\tremaining: 11s\n",
      "400:\tlearn: 0.4445993\ttest: 0.4837043\tbest: 0.4836538 (394)\ttotal: 6.22s\tremaining: 9.29s\n",
      "500:\tlearn: 0.4418846\ttest: 0.4835372\tbest: 0.4835132 (491)\ttotal: 7.68s\tremaining: 7.65s\n",
      "600:\tlearn: 0.4397508\ttest: 0.4834200\tbest: 0.4834140 (591)\ttotal: 9.15s\tremaining: 6.07s\n",
      "700:\tlearn: 0.4379235\ttest: 0.4833053\tbest: 0.4832655 (691)\ttotal: 10.7s\tremaining: 4.55s\n",
      "800:\tlearn: 0.4363125\ttest: 0.4832221\tbest: 0.4832096 (796)\ttotal: 12.5s\tremaining: 3.1s\n",
      "bestTest = 0.4832095965\n",
      "bestIteration = 796\n",
      "Shrink model to first 797 iterations.\n",
      "===== ACCURACY SCORE 0.781365 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6878253\ttest: 0.6881342\tbest: 0.6881342 (0)\ttotal: 53.1ms\tremaining: 53.1s\n",
      "100:\tlearn: 0.4824576\ttest: 0.5047495\tbest: 0.5047495 (100)\ttotal: 1.67s\tremaining: 14.9s\n",
      "200:\tlearn: 0.4543341\ttest: 0.4901971\tbest: 0.4901971 (200)\ttotal: 3.15s\tremaining: 12.5s\n",
      "300:\tlearn: 0.4464717\ttest: 0.4895877\tbest: 0.4893499 (264)\ttotal: 4.61s\tremaining: 10.7s\n",
      "bestTest = 0.4893498856\n",
      "bestIteration = 264\n",
      "Shrink model to first 265 iterations.\n",
      "===== ACCURACY SCORE 0.777427 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6879118\ttest: 0.6880553\tbest: 0.6880553 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4842918\ttest: 0.4999291\tbest: 0.4999291 (100)\ttotal: 1.78s\tremaining: 15.9s\n",
      "200:\tlearn: 0.4563073\ttest: 0.4837485\tbest: 0.4837485 (200)\ttotal: 3.25s\tremaining: 12.9s\n",
      "300:\tlearn: 0.4485966\ttest: 0.4822994\tbest: 0.4822994 (300)\ttotal: 4.73s\tremaining: 11s\n",
      "400:\tlearn: 0.4445855\ttest: 0.4821512\tbest: 0.4821512 (400)\ttotal: 6.21s\tremaining: 9.28s\n",
      "500:\tlearn: 0.4417703\ttest: 0.4822336\tbest: 0.4820583 (446)\ttotal: 7.67s\tremaining: 7.64s\n",
      "bestTest = 0.4820582519\n",
      "bestIteration = 446\n",
      "Shrink model to first 447 iterations.\n",
      "===== ACCURACY SCORE 0.783465 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779010 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6879113\ttest: 0.6880922\tbest: 0.6880922 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4848056\ttest: 0.5008412\tbest: 0.5008412 (100)\ttotal: 1.54s\tremaining: 13.7s\n",
      "200:\tlearn: 0.4567191\ttest: 0.4838515\tbest: 0.4838515 (200)\ttotal: 3.33s\tremaining: 13.2s\n",
      "300:\tlearn: 0.4489184\ttest: 0.4820496\tbest: 0.4820359 (299)\ttotal: 4.82s\tremaining: 11.2s\n",
      "400:\tlearn: 0.4449067\ttest: 0.4818774\tbest: 0.4817868 (389)\ttotal: 6.28s\tremaining: 9.38s\n",
      "bestTest = 0.481786754\n",
      "bestIteration = 389\n",
      "Shrink model to first 390 iterations.\n",
      "===== ACCURACY SCORE 0.778343 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6878724\ttest: 0.6881673\tbest: 0.6881673 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4834382\ttest: 0.5059975\tbest: 0.5059975 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4554003\ttest: 0.4907309\tbest: 0.4907211 (199)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4474139\ttest: 0.4893588\tbest: 0.4893586 (299)\ttotal: 4.53s\tremaining: 10.5s\n",
      "400:\tlearn: 0.4434164\ttest: 0.4892240\tbest: 0.4891503 (364)\ttotal: 6.72s\tremaining: 10s\n",
      "bestTest = 0.4891503335\n",
      "bestIteration = 364\n",
      "Shrink model to first 365 iterations.\n",
      "===== ACCURACY SCORE 0.776113 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6879330\ttest: 0.6880164\tbest: 0.6880164 (0)\ttotal: 17.4ms\tremaining: 17.4s\n",
      "100:\tlearn: 0.4853278\ttest: 0.4953389\tbest: 0.4953389 (100)\ttotal: 1.51s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4575015\ttest: 0.4759094\tbest: 0.4759094 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4495998\ttest: 0.4728938\tbest: 0.4728938 (300)\ttotal: 4.44s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4455724\ttest: 0.4718508\tbest: 0.4718508 (400)\ttotal: 5.96s\tremaining: 8.91s\n",
      "500:\tlearn: 0.4428318\ttest: 0.4713147\tbest: 0.4713147 (500)\ttotal: 7.76s\tremaining: 7.72s\n",
      "600:\tlearn: 0.4407353\ttest: 0.4709766\tbest: 0.4709766 (600)\ttotal: 9.21s\tremaining: 6.12s\n",
      "700:\tlearn: 0.4388881\ttest: 0.4706650\tbest: 0.4706647 (699)\ttotal: 10.7s\tremaining: 4.55s\n",
      "800:\tlearn: 0.4373303\ttest: 0.4704950\tbest: 0.4704950 (800)\ttotal: 12.1s\tremaining: 3.02s\n",
      "900:\tlearn: 0.4358393\ttest: 0.4704204\tbest: 0.4704017 (886)\ttotal: 13.6s\tremaining: 1.49s\n",
      "999:\tlearn: 0.4344253\ttest: 0.4703430\tbest: 0.4703177 (990)\ttotal: 15.1s\tremaining: 0us\n",
      "bestTest = 0.4703176501\n",
      "bestIteration = 990\n",
      "Shrink model to first 991 iterations.\n",
      "===== ACCURACY SCORE 0.791257 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6879359\ttest: 0.6883164\tbest: 0.6883164 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4853939\ttest: 0.5111129\tbest: 0.5111129 (100)\ttotal: 1.6s\tremaining: 14.2s\n",
      "200:\tlearn: 0.4571793\ttest: 0.4967982\tbest: 0.4967982 (200)\ttotal: 3.32s\tremaining: 13.2s\n",
      "300:\tlearn: 0.4493194\ttest: 0.4957164\tbest: 0.4956468 (281)\ttotal: 4.78s\tremaining: 11.1s\n",
      "400:\tlearn: 0.4454292\ttest: 0.4954170\tbest: 0.4954170 (400)\ttotal: 6.23s\tremaining: 9.31s\n",
      "500:\tlearn: 0.4427566\ttest: 0.4952187\tbest: 0.4952187 (500)\ttotal: 7.68s\tremaining: 7.65s\n",
      "600:\tlearn: 0.4406040\ttest: 0.4950734\tbest: 0.4950583 (596)\ttotal: 9.13s\tremaining: 6.06s\n",
      "700:\tlearn: 0.4387761\ttest: 0.4949151\tbest: 0.4948867 (692)\ttotal: 10.6s\tremaining: 4.53s\n",
      "bestTest = 0.4948867227\n",
      "bestIteration = 692\n",
      "Shrink model to first 693 iterations.\n",
      "===== ACCURACY SCORE 0.775437 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6878874\ttest: 0.6882171\tbest: 0.6882171 (0)\ttotal: 28.1ms\tremaining: 28.1s\n",
      "100:\tlearn: 0.4849506\ttest: 0.5076363\tbest: 0.5076363 (100)\ttotal: 1.54s\tremaining: 13.7s\n",
      "200:\tlearn: 0.4570174\ttest: 0.4926434\tbest: 0.4926434 (200)\ttotal: 3s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4492083\ttest: 0.4914196\tbest: 0.4913795 (293)\ttotal: 4.47s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4452334\ttest: 0.4914667\tbest: 0.4913770 (317)\ttotal: 5.92s\tremaining: 8.85s\n",
      "bestTest = 0.4913770002\n",
      "bestIteration = 317\n",
      "Shrink model to first 318 iterations.\n",
      "===== ACCURACY SCORE 0.772800 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6879164\ttest: 0.6882453\tbest: 0.6882453 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4845792\ttest: 0.5112781\tbest: 0.5112781 (100)\ttotal: 1.54s\tremaining: 13.7s\n",
      "200:\tlearn: 0.4567269\ttest: 0.4983121\tbest: 0.4983121 (200)\ttotal: 3.32s\tremaining: 13.2s\n",
      "300:\tlearn: 0.4490334\ttest: 0.4978846\tbest: 0.4978400 (237)\ttotal: 4.78s\tremaining: 11.1s\n",
      "bestTest = 0.4978399597\n",
      "bestIteration = 237\n",
      "Shrink model to first 238 iterations.\n",
      "===== ACCURACY SCORE 0.776715 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6879154\ttest: 0.6881081\tbest: 0.6881081 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4850997\ttest: 0.5016775\tbest: 0.5016775 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4570643\ttest: 0.4857847\tbest: 0.4857847 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4491086\ttest: 0.4840645\tbest: 0.4840507 (296)\ttotal: 4.43s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4450490\ttest: 0.4839759\tbest: 0.4839382 (363)\ttotal: 5.9s\tremaining: 8.81s\n",
      "500:\tlearn: 0.4422784\ttest: 0.4839055\tbest: 0.4838998 (499)\ttotal: 7.61s\tremaining: 7.58s\n",
      "600:\tlearn: 0.4401765\ttest: 0.4838643\tbest: 0.4838590 (528)\ttotal: 9.19s\tremaining: 6.1s\n",
      "700:\tlearn: 0.4384004\ttest: 0.4838454\tbest: 0.4838117 (605)\ttotal: 10.7s\tremaining: 4.54s\n",
      "bestTest = 0.4838116973\n",
      "bestIteration = 605\n",
      "Shrink model to first 606 iterations.\n",
      "===== ACCURACY SCORE 0.780956 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6879155\ttest: 0.6881677\tbest: 0.6881677 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4845039\ttest: 0.5055057\tbest: 0.5055057 (100)\ttotal: 1.54s\tremaining: 13.7s\n",
      "200:\tlearn: 0.4565513\ttest: 0.4903664\tbest: 0.4903664 (200)\ttotal: 3s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4488608\ttest: 0.4891294\tbest: 0.4891291 (299)\ttotal: 4.46s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4449217\ttest: 0.4891654\tbest: 0.4890836 (392)\ttotal: 6.96s\tremaining: 10.4s\n",
      "500:\tlearn: 0.4422340\ttest: 0.4891453\tbest: 0.4890245 (456)\ttotal: 8.6s\tremaining: 8.56s\n",
      "bestTest = 0.4890244922\n",
      "bestIteration = 456\n",
      "Shrink model to first 457 iterations.\n",
      "===== ACCURACY SCORE 0.777900 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6879017\ttest: 0.6881838\tbest: 0.6881838 (0)\ttotal: 15.8ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4845059\ttest: 0.5065472\tbest: 0.5065472 (100)\ttotal: 1.52s\tremaining: 13.6s\n",
      "200:\tlearn: 0.4565191\ttest: 0.4913286\tbest: 0.4913286 (200)\ttotal: 2.98s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4485683\ttest: 0.4901958\tbest: 0.4901958 (300)\ttotal: 4.44s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4446178\ttest: 0.4901356\tbest: 0.4900709 (348)\ttotal: 6s\tremaining: 8.96s\n",
      "bestTest = 0.4900709459\n",
      "bestIteration = 348\n",
      "Shrink model to first 349 iterations.\n",
      "===== ACCURACY SCORE 0.776531 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6879617\ttest: 0.6881206\tbest: 0.6881206 (0)\ttotal: 16.9ms\tremaining: 16.9s\n",
      "100:\tlearn: 0.4858360\ttest: 0.5023184\tbest: 0.5023184 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4578572\ttest: 0.4860421\tbest: 0.4860421 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4500659\ttest: 0.4845384\tbest: 0.4845384 (300)\ttotal: 4.44s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4460835\ttest: 0.4842447\tbest: 0.4842320 (394)\ttotal: 5.91s\tremaining: 8.83s\n",
      "500:\tlearn: 0.4433699\ttest: 0.4841575\tbest: 0.4841575 (500)\ttotal: 7.37s\tremaining: 7.34s\n",
      "600:\tlearn: 0.4412477\ttest: 0.4840463\tbest: 0.4840286 (594)\ttotal: 8.84s\tremaining: 5.87s\n",
      "700:\tlearn: 0.4393411\ttest: 0.4837729\tbest: 0.4837705 (697)\ttotal: 10.5s\tremaining: 4.48s\n",
      "800:\tlearn: 0.4377366\ttest: 0.4837106\tbest: 0.4836881 (796)\ttotal: 12.1s\tremaining: 3.02s\n",
      "900:\tlearn: 0.4362306\ttest: 0.4837224\tbest: 0.4836772 (870)\ttotal: 13.6s\tremaining: 1.5s\n",
      "999:\tlearn: 0.4348753\ttest: 0.4837359\tbest: 0.4836671 (979)\ttotal: 15.1s\tremaining: 0us\n",
      "bestTest = 0.4836671043\n",
      "bestIteration = 979\n",
      "Shrink model to first 980 iterations.\n",
      "===== ACCURACY SCORE 0.783803 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778980 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6879318\ttest: 0.6880538\tbest: 0.6880538 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4854717\ttest: 0.4978754\tbest: 0.4978754 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4576001\ttest: 0.4800235\tbest: 0.4800235 (200)\ttotal: 3.35s\tremaining: 13.3s\n",
      "300:\tlearn: 0.4497431\ttest: 0.4775992\tbest: 0.4775992 (300)\ttotal: 5.61s\tremaining: 13s\n",
      "400:\tlearn: 0.4457642\ttest: 0.4772443\tbest: 0.4772443 (400)\ttotal: 7.15s\tremaining: 10.7s\n",
      "500:\tlearn: 0.4430788\ttest: 0.4768319\tbest: 0.4768319 (500)\ttotal: 8.62s\tremaining: 8.59s\n",
      "600:\tlearn: 0.4409652\ttest: 0.4767462\tbest: 0.4767462 (600)\ttotal: 10.1s\tremaining: 6.69s\n",
      "700:\tlearn: 0.4391483\ttest: 0.4767860\tbest: 0.4767316 (645)\ttotal: 11.5s\tremaining: 4.92s\n",
      "bestTest = 0.4767315909\n",
      "bestIteration = 645\n",
      "Shrink model to first 646 iterations.\n",
      "===== ACCURACY SCORE 0.788845 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6879150\ttest: 0.6880388\tbest: 0.6880388 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4845849\ttest: 0.4977459\tbest: 0.4977459 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4565640\ttest: 0.4804485\tbest: 0.4804485 (200)\ttotal: 3.13s\tremaining: 12.4s\n",
      "300:\tlearn: 0.4486047\ttest: 0.4786745\tbest: 0.4786745 (300)\ttotal: 4.7s\tremaining: 10.9s\n",
      "400:\tlearn: 0.4445582\ttest: 0.4783699\tbest: 0.4783672 (399)\ttotal: 6.15s\tremaining: 9.19s\n",
      "500:\tlearn: 0.4418089\ttest: 0.4782284\tbest: 0.4781759 (492)\ttotal: 7.6s\tremaining: 7.57s\n",
      "600:\tlearn: 0.4395998\ttest: 0.4780632\tbest: 0.4780632 (600)\ttotal: 9.06s\tremaining: 6.01s\n",
      "700:\tlearn: 0.4377330\ttest: 0.4779365\tbest: 0.4778805 (687)\ttotal: 10.5s\tremaining: 4.49s\n",
      "800:\tlearn: 0.4360889\ttest: 0.4778356\tbest: 0.4778324 (793)\ttotal: 12s\tremaining: 2.99s\n",
      "900:\tlearn: 0.4345675\ttest: 0.4778037\tbest: 0.4777822 (878)\ttotal: 13.6s\tremaining: 1.5s\n",
      "999:\tlearn: 0.4331924\ttest: 0.4777367\tbest: 0.4777306 (951)\ttotal: 15.4s\tremaining: 0us\n",
      "bestTest = 0.4777305655\n",
      "bestIteration = 951\n",
      "Shrink model to first 952 iterations.\n",
      "===== ACCURACY SCORE 0.783795 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6879140\ttest: 0.6883573\tbest: 0.6883573 (0)\ttotal: 14.1ms\tremaining: 14.1s\n",
      "100:\tlearn: 0.4834171\ttest: 0.5164634\tbest: 0.5164634 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4555438\ttest: 0.5047339\tbest: 0.5047089 (198)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4477965\ttest: 0.5044078\tbest: 0.5043367 (245)\ttotal: 4.44s\tremaining: 10.3s\n",
      "bestTest = 0.5043367319\n",
      "bestIteration = 245\n",
      "Shrink model to first 246 iterations.\n",
      "===== ACCURACY SCORE 0.765985 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6878410\ttest: 0.6882403\tbest: 0.6882403 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4827690\ttest: 0.5126502\tbest: 0.5126502 (100)\ttotal: 1.6s\tremaining: 14.3s\n",
      "200:\tlearn: 0.4548196\ttest: 0.5005382\tbest: 0.5005217 (197)\ttotal: 3.37s\tremaining: 13.4s\n",
      "300:\tlearn: 0.4470316\ttest: 0.5000630\tbest: 0.5000630 (300)\ttotal: 4.82s\tremaining: 11.2s\n",
      "400:\tlearn: 0.4430621\ttest: 0.5001131\tbest: 0.5000316 (365)\ttotal: 6.26s\tremaining: 9.36s\n",
      "bestTest = 0.5000316384\n",
      "bestIteration = 365\n",
      "Shrink model to first 366 iterations.\n",
      "===== ACCURACY SCORE 0.772868 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6878799\ttest: 0.6882774\tbest: 0.6882774 (0)\ttotal: 17ms\tremaining: 16.9s\n",
      "100:\tlearn: 0.4837654\ttest: 0.5120213\tbest: 0.5120213 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4556977\ttest: 0.4990911\tbest: 0.4990911 (200)\ttotal: 2.98s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4479034\ttest: 0.4986050\tbest: 0.4985043 (270)\ttotal: 4.56s\tremaining: 10.6s\n",
      "bestTest = 0.4985042812\n",
      "bestIteration = 270\n",
      "Shrink model to first 271 iterations.\n",
      "===== ACCURACY SCORE 0.773377 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6878647\ttest: 0.6881224\tbest: 0.6881224 (0)\ttotal: 16.6ms\tremaining: 16.6s\n",
      "100:\tlearn: 0.4834562\ttest: 0.5057144\tbest: 0.5057144 (100)\ttotal: 1.6s\tremaining: 14.3s\n",
      "200:\tlearn: 0.4551240\ttest: 0.4913611\tbest: 0.4913611 (200)\ttotal: 3.06s\tremaining: 12.2s\n",
      "300:\tlearn: 0.4471816\ttest: 0.4908229\tbest: 0.4907749 (292)\ttotal: 4.53s\tremaining: 10.5s\n",
      "400:\tlearn: 0.4431051\ttest: 0.4910407\tbest: 0.4907483 (307)\ttotal: 6s\tremaining: 8.97s\n",
      "bestTest = 0.490748252\n",
      "bestIteration = 307\n",
      "Shrink model to first 308 iterations.\n",
      "===== ACCURACY SCORE 0.778369 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6879199\ttest: 0.6881990\tbest: 0.6881990 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4844571\ttest: 0.5054305\tbest: 0.5054305 (100)\ttotal: 1.58s\tremaining: 14.1s\n",
      "200:\tlearn: 0.4564293\ttest: 0.4887438\tbest: 0.4887438 (200)\ttotal: 3.38s\tremaining: 13.4s\n",
      "300:\tlearn: 0.4485414\ttest: 0.4871467\tbest: 0.4871286 (299)\ttotal: 4.85s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4445494\ttest: 0.4869800\tbest: 0.4869767 (399)\ttotal: 6.32s\tremaining: 9.44s\n",
      "500:\tlearn: 0.4418261\ttest: 0.4869081\tbest: 0.4868684 (467)\ttotal: 7.79s\tremaining: 7.76s\n",
      "600:\tlearn: 0.4397101\ttest: 0.4868678\tbest: 0.4868032 (538)\ttotal: 10.3s\tremaining: 6.82s\n",
      "700:\tlearn: 0.4378924\ttest: 0.4867653\tbest: 0.4867212 (655)\ttotal: 11.8s\tremaining: 5.02s\n",
      "800:\tlearn: 0.4361882\ttest: 0.4867355\tbest: 0.4867095 (721)\ttotal: 13.6s\tremaining: 3.37s\n",
      "900:\tlearn: 0.4346972\ttest: 0.4866567\tbest: 0.4866529 (898)\ttotal: 15s\tremaining: 1.65s\n",
      "999:\tlearn: 0.4332904\ttest: 0.4866302\tbest: 0.4865656 (927)\ttotal: 16.5s\tremaining: 0us\n",
      "bestTest = 0.486565566\n",
      "bestIteration = 927\n",
      "Shrink model to first 928 iterations.\n",
      "===== ACCURACY SCORE 0.777240 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878353\ttest: 0.6879379\tbest: 0.6879379 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4830892\ttest: 0.4938366\tbest: 0.4938366 (100)\ttotal: 1.51s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4551083\ttest: 0.4749016\tbest: 0.4749016 (200)\ttotal: 2.98s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4473307\ttest: 0.4720631\tbest: 0.4720631 (300)\ttotal: 4.49s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4433635\ttest: 0.4713602\tbest: 0.4713602 (400)\ttotal: 6.09s\tremaining: 9.11s\n",
      "500:\tlearn: 0.4407674\ttest: 0.4710154\tbest: 0.4710105 (499)\ttotal: 7.92s\tremaining: 7.88s\n",
      "600:\tlearn: 0.4386307\ttest: 0.4707108\tbest: 0.4706990 (589)\ttotal: 9.43s\tremaining: 6.26s\n",
      "700:\tlearn: 0.4367754\ttest: 0.4704605\tbest: 0.4704453 (697)\ttotal: 10.9s\tremaining: 4.67s\n",
      "800:\tlearn: 0.4351727\ttest: 0.4703878\tbest: 0.4703538 (750)\ttotal: 12.4s\tremaining: 3.08s\n",
      "900:\tlearn: 0.4337011\ttest: 0.4702801\tbest: 0.4702793 (892)\ttotal: 13.9s\tremaining: 1.53s\n",
      "999:\tlearn: 0.4322980\ttest: 0.4703002\tbest: 0.4702660 (987)\ttotal: 15.4s\tremaining: 0us\n",
      "bestTest = 0.4702660318\n",
      "bestIteration = 987\n",
      "Shrink model to first 988 iterations.\n",
      "===== ACCURACY SCORE 0.787643 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6879553\ttest: 0.6881931\tbest: 0.6881931 (0)\ttotal: 16.7ms\tremaining: 16.7s\n",
      "100:\tlearn: 0.4850042\ttest: 0.5044498\tbest: 0.5044498 (100)\ttotal: 1.77s\tremaining: 15.8s\n",
      "200:\tlearn: 0.4568303\ttest: 0.4879932\tbest: 0.4879932 (200)\ttotal: 3.25s\tremaining: 12.9s\n",
      "300:\tlearn: 0.4489300\ttest: 0.4861021\tbest: 0.4861021 (300)\ttotal: 4.74s\tremaining: 11s\n",
      "400:\tlearn: 0.4448413\ttest: 0.4857084\tbest: 0.4857005 (368)\ttotal: 6.5s\tremaining: 9.7s\n",
      "500:\tlearn: 0.4420857\ttest: 0.4852322\tbest: 0.4852216 (497)\ttotal: 8.52s\tremaining: 8.49s\n",
      "600:\tlearn: 0.4398989\ttest: 0.4849873\tbest: 0.4849801 (599)\ttotal: 10s\tremaining: 6.64s\n",
      "700:\tlearn: 0.4380639\ttest: 0.4848423\tbest: 0.4848305 (694)\ttotal: 11.7s\tremaining: 4.97s\n",
      "800:\tlearn: 0.4364268\ttest: 0.4846580\tbest: 0.4846571 (792)\ttotal: 13.3s\tremaining: 3.3s\n",
      "900:\tlearn: 0.4349162\ttest: 0.4846064\tbest: 0.4845857 (878)\ttotal: 14.8s\tremaining: 1.62s\n",
      "999:\tlearn: 0.4334255\ttest: 0.4845347\tbest: 0.4845289 (996)\ttotal: 16.2s\tremaining: 0us\n",
      "bestTest = 0.4845288775\n",
      "bestIteration = 996\n",
      "Shrink model to first 997 iterations.\n",
      "===== ACCURACY SCORE 0.780092 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6879000\ttest: 0.6880929\tbest: 0.6880929 (0)\ttotal: 14.2ms\tremaining: 14.2s\n",
      "100:\tlearn: 0.4827975\ttest: 0.4996159\tbest: 0.4996159 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4548831\ttest: 0.4818531\tbest: 0.4818531 (200)\ttotal: 2.95s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4469730\ttest: 0.4793403\tbest: 0.4793403 (300)\ttotal: 4.47s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4429790\ttest: 0.4783634\tbest: 0.4783634 (400)\ttotal: 6.29s\tremaining: 9.39s\n",
      "500:\tlearn: 0.4402216\ttest: 0.4779373\tbest: 0.4779284 (498)\ttotal: 7.76s\tremaining: 7.73s\n",
      "600:\tlearn: 0.4381002\ttest: 0.4776490\tbest: 0.4776136 (579)\ttotal: 9.21s\tremaining: 6.12s\n",
      "700:\tlearn: 0.4362774\ttest: 0.4774263\tbest: 0.4774097 (698)\ttotal: 10.7s\tremaining: 4.55s\n",
      "800:\tlearn: 0.4346655\ttest: 0.4773116\tbest: 0.4773001 (783)\ttotal: 12.1s\tremaining: 3.01s\n",
      "900:\tlearn: 0.4331561\ttest: 0.4772783\tbest: 0.4772593 (893)\ttotal: 13.6s\tremaining: 1.49s\n",
      "999:\tlearn: 0.4317990\ttest: 0.4772514\tbest: 0.4772423 (997)\ttotal: 15.1s\tremaining: 0us\n",
      "bestTest = 0.4772422957\n",
      "bestIteration = 997\n",
      "Shrink model to first 998 iterations.\n",
      "===== ACCURACY SCORE 0.786043 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779450 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6878816\ttest: 0.6880969\tbest: 0.6880969 (0)\ttotal: 51.1ms\tremaining: 51s\n",
      "100:\tlearn: 0.4841262\ttest: 0.5014594\tbest: 0.5014594 (100)\ttotal: 1.85s\tremaining: 16.4s\n",
      "200:\tlearn: 0.4560915\ttest: 0.4847880\tbest: 0.4847880 (200)\ttotal: 3.31s\tremaining: 13.2s\n",
      "300:\tlearn: 0.4482411\ttest: 0.4828007\tbest: 0.4828007 (300)\ttotal: 5.63s\tremaining: 13.1s\n",
      "400:\tlearn: 0.4443101\ttest: 0.4825513\tbest: 0.4824611 (360)\ttotal: 7.12s\tremaining: 10.6s\n",
      "bestTest = 0.4824610638\n",
      "bestIteration = 360\n",
      "Shrink model to first 361 iterations.\n",
      "===== ACCURACY SCORE 0.780706 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6878841\ttest: 0.6880956\tbest: 0.6880956 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4837088\ttest: 0.4998919\tbest: 0.4998919 (100)\ttotal: 1.59s\tremaining: 14.2s\n",
      "200:\tlearn: 0.4557290\ttest: 0.4827477\tbest: 0.4827477 (200)\ttotal: 3.33s\tremaining: 13.2s\n",
      "300:\tlearn: 0.4477451\ttest: 0.4807948\tbest: 0.4807943 (299)\ttotal: 4.79s\tremaining: 11.1s\n",
      "400:\tlearn: 0.4437533\ttest: 0.4803269\tbest: 0.4803269 (400)\ttotal: 6.26s\tremaining: 9.36s\n",
      "500:\tlearn: 0.4410397\ttest: 0.4801922\tbest: 0.4801820 (499)\ttotal: 7.74s\tremaining: 7.71s\n",
      "600:\tlearn: 0.4388856\ttest: 0.4799358\tbest: 0.4799322 (599)\ttotal: 9.21s\tremaining: 6.12s\n",
      "700:\tlearn: 0.4369918\ttest: 0.4798659\tbest: 0.4798659 (700)\ttotal: 10.7s\tremaining: 4.57s\n",
      "800:\tlearn: 0.4352461\ttest: 0.4797787\tbest: 0.4797536 (785)\ttotal: 12.3s\tremaining: 3.04s\n",
      "900:\tlearn: 0.4337345\ttest: 0.4796561\tbest: 0.4796462 (895)\ttotal: 14.1s\tremaining: 1.55s\n",
      "999:\tlearn: 0.4323799\ttest: 0.4795956\tbest: 0.4795605 (973)\ttotal: 15.6s\tremaining: 0us\n",
      "bestTest = 0.4795604745\n",
      "bestIteration = 973\n",
      "Shrink model to first 974 iterations.\n",
      "===== ACCURACY SCORE 0.785614 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6878263\ttest: 0.6880632\tbest: 0.6880632 (0)\ttotal: 17ms\tremaining: 17s\n",
      "100:\tlearn: 0.4841639\ttest: 0.5081322\tbest: 0.5081322 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4561174\ttest: 0.4938428\tbest: 0.4938402 (199)\ttotal: 2.98s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4482217\ttest: 0.4925625\tbest: 0.4925484 (289)\ttotal: 4.45s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4442899\ttest: 0.4925041\tbest: 0.4924108 (390)\ttotal: 5.95s\tremaining: 8.89s\n",
      "bestTest = 0.4924108403\n",
      "bestIteration = 390\n",
      "Shrink model to first 391 iterations.\n",
      "===== ACCURACY SCORE 0.770095 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6878915\ttest: 0.6882595\tbest: 0.6882595 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4835871\ttest: 0.5076647\tbest: 0.5076647 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4555428\ttest: 0.4918127\tbest: 0.4918127 (200)\ttotal: 3.71s\tremaining: 14.8s\n",
      "300:\tlearn: 0.4476887\ttest: 0.4899191\tbest: 0.4899083 (299)\ttotal: 5.17s\tremaining: 12s\n",
      "400:\tlearn: 0.4436508\ttest: 0.4895053\tbest: 0.4895028 (399)\ttotal: 6.65s\tremaining: 9.93s\n",
      "500:\tlearn: 0.4409276\ttest: 0.4891259\tbest: 0.4891259 (500)\ttotal: 8.12s\tremaining: 8.09s\n",
      "600:\tlearn: 0.4388329\ttest: 0.4890388\tbest: 0.4889881 (573)\ttotal: 9.7s\tremaining: 6.44s\n",
      "bestTest = 0.4889881009\n",
      "bestIteration = 573\n",
      "Shrink model to first 574 iterations.\n",
      "===== ACCURACY SCORE 0.775933 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6878745\ttest: 0.6882622\tbest: 0.6882622 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4836172\ttest: 0.5129604\tbest: 0.5129604 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4556054\ttest: 0.5007225\tbest: 0.5007225 (200)\ttotal: 2.95s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4478309\ttest: 0.5005633\tbest: 0.5004083 (246)\ttotal: 4.42s\tremaining: 10.3s\n",
      "bestTest = 0.5004083075\n",
      "bestIteration = 246\n",
      "Shrink model to first 247 iterations.\n",
      "===== ACCURACY SCORE 0.770064 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6879686\ttest: 0.6881600\tbest: 0.6881600 (0)\ttotal: 16.1ms\tremaining: 16.1s\n",
      "100:\tlearn: 0.4860410\ttest: 0.5029002\tbest: 0.5029002 (100)\ttotal: 3.07s\tremaining: 27.3s\n",
      "200:\tlearn: 0.4581302\ttest: 0.4861751\tbest: 0.4861751 (200)\ttotal: 4.52s\tremaining: 18s\n",
      "300:\tlearn: 0.4503677\ttest: 0.4839806\tbest: 0.4839783 (299)\ttotal: 5.98s\tremaining: 13.9s\n",
      "400:\tlearn: 0.4463408\ttest: 0.4834377\tbest: 0.4834377 (400)\ttotal: 7.45s\tremaining: 11.1s\n",
      "500:\tlearn: 0.4435680\ttest: 0.4829936\tbest: 0.4829857 (493)\ttotal: 8.93s\tremaining: 8.89s\n",
      "600:\tlearn: 0.4414537\ttest: 0.4828653\tbest: 0.4828309 (559)\ttotal: 10.4s\tremaining: 6.92s\n",
      "700:\tlearn: 0.4396752\ttest: 0.4827125\tbest: 0.4826903 (697)\ttotal: 11.9s\tremaining: 5.07s\n",
      "800:\tlearn: 0.4379868\ttest: 0.4825662\tbest: 0.4825572 (787)\ttotal: 13.3s\tremaining: 3.32s\n",
      "900:\tlearn: 0.4364825\ttest: 0.4824957\tbest: 0.4824957 (900)\ttotal: 14.8s\tremaining: 1.63s\n",
      "999:\tlearn: 0.4351126\ttest: 0.4824741\tbest: 0.4824215 (973)\ttotal: 17.2s\tremaining: 0us\n",
      "bestTest = 0.4824214882\n",
      "bestIteration = 973\n",
      "Shrink model to first 974 iterations.\n",
      "===== ACCURACY SCORE 0.782178 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6878747\ttest: 0.6880611\tbest: 0.6880611 (0)\ttotal: 15.7ms\tremaining: 15.6s\n",
      "100:\tlearn: 0.4836514\ttest: 0.5007797\tbest: 0.5007797 (100)\ttotal: 1.47s\tremaining: 13.1s\n",
      "200:\tlearn: 0.4556872\ttest: 0.4835591\tbest: 0.4835591 (200)\ttotal: 2.93s\tremaining: 11.6s\n",
      "300:\tlearn: 0.4479719\ttest: 0.4811056\tbest: 0.4811056 (300)\ttotal: 4.41s\tremaining: 10.2s\n",
      "400:\tlearn: 0.4439878\ttest: 0.4805568\tbest: 0.4805336 (399)\ttotal: 5.86s\tremaining: 8.75s\n",
      "500:\tlearn: 0.4412723\ttest: 0.4801559\tbest: 0.4801559 (500)\ttotal: 7.32s\tremaining: 7.29s\n",
      "600:\tlearn: 0.4391649\ttest: 0.4799564\tbest: 0.4799440 (593)\ttotal: 8.84s\tremaining: 5.87s\n",
      "700:\tlearn: 0.4372984\ttest: 0.4796505\tbest: 0.4796375 (698)\ttotal: 10.3s\tremaining: 4.39s\n",
      "800:\tlearn: 0.4356707\ttest: 0.4795953\tbest: 0.4795343 (784)\ttotal: 11.8s\tremaining: 2.92s\n",
      "900:\tlearn: 0.4342082\ttest: 0.4794089\tbest: 0.4793982 (895)\ttotal: 13.2s\tremaining: 1.45s\n",
      "999:\tlearn: 0.4328733\ttest: 0.4793911\tbest: 0.4793339 (987)\ttotal: 14.7s\tremaining: 0us\n",
      "bestTest = 0.4793339224\n",
      "bestIteration = 987\n",
      "Shrink model to first 988 iterations.\n",
      "===== ACCURACY SCORE 0.783248 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878590\ttest: 0.6881132\tbest: 0.6881132 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4832754\ttest: 0.5027064\tbest: 0.5027064 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4554605\ttest: 0.4871723\tbest: 0.4871723 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4476791\ttest: 0.4859035\tbest: 0.4859035 (300)\ttotal: 4.45s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4437258\ttest: 0.4856871\tbest: 0.4856453 (369)\ttotal: 5.92s\tremaining: 8.84s\n",
      "bestTest = 0.4856452893\n",
      "bestIteration = 369\n",
      "Shrink model to first 370 iterations.\n",
      "===== ACCURACY SCORE 0.776495 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6878447\ttest: 0.6881104\tbest: 0.6881104 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4827883\ttest: 0.5062649\tbest: 0.5062649 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4550080\ttest: 0.4919146\tbest: 0.4919146 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4472276\ttest: 0.4907274\tbest: 0.4907200 (299)\ttotal: 4.42s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4432390\ttest: 0.4905935\tbest: 0.4905733 (360)\ttotal: 6.45s\tremaining: 9.63s\n",
      "500:\tlearn: 0.4405530\ttest: 0.4904990\tbest: 0.4904835 (497)\ttotal: 8.16s\tremaining: 8.13s\n",
      "600:\tlearn: 0.4384369\ttest: 0.4902287\tbest: 0.4902017 (585)\ttotal: 9.62s\tremaining: 6.39s\n",
      "700:\tlearn: 0.4366634\ttest: 0.4900149\tbest: 0.4900016 (693)\ttotal: 11.1s\tremaining: 4.72s\n",
      "800:\tlearn: 0.4350066\ttest: 0.4898929\tbest: 0.4898920 (798)\ttotal: 12.5s\tremaining: 3.11s\n",
      "900:\tlearn: 0.4335139\ttest: 0.4896182\tbest: 0.4896101 (894)\ttotal: 14s\tremaining: 1.54s\n",
      "999:\tlearn: 0.4321016\ttest: 0.4895703\tbest: 0.4895506 (987)\ttotal: 15.5s\tremaining: 0us\n",
      "bestTest = 0.4895505951\n",
      "bestIteration = 987\n",
      "Shrink model to first 988 iterations.\n",
      "===== ACCURACY SCORE 0.782404 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6878443\ttest: 0.6879856\tbest: 0.6879856 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4848601\ttest: 0.5037205\tbest: 0.5037205 (100)\ttotal: 1.6s\tremaining: 14.2s\n",
      "200:\tlearn: 0.4567911\ttest: 0.4878193\tbest: 0.4878193 (200)\ttotal: 3.41s\tremaining: 13.6s\n",
      "300:\tlearn: 0.4488684\ttest: 0.4864135\tbest: 0.4864135 (300)\ttotal: 4.94s\tremaining: 11.5s\n",
      "400:\tlearn: 0.4448300\ttest: 0.4864638\tbest: 0.4863598 (363)\ttotal: 6.4s\tremaining: 9.57s\n",
      "bestTest = 0.4863597514\n",
      "bestIteration = 363\n",
      "Shrink model to first 364 iterations.\n",
      "===== ACCURACY SCORE 0.780083 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778680 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6879170\ttest: 0.6881059\tbest: 0.6881059 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4849081\ttest: 0.5034197\tbest: 0.5034197 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4571913\ttest: 0.4878719\tbest: 0.4878719 (200)\ttotal: 3.06s\tremaining: 12.2s\n",
      "300:\tlearn: 0.4494700\ttest: 0.4861522\tbest: 0.4861419 (299)\ttotal: 4.69s\tremaining: 10.9s\n",
      "400:\tlearn: 0.4455431\ttest: 0.4855105\tbest: 0.4855078 (399)\ttotal: 6.49s\tremaining: 9.69s\n",
      "500:\tlearn: 0.4429103\ttest: 0.4852302\tbest: 0.4852242 (495)\ttotal: 7.94s\tremaining: 7.91s\n",
      "600:\tlearn: 0.4407812\ttest: 0.4848545\tbest: 0.4848545 (600)\ttotal: 9.39s\tremaining: 6.24s\n",
      "700:\tlearn: 0.4390306\ttest: 0.4844287\tbest: 0.4844287 (700)\ttotal: 10.8s\tremaining: 4.62s\n",
      "800:\tlearn: 0.4374162\ttest: 0.4842593\tbest: 0.4842593 (800)\ttotal: 12.5s\tremaining: 3.1s\n",
      "900:\tlearn: 0.4359218\ttest: 0.4841222\tbest: 0.4841126 (891)\ttotal: 14.6s\tremaining: 1.6s\n",
      "999:\tlearn: 0.4345648\ttest: 0.4838982\tbest: 0.4838886 (991)\ttotal: 16.1s\tremaining: 0us\n",
      "bestTest = 0.483888623\n",
      "bestIteration = 991\n",
      "Shrink model to first 992 iterations.\n",
      "===== ACCURACY SCORE 0.782100 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6879114\ttest: 0.6881850\tbest: 0.6881850 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4849568\ttest: 0.5047187\tbest: 0.5047187 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4569325\ttest: 0.4883876\tbest: 0.4883876 (200)\ttotal: 3.01s\tremaining: 12s\n",
      "300:\tlearn: 0.4490112\ttest: 0.4868084\tbest: 0.4868084 (300)\ttotal: 4.48s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4451063\ttest: 0.4864574\tbest: 0.4864080 (390)\ttotal: 5.96s\tremaining: 8.9s\n",
      "bestTest = 0.4864079818\n",
      "bestIteration = 390\n",
      "Shrink model to first 391 iterations.\n",
      "===== ACCURACY SCORE 0.776872 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6879042\ttest: 0.6881950\tbest: 0.6881950 (0)\ttotal: 16.6ms\tremaining: 16.6s\n",
      "100:\tlearn: 0.4844772\ttest: 0.5081397\tbest: 0.5081397 (100)\ttotal: 1.57s\tremaining: 13.9s\n",
      "200:\tlearn: 0.4563199\ttest: 0.4933493\tbest: 0.4933493 (200)\ttotal: 3.35s\tremaining: 13.3s\n",
      "300:\tlearn: 0.4484443\ttest: 0.4920574\tbest: 0.4920574 (300)\ttotal: 4.79s\tremaining: 11.1s\n",
      "400:\tlearn: 0.4444658\ttest: 0.4917333\tbest: 0.4917225 (395)\ttotal: 6.25s\tremaining: 9.33s\n",
      "500:\tlearn: 0.4418217\ttest: 0.4915720\tbest: 0.4915476 (498)\ttotal: 7.77s\tremaining: 7.74s\n",
      "600:\tlearn: 0.4397132\ttest: 0.4914974\tbest: 0.4914974 (600)\ttotal: 9.22s\tremaining: 6.12s\n",
      "700:\tlearn: 0.4378551\ttest: 0.4914406\tbest: 0.4914087 (694)\ttotal: 10.7s\tremaining: 4.56s\n",
      "800:\tlearn: 0.4362756\ttest: 0.4912318\tbest: 0.4912288 (797)\ttotal: 12.2s\tremaining: 3.03s\n",
      "900:\tlearn: 0.4347391\ttest: 0.4911560\tbest: 0.4911355 (883)\ttotal: 14s\tremaining: 1.54s\n",
      "bestTest = 0.4911354891\n",
      "bestIteration = 883\n",
      "Shrink model to first 884 iterations.\n",
      "===== ACCURACY SCORE 0.776465 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6878717\ttest: 0.6881252\tbest: 0.6881252 (0)\ttotal: 16.2ms\tremaining: 16.2s\n",
      "100:\tlearn: 0.4834299\ttest: 0.5018892\tbest: 0.5018892 (100)\ttotal: 1.51s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4553137\ttest: 0.4851380\tbest: 0.4851371 (199)\ttotal: 3.79s\tremaining: 15s\n",
      "300:\tlearn: 0.4475713\ttest: 0.4829781\tbest: 0.4829781 (300)\ttotal: 5.24s\tremaining: 12.2s\n",
      "400:\tlearn: 0.4436097\ttest: 0.4824695\tbest: 0.4824695 (400)\ttotal: 6.78s\tremaining: 10.1s\n",
      "500:\tlearn: 0.4409086\ttest: 0.4822962\tbest: 0.4822962 (500)\ttotal: 8.57s\tremaining: 8.53s\n",
      "600:\tlearn: 0.4387355\ttest: 0.4822055\tbest: 0.4821729 (589)\ttotal: 10s\tremaining: 6.66s\n",
      "700:\tlearn: 0.4368780\ttest: 0.4821838\tbest: 0.4821551 (683)\ttotal: 11.5s\tremaining: 4.92s\n",
      "800:\tlearn: 0.4352109\ttest: 0.4820930\tbest: 0.4820687 (779)\ttotal: 13s\tremaining: 3.23s\n",
      "900:\tlearn: 0.4337277\ttest: 0.4820690\tbest: 0.4820608 (887)\ttotal: 14.4s\tremaining: 1.59s\n",
      "999:\tlearn: 0.4324129\ttest: 0.4820530\tbest: 0.4820440 (982)\ttotal: 15.9s\tremaining: 0us\n",
      "bestTest = 0.482043955\n",
      "bestIteration = 982\n",
      "Shrink model to first 983 iterations.\n",
      "===== ACCURACY SCORE 0.781798 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6879149\ttest: 0.6881640\tbest: 0.6881640 (0)\ttotal: 16ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4849605\ttest: 0.5051311\tbest: 0.5051311 (100)\ttotal: 1.76s\tremaining: 15.7s\n",
      "200:\tlearn: 0.4570672\ttest: 0.4890470\tbest: 0.4890470 (200)\ttotal: 3.33s\tremaining: 13.2s\n",
      "300:\tlearn: 0.4492718\ttest: 0.4871627\tbest: 0.4871627 (300)\ttotal: 4.84s\tremaining: 11.2s\n",
      "400:\tlearn: 0.4453372\ttest: 0.4869326\tbest: 0.4869297 (392)\ttotal: 6.3s\tremaining: 9.41s\n",
      "500:\tlearn: 0.4426656\ttest: 0.4867168\tbest: 0.4866901 (494)\ttotal: 7.76s\tremaining: 7.73s\n",
      "600:\tlearn: 0.4406250\ttest: 0.4865908\tbest: 0.4865779 (592)\ttotal: 9.24s\tremaining: 6.13s\n",
      "700:\tlearn: 0.4387669\ttest: 0.4864249\tbest: 0.4864108 (699)\ttotal: 10.7s\tremaining: 4.57s\n",
      "800:\tlearn: 0.4371748\ttest: 0.4864005\tbest: 0.4863942 (710)\ttotal: 12.3s\tremaining: 3.07s\n",
      "900:\tlearn: 0.4356274\ttest: 0.4863908\tbest: 0.4863302 (851)\ttotal: 14.1s\tremaining: 1.55s\n",
      "bestTest = 0.4863301705\n",
      "bestIteration = 851\n",
      "Shrink model to first 852 iterations.\n",
      "===== ACCURACY SCORE 0.781169 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6878755\ttest: 0.6881293\tbest: 0.6881293 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4838581\ttest: 0.5034570\tbest: 0.5034570 (100)\ttotal: 2.08s\tremaining: 18.5s\n",
      "200:\tlearn: 0.4559002\ttest: 0.4878080\tbest: 0.4878080 (200)\ttotal: 3.82s\tremaining: 15.2s\n",
      "300:\tlearn: 0.4480834\ttest: 0.4865262\tbest: 0.4865262 (300)\ttotal: 5.34s\tremaining: 12.4s\n",
      "400:\tlearn: 0.4440942\ttest: 0.4863407\tbest: 0.4862680 (330)\ttotal: 6.85s\tremaining: 10.2s\n",
      "500:\tlearn: 0.4414179\ttest: 0.4862513\tbest: 0.4862163 (495)\ttotal: 8.71s\tremaining: 8.68s\n",
      "600:\tlearn: 0.4393169\ttest: 0.4860490\tbest: 0.4860462 (598)\ttotal: 10.2s\tremaining: 6.75s\n",
      "700:\tlearn: 0.4374667\ttest: 0.4859832\tbest: 0.4859551 (653)\ttotal: 11.6s\tremaining: 4.96s\n",
      "800:\tlearn: 0.4358217\ttest: 0.4859033\tbest: 0.4858623 (765)\ttotal: 13.1s\tremaining: 3.26s\n",
      "900:\tlearn: 0.4343198\ttest: 0.4858151\tbest: 0.4857864 (862)\ttotal: 14.6s\tremaining: 1.6s\n",
      "999:\tlearn: 0.4329250\ttest: 0.4857121\tbest: 0.4857025 (987)\ttotal: 16.1s\tremaining: 0us\n",
      "bestTest = 0.4857024948\n",
      "bestIteration = 987\n",
      "Shrink model to first 988 iterations.\n",
      "===== ACCURACY SCORE 0.781140 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6878997\ttest: 0.6880766\tbest: 0.6880766 (0)\ttotal: 15.9ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4837707\ttest: 0.5003210\tbest: 0.5003210 (100)\ttotal: 2.01s\tremaining: 17.9s\n",
      "200:\tlearn: 0.4555935\ttest: 0.4836612\tbest: 0.4836612 (200)\ttotal: 3.48s\tremaining: 13.8s\n",
      "300:\tlearn: 0.4477530\ttest: 0.4822724\tbest: 0.4822724 (300)\ttotal: 4.93s\tremaining: 11.5s\n",
      "400:\tlearn: 0.4437332\ttest: 0.4821758\tbest: 0.4821758 (400)\ttotal: 6.4s\tremaining: 9.56s\n",
      "500:\tlearn: 0.4410584\ttest: 0.4822793\tbest: 0.4821241 (411)\ttotal: 7.88s\tremaining: 7.84s\n",
      "bestTest = 0.4821240891\n",
      "bestIteration = 411\n",
      "Shrink model to first 412 iterations.\n",
      "===== ACCURACY SCORE 0.784056 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878966\ttest: 0.6881758\tbest: 0.6881758 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4841746\ttest: 0.5056433\tbest: 0.5056433 (100)\ttotal: 1.51s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4560628\ttest: 0.4907579\tbest: 0.4907579 (200)\ttotal: 3.12s\tremaining: 12.4s\n",
      "300:\tlearn: 0.4480173\ttest: 0.4896880\tbest: 0.4896750 (299)\ttotal: 4.9s\tremaining: 11.4s\n",
      "400:\tlearn: 0.4439303\ttest: 0.4896522\tbest: 0.4896161 (324)\ttotal: 6.37s\tremaining: 9.51s\n",
      "bestTest = 0.4896161015\n",
      "bestIteration = 324\n",
      "Shrink model to first 325 iterations.\n",
      "===== ACCURACY SCORE 0.776974 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6879295\ttest: 0.6881658\tbest: 0.6881658 (0)\ttotal: 18.6ms\tremaining: 18.6s\n",
      "100:\tlearn: 0.4851178\ttest: 0.5031142\tbest: 0.5031142 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4571738\ttest: 0.4868907\tbest: 0.4868907 (200)\ttotal: 3.03s\tremaining: 12s\n",
      "300:\tlearn: 0.4493246\ttest: 0.4851157\tbest: 0.4851106 (299)\ttotal: 4.54s\tremaining: 10.5s\n",
      "400:\tlearn: 0.4453444\ttest: 0.4846580\tbest: 0.4846481 (395)\ttotal: 6.38s\tremaining: 9.53s\n",
      "500:\tlearn: 0.4426983\ttest: 0.4843882\tbest: 0.4843625 (494)\ttotal: 7.85s\tremaining: 7.82s\n",
      "600:\tlearn: 0.4405618\ttest: 0.4841435\tbest: 0.4841139 (561)\ttotal: 9.32s\tremaining: 6.19s\n",
      "700:\tlearn: 0.4387411\ttest: 0.4840317\tbest: 0.4840169 (669)\ttotal: 11s\tremaining: 4.71s\n",
      "800:\tlearn: 0.4371305\ttest: 0.4838567\tbest: 0.4838567 (800)\ttotal: 12.7s\tremaining: 3.14s\n",
      "900:\tlearn: 0.4356059\ttest: 0.4838366\tbest: 0.4837948 (853)\ttotal: 14.1s\tremaining: 1.55s\n",
      "999:\tlearn: 0.4342528\ttest: 0.4838443\tbest: 0.4837860 (941)\ttotal: 15.7s\tremaining: 0us\n",
      "bestTest = 0.4837860498\n",
      "bestIteration = 941\n",
      "Shrink model to first 942 iterations.\n",
      "===== ACCURACY SCORE 0.779615 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6878713\ttest: 0.6882806\tbest: 0.6882806 (0)\ttotal: 16.8ms\tremaining: 16.8s\n",
      "100:\tlearn: 0.4835068\ttest: 0.5121681\tbest: 0.5121681 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4556487\ttest: 0.4988690\tbest: 0.4988690 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4478780\ttest: 0.4982959\tbest: 0.4982213 (291)\ttotal: 4.45s\tremaining: 10.3s\n",
      "bestTest = 0.4982213137\n",
      "bestIteration = 291\n",
      "Shrink model to first 292 iterations.\n",
      "===== ACCURACY SCORE 0.770095 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779030 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6878823\ttest: 0.6881028\tbest: 0.6881028 (0)\ttotal: 16.5ms\tremaining: 16.4s\n",
      "100:\tlearn: 0.4837046\ttest: 0.5009915\tbest: 0.5009915 (100)\ttotal: 1.54s\tremaining: 13.7s\n",
      "200:\tlearn: 0.4556074\ttest: 0.4838855\tbest: 0.4838855 (200)\ttotal: 3.09s\tremaining: 12.3s\n",
      "300:\tlearn: 0.4479115\ttest: 0.4819439\tbest: 0.4819439 (300)\ttotal: 4.8s\tremaining: 11.2s\n",
      "400:\tlearn: 0.4439344\ttest: 0.4816900\tbest: 0.4816458 (390)\ttotal: 6.71s\tremaining: 10s\n",
      "bestTest = 0.4816457895\n",
      "bestIteration = 390\n",
      "Shrink model to first 391 iterations.\n",
      "===== ACCURACY SCORE 0.780666 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6878786\ttest: 0.6881193\tbest: 0.6881193 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4832272\ttest: 0.5058175\tbest: 0.5058175 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4548860\ttest: 0.4910455\tbest: 0.4910435 (199)\ttotal: 2.98s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4469338\ttest: 0.4895046\tbest: 0.4895046 (300)\ttotal: 4.52s\tremaining: 10.5s\n",
      "400:\tlearn: 0.4429866\ttest: 0.4892798\tbest: 0.4891793 (360)\ttotal: 6.47s\tremaining: 9.66s\n",
      "500:\tlearn: 0.4402156\ttest: 0.4891332\tbest: 0.4890951 (493)\ttotal: 7.96s\tremaining: 7.92s\n",
      "600:\tlearn: 0.4380672\ttest: 0.4890074\tbest: 0.4889959 (595)\ttotal: 9.48s\tremaining: 6.29s\n",
      "700:\tlearn: 0.4362093\ttest: 0.4890590\tbest: 0.4889682 (644)\ttotal: 11s\tremaining: 4.68s\n",
      "bestTest = 0.4889681541\n",
      "bestIteration = 644\n",
      "Shrink model to first 645 iterations.\n",
      "===== ACCURACY SCORE 0.776886 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6878770\ttest: 0.6881110\tbest: 0.6881110 (0)\ttotal: 17.1ms\tremaining: 17.1s\n",
      "100:\tlearn: 0.4836955\ttest: 0.5047601\tbest: 0.5047601 (100)\ttotal: 1.57s\tremaining: 14s\n",
      "200:\tlearn: 0.4556224\ttest: 0.4903688\tbest: 0.4903688 (200)\ttotal: 3.2s\tremaining: 12.7s\n",
      "300:\tlearn: 0.4478790\ttest: 0.4894291\tbest: 0.4893871 (276)\ttotal: 4.97s\tremaining: 11.5s\n",
      "400:\tlearn: 0.4439537\ttest: 0.4895604\tbest: 0.4893533 (318)\ttotal: 6.48s\tremaining: 9.68s\n",
      "bestTest = 0.4893532859\n",
      "bestIteration = 318\n",
      "Shrink model to first 319 iterations.\n",
      "===== ACCURACY SCORE 0.781514 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6878836\ttest: 0.6880804\tbest: 0.6880804 (0)\ttotal: 14.7ms\tremaining: 14.7s\n",
      "100:\tlearn: 0.4826561\ttest: 0.5018353\tbest: 0.5018353 (100)\ttotal: 1.52s\tremaining: 13.6s\n",
      "200:\tlearn: 0.4545280\ttest: 0.4860442\tbest: 0.4860442 (200)\ttotal: 3.05s\tremaining: 12.1s\n",
      "300:\tlearn: 0.4467212\ttest: 0.4840744\tbest: 0.4840744 (300)\ttotal: 4.56s\tremaining: 10.6s\n",
      "400:\tlearn: 0.4427273\ttest: 0.4836095\tbest: 0.4836015 (399)\ttotal: 6.17s\tremaining: 9.21s\n",
      "500:\tlearn: 0.4399908\ttest: 0.4834451\tbest: 0.4834155 (493)\ttotal: 8.06s\tremaining: 8.03s\n",
      "600:\tlearn: 0.4378290\ttest: 0.4834109\tbest: 0.4833943 (505)\ttotal: 10.5s\tremaining: 6.98s\n",
      "700:\tlearn: 0.4360389\ttest: 0.4831323\tbest: 0.4831323 (700)\ttotal: 12s\tremaining: 5.12s\n",
      "800:\tlearn: 0.4344007\ttest: 0.4829262\tbest: 0.4829241 (796)\ttotal: 13.5s\tremaining: 3.35s\n",
      "900:\tlearn: 0.4329246\ttest: 0.4827934\tbest: 0.4827934 (900)\ttotal: 15s\tremaining: 1.65s\n",
      "999:\tlearn: 0.4315567\ttest: 0.4827090\tbest: 0.4826875 (994)\ttotal: 16.5s\tremaining: 0us\n",
      "bestTest = 0.4826874537\n",
      "bestIteration = 994\n",
      "Shrink model to first 995 iterations.\n",
      "===== ACCURACY SCORE 0.781820 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6879126\ttest: 0.6882381\tbest: 0.6882381 (0)\ttotal: 26.2ms\tremaining: 26.2s\n",
      "100:\tlearn: 0.4834652\ttest: 0.5068099\tbest: 0.5068099 (100)\ttotal: 1.67s\tremaining: 14.8s\n",
      "200:\tlearn: 0.4551924\ttest: 0.4919581\tbest: 0.4919581 (200)\ttotal: 3.13s\tremaining: 12.4s\n",
      "300:\tlearn: 0.4473080\ttest: 0.4912211\tbest: 0.4912047 (289)\ttotal: 4.6s\tremaining: 10.7s\n",
      "400:\tlearn: 0.4433036\ttest: 0.4915395\tbest: 0.4911998 (306)\ttotal: 6.09s\tremaining: 9.11s\n",
      "bestTest = 0.4911998457\n",
      "bestIteration = 306\n",
      "Shrink model to first 307 iterations.\n",
      "===== ACCURACY SCORE 0.776029 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6878536\ttest: 0.6882914\tbest: 0.6882914 (0)\ttotal: 16.4ms\tremaining: 16.4s\n",
      "100:\tlearn: 0.4831776\ttest: 0.5140525\tbest: 0.5140525 (100)\ttotal: 1.53s\tremaining: 13.7s\n",
      "200:\tlearn: 0.4550612\ttest: 0.5007047\tbest: 0.5007047 (200)\ttotal: 3.13s\tremaining: 12.4s\n",
      "300:\tlearn: 0.4471734\ttest: 0.4995049\tbest: 0.4995034 (299)\ttotal: 4.97s\tremaining: 11.5s\n",
      "400:\tlearn: 0.4431424\ttest: 0.4990903\tbest: 0.4990903 (400)\ttotal: 6.45s\tremaining: 9.64s\n",
      "500:\tlearn: 0.4404248\ttest: 0.4988460\tbest: 0.4988351 (496)\ttotal: 7.93s\tremaining: 7.9s\n",
      "600:\tlearn: 0.4382948\ttest: 0.4985556\tbest: 0.4985420 (595)\ttotal: 9.42s\tremaining: 6.25s\n",
      "700:\tlearn: 0.4364399\ttest: 0.4982684\tbest: 0.4982684 (700)\ttotal: 10.9s\tremaining: 4.65s\n",
      "800:\tlearn: 0.4348612\ttest: 0.4981612\tbest: 0.4981612 (800)\ttotal: 12.4s\tremaining: 3.08s\n",
      "900:\tlearn: 0.4333501\ttest: 0.4979838\tbest: 0.4979699 (891)\ttotal: 14s\tremaining: 1.53s\n",
      "999:\tlearn: 0.4319681\ttest: 0.4977733\tbest: 0.4977722 (995)\ttotal: 16.5s\tremaining: 0us\n",
      "bestTest = 0.4977722322\n",
      "bestIteration = 995\n",
      "Shrink model to first 996 iterations.\n",
      "===== ACCURACY SCORE 0.772714 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6878760\ttest: 0.6881305\tbest: 0.6881305 (0)\ttotal: 17.1ms\tremaining: 17.1s\n",
      "100:\tlearn: 0.4838102\ttest: 0.5033686\tbest: 0.5033686 (100)\ttotal: 1.54s\tremaining: 13.7s\n",
      "200:\tlearn: 0.4558859\ttest: 0.4873875\tbest: 0.4873875 (200)\ttotal: 3.07s\tremaining: 12.2s\n",
      "300:\tlearn: 0.4480536\ttest: 0.4859924\tbest: 0.4859889 (293)\ttotal: 4.58s\tremaining: 10.6s\n",
      "400:\tlearn: 0.4440691\ttest: 0.4857432\tbest: 0.4857432 (400)\ttotal: 6.14s\tremaining: 9.17s\n",
      "500:\tlearn: 0.4413240\ttest: 0.4855625\tbest: 0.4855625 (500)\ttotal: 7.83s\tremaining: 7.8s\n",
      "600:\tlearn: 0.4391740\ttest: 0.4854316\tbest: 0.4854075 (595)\ttotal: 9.59s\tremaining: 6.37s\n",
      "700:\tlearn: 0.4373034\ttest: 0.4854053\tbest: 0.4854029 (692)\ttotal: 11.1s\tremaining: 4.73s\n",
      "800:\tlearn: 0.4356282\ttest: 0.4853358\tbest: 0.4853351 (799)\ttotal: 12.6s\tremaining: 3.13s\n",
      "900:\tlearn: 0.4340853\ttest: 0.4853249\tbest: 0.4852895 (865)\ttotal: 14.1s\tremaining: 1.55s\n",
      "999:\tlearn: 0.4326990\ttest: 0.4852382\tbest: 0.4852195 (994)\ttotal: 15.6s\tremaining: 0us\n",
      "bestTest = 0.4852195484\n",
      "bestIteration = 994\n",
      "Shrink model to first 995 iterations.\n",
      "===== ACCURACY SCORE 0.780010 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878940\ttest: 0.6880915\tbest: 0.6880915 (0)\ttotal: 16.3ms\tremaining: 16.3s\n",
      "100:\tlearn: 0.4840865\ttest: 0.5025102\tbest: 0.5025102 (100)\ttotal: 1.55s\tremaining: 13.8s\n",
      "200:\tlearn: 0.4563807\ttest: 0.4866903\tbest: 0.4866903 (200)\ttotal: 3.39s\tremaining: 13.5s\n",
      "300:\tlearn: 0.4484813\ttest: 0.4848890\tbest: 0.4848890 (300)\ttotal: 4.88s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4445199\ttest: 0.4844761\tbest: 0.4844215 (390)\ttotal: 6.38s\tremaining: 9.54s\n",
      "500:\tlearn: 0.4418715\ttest: 0.4843562\tbest: 0.4843195 (456)\ttotal: 7.93s\tremaining: 7.9s\n",
      "600:\tlearn: 0.4397634\ttest: 0.4842918\tbest: 0.4842826 (593)\ttotal: 9.47s\tremaining: 6.29s\n",
      "700:\tlearn: 0.4379611\ttest: 0.4842696\tbest: 0.4841992 (676)\ttotal: 11s\tremaining: 4.67s\n",
      "bestTest = 0.4841991608\n",
      "bestIteration = 676\n",
      "Shrink model to first 677 iterations.\n",
      "===== ACCURACY SCORE 0.779812 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6879080\ttest: 0.6881441\tbest: 0.6881441 (0)\ttotal: 17.6ms\tremaining: 17.6s\n",
      "100:\tlearn: 0.4843985\ttest: 0.5021778\tbest: 0.5021778 (100)\ttotal: 1.54s\tremaining: 13.7s\n",
      "200:\tlearn: 0.4562821\ttest: 0.4851636\tbest: 0.4851636 (200)\ttotal: 3.02s\tremaining: 12s\n",
      "300:\tlearn: 0.4485834\ttest: 0.4832788\tbest: 0.4832777 (299)\ttotal: 4.52s\tremaining: 10.5s\n",
      "400:\tlearn: 0.4445674\ttest: 0.4828811\tbest: 0.4828789 (399)\ttotal: 6.06s\tremaining: 9.05s\n",
      "500:\tlearn: 0.4418090\ttest: 0.4827423\tbest: 0.4827365 (497)\ttotal: 7.57s\tremaining: 7.54s\n",
      "600:\tlearn: 0.4396709\ttest: 0.4827946\tbest: 0.4827140 (505)\ttotal: 9.06s\tremaining: 6.01s\n",
      "bestTest = 0.4827139665\n",
      "bestIteration = 505\n",
      "Shrink model to first 506 iterations.\n",
      "===== ACCURACY SCORE 0.779572 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6879268\ttest: 0.6881650\tbest: 0.6881650 (0)\ttotal: 28.2ms\tremaining: 28.2s\n",
      "100:\tlearn: 0.4849678\ttest: 0.5038710\tbest: 0.5038710 (100)\ttotal: 1.67s\tremaining: 14.9s\n",
      "200:\tlearn: 0.4570129\ttest: 0.4870198\tbest: 0.4870198 (200)\ttotal: 3.19s\tremaining: 12.7s\n",
      "300:\tlearn: 0.4492639\ttest: 0.4845923\tbest: 0.4845923 (300)\ttotal: 4.68s\tremaining: 10.9s\n",
      "400:\tlearn: 0.4452895\ttest: 0.4837676\tbest: 0.4837676 (400)\ttotal: 6.17s\tremaining: 9.22s\n",
      "500:\tlearn: 0.4425509\ttest: 0.4833966\tbest: 0.4833966 (500)\ttotal: 7.66s\tremaining: 7.63s\n",
      "600:\tlearn: 0.4403628\ttest: 0.4830655\tbest: 0.4830655 (600)\ttotal: 9.14s\tremaining: 6.07s\n",
      "700:\tlearn: 0.4385242\ttest: 0.4829095\tbest: 0.4828962 (676)\ttotal: 10.8s\tremaining: 4.6s\n",
      "800:\tlearn: 0.4368623\ttest: 0.4827766\tbest: 0.4827671 (794)\ttotal: 12.5s\tremaining: 3.1s\n",
      "900:\tlearn: 0.4353727\ttest: 0.4826942\tbest: 0.4826942 (900)\ttotal: 14s\tremaining: 1.53s\n",
      "999:\tlearn: 0.4340379\ttest: 0.4824631\tbest: 0.4824593 (997)\ttotal: 15.5s\tremaining: 0us\n",
      "bestTest = 0.4824592882\n",
      "bestIteration = 997\n",
      "Shrink model to first 998 iterations.\n",
      "===== ACCURACY SCORE 0.781968 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779100 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6879143\ttest: 0.6881310\tbest: 0.6881310 (0)\ttotal: 16ms\tremaining: 16s\n",
      "100:\tlearn: 0.4848000\ttest: 0.5035877\tbest: 0.5035877 (100)\ttotal: 1.51s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4566380\ttest: 0.4876618\tbest: 0.4876618 (200)\ttotal: 3s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4486949\ttest: 0.4860884\tbest: 0.4860875 (298)\ttotal: 5.97s\tremaining: 13.9s\n",
      "400:\tlearn: 0.4446726\ttest: 0.4858463\tbest: 0.4858463 (400)\ttotal: 7.51s\tremaining: 11.2s\n",
      "500:\tlearn: 0.4419648\ttest: 0.4857117\tbest: 0.4856670 (489)\ttotal: 9.04s\tremaining: 9.01s\n",
      "600:\tlearn: 0.4398357\ttest: 0.4856541\tbest: 0.4856204 (561)\ttotal: 10.6s\tremaining: 7.01s\n",
      "700:\tlearn: 0.4379556\ttest: 0.4855455\tbest: 0.4855151 (664)\ttotal: 12.1s\tremaining: 5.15s\n",
      "800:\tlearn: 0.4363716\ttest: 0.4855380\tbest: 0.4854983 (766)\ttotal: 13.6s\tremaining: 3.38s\n",
      "bestTest = 0.4854983455\n",
      "bestIteration = 766\n",
      "Shrink model to first 767 iterations.\n",
      "===== ACCURACY SCORE 0.779906 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6878834\ttest: 0.6881893\tbest: 0.6881893 (0)\ttotal: 17.3ms\tremaining: 17.3s\n",
      "100:\tlearn: 0.4843627\ttest: 0.5063730\tbest: 0.5063730 (100)\ttotal: 1.99s\tremaining: 17.7s\n",
      "200:\tlearn: 0.4563267\ttest: 0.4907053\tbest: 0.4907053 (200)\ttotal: 3.52s\tremaining: 14s\n",
      "300:\tlearn: 0.4484333\ttest: 0.4888208\tbest: 0.4888208 (300)\ttotal: 5.05s\tremaining: 11.7s\n",
      "400:\tlearn: 0.4444486\ttest: 0.4883168\tbest: 0.4882880 (395)\ttotal: 6.56s\tremaining: 9.79s\n",
      "500:\tlearn: 0.4417165\ttest: 0.4880075\tbest: 0.4880046 (499)\ttotal: 8.08s\tremaining: 8.04s\n",
      "600:\tlearn: 0.4395875\ttest: 0.4878766\tbest: 0.4878438 (564)\ttotal: 9.6s\tremaining: 6.37s\n",
      "700:\tlearn: 0.4377100\ttest: 0.4877022\tbest: 0.4876884 (692)\ttotal: 11.3s\tremaining: 4.83s\n",
      "800:\tlearn: 0.4360858\ttest: 0.4875730\tbest: 0.4875566 (784)\ttotal: 13s\tremaining: 3.23s\n",
      "900:\tlearn: 0.4345349\ttest: 0.4874240\tbest: 0.4874210 (861)\ttotal: 14.5s\tremaining: 1.59s\n",
      "999:\tlearn: 0.4331662\ttest: 0.4872615\tbest: 0.4872615 (999)\ttotal: 16s\tremaining: 0us\n",
      "bestTest = 0.4872614986\n",
      "bestIteration = 999\n",
      "===== ACCURACY SCORE 0.778031 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6879222\ttest: 0.6880787\tbest: 0.6880787 (0)\ttotal: 16ms\tremaining: 16s\n",
      "100:\tlearn: 0.4842158\ttest: 0.4991952\tbest: 0.4991952 (100)\ttotal: 1.51s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4562073\ttest: 0.4810974\tbest: 0.4810974 (200)\ttotal: 3.68s\tremaining: 14.6s\n",
      "300:\tlearn: 0.4483789\ttest: 0.4787850\tbest: 0.4787850 (300)\ttotal: 5.7s\tremaining: 13.2s\n",
      "400:\tlearn: 0.4445115\ttest: 0.4781494\tbest: 0.4781398 (399)\ttotal: 7.3s\tremaining: 10.9s\n",
      "500:\tlearn: 0.4418682\ttest: 0.4776795\tbest: 0.4776594 (481)\ttotal: 8.78s\tremaining: 8.74s\n",
      "600:\tlearn: 0.4397823\ttest: 0.4771495\tbest: 0.4771495 (600)\ttotal: 10.3s\tremaining: 6.82s\n",
      "700:\tlearn: 0.4379391\ttest: 0.4767249\tbest: 0.4767249 (700)\ttotal: 11.7s\tremaining: 5.01s\n",
      "800:\tlearn: 0.4363030\ttest: 0.4764985\tbest: 0.4764818 (794)\ttotal: 13.2s\tremaining: 3.29s\n",
      "900:\tlearn: 0.4347962\ttest: 0.4762550\tbest: 0.4762550 (900)\ttotal: 14.8s\tremaining: 1.62s\n",
      "999:\tlearn: 0.4335022\ttest: 0.4761230\tbest: 0.4761081 (993)\ttotal: 16.6s\tremaining: 0us\n",
      "bestTest = 0.4761080793\n",
      "bestIteration = 993\n",
      "Shrink model to first 994 iterations.\n",
      "===== ACCURACY SCORE 0.787086 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6879177\ttest: 0.6881409\tbest: 0.6881409 (0)\ttotal: 16.1ms\tremaining: 16s\n",
      "100:\tlearn: 0.4848730\ttest: 0.5030799\tbest: 0.5030799 (100)\ttotal: 1.51s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4568701\ttest: 0.4869298\tbest: 0.4869298 (200)\ttotal: 2.98s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4491799\ttest: 0.4852142\tbest: 0.4852098 (295)\ttotal: 4.47s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4452481\ttest: 0.4848041\tbest: 0.4848041 (400)\ttotal: 5.98s\tremaining: 8.94s\n",
      "500:\tlearn: 0.4425328\ttest: 0.4847706\tbest: 0.4847015 (462)\ttotal: 7.49s\tremaining: 7.46s\n",
      "bestTest = 0.4847015214\n",
      "bestIteration = 462\n",
      "Shrink model to first 463 iterations.\n",
      "===== ACCURACY SCORE 0.780764 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6879211\ttest: 0.6881713\tbest: 0.6881713 (0)\ttotal: 18.4ms\tremaining: 18.4s\n",
      "100:\tlearn: 0.4842049\ttest: 0.5052900\tbest: 0.5052900 (100)\ttotal: 1.63s\tremaining: 14.5s\n",
      "200:\tlearn: 0.4561089\ttest: 0.4904910\tbest: 0.4904910 (200)\ttotal: 3.11s\tremaining: 12.3s\n",
      "300:\tlearn: 0.4482204\ttest: 0.4896890\tbest: 0.4896862 (299)\ttotal: 4.58s\tremaining: 10.6s\n",
      "400:\tlearn: 0.4442346\ttest: 0.4898041\tbest: 0.4896739 (303)\ttotal: 6.07s\tremaining: 9.06s\n",
      "bestTest = 0.4896739101\n",
      "bestIteration = 303\n",
      "Shrink model to first 304 iterations.\n",
      "===== ACCURACY SCORE 0.775692 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6879134\ttest: 0.6882105\tbest: 0.6882105 (0)\ttotal: 31.7ms\tremaining: 31.6s\n",
      "100:\tlearn: 0.4850813\ttest: 0.5071796\tbest: 0.5071796 (100)\ttotal: 2.32s\tremaining: 20.7s\n",
      "200:\tlearn: 0.4571555\ttest: 0.4925972\tbest: 0.4925972 (200)\ttotal: 4.18s\tremaining: 16.6s\n",
      "300:\tlearn: 0.4492813\ttest: 0.4915213\tbest: 0.4915092 (295)\ttotal: 5.68s\tremaining: 13.2s\n",
      "400:\tlearn: 0.4453168\ttest: 0.4914519\tbest: 0.4913912 (390)\ttotal: 7.18s\tremaining: 10.7s\n",
      "bestTest = 0.4913912435\n",
      "bestIteration = 390\n",
      "Shrink model to first 391 iterations.\n",
      "===== ACCURACY SCORE 0.775857 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6878072\ttest: 0.6880875\tbest: 0.6880875 (0)\ttotal: 17.9ms\tremaining: 17.9s\n",
      "100:\tlearn: 0.4816031\ttest: 0.5050172\tbest: 0.5050172 (100)\ttotal: 1.63s\tremaining: 14.5s\n",
      "200:\tlearn: 0.4533446\ttest: 0.4900275\tbest: 0.4900275 (200)\ttotal: 3.15s\tremaining: 12.5s\n",
      "300:\tlearn: 0.4456699\ttest: 0.4889080\tbest: 0.4888922 (299)\ttotal: 4.88s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4417283\ttest: 0.4887306\tbest: 0.4887191 (395)\ttotal: 6.57s\tremaining: 9.81s\n",
      "500:\tlearn: 0.4391350\ttest: 0.4884853\tbest: 0.4884795 (498)\ttotal: 8.05s\tremaining: 8.02s\n",
      "600:\tlearn: 0.4370174\ttest: 0.4884582\tbest: 0.4884403 (536)\ttotal: 9.55s\tremaining: 6.34s\n",
      "700:\tlearn: 0.4352595\ttest: 0.4885364\tbest: 0.4884249 (635)\ttotal: 11.1s\tremaining: 4.73s\n",
      "bestTest = 0.4884248995\n",
      "bestIteration = 635\n",
      "Shrink model to first 636 iterations.\n",
      "===== ACCURACY SCORE 0.780681 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878744\ttest: 0.6882134\tbest: 0.6882134 (0)\ttotal: 16.8ms\tremaining: 16.8s\n",
      "100:\tlearn: 0.4834181\ttest: 0.5099100\tbest: 0.5099100 (100)\ttotal: 1.53s\tremaining: 13.6s\n",
      "200:\tlearn: 0.4553436\ttest: 0.4957801\tbest: 0.4957801 (200)\ttotal: 3.23s\tremaining: 12.8s\n",
      "300:\tlearn: 0.4474603\ttest: 0.4947400\tbest: 0.4947302 (293)\ttotal: 4.91s\tremaining: 11.4s\n",
      "400:\tlearn: 0.4434447\ttest: 0.4947417\tbest: 0.4946571 (307)\ttotal: 6.41s\tremaining: 9.57s\n",
      "bestTest = 0.4946571352\n",
      "bestIteration = 307\n",
      "Shrink model to first 308 iterations.\n",
      "===== ACCURACY SCORE 0.770366 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6878983\ttest: 0.6880822\tbest: 0.6880822 (0)\ttotal: 16ms\tremaining: 16s\n",
      "100:\tlearn: 0.4827648\ttest: 0.5020508\tbest: 0.5020508 (100)\ttotal: 1.58s\tremaining: 14.1s\n",
      "200:\tlearn: 0.4546306\ttest: 0.4860149\tbest: 0.4860149 (200)\ttotal: 3.92s\tremaining: 15.6s\n",
      "300:\tlearn: 0.4467549\ttest: 0.4844558\tbest: 0.4844297 (298)\ttotal: 5.4s\tremaining: 12.5s\n",
      "400:\tlearn: 0.4428329\ttest: 0.4841581\tbest: 0.4841270 (389)\ttotal: 7.29s\tremaining: 10.9s\n",
      "500:\tlearn: 0.4401085\ttest: 0.4841366\tbest: 0.4840517 (473)\ttotal: 8.76s\tremaining: 8.73s\n",
      "600:\tlearn: 0.4380176\ttest: 0.4840329\tbest: 0.4839861 (557)\ttotal: 10.2s\tremaining: 6.8s\n",
      "700:\tlearn: 0.4362439\ttest: 0.4838684\tbest: 0.4838271 (689)\ttotal: 11.8s\tremaining: 5.03s\n",
      "bestTest = 0.4838270795\n",
      "bestIteration = 689\n",
      "Shrink model to first 690 iterations.\n",
      "===== ACCURACY SCORE 0.784780 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6878766\ttest: 0.6881824\tbest: 0.6881824 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4831934\ttest: 0.5058366\tbest: 0.5058366 (100)\ttotal: 1.52s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4548127\ttest: 0.4897517\tbest: 0.4897517 (200)\ttotal: 3.1s\tremaining: 12.3s\n",
      "300:\tlearn: 0.4468213\ttest: 0.4877179\tbest: 0.4877090 (299)\ttotal: 4.91s\tremaining: 11.4s\n",
      "400:\tlearn: 0.4427012\ttest: 0.4875208\tbest: 0.4874741 (379)\ttotal: 6.46s\tremaining: 9.65s\n",
      "500:\tlearn: 0.4399724\ttest: 0.4876270\tbest: 0.4874636 (453)\ttotal: 7.98s\tremaining: 7.95s\n",
      "bestTest = 0.4874635807\n",
      "bestIteration = 453\n",
      "Shrink model to first 454 iterations.\n",
      "===== ACCURACY SCORE 0.777349 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779070 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6879263\ttest: 0.6881301\tbest: 0.6881301 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4846915\ttest: 0.5024494\tbest: 0.5024494 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4565676\ttest: 0.4854423\tbest: 0.4854423 (200)\ttotal: 2.99s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4487304\ttest: 0.4837706\tbest: 0.4837686 (299)\ttotal: 4.74s\tremaining: 11s\n",
      "400:\tlearn: 0.4448286\ttest: 0.4836867\tbest: 0.4836867 (400)\ttotal: 6.39s\tremaining: 9.55s\n",
      "500:\tlearn: 0.4421619\ttest: 0.4837491\tbest: 0.4836815 (471)\ttotal: 7.91s\tremaining: 7.87s\n",
      "600:\tlearn: 0.4400519\ttest: 0.4835774\tbest: 0.4835511 (592)\ttotal: 9.4s\tremaining: 6.24s\n",
      "700:\tlearn: 0.4382763\ttest: 0.4834839\tbest: 0.4834755 (697)\ttotal: 11.8s\tremaining: 5.04s\n",
      "800:\tlearn: 0.4366545\ttest: 0.4833529\tbest: 0.4833529 (800)\ttotal: 13.3s\tremaining: 3.31s\n",
      "900:\tlearn: 0.4351505\ttest: 0.4832297\tbest: 0.4832255 (895)\ttotal: 14.9s\tremaining: 1.64s\n",
      "999:\tlearn: 0.4337724\ttest: 0.4831223\tbest: 0.4830898 (983)\ttotal: 16.8s\tremaining: 0us\n",
      "bestTest = 0.4830897918\n",
      "bestIteration = 983\n",
      "Shrink model to first 984 iterations.\n",
      "===== ACCURACY SCORE 0.782816 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6879123\ttest: 0.6881176\tbest: 0.6881176 (0)\ttotal: 16.3ms\tremaining: 16.3s\n",
      "100:\tlearn: 0.4846458\ttest: 0.5023981\tbest: 0.5023981 (100)\ttotal: 1.55s\tremaining: 13.8s\n",
      "200:\tlearn: 0.4565794\ttest: 0.4856495\tbest: 0.4856495 (200)\ttotal: 3.04s\tremaining: 12.1s\n",
      "300:\tlearn: 0.4487382\ttest: 0.4836786\tbest: 0.4836760 (299)\ttotal: 4.54s\tremaining: 10.5s\n",
      "400:\tlearn: 0.4447368\ttest: 0.4831190\tbest: 0.4831190 (400)\ttotal: 6.03s\tremaining: 9.01s\n",
      "500:\tlearn: 0.4420844\ttest: 0.4827451\tbest: 0.4827238 (499)\ttotal: 7.54s\tremaining: 7.51s\n",
      "600:\tlearn: 0.4399701\ttest: 0.4826882\tbest: 0.4826882 (600)\ttotal: 9.62s\tremaining: 6.38s\n",
      "700:\tlearn: 0.4381674\ttest: 0.4826359\tbest: 0.4825807 (639)\ttotal: 11.1s\tremaining: 4.73s\n",
      "800:\tlearn: 0.4365354\ttest: 0.4824973\tbest: 0.4824681 (798)\ttotal: 12.6s\tremaining: 3.13s\n",
      "900:\tlearn: 0.4350243\ttest: 0.4824239\tbest: 0.4824091 (865)\ttotal: 14.1s\tremaining: 1.55s\n",
      "999:\tlearn: 0.4336615\ttest: 0.4823287\tbest: 0.4823211 (989)\ttotal: 15.6s\tremaining: 0us\n",
      "bestTest = 0.4823210792\n",
      "bestIteration = 989\n",
      "Shrink model to first 990 iterations.\n",
      "===== ACCURACY SCORE 0.778541 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6878556\ttest: 0.6880686\tbest: 0.6880686 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4829282\ttest: 0.5013550\tbest: 0.5013550 (100)\ttotal: 1.51s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4549519\ttest: 0.4846877\tbest: 0.4846877 (200)\ttotal: 3.33s\tremaining: 13.2s\n",
      "300:\tlearn: 0.4471802\ttest: 0.4825635\tbest: 0.4825635 (300)\ttotal: 4.87s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4432510\ttest: 0.4822098\tbest: 0.4821913 (390)\ttotal: 6.38s\tremaining: 9.53s\n",
      "500:\tlearn: 0.4405825\ttest: 0.4821104\tbest: 0.4820964 (486)\ttotal: 8.61s\tremaining: 8.57s\n",
      "600:\tlearn: 0.4384269\ttest: 0.4821144\tbest: 0.4820845 (567)\ttotal: 10.1s\tremaining: 6.72s\n",
      "700:\tlearn: 0.4366085\ttest: 0.4820059\tbest: 0.4819967 (670)\ttotal: 11.6s\tremaining: 4.96s\n",
      "800:\tlearn: 0.4350291\ttest: 0.4819535\tbest: 0.4819535 (800)\ttotal: 13.2s\tremaining: 3.29s\n",
      "900:\tlearn: 0.4335180\ttest: 0.4820130\tbest: 0.4819433 (805)\ttotal: 15.1s\tremaining: 1.66s\n",
      "bestTest = 0.4819433232\n",
      "bestIteration = 805\n",
      "Shrink model to first 806 iterations.\n",
      "===== ACCURACY SCORE 0.781316 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6879024\ttest: 0.6882276\tbest: 0.6882276 (0)\ttotal: 16.4ms\tremaining: 16.4s\n",
      "100:\tlearn: 0.4836748\ttest: 0.5091985\tbest: 0.5091985 (100)\ttotal: 1.55s\tremaining: 13.8s\n",
      "200:\tlearn: 0.4555592\ttest: 0.4955103\tbest: 0.4955059 (199)\ttotal: 3.06s\tremaining: 12.2s\n",
      "300:\tlearn: 0.4477112\ttest: 0.4945776\tbest: 0.4945776 (300)\ttotal: 4.61s\tremaining: 10.7s\n",
      "400:\tlearn: 0.4438023\ttest: 0.4943423\tbest: 0.4943423 (400)\ttotal: 6.14s\tremaining: 9.17s\n",
      "500:\tlearn: 0.4411111\ttest: 0.4944321\tbest: 0.4943412 (465)\ttotal: 7.67s\tremaining: 7.64s\n",
      "600:\tlearn: 0.4390246\ttest: 0.4943017\tbest: 0.4942663 (587)\ttotal: 9.53s\tremaining: 6.33s\n",
      "700:\tlearn: 0.4372152\ttest: 0.4942790\tbest: 0.4942499 (684)\ttotal: 11.1s\tremaining: 4.72s\n",
      "800:\tlearn: 0.4356097\ttest: 0.4942728\tbest: 0.4942318 (784)\ttotal: 12.6s\tremaining: 3.12s\n",
      "bestTest = 0.4942317618\n",
      "bestIteration = 784\n",
      "Shrink model to first 785 iterations.\n",
      "===== ACCURACY SCORE 0.772659 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6878553\ttest: 0.6880732\tbest: 0.6880732 (0)\ttotal: 17.1ms\tremaining: 17.1s\n",
      "100:\tlearn: 0.4832439\ttest: 0.4990588\tbest: 0.4990588 (100)\ttotal: 1.55s\tremaining: 13.8s\n",
      "200:\tlearn: 0.4552210\ttest: 0.4816212\tbest: 0.4816212 (200)\ttotal: 3.05s\tremaining: 12.1s\n",
      "300:\tlearn: 0.4474070\ttest: 0.4794182\tbest: 0.4794173 (297)\ttotal: 4.89s\tremaining: 11.4s\n",
      "400:\tlearn: 0.4435145\ttest: 0.4787025\tbest: 0.4787025 (400)\ttotal: 6.51s\tremaining: 9.72s\n",
      "500:\tlearn: 0.4408167\ttest: 0.4783312\tbest: 0.4783308 (499)\ttotal: 8.51s\tremaining: 8.47s\n",
      "600:\tlearn: 0.4386937\ttest: 0.4780841\tbest: 0.4780745 (598)\ttotal: 10.3s\tremaining: 6.87s\n",
      "700:\tlearn: 0.4368450\ttest: 0.4778388\tbest: 0.4778388 (700)\ttotal: 11.9s\tremaining: 5.06s\n",
      "800:\tlearn: 0.4351839\ttest: 0.4776961\tbest: 0.4776961 (800)\ttotal: 13.4s\tremaining: 3.33s\n",
      "900:\tlearn: 0.4336967\ttest: 0.4776662\tbest: 0.4776316 (875)\ttotal: 15s\tremaining: 1.65s\n",
      "bestTest = 0.4776315987\n",
      "bestIteration = 875\n",
      "Shrink model to first 876 iterations.\n",
      "===== ACCURACY SCORE 0.782806 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6879449\ttest: 0.6881349\tbest: 0.6881349 (0)\ttotal: 16.8ms\tremaining: 16.7s\n",
      "100:\tlearn: 0.4849944\ttest: 0.5044439\tbest: 0.5044439 (100)\ttotal: 1.55s\tremaining: 13.8s\n",
      "200:\tlearn: 0.4567345\ttest: 0.4892938\tbest: 0.4892852 (199)\ttotal: 3.11s\tremaining: 12.4s\n",
      "300:\tlearn: 0.4487439\ttest: 0.4884131\tbest: 0.4883206 (265)\ttotal: 4.64s\tremaining: 10.8s\n",
      "bestTest = 0.4883206291\n",
      "bestIteration = 265\n",
      "Shrink model to first 266 iterations.\n",
      "===== ACCURACY SCORE 0.779236 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6879181\ttest: 0.6882369\tbest: 0.6882369 (0)\ttotal: 17.3ms\tremaining: 17.2s\n",
      "100:\tlearn: 0.4849655\ttest: 0.5089190\tbest: 0.5089190 (100)\ttotal: 1.6s\tremaining: 14.3s\n",
      "200:\tlearn: 0.4570288\ttest: 0.4936950\tbest: 0.4936950 (200)\ttotal: 3.42s\tremaining: 13.6s\n",
      "300:\tlearn: 0.4492717\ttest: 0.4920926\tbest: 0.4920926 (300)\ttotal: 4.91s\tremaining: 11.4s\n",
      "400:\tlearn: 0.4454296\ttest: 0.4915775\tbest: 0.4915370 (390)\ttotal: 6.43s\tremaining: 9.61s\n",
      "500:\tlearn: 0.4427546\ttest: 0.4912270\tbest: 0.4912134 (487)\ttotal: 7.94s\tremaining: 7.9s\n",
      "600:\tlearn: 0.4406804\ttest: 0.4910956\tbest: 0.4910931 (599)\ttotal: 9.43s\tremaining: 6.26s\n",
      "700:\tlearn: 0.4388693\ttest: 0.4907538\tbest: 0.4907471 (699)\ttotal: 10.9s\tremaining: 4.66s\n",
      "800:\tlearn: 0.4373119\ttest: 0.4906837\tbest: 0.4906587 (765)\ttotal: 12.4s\tremaining: 3.09s\n",
      "900:\tlearn: 0.4358663\ttest: 0.4905856\tbest: 0.4905609 (888)\ttotal: 14.3s\tremaining: 1.57s\n",
      "999:\tlearn: 0.4345276\ttest: 0.4904509\tbest: 0.4904102 (986)\ttotal: 16.4s\tremaining: 0us\n",
      "bestTest = 0.4904101834\n",
      "bestIteration = 986\n",
      "Shrink model to first 987 iterations.\n",
      "===== ACCURACY SCORE 0.776764 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878550\ttest: 0.6882920\tbest: 0.6882920 (0)\ttotal: 17.5ms\tremaining: 17.5s\n",
      "100:\tlearn: 0.4825133\ttest: 0.5140244\tbest: 0.5140244 (100)\ttotal: 1.54s\tremaining: 13.7s\n",
      "200:\tlearn: 0.4541996\ttest: 0.5016658\tbest: 0.5016635 (199)\ttotal: 3.04s\tremaining: 12.1s\n",
      "300:\tlearn: 0.4463376\ttest: 0.5015303\tbest: 0.5014020 (244)\ttotal: 4.53s\tremaining: 10.5s\n",
      "bestTest = 0.5014019699\n",
      "bestIteration = 244\n",
      "Shrink model to first 245 iterations.\n",
      "===== ACCURACY SCORE 0.768564 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6878970\ttest: 0.6881979\tbest: 0.6881979 (0)\ttotal: 16.1ms\tremaining: 16.1s\n",
      "100:\tlearn: 0.4838437\ttest: 0.5071808\tbest: 0.5071808 (100)\ttotal: 1.93s\tremaining: 17.2s\n",
      "200:\tlearn: 0.4558101\ttest: 0.4923694\tbest: 0.4923694 (200)\ttotal: 3.44s\tremaining: 13.7s\n",
      "300:\tlearn: 0.4479305\ttest: 0.4911747\tbest: 0.4911747 (300)\ttotal: 4.93s\tremaining: 11.5s\n",
      "400:\tlearn: 0.4438422\ttest: 0.4909641\tbest: 0.4909386 (390)\ttotal: 6.42s\tremaining: 9.59s\n",
      "500:\tlearn: 0.4411011\ttest: 0.4909249\tbest: 0.4908477 (457)\ttotal: 7.89s\tremaining: 7.86s\n",
      "bestTest = 0.4908476961\n",
      "bestIteration = 457\n",
      "Shrink model to first 458 iterations.\n",
      "===== ACCURACY SCORE 0.778156 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6879201\ttest: 0.6880927\tbest: 0.6880927 (0)\ttotal: 16.7ms\tremaining: 16.7s\n",
      "100:\tlearn: 0.4852024\ttest: 0.4975055\tbest: 0.4975055 (100)\ttotal: 1.72s\tremaining: 15.3s\n",
      "200:\tlearn: 0.4571007\ttest: 0.4794939\tbest: 0.4794939 (200)\ttotal: 3.44s\tremaining: 13.7s\n",
      "300:\tlearn: 0.4492309\ttest: 0.4771661\tbest: 0.4771661 (300)\ttotal: 4.94s\tremaining: 11.5s\n",
      "400:\tlearn: 0.4452690\ttest: 0.4766701\tbest: 0.4766481 (392)\ttotal: 6.43s\tremaining: 9.6s\n",
      "500:\tlearn: 0.4425051\ttest: 0.4764645\tbest: 0.4764284 (495)\ttotal: 7.92s\tremaining: 7.89s\n",
      "600:\tlearn: 0.4403775\ttest: 0.4763905\tbest: 0.4763705 (594)\ttotal: 9.42s\tremaining: 6.26s\n",
      "700:\tlearn: 0.4385503\ttest: 0.4763528\tbest: 0.4763470 (684)\ttotal: 10.9s\tremaining: 4.66s\n",
      "800:\tlearn: 0.4369365\ttest: 0.4762529\tbest: 0.4762529 (800)\ttotal: 12.6s\tremaining: 3.13s\n",
      "900:\tlearn: 0.4354614\ttest: 0.4764214\tbest: 0.4762498 (814)\ttotal: 15.2s\tremaining: 1.67s\n",
      "bestTest = 0.4762498183\n",
      "bestIteration = 814\n",
      "Shrink model to first 815 iterations.\n",
      "===== ACCURACY SCORE 0.789644 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779040 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6879284\ttest: 0.6880503\tbest: 0.6880503 (0)\ttotal: 17.4ms\tremaining: 17.4s\n",
      "100:\tlearn: 0.4852330\ttest: 0.4985385\tbest: 0.4985385 (100)\ttotal: 1.55s\tremaining: 13.8s\n",
      "200:\tlearn: 0.4574002\ttest: 0.4812404\tbest: 0.4812404 (200)\ttotal: 3.05s\tremaining: 12.1s\n",
      "300:\tlearn: 0.4494909\ttest: 0.4793706\tbest: 0.4793697 (299)\ttotal: 4.56s\tremaining: 10.6s\n",
      "400:\tlearn: 0.4454562\ttest: 0.4790645\tbest: 0.4790510 (392)\ttotal: 6.1s\tremaining: 9.11s\n",
      "500:\tlearn: 0.4427253\ttest: 0.4790723\tbest: 0.4789888 (430)\ttotal: 8.14s\tremaining: 8.11s\n",
      "bestTest = 0.4789888043\n",
      "bestIteration = 430\n",
      "Shrink model to first 431 iterations.\n",
      "===== ACCURACY SCORE 0.784097 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6878701\ttest: 0.6882011\tbest: 0.6882011 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4840004\ttest: 0.5080963\tbest: 0.5080963 (100)\ttotal: 1.51s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4560405\ttest: 0.4938185\tbest: 0.4938185 (200)\ttotal: 3.01s\tremaining: 12s\n",
      "300:\tlearn: 0.4482629\ttest: 0.4926604\tbest: 0.4926604 (300)\ttotal: 4.51s\tremaining: 10.5s\n",
      "400:\tlearn: 0.4444000\ttest: 0.4926808\tbest: 0.4925348 (361)\ttotal: 6.04s\tremaining: 9.02s\n",
      "bestTest = 0.4925348157\n",
      "bestIteration = 361\n",
      "Shrink model to first 362 iterations.\n",
      "===== ACCURACY SCORE 0.774050 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6878623\ttest: 0.6880076\tbest: 0.6880076 (0)\ttotal: 16.5ms\tremaining: 16.5s\n",
      "100:\tlearn: 0.4835003\ttest: 0.4994368\tbest: 0.4994368 (100)\ttotal: 1.52s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4556283\ttest: 0.4825174\tbest: 0.4825174 (200)\ttotal: 3.03s\tremaining: 12.1s\n",
      "300:\tlearn: 0.4478322\ttest: 0.4807637\tbest: 0.4807590 (298)\ttotal: 4.54s\tremaining: 10.5s\n",
      "400:\tlearn: 0.4438742\ttest: 0.4803177\tbest: 0.4802994 (391)\ttotal: 6.05s\tremaining: 9.04s\n",
      "500:\tlearn: 0.4412020\ttest: 0.4801619\tbest: 0.4801613 (498)\ttotal: 7.69s\tremaining: 7.66s\n",
      "600:\tlearn: 0.4390475\ttest: 0.4801484\tbest: 0.4801090 (574)\ttotal: 9.28s\tremaining: 6.16s\n",
      "bestTest = 0.480108969\n",
      "bestIteration = 574\n",
      "Shrink model to first 575 iterations.\n",
      "===== ACCURACY SCORE 0.784498 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6878606\ttest: 0.6881433\tbest: 0.6881433 (0)\ttotal: 28.8ms\tremaining: 28.8s\n",
      "100:\tlearn: 0.4827413\ttest: 0.5039131\tbest: 0.5039131 (100)\ttotal: 2.02s\tremaining: 18s\n",
      "200:\tlearn: 0.4548781\ttest: 0.4886221\tbest: 0.4886221 (200)\ttotal: 3.53s\tremaining: 14s\n",
      "300:\tlearn: 0.4471134\ttest: 0.4872481\tbest: 0.4872481 (300)\ttotal: 5.07s\tremaining: 11.8s\n",
      "400:\tlearn: 0.4431234\ttest: 0.4868492\tbest: 0.4867950 (393)\ttotal: 6.55s\tremaining: 9.79s\n",
      "500:\tlearn: 0.4403646\ttest: 0.4869071\tbest: 0.4867707 (465)\ttotal: 8.04s\tremaining: 8.01s\n",
      "bestTest = 0.4867707376\n",
      "bestIteration = 465\n",
      "Shrink model to first 466 iterations.\n",
      "===== ACCURACY SCORE 0.778551 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6878924\ttest: 0.6881170\tbest: 0.6881170 (0)\ttotal: 17.1ms\tremaining: 17.1s\n",
      "100:\tlearn: 0.4837055\ttest: 0.5022089\tbest: 0.5022089 (100)\ttotal: 1.52s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4556143\ttest: 0.4854759\tbest: 0.4854759 (200)\ttotal: 3.03s\tremaining: 12s\n",
      "300:\tlearn: 0.4478418\ttest: 0.4840475\tbest: 0.4840418 (293)\ttotal: 4.5s\tremaining: 10.5s\n",
      "400:\tlearn: 0.4438806\ttest: 0.4838053\tbest: 0.4837941 (396)\ttotal: 6s\tremaining: 8.96s\n",
      "500:\tlearn: 0.4411714\ttest: 0.4837933\tbest: 0.4837790 (404)\ttotal: 7.49s\tremaining: 7.46s\n",
      "bestTest = 0.4837790432\n",
      "bestIteration = 404\n",
      "Shrink model to first 405 iterations.\n",
      "===== ACCURACY SCORE 0.784854 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6878505\ttest: 0.6880346\tbest: 0.6880346 (0)\ttotal: 16ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4847597\ttest: 0.5072082\tbest: 0.5072082 (100)\ttotal: 1.54s\tremaining: 13.7s\n",
      "200:\tlearn: 0.4567849\ttest: 0.4922620\tbest: 0.4922620 (200)\ttotal: 3.02s\tremaining: 12s\n",
      "300:\tlearn: 0.4490024\ttest: 0.4908210\tbest: 0.4908204 (299)\ttotal: 4.5s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4450256\ttest: 0.4903990\tbest: 0.4903725 (398)\ttotal: 5.97s\tremaining: 8.92s\n",
      "500:\tlearn: 0.4423358\ttest: 0.4901672\tbest: 0.4901048 (478)\ttotal: 7.45s\tremaining: 7.42s\n",
      "bestTest = 0.490104758\n",
      "bestIteration = 478\n",
      "Shrink model to first 479 iterations.\n",
      "===== ACCURACY SCORE 0.776696 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6878893\ttest: 0.6882889\tbest: 0.6882889 (0)\ttotal: 16.5ms\tremaining: 16.5s\n",
      "100:\tlearn: 0.4837461\ttest: 0.5126335\tbest: 0.5126335 (100)\ttotal: 1.52s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4556546\ttest: 0.4988718\tbest: 0.4988718 (200)\ttotal: 3.02s\tremaining: 12s\n",
      "300:\tlearn: 0.4478706\ttest: 0.4975636\tbest: 0.4975636 (300)\ttotal: 5.66s\tremaining: 13.2s\n",
      "400:\tlearn: 0.4438088\ttest: 0.4969436\tbest: 0.4969436 (400)\ttotal: 7.17s\tremaining: 10.7s\n",
      "500:\tlearn: 0.4411196\ttest: 0.4965173\tbest: 0.4965173 (500)\ttotal: 8.67s\tremaining: 8.63s\n",
      "600:\tlearn: 0.4389500\ttest: 0.4961077\tbest: 0.4961077 (600)\ttotal: 10.2s\tremaining: 6.75s\n",
      "700:\tlearn: 0.4371211\ttest: 0.4957214\tbest: 0.4957138 (699)\ttotal: 11.7s\tremaining: 4.98s\n",
      "800:\tlearn: 0.4355057\ttest: 0.4954884\tbest: 0.4954884 (800)\ttotal: 13.2s\tremaining: 3.27s\n",
      "900:\tlearn: 0.4340010\ttest: 0.4951690\tbest: 0.4951564 (894)\ttotal: 14.7s\tremaining: 1.61s\n",
      "999:\tlearn: 0.4325972\ttest: 0.4949350\tbest: 0.4949329 (998)\ttotal: 16.2s\tremaining: 0us\n",
      "bestTest = 0.4949329369\n",
      "bestIteration = 998\n",
      "Shrink model to first 999 iterations.\n",
      "===== ACCURACY SCORE 0.774857 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878341\ttest: 0.6882045\tbest: 0.6882045 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4824694\ttest: 0.5084426\tbest: 0.5084426 (100)\ttotal: 1.51s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4543310\ttest: 0.4944235\tbest: 0.4944235 (200)\ttotal: 2.99s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4464139\ttest: 0.4933391\tbest: 0.4933360 (299)\ttotal: 4.47s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4424233\ttest: 0.4933854\tbest: 0.4932854 (312)\ttotal: 5.96s\tremaining: 8.91s\n",
      "bestTest = 0.4932854047\n",
      "bestIteration = 312\n",
      "Shrink model to first 313 iterations.\n",
      "===== ACCURACY SCORE 0.769892 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6879102\ttest: 0.6881586\tbest: 0.6881586 (0)\ttotal: 16.3ms\tremaining: 16.3s\n",
      "100:\tlearn: 0.4843304\ttest: 0.5062128\tbest: 0.5062128 (100)\ttotal: 1.51s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4562254\ttest: 0.4918314\tbest: 0.4918314 (200)\ttotal: 3.06s\tremaining: 12.2s\n",
      "300:\tlearn: 0.4482253\ttest: 0.4914096\tbest: 0.4912068 (259)\ttotal: 4.86s\tremaining: 11.3s\n",
      "bestTest = 0.4912068024\n",
      "bestIteration = 259\n",
      "Shrink model to first 260 iterations.\n",
      "===== ACCURACY SCORE 0.777843 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6878581\ttest: 0.6879130\tbest: 0.6879130 (0)\ttotal: 17.4ms\tremaining: 17.3s\n",
      "100:\tlearn: 0.4848334\ttest: 0.4986965\tbest: 0.4986965 (100)\ttotal: 1.53s\tremaining: 13.6s\n",
      "200:\tlearn: 0.4567352\ttest: 0.4807268\tbest: 0.4807268 (200)\ttotal: 3.07s\tremaining: 12.2s\n",
      "300:\tlearn: 0.4488165\ttest: 0.4783195\tbest: 0.4783195 (300)\ttotal: 5.04s\tremaining: 11.7s\n",
      "400:\tlearn: 0.4448960\ttest: 0.4775534\tbest: 0.4775534 (400)\ttotal: 7.02s\tremaining: 10.5s\n",
      "500:\tlearn: 0.4422383\ttest: 0.4770605\tbest: 0.4770551 (499)\ttotal: 8.91s\tremaining: 8.88s\n",
      "600:\tlearn: 0.4401311\ttest: 0.4766488\tbest: 0.4766377 (598)\ttotal: 10.4s\tremaining: 6.93s\n",
      "700:\tlearn: 0.4382559\ttest: 0.4763175\tbest: 0.4763111 (693)\ttotal: 11.9s\tremaining: 5.08s\n",
      "800:\tlearn: 0.4366282\ttest: 0.4760578\tbest: 0.4760562 (798)\ttotal: 13.4s\tremaining: 3.33s\n",
      "900:\tlearn: 0.4351353\ttest: 0.4758956\tbest: 0.4758956 (900)\ttotal: 14.9s\tremaining: 1.63s\n",
      "999:\tlearn: 0.4337611\ttest: 0.4756590\tbest: 0.4756531 (994)\ttotal: 16.4s\tremaining: 0us\n",
      "bestTest = 0.4756530585\n",
      "bestIteration = 994\n",
      "Shrink model to first 995 iterations.\n",
      "===== ACCURACY SCORE 0.786732 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779230 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6878828\ttest: 0.6881679\tbest: 0.6881679 (0)\ttotal: 16.4ms\tremaining: 16.4s\n",
      "100:\tlearn: 0.4828865\ttest: 0.5070042\tbest: 0.5070042 (100)\ttotal: 1.61s\tremaining: 14.3s\n",
      "200:\tlearn: 0.4547707\ttest: 0.4930881\tbest: 0.4930881 (200)\ttotal: 3.51s\tremaining: 14s\n",
      "300:\tlearn: 0.4469888\ttest: 0.4922969\tbest: 0.4922969 (300)\ttotal: 5s\tremaining: 11.6s\n",
      "400:\tlearn: 0.4430760\ttest: 0.4924424\tbest: 0.4922846 (326)\ttotal: 6.5s\tremaining: 9.72s\n",
      "bestTest = 0.4922845603\n",
      "bestIteration = 326\n",
      "Shrink model to first 327 iterations.\n",
      "===== ACCURACY SCORE 0.775110 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6879226\ttest: 0.6881448\tbest: 0.6881448 (0)\ttotal: 32.9ms\tremaining: 32.9s\n",
      "100:\tlearn: 0.4847179\ttest: 0.5018300\tbest: 0.5018300 (100)\ttotal: 1.54s\tremaining: 13.7s\n",
      "200:\tlearn: 0.4566754\ttest: 0.4844717\tbest: 0.4844717 (200)\ttotal: 3.05s\tremaining: 12.1s\n",
      "300:\tlearn: 0.4488303\ttest: 0.4823153\tbest: 0.4823129 (293)\ttotal: 4.62s\tremaining: 10.7s\n",
      "400:\tlearn: 0.4448716\ttest: 0.4819355\tbest: 0.4818927 (390)\ttotal: 6.41s\tremaining: 9.57s\n",
      "500:\tlearn: 0.4421850\ttest: 0.4818089\tbest: 0.4817788 (458)\ttotal: 7.9s\tremaining: 7.87s\n",
      "bestTest = 0.481778839\n",
      "bestIteration = 458\n",
      "Shrink model to first 459 iterations.\n",
      "===== ACCURACY SCORE 0.781833 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6877833\ttest: 0.6880383\tbest: 0.6880383 (0)\ttotal: 17.2ms\tremaining: 17.2s\n",
      "100:\tlearn: 0.4830250\ttest: 0.5075745\tbest: 0.5075745 (100)\ttotal: 2.04s\tremaining: 18.2s\n",
      "200:\tlearn: 0.4549405\ttest: 0.4928520\tbest: 0.4928520 (200)\ttotal: 3.82s\tremaining: 15.2s\n",
      "300:\tlearn: 0.4470324\ttest: 0.4916174\tbest: 0.4916041 (296)\ttotal: 5.3s\tremaining: 12.3s\n",
      "400:\tlearn: 0.4429721\ttest: 0.4915442\tbest: 0.4915334 (395)\ttotal: 7.16s\tremaining: 10.7s\n",
      "500:\tlearn: 0.4402340\ttest: 0.4915687\tbest: 0.4914701 (458)\ttotal: 8.63s\tremaining: 8.6s\n",
      "bestTest = 0.4914701084\n",
      "bestIteration = 458\n",
      "Shrink model to first 459 iterations.\n",
      "===== ACCURACY SCORE 0.775962 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6879087\ttest: 0.6881862\tbest: 0.6881862 (0)\ttotal: 16.9ms\tremaining: 16.9s\n",
      "100:\tlearn: 0.4843115\ttest: 0.5054411\tbest: 0.5054411 (100)\ttotal: 1.51s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4562217\ttest: 0.4892054\tbest: 0.4892054 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4482362\ttest: 0.4870356\tbest: 0.4870356 (300)\ttotal: 4.43s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4442224\ttest: 0.4866089\tbest: 0.4865944 (391)\ttotal: 5.94s\tremaining: 8.87s\n",
      "500:\tlearn: 0.4415049\ttest: 0.4862842\tbest: 0.4862807 (499)\ttotal: 7.75s\tremaining: 7.71s\n",
      "bestTest = 0.4862807475\n",
      "bestIteration = 499\n",
      "Shrink model to first 500 iterations.\n",
      "===== ACCURACY SCORE 0.778334 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6878753\ttest: 0.6880789\tbest: 0.6880789 (0)\ttotal: 15.8ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4834032\ttest: 0.5017262\tbest: 0.5017262 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4553527\ttest: 0.4854552\tbest: 0.4854552 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4475336\ttest: 0.4839469\tbest: 0.4839469 (300)\ttotal: 4.47s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4435797\ttest: 0.4837162\tbest: 0.4836697 (365)\ttotal: 5.94s\tremaining: 8.88s\n",
      "500:\tlearn: 0.4409016\ttest: 0.4835784\tbest: 0.4835784 (500)\ttotal: 7.64s\tremaining: 7.61s\n",
      "600:\tlearn: 0.4387509\ttest: 0.4836016\tbest: 0.4835216 (540)\ttotal: 9.37s\tremaining: 6.22s\n",
      "bestTest = 0.4835216387\n",
      "bestIteration = 540\n",
      "Shrink model to first 541 iterations.\n",
      "===== ACCURACY SCORE 0.779759 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6878563\ttest: 0.6881702\tbest: 0.6881702 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4827928\ttest: 0.5057263\tbest: 0.5057263 (100)\ttotal: 1.74s\tremaining: 15.5s\n",
      "200:\tlearn: 0.4547709\ttest: 0.4910127\tbest: 0.4910127 (200)\ttotal: 3.79s\tremaining: 15.1s\n",
      "300:\tlearn: 0.4469142\ttest: 0.4901371\tbest: 0.4900400 (284)\ttotal: 5.27s\tremaining: 12.2s\n",
      "400:\tlearn: 0.4429911\ttest: 0.4900361\tbest: 0.4899879 (390)\ttotal: 6.82s\tremaining: 10.2s\n",
      "bestTest = 0.4899879106\n",
      "bestIteration = 390\n",
      "Shrink model to first 391 iterations.\n",
      "===== ACCURACY SCORE 0.776676 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6879464\ttest: 0.6881375\tbest: 0.6881375 (0)\ttotal: 16ms\tremaining: 16s\n",
      "100:\tlearn: 0.4855524\ttest: 0.5029812\tbest: 0.5029812 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4578392\ttest: 0.4865622\tbest: 0.4865622 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4500892\ttest: 0.4848643\tbest: 0.4848550 (299)\ttotal: 4.46s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4461508\ttest: 0.4845643\tbest: 0.4845390 (393)\ttotal: 5.96s\tremaining: 8.9s\n",
      "500:\tlearn: 0.4435566\ttest: 0.4844751\tbest: 0.4844444 (464)\ttotal: 7.42s\tremaining: 7.39s\n",
      "bestTest = 0.484444439\n",
      "bestIteration = 464\n",
      "Shrink model to first 465 iterations.\n",
      "===== ACCURACY SCORE 0.782010 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6879217\ttest: 0.6881645\tbest: 0.6881645 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4845546\ttest: 0.5030273\tbest: 0.5030273 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4564939\ttest: 0.4860875\tbest: 0.4860875 (200)\ttotal: 2.94s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4487145\ttest: 0.4836878\tbest: 0.4836878 (300)\ttotal: 4.39s\tremaining: 10.2s\n",
      "400:\tlearn: 0.4447592\ttest: 0.4830875\tbest: 0.4830669 (396)\ttotal: 5.85s\tremaining: 8.74s\n",
      "500:\tlearn: 0.4420531\ttest: 0.4826954\tbest: 0.4826766 (499)\ttotal: 7.31s\tremaining: 7.28s\n",
      "600:\tlearn: 0.4398986\ttest: 0.4825614\tbest: 0.4825614 (600)\ttotal: 8.8s\tremaining: 5.84s\n",
      "700:\tlearn: 0.4381092\ttest: 0.4823906\tbest: 0.4823851 (699)\ttotal: 10.5s\tremaining: 4.47s\n",
      "800:\tlearn: 0.4365056\ttest: 0.4821920\tbest: 0.4821911 (799)\ttotal: 12.1s\tremaining: 2.99s\n",
      "900:\tlearn: 0.4350250\ttest: 0.4821199\tbest: 0.4821074 (897)\ttotal: 13.5s\tremaining: 1.48s\n",
      "999:\tlearn: 0.4336631\ttest: 0.4821010\tbest: 0.4820644 (986)\ttotal: 15.8s\tremaining: 0us\n",
      "bestTest = 0.4820644131\n",
      "bestIteration = 986\n",
      "Shrink model to first 987 iterations.\n",
      "===== ACCURACY SCORE 0.783477 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6878867\ttest: 0.6882136\tbest: 0.6882136 (0)\ttotal: 15.9ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4838929\ttest: 0.5090114\tbest: 0.5090114 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4556266\ttest: 0.4952953\tbest: 0.4952953 (200)\ttotal: 2.98s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4476625\ttest: 0.4952117\tbest: 0.4948719 (233)\ttotal: 4.79s\tremaining: 11.1s\n",
      "bestTest = 0.4948718764\n",
      "bestIteration = 233\n",
      "Shrink model to first 234 iterations.\n",
      "===== ACCURACY SCORE 0.772723 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6879093\ttest: 0.6881410\tbest: 0.6881410 (0)\ttotal: 15ms\tremaining: 15s\n",
      "100:\tlearn: 0.4832695\ttest: 0.5030401\tbest: 0.5030401 (100)\ttotal: 1.52s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4554621\ttest: 0.4870220\tbest: 0.4870220 (200)\ttotal: 2.99s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4476857\ttest: 0.4848477\tbest: 0.4848477 (300)\ttotal: 4.44s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4436748\ttest: 0.4842403\tbest: 0.4842211 (398)\ttotal: 5.9s\tremaining: 8.81s\n",
      "500:\tlearn: 0.4409893\ttest: 0.4840809\tbest: 0.4840750 (497)\ttotal: 7.42s\tremaining: 7.39s\n",
      "600:\tlearn: 0.4388242\ttest: 0.4837806\tbest: 0.4837806 (600)\ttotal: 9.14s\tremaining: 6.07s\n",
      "700:\tlearn: 0.4370126\ttest: 0.4836357\tbest: 0.4836132 (695)\ttotal: 10.7s\tremaining: 4.58s\n",
      "800:\tlearn: 0.4353253\ttest: 0.4834933\tbest: 0.4834930 (799)\ttotal: 12.2s\tremaining: 3.03s\n",
      "900:\tlearn: 0.4337956\ttest: 0.4833455\tbest: 0.4833408 (899)\ttotal: 13.7s\tremaining: 1.5s\n",
      "999:\tlearn: 0.4324877\ttest: 0.4833180\tbest: 0.4832935 (985)\ttotal: 15.1s\tremaining: 0us\n",
      "bestTest = 0.4832934945\n",
      "bestIteration = 985\n",
      "Shrink model to first 986 iterations.\n",
      "===== ACCURACY SCORE 0.777856 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778380 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6879281\ttest: 0.6881306\tbest: 0.6881306 (0)\ttotal: 16.6ms\tremaining: 16.6s\n",
      "100:\tlearn: 0.4853960\ttest: 0.5048816\tbest: 0.5048816 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4578570\ttest: 0.4899424\tbest: 0.4899424 (200)\ttotal: 3.06s\tremaining: 12.2s\n",
      "300:\tlearn: 0.4502961\ttest: 0.4883807\tbest: 0.4883569 (293)\ttotal: 4.87s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4464973\ttest: 0.4879582\tbest: 0.4878981 (389)\ttotal: 6.33s\tremaining: 9.45s\n",
      "500:\tlearn: 0.4438822\ttest: 0.4879422\tbest: 0.4878228 (424)\ttotal: 8.6s\tremaining: 8.56s\n",
      "bestTest = 0.4878228464\n",
      "bestIteration = 424\n",
      "Shrink model to first 425 iterations.\n",
      "===== ACCURACY SCORE 0.777823 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6878641\ttest: 0.6882217\tbest: 0.6882217 (0)\ttotal: 16.8ms\tremaining: 16.8s\n",
      "100:\tlearn: 0.4829214\ttest: 0.5074340\tbest: 0.5074340 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4546539\ttest: 0.4923842\tbest: 0.4923842 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4467216\ttest: 0.4910990\tbest: 0.4910795 (291)\ttotal: 4.55s\tremaining: 10.6s\n",
      "400:\tlearn: 0.4426781\ttest: 0.4912356\tbest: 0.4910659 (316)\ttotal: 6.38s\tremaining: 9.53s\n",
      "bestTest = 0.4910658513\n",
      "bestIteration = 316\n",
      "Shrink model to first 317 iterations.\n",
      "===== ACCURACY SCORE 0.774695 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6878834\ttest: 0.6881593\tbest: 0.6881593 (0)\ttotal: 16.1ms\tremaining: 16.1s\n",
      "100:\tlearn: 0.4834156\ttest: 0.5054745\tbest: 0.5054745 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4554138\ttest: 0.4900695\tbest: 0.4900695 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4475490\ttest: 0.4885999\tbest: 0.4885999 (300)\ttotal: 4.44s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4435094\ttest: 0.4884819\tbest: 0.4884718 (397)\ttotal: 5.89s\tremaining: 8.8s\n",
      "500:\tlearn: 0.4408200\ttest: 0.4883332\tbest: 0.4883332 (500)\ttotal: 7.41s\tremaining: 7.38s\n",
      "600:\tlearn: 0.4386875\ttest: 0.4882610\tbest: 0.4882508 (597)\ttotal: 9.15s\tremaining: 6.08s\n",
      "bestTest = 0.4882507662\n",
      "bestIteration = 597\n",
      "Shrink model to first 598 iterations.\n",
      "===== ACCURACY SCORE 0.783050 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6878959\ttest: 0.6880528\tbest: 0.6880528 (0)\ttotal: 16.6ms\tremaining: 16.5s\n",
      "100:\tlearn: 0.4845493\ttest: 0.4990166\tbest: 0.4990166 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4566714\ttest: 0.4819758\tbest: 0.4819758 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4489395\ttest: 0.4804617\tbest: 0.4804551 (299)\ttotal: 4.47s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4449039\ttest: 0.4803533\tbest: 0.4802654 (351)\ttotal: 5.95s\tremaining: 8.89s\n",
      "bestTest = 0.4802653724\n",
      "bestIteration = 351\n",
      "Shrink model to first 352 iterations.\n",
      "===== ACCURACY SCORE 0.784917 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6877912\ttest: 0.6879298\tbest: 0.6879298 (0)\ttotal: 28.2ms\tremaining: 28.2s\n",
      "100:\tlearn: 0.4839533\ttest: 0.5007103\tbest: 0.5007103 (100)\ttotal: 1.96s\tremaining: 17.4s\n",
      "200:\tlearn: 0.4559085\ttest: 0.4837152\tbest: 0.4837152 (200)\ttotal: 4.24s\tremaining: 16.8s\n",
      "300:\tlearn: 0.4480937\ttest: 0.4820538\tbest: 0.4820501 (298)\ttotal: 5.71s\tremaining: 13.3s\n",
      "400:\tlearn: 0.4441510\ttest: 0.4815192\tbest: 0.4815098 (392)\ttotal: 7.17s\tremaining: 10.7s\n",
      "500:\tlearn: 0.4414495\ttest: 0.4814924\tbest: 0.4814655 (475)\ttotal: 8.66s\tremaining: 8.63s\n",
      "600:\tlearn: 0.4393336\ttest: 0.4813532\tbest: 0.4813405 (592)\ttotal: 10.3s\tremaining: 6.81s\n",
      "bestTest = 0.4813404849\n",
      "bestIteration = 592\n",
      "Shrink model to first 593 iterations.\n",
      "===== ACCURACY SCORE 0.783507 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6878533\ttest: 0.6882041\tbest: 0.6882041 (0)\ttotal: 15.6ms\tremaining: 15.6s\n",
      "100:\tlearn: 0.4830432\ttest: 0.5081677\tbest: 0.5081677 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4550986\ttest: 0.4947615\tbest: 0.4947615 (200)\ttotal: 2.94s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4472803\ttest: 0.4941050\tbest: 0.4940903 (299)\ttotal: 4.42s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4433064\ttest: 0.4940474\tbest: 0.4940365 (390)\ttotal: 5.89s\tremaining: 8.79s\n",
      "bestTest = 0.4940365069\n",
      "bestIteration = 390\n",
      "Shrink model to first 391 iterations.\n",
      "===== ACCURACY SCORE 0.778192 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6879291\ttest: 0.6880265\tbest: 0.6880265 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4850234\ttest: 0.4977666\tbest: 0.4977666 (100)\ttotal: 1.92s\tremaining: 17.1s\n",
      "200:\tlearn: 0.4570471\ttest: 0.4800977\tbest: 0.4800977 (200)\ttotal: 3.38s\tremaining: 13.5s\n",
      "300:\tlearn: 0.4491287\ttest: 0.4781015\tbest: 0.4781015 (300)\ttotal: 4.87s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4451110\ttest: 0.4774650\tbest: 0.4774642 (396)\ttotal: 6.38s\tremaining: 9.53s\n",
      "500:\tlearn: 0.4423701\ttest: 0.4771669\tbest: 0.4771546 (497)\ttotal: 7.85s\tremaining: 7.82s\n",
      "600:\tlearn: 0.4402398\ttest: 0.4768970\tbest: 0.4768854 (598)\ttotal: 9.33s\tremaining: 6.2s\n",
      "700:\tlearn: 0.4384745\ttest: 0.4767705\tbest: 0.4767465 (697)\ttotal: 10.9s\tremaining: 4.65s\n",
      "800:\tlearn: 0.4367588\ttest: 0.4766590\tbest: 0.4766590 (800)\ttotal: 13.3s\tremaining: 3.3s\n",
      "900:\tlearn: 0.4352301\ttest: 0.4764618\tbest: 0.4764601 (899)\ttotal: 15s\tremaining: 1.65s\n",
      "999:\tlearn: 0.4338390\ttest: 0.4764115\tbest: 0.4764063 (936)\ttotal: 16.5s\tremaining: 0us\n",
      "bestTest = 0.4764062934\n",
      "bestIteration = 936\n",
      "Shrink model to first 937 iterations.\n",
      "===== ACCURACY SCORE 0.785044 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878138\ttest: 0.6880471\tbest: 0.6880471 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4834757\ttest: 0.5088231\tbest: 0.5088231 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4553030\ttest: 0.4946379\tbest: 0.4946379 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4475087\ttest: 0.4934650\tbest: 0.4934650 (300)\ttotal: 4.54s\tremaining: 10.6s\n",
      "400:\tlearn: 0.4435964\ttest: 0.4930896\tbest: 0.4930486 (388)\ttotal: 6.32s\tremaining: 9.44s\n",
      "500:\tlearn: 0.4408597\ttest: 0.4927835\tbest: 0.4927835 (500)\ttotal: 7.78s\tremaining: 7.74s\n",
      "600:\tlearn: 0.4387106\ttest: 0.4927633\tbest: 0.4927532 (592)\ttotal: 9.23s\tremaining: 6.13s\n",
      "bestTest = 0.4927532006\n",
      "bestIteration = 592\n",
      "Shrink model to first 593 iterations.\n",
      "===== ACCURACY SCORE 0.770379 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6878670\ttest: 0.6882512\tbest: 0.6882512 (0)\ttotal: 16.7ms\tremaining: 16.7s\n",
      "100:\tlearn: 0.4830064\ttest: 0.5096192\tbest: 0.5096192 (100)\ttotal: 1.54s\tremaining: 13.7s\n",
      "200:\tlearn: 0.4548030\ttest: 0.4956255\tbest: 0.4956255 (200)\ttotal: 3.04s\tremaining: 12.1s\n",
      "300:\tlearn: 0.4468687\ttest: 0.4948615\tbest: 0.4948514 (288)\ttotal: 4.88s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4427967\ttest: 0.4950128\tbest: 0.4948208 (311)\ttotal: 6.35s\tremaining: 9.48s\n",
      "bestTest = 0.4948208185\n",
      "bestIteration = 311\n",
      "Shrink model to first 312 iterations.\n",
      "===== ACCURACY SCORE 0.770335 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6878367\ttest: 0.6880888\tbest: 0.6880888 (0)\ttotal: 15.5ms\tremaining: 15.5s\n",
      "100:\tlearn: 0.4822690\ttest: 0.5022509\tbest: 0.5022509 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4542471\ttest: 0.4864028\tbest: 0.4864028 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4463467\ttest: 0.4846686\tbest: 0.4846659 (299)\ttotal: 4.43s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4422753\ttest: 0.4841422\tbest: 0.4841321 (394)\ttotal: 5.92s\tremaining: 8.85s\n",
      "500:\tlearn: 0.4395898\ttest: 0.4839929\tbest: 0.4839717 (498)\ttotal: 7.74s\tremaining: 7.71s\n",
      "600:\tlearn: 0.4375339\ttest: 0.4839520\tbest: 0.4839257 (536)\ttotal: 10.1s\tremaining: 6.72s\n",
      "bestTest = 0.4839257441\n",
      "bestIteration = 536\n",
      "Shrink model to first 537 iterations.\n",
      "===== ACCURACY SCORE 0.780534 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778820 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6878889\ttest: 0.6881217\tbest: 0.6881217 (0)\ttotal: 16.5ms\tremaining: 16.5s\n",
      "100:\tlearn: 0.4838679\ttest: 0.5038867\tbest: 0.5038867 (100)\ttotal: 1.52s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4559227\ttest: 0.4888477\tbest: 0.4888477 (200)\ttotal: 3.07s\tremaining: 12.2s\n",
      "300:\tlearn: 0.4480546\ttest: 0.4876332\tbest: 0.4876011 (286)\ttotal: 4.57s\tremaining: 10.6s\n",
      "400:\tlearn: 0.4440627\ttest: 0.4875617\tbest: 0.4875366 (315)\ttotal: 6.13s\tremaining: 9.15s\n",
      "500:\tlearn: 0.4413445\ttest: 0.4874877\tbest: 0.4874624 (434)\ttotal: 7.89s\tremaining: 7.86s\n",
      "600:\tlearn: 0.4391937\ttest: 0.4874702\tbest: 0.4874339 (505)\ttotal: 9.36s\tremaining: 6.21s\n",
      "bestTest = 0.4874339184\n",
      "bestIteration = 505\n",
      "Shrink model to first 506 iterations.\n",
      "===== ACCURACY SCORE 0.781624 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6878737\ttest: 0.6881657\tbest: 0.6881657 (0)\ttotal: 16.6ms\tremaining: 16.6s\n",
      "100:\tlearn: 0.4835852\ttest: 0.5062649\tbest: 0.5062649 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4555212\ttest: 0.4913396\tbest: 0.4913396 (200)\ttotal: 3.01s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4476462\ttest: 0.4902882\tbest: 0.4902882 (300)\ttotal: 4.47s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4436426\ttest: 0.4902755\tbest: 0.4901914 (365)\ttotal: 5.94s\tremaining: 8.87s\n",
      "bestTest = 0.4901913811\n",
      "bestIteration = 365\n",
      "Shrink model to first 366 iterations.\n",
      "===== ACCURACY SCORE 0.778582 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6878704\ttest: 0.6882270\tbest: 0.6882270 (0)\ttotal: 14.5ms\tremaining: 14.5s\n",
      "100:\tlearn: 0.4819730\ttest: 0.5086228\tbest: 0.5086228 (100)\ttotal: 1.51s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4537791\ttest: 0.4941020\tbest: 0.4941020 (200)\ttotal: 2.98s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4460776\ttest: 0.4929172\tbest: 0.4929172 (300)\ttotal: 4.5s\tremaining: 10.5s\n",
      "400:\tlearn: 0.4421038\ttest: 0.4928312\tbest: 0.4927806 (390)\ttotal: 5.98s\tremaining: 8.94s\n",
      "500:\tlearn: 0.4394609\ttest: 0.4927308\tbest: 0.4926749 (471)\ttotal: 7.45s\tremaining: 7.42s\n",
      "600:\tlearn: 0.4374265\ttest: 0.4926793\tbest: 0.4926257 (559)\ttotal: 9.09s\tremaining: 6.03s\n",
      "bestTest = 0.4926257049\n",
      "bestIteration = 559\n",
      "Shrink model to first 560 iterations.\n",
      "===== ACCURACY SCORE 0.771710 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6879141\ttest: 0.6882102\tbest: 0.6882102 (0)\ttotal: 16.1ms\tremaining: 16.1s\n",
      "100:\tlearn: 0.4844234\ttest: 0.5080865\tbest: 0.5080865 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4563155\ttest: 0.4936170\tbest: 0.4936170 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4483655\ttest: 0.4925927\tbest: 0.4925840 (299)\ttotal: 4.43s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4443293\ttest: 0.4925442\tbest: 0.4925442 (400)\ttotal: 5.91s\tremaining: 8.82s\n",
      "500:\tlearn: 0.4416504\ttest: 0.4924253\tbest: 0.4924253 (500)\ttotal: 7.41s\tremaining: 7.38s\n",
      "600:\tlearn: 0.4394787\ttest: 0.4922441\tbest: 0.4922304 (593)\ttotal: 9.04s\tremaining: 6s\n",
      "700:\tlearn: 0.4376936\ttest: 0.4921362\tbest: 0.4920693 (669)\ttotal: 10.8s\tremaining: 4.6s\n",
      "800:\tlearn: 0.4360133\ttest: 0.4919234\tbest: 0.4919234 (800)\ttotal: 12.3s\tremaining: 3.05s\n",
      "900:\tlearn: 0.4345257\ttest: 0.4918717\tbest: 0.4918511 (875)\ttotal: 13.8s\tremaining: 1.51s\n",
      "999:\tlearn: 0.4331891\ttest: 0.4917909\tbest: 0.4917879 (984)\ttotal: 15.2s\tremaining: 0us\n",
      "bestTest = 0.4917879208\n",
      "bestIteration = 984\n",
      "Shrink model to first 985 iterations.\n",
      "===== ACCURACY SCORE 0.775326 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6878202\ttest: 0.6880000\tbest: 0.6880000 (0)\ttotal: 16ms\tremaining: 16s\n",
      "100:\tlearn: 0.4840656\ttest: 0.5046773\tbest: 0.5046773 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4559739\ttest: 0.4889161\tbest: 0.4889161 (200)\ttotal: 3.05s\tremaining: 12.1s\n",
      "300:\tlearn: 0.4481651\ttest: 0.4873571\tbest: 0.4873296 (294)\ttotal: 4.96s\tremaining: 11.5s\n",
      "400:\tlearn: 0.4441523\ttest: 0.4871392\tbest: 0.4870892 (388)\ttotal: 6.46s\tremaining: 9.65s\n",
      "500:\tlearn: 0.4414096\ttest: 0.4870583\tbest: 0.4869719 (485)\ttotal: 7.92s\tremaining: 7.89s\n",
      "bestTest = 0.4869719136\n",
      "bestIteration = 485\n",
      "Shrink model to first 486 iterations.\n",
      "===== ACCURACY SCORE 0.776783 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6878477\ttest: 0.6880606\tbest: 0.6880606 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4832266\ttest: 0.5018021\tbest: 0.5018021 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4551039\ttest: 0.4861296\tbest: 0.4861296 (200)\ttotal: 3.52s\tremaining: 14s\n",
      "300:\tlearn: 0.4471106\ttest: 0.4843423\tbest: 0.4843395 (299)\ttotal: 5.63s\tremaining: 13.1s\n",
      "400:\tlearn: 0.4430359\ttest: 0.4841155\tbest: 0.4841115 (399)\ttotal: 7.18s\tremaining: 10.7s\n",
      "500:\tlearn: 0.4402908\ttest: 0.4841498\tbest: 0.4840622 (432)\ttotal: 8.64s\tremaining: 8.61s\n",
      "bestTest = 0.4840621819\n",
      "bestIteration = 432\n",
      "Shrink model to first 433 iterations.\n",
      "===== ACCURACY SCORE 0.781153 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6879438\ttest: 0.6881568\tbest: 0.6881568 (0)\ttotal: 15.5ms\tremaining: 15.5s\n",
      "100:\tlearn: 0.4847098\ttest: 0.5023590\tbest: 0.5023590 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4568641\ttest: 0.4856350\tbest: 0.4856350 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4490089\ttest: 0.4837225\tbest: 0.4837225 (300)\ttotal: 4.42s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4450218\ttest: 0.4832033\tbest: 0.4831834 (392)\ttotal: 6.36s\tremaining: 9.51s\n",
      "500:\tlearn: 0.4423060\ttest: 0.4829416\tbest: 0.4829014 (494)\ttotal: 7.82s\tremaining: 7.79s\n",
      "600:\tlearn: 0.4401885\ttest: 0.4828128\tbest: 0.4827947 (586)\ttotal: 9.27s\tremaining: 6.15s\n",
      "700:\tlearn: 0.4383883\ttest: 0.4827572\tbest: 0.4827225 (694)\ttotal: 10.7s\tremaining: 4.58s\n",
      "800:\tlearn: 0.4367718\ttest: 0.4826093\tbest: 0.4826093 (800)\ttotal: 12.2s\tremaining: 3.04s\n",
      "900:\tlearn: 0.4352711\ttest: 0.4825584\tbest: 0.4825248 (884)\ttotal: 13.7s\tremaining: 1.51s\n",
      "999:\tlearn: 0.4338776\ttest: 0.4824673\tbest: 0.4824344 (980)\ttotal: 15.2s\tremaining: 0us\n",
      "bestTest = 0.4824343661\n",
      "bestIteration = 980\n",
      "Shrink model to first 981 iterations.\n",
      "===== ACCURACY SCORE 0.781400 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6879185\ttest: 0.6881500\tbest: 0.6881500 (0)\ttotal: 41.8ms\tremaining: 41.7s\n",
      "100:\tlearn: 0.4847258\ttest: 0.5040729\tbest: 0.5040729 (100)\ttotal: 1.77s\tremaining: 15.8s\n",
      "200:\tlearn: 0.4566657\ttest: 0.4876865\tbest: 0.4876865 (200)\ttotal: 3.23s\tremaining: 12.8s\n",
      "300:\tlearn: 0.4487599\ttest: 0.4859788\tbest: 0.4859788 (300)\ttotal: 4.69s\tremaining: 10.9s\n",
      "400:\tlearn: 0.4446748\ttest: 0.4857828\tbest: 0.4857491 (375)\ttotal: 6.14s\tremaining: 9.18s\n",
      "500:\tlearn: 0.4419261\ttest: 0.4856437\tbest: 0.4856225 (454)\ttotal: 7.6s\tremaining: 7.57s\n",
      "600:\tlearn: 0.4397320\ttest: 0.4855808\tbest: 0.4855478 (547)\ttotal: 9.88s\tremaining: 6.56s\n",
      "bestTest = 0.4855477699\n",
      "bestIteration = 547\n",
      "Shrink model to first 548 iterations.\n",
      "===== ACCURACY SCORE 0.783445 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6878685\ttest: 0.6880931\tbest: 0.6880931 (0)\ttotal: 16.3ms\tremaining: 16.2s\n",
      "100:\tlearn: 0.4837164\ttest: 0.5031672\tbest: 0.5031672 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4557837\ttest: 0.4870235\tbest: 0.4870235 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4479197\ttest: 0.4853646\tbest: 0.4853646 (300)\ttotal: 4.45s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4439326\ttest: 0.4852243\tbest: 0.4851647 (390)\ttotal: 5.91s\tremaining: 8.82s\n",
      "bestTest = 0.4851646943\n",
      "bestIteration = 390\n",
      "Shrink model to first 391 iterations.\n",
      "===== ACCURACY SCORE 0.776621 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6878293\ttest: 0.6880654\tbest: 0.6880654 (0)\ttotal: 17.3ms\tremaining: 17.3s\n",
      "100:\tlearn: 0.4819699\ttest: 0.5020796\tbest: 0.5020796 (100)\ttotal: 1.57s\tremaining: 14s\n",
      "200:\tlearn: 0.4537458\ttest: 0.4860625\tbest: 0.4860625 (200)\ttotal: 3.29s\tremaining: 13.1s\n",
      "300:\tlearn: 0.4458405\ttest: 0.4840564\tbest: 0.4840564 (300)\ttotal: 4.74s\tremaining: 11s\n",
      "400:\tlearn: 0.4418349\ttest: 0.4835049\tbest: 0.4834995 (399)\ttotal: 6.21s\tremaining: 9.28s\n",
      "500:\tlearn: 0.4391669\ttest: 0.4831567\tbest: 0.4831567 (500)\ttotal: 7.68s\tremaining: 7.65s\n",
      "600:\tlearn: 0.4370196\ttest: 0.4827926\tbest: 0.4827926 (600)\ttotal: 9.17s\tremaining: 6.09s\n",
      "700:\tlearn: 0.4352373\ttest: 0.4825312\tbest: 0.4825127 (689)\ttotal: 10.6s\tremaining: 4.54s\n",
      "800:\tlearn: 0.4336316\ttest: 0.4822877\tbest: 0.4822684 (787)\ttotal: 12.1s\tremaining: 3.02s\n",
      "900:\tlearn: 0.4321223\ttest: 0.4820512\tbest: 0.4820483 (899)\ttotal: 14s\tremaining: 1.53s\n",
      "999:\tlearn: 0.4308028\ttest: 0.4818924\tbest: 0.4818863 (994)\ttotal: 15.4s\tremaining: 0us\n",
      "bestTest = 0.4818862778\n",
      "bestIteration = 994\n",
      "Shrink model to first 995 iterations.\n",
      "===== ACCURACY SCORE 0.782218 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778890 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6879231\ttest: 0.6882126\tbest: 0.6882126 (0)\ttotal: 16ms\tremaining: 16s\n",
      "100:\tlearn: 0.4852402\ttest: 0.5089282\tbest: 0.5089282 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4572196\ttest: 0.4954843\tbest: 0.4954843 (200)\ttotal: 3.01s\tremaining: 12s\n",
      "300:\tlearn: 0.4493902\ttest: 0.4953999\tbest: 0.4951247 (246)\ttotal: 5.2s\tremaining: 12.1s\n",
      "bestTest = 0.4951247212\n",
      "bestIteration = 246\n",
      "Shrink model to first 247 iterations.\n",
      "===== ACCURACY SCORE 0.773940 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6878622\ttest: 0.6881275\tbest: 0.6881275 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4830493\ttest: 0.5013507\tbest: 0.5013507 (100)\ttotal: 1.78s\tremaining: 15.8s\n",
      "200:\tlearn: 0.4547970\ttest: 0.4832035\tbest: 0.4832035 (200)\ttotal: 3.23s\tremaining: 12.8s\n",
      "300:\tlearn: 0.4469291\ttest: 0.4808315\tbest: 0.4808315 (300)\ttotal: 4.72s\tremaining: 11s\n",
      "400:\tlearn: 0.4429945\ttest: 0.4802982\tbest: 0.4802941 (399)\ttotal: 6.24s\tremaining: 9.33s\n",
      "500:\tlearn: 0.4403650\ttest: 0.4800699\tbest: 0.4800280 (479)\ttotal: 7.7s\tremaining: 7.67s\n",
      "600:\tlearn: 0.4382642\ttest: 0.4798100\tbest: 0.4797980 (597)\ttotal: 9.18s\tremaining: 6.09s\n",
      "700:\tlearn: 0.4363781\ttest: 0.4795946\tbest: 0.4795357 (641)\ttotal: 10.6s\tremaining: 4.54s\n",
      "800:\tlearn: 0.4347833\ttest: 0.4794427\tbest: 0.4794378 (798)\ttotal: 12.4s\tremaining: 3.09s\n",
      "900:\tlearn: 0.4332647\ttest: 0.4793765\tbest: 0.4793660 (899)\ttotal: 13.9s\tremaining: 1.53s\n",
      "999:\tlearn: 0.4318569\ttest: 0.4793567\tbest: 0.4793427 (990)\ttotal: 15.4s\tremaining: 0us\n",
      "bestTest = 0.4793426709\n",
      "bestIteration = 990\n",
      "Shrink model to first 991 iterations.\n",
      "===== ACCURACY SCORE 0.786142 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6879043\ttest: 0.6881156\tbest: 0.6881156 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4843036\ttest: 0.5027573\tbest: 0.5027573 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4562975\ttest: 0.4867252\tbest: 0.4867252 (200)\ttotal: 2.93s\tremaining: 11.6s\n",
      "300:\tlearn: 0.4486032\ttest: 0.4852625\tbest: 0.4852291 (293)\ttotal: 4.4s\tremaining: 10.2s\n",
      "400:\tlearn: 0.4447093\ttest: 0.4849532\tbest: 0.4849454 (399)\ttotal: 5.98s\tremaining: 8.94s\n",
      "500:\tlearn: 0.4420482\ttest: 0.4848203\tbest: 0.4848203 (500)\ttotal: 7.75s\tremaining: 7.72s\n",
      "600:\tlearn: 0.4399926\ttest: 0.4847050\tbest: 0.4846579 (558)\ttotal: 9.22s\tremaining: 6.12s\n",
      "700:\tlearn: 0.4382518\ttest: 0.4845509\tbest: 0.4845369 (690)\ttotal: 10.7s\tremaining: 4.56s\n",
      "800:\tlearn: 0.4366624\ttest: 0.4843850\tbest: 0.4843749 (798)\ttotal: 12.9s\tremaining: 3.21s\n",
      "900:\tlearn: 0.4351514\ttest: 0.4842593\tbest: 0.4842567 (899)\ttotal: 14.5s\tremaining: 1.59s\n",
      "999:\tlearn: 0.4337562\ttest: 0.4841221\tbest: 0.4841169 (977)\ttotal: 15.9s\tremaining: 0us\n",
      "bestTest = 0.4841169203\n",
      "bestIteration = 977\n",
      "Shrink model to first 978 iterations.\n",
      "===== ACCURACY SCORE 0.782622 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6877770\ttest: 0.6880989\tbest: 0.6880989 (0)\ttotal: 26.8ms\tremaining: 26.8s\n",
      "100:\tlearn: 0.4835645\ttest: 0.5116311\tbest: 0.5116311 (100)\ttotal: 1.71s\tremaining: 15.2s\n",
      "200:\tlearn: 0.4556682\ttest: 0.4977112\tbest: 0.4976993 (198)\ttotal: 3.22s\tremaining: 12.8s\n",
      "300:\tlearn: 0.4478239\ttest: 0.4966474\tbest: 0.4966474 (300)\ttotal: 4.69s\tremaining: 10.9s\n",
      "400:\tlearn: 0.4438612\ttest: 0.4963877\tbest: 0.4963679 (389)\ttotal: 6.15s\tremaining: 9.19s\n",
      "500:\tlearn: 0.4412311\ttest: 0.4961718\tbest: 0.4961718 (500)\ttotal: 7.63s\tremaining: 7.6s\n",
      "600:\tlearn: 0.4391553\ttest: 0.4960003\tbest: 0.4959801 (593)\ttotal: 9.12s\tremaining: 6.06s\n",
      "700:\tlearn: 0.4374174\ttest: 0.4959934\tbest: 0.4959656 (636)\ttotal: 10.7s\tremaining: 4.58s\n",
      "800:\tlearn: 0.4358574\ttest: 0.4959627\tbest: 0.4959482 (713)\ttotal: 12.5s\tremaining: 3.11s\n",
      "bestTest = 0.4959482338\n",
      "bestIteration = 713\n",
      "Shrink model to first 714 iterations.\n",
      "===== ACCURACY SCORE 0.773182 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6878646\ttest: 0.6882043\tbest: 0.6882043 (0)\ttotal: 16ms\tremaining: 16s\n",
      "100:\tlearn: 0.4831926\ttest: 0.5075946\tbest: 0.5075946 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4549686\ttest: 0.4925128\tbest: 0.4925128 (200)\ttotal: 2.95s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4472043\ttest: 0.4915687\tbest: 0.4915687 (300)\ttotal: 4.42s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4432477\ttest: 0.4914455\tbest: 0.4914385 (390)\ttotal: 5.88s\tremaining: 8.79s\n",
      "500:\tlearn: 0.4406080\ttest: 0.4914971\tbest: 0.4914302 (430)\ttotal: 7.41s\tremaining: 7.38s\n",
      "600:\tlearn: 0.4385230\ttest: 0.4914417\tbest: 0.4914136 (550)\ttotal: 9.32s\tremaining: 6.18s\n",
      "700:\tlearn: 0.4367691\ttest: 0.4912256\tbest: 0.4911890 (687)\ttotal: 10.8s\tremaining: 4.6s\n",
      "800:\tlearn: 0.4351893\ttest: 0.4910858\tbest: 0.4910854 (799)\ttotal: 12.2s\tremaining: 3.04s\n",
      "900:\tlearn: 0.4336881\ttest: 0.4909425\tbest: 0.4909342 (895)\ttotal: 14.5s\tremaining: 1.59s\n",
      "999:\tlearn: 0.4323082\ttest: 0.4907810\tbest: 0.4907677 (994)\ttotal: 15.9s\tremaining: 0us\n",
      "bestTest = 0.4907677246\n",
      "bestIteration = 994\n",
      "Shrink model to first 995 iterations.\n",
      "===== ACCURACY SCORE 0.781500 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6879483\ttest: 0.6881245\tbest: 0.6881245 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4854381\ttest: 0.5003451\tbest: 0.5003451 (100)\ttotal: 1.59s\tremaining: 14.1s\n",
      "200:\tlearn: 0.4572379\ttest: 0.4823757\tbest: 0.4823757 (200)\ttotal: 3.49s\tremaining: 13.9s\n",
      "300:\tlearn: 0.4492356\ttest: 0.4801325\tbest: 0.4801325 (300)\ttotal: 4.96s\tremaining: 11.5s\n",
      "400:\tlearn: 0.4451991\ttest: 0.4795994\tbest: 0.4795994 (400)\ttotal: 6.41s\tremaining: 9.58s\n",
      "500:\tlearn: 0.4424424\ttest: 0.4794615\tbest: 0.4794117 (473)\ttotal: 7.88s\tremaining: 7.85s\n",
      "600:\tlearn: 0.4403250\ttest: 0.4793660\tbest: 0.4793366 (550)\ttotal: 9.35s\tremaining: 6.21s\n",
      "700:\tlearn: 0.4384907\ttest: 0.4792996\tbest: 0.4792594 (667)\ttotal: 10.8s\tremaining: 4.63s\n",
      "800:\tlearn: 0.4368986\ttest: 0.4792856\tbest: 0.4792484 (756)\ttotal: 12.4s\tremaining: 3.08s\n",
      "900:\tlearn: 0.4353503\ttest: 0.4791565\tbest: 0.4791427 (898)\ttotal: 14.2s\tremaining: 1.56s\n",
      "999:\tlearn: 0.4339315\ttest: 0.4791314\tbest: 0.4791060 (980)\ttotal: 15.7s\tremaining: 0us\n",
      "bestTest = 0.4791060365\n",
      "bestIteration = 980\n",
      "Shrink model to first 981 iterations.\n",
      "===== ACCURACY SCORE 0.782435 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6878820\ttest: 0.6880322\tbest: 0.6880322 (0)\ttotal: 16ms\tremaining: 16s\n",
      "100:\tlearn: 0.4835410\ttest: 0.4994162\tbest: 0.4994162 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4554416\ttest: 0.4823856\tbest: 0.4823856 (200)\ttotal: 2.94s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4476606\ttest: 0.4802191\tbest: 0.4802162 (299)\ttotal: 4.42s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4436568\ttest: 0.4795260\tbest: 0.4795260 (400)\ttotal: 5.89s\tremaining: 8.81s\n",
      "500:\tlearn: 0.4409062\ttest: 0.4790475\tbest: 0.4790287 (496)\ttotal: 7.92s\tremaining: 7.89s\n",
      "600:\tlearn: 0.4387098\ttest: 0.4787151\tbest: 0.4787151 (600)\ttotal: 9.45s\tremaining: 6.27s\n",
      "700:\tlearn: 0.4368327\ttest: 0.4785205\tbest: 0.4784950 (683)\ttotal: 11.8s\tremaining: 5.03s\n",
      "800:\tlearn: 0.4352160\ttest: 0.4783452\tbest: 0.4783195 (797)\ttotal: 13.4s\tremaining: 3.33s\n",
      "900:\tlearn: 0.4336819\ttest: 0.4783225\tbest: 0.4782985 (861)\ttotal: 14.9s\tremaining: 1.64s\n",
      "999:\tlearn: 0.4323345\ttest: 0.4782048\tbest: 0.4781802 (994)\ttotal: 16.3s\tremaining: 0us\n",
      "bestTest = 0.4781802409\n",
      "bestIteration = 994\n",
      "Shrink model to first 995 iterations.\n",
      "===== ACCURACY SCORE 0.783529 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878484\ttest: 0.6881077\tbest: 0.6881077 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4832184\ttest: 0.5054494\tbest: 0.5054494 (100)\ttotal: 1.84s\tremaining: 16.4s\n",
      "200:\tlearn: 0.4550788\ttest: 0.4906817\tbest: 0.4906817 (200)\ttotal: 3.33s\tremaining: 13.3s\n",
      "300:\tlearn: 0.4473559\ttest: 0.4895788\tbest: 0.4895688 (299)\ttotal: 4.83s\tremaining: 11.2s\n",
      "400:\tlearn: 0.4433703\ttest: 0.4895308\tbest: 0.4894512 (390)\ttotal: 6.31s\tremaining: 9.42s\n",
      "500:\tlearn: 0.4406872\ttest: 0.4894707\tbest: 0.4894116 (473)\ttotal: 7.85s\tremaining: 7.82s\n",
      "bestTest = 0.4894115779\n",
      "bestIteration = 473\n",
      "Shrink model to first 474 iterations.\n",
      "===== ACCURACY SCORE 0.775523 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6878998\ttest: 0.6881679\tbest: 0.6881679 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4844988\ttest: 0.5060133\tbest: 0.5060133 (100)\ttotal: 1.59s\tremaining: 14.1s\n",
      "200:\tlearn: 0.4565174\ttest: 0.4913645\tbest: 0.4913645 (200)\ttotal: 3.42s\tremaining: 13.6s\n",
      "300:\tlearn: 0.4487307\ttest: 0.4903935\tbest: 0.4903529 (294)\ttotal: 4.88s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4447342\ttest: 0.4904130\tbest: 0.4902089 (363)\ttotal: 6.35s\tremaining: 9.49s\n",
      "bestTest = 0.4902088568\n",
      "bestIteration = 363\n",
      "Shrink model to first 364 iterations.\n",
      "===== ACCURACY SCORE 0.779296 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6878631\ttest: 0.6881352\tbest: 0.6881352 (0)\ttotal: 16ms\tremaining: 16s\n",
      "100:\tlearn: 0.4830155\ttest: 0.5038236\tbest: 0.5038236 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4547919\ttest: 0.4880297\tbest: 0.4880297 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4470512\ttest: 0.4864859\tbest: 0.4864813 (299)\ttotal: 4.84s\tremaining: 11.2s\n",
      "400:\tlearn: 0.4430859\ttest: 0.4862094\tbest: 0.4861958 (390)\ttotal: 6.4s\tremaining: 9.56s\n",
      "500:\tlearn: 0.4403736\ttest: 0.4860418\tbest: 0.4859880 (471)\ttotal: 8.74s\tremaining: 8.7s\n",
      "600:\tlearn: 0.4382723\ttest: 0.4860713\tbest: 0.4859546 (527)\ttotal: 10.2s\tremaining: 6.78s\n",
      "bestTest = 0.485954604\n",
      "bestIteration = 527\n",
      "Shrink model to first 528 iterations.\n",
      "===== ACCURACY SCORE 0.776087 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779430 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6879313\ttest: 0.6882183\tbest: 0.6882183 (0)\ttotal: 15.1ms\tremaining: 15.1s\n",
      "100:\tlearn: 0.4841803\ttest: 0.5072358\tbest: 0.5072358 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4561006\ttest: 0.4921634\tbest: 0.4921634 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4483285\ttest: 0.4906125\tbest: 0.4906125 (300)\ttotal: 4.75s\tremaining: 11s\n",
      "400:\tlearn: 0.4445172\ttest: 0.4904032\tbest: 0.4903388 (387)\ttotal: 6.21s\tremaining: 9.28s\n",
      "500:\tlearn: 0.4418259\ttest: 0.4901010\tbest: 0.4900866 (498)\ttotal: 7.71s\tremaining: 7.68s\n",
      "600:\tlearn: 0.4397447\ttest: 0.4899783\tbest: 0.4899741 (593)\ttotal: 9.21s\tremaining: 6.12s\n",
      "700:\tlearn: 0.4379005\ttest: 0.4898526\tbest: 0.4898416 (697)\ttotal: 10.7s\tremaining: 4.56s\n",
      "800:\tlearn: 0.4363037\ttest: 0.4897321\tbest: 0.4897181 (794)\ttotal: 12.2s\tremaining: 3.02s\n",
      "900:\tlearn: 0.4348133\ttest: 0.4895558\tbest: 0.4895326 (891)\ttotal: 13.6s\tremaining: 1.5s\n",
      "bestTest = 0.4895326361\n",
      "bestIteration = 891\n",
      "Shrink model to first 892 iterations.\n",
      "===== ACCURACY SCORE 0.779161 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6879249\ttest: 0.6880763\tbest: 0.6880763 (0)\ttotal: 16.1ms\tremaining: 16.1s\n",
      "100:\tlearn: 0.4844384\ttest: 0.4992224\tbest: 0.4992224 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4563659\ttest: 0.4821326\tbest: 0.4821326 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4484932\ttest: 0.4801769\tbest: 0.4801769 (300)\ttotal: 4.43s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4444997\ttest: 0.4799343\tbest: 0.4799179 (395)\ttotal: 5.9s\tremaining: 8.81s\n",
      "500:\tlearn: 0.4418359\ttest: 0.4799509\tbest: 0.4798520 (461)\ttotal: 7.38s\tremaining: 7.35s\n",
      "bestTest = 0.4798519762\n",
      "bestIteration = 461\n",
      "Shrink model to first 462 iterations.\n",
      "===== ACCURACY SCORE 0.782769 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6878776\ttest: 0.6882273\tbest: 0.6882273 (0)\ttotal: 20.8ms\tremaining: 20.8s\n",
      "100:\tlearn: 0.4838590\ttest: 0.5079947\tbest: 0.5079947 (100)\ttotal: 2.52s\tremaining: 22.4s\n",
      "200:\tlearn: 0.4558941\ttest: 0.4934740\tbest: 0.4934740 (200)\ttotal: 4.02s\tremaining: 16s\n",
      "300:\tlearn: 0.4481156\ttest: 0.4924312\tbest: 0.4924106 (290)\ttotal: 5.49s\tremaining: 12.8s\n",
      "400:\tlearn: 0.4441790\ttest: 0.4923892\tbest: 0.4922860 (366)\ttotal: 6.97s\tremaining: 10.4s\n",
      "500:\tlearn: 0.4414612\ttest: 0.4923372\tbest: 0.4922305 (432)\ttotal: 8.45s\tremaining: 8.42s\n",
      "bestTest = 0.4922305443\n",
      "bestIteration = 432\n",
      "Shrink model to first 433 iterations.\n",
      "===== ACCURACY SCORE 0.774141 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6878558\ttest: 0.6881411\tbest: 0.6881411 (0)\ttotal: 17ms\tremaining: 17s\n",
      "100:\tlearn: 0.4824321\ttest: 0.5050565\tbest: 0.5050565 (100)\ttotal: 1.96s\tremaining: 17.4s\n",
      "200:\tlearn: 0.4540699\ttest: 0.4892570\tbest: 0.4892570 (200)\ttotal: 3.49s\tremaining: 13.9s\n",
      "300:\tlearn: 0.4461479\ttest: 0.4873068\tbest: 0.4873068 (300)\ttotal: 4.95s\tremaining: 11.5s\n",
      "400:\tlearn: 0.4421434\ttest: 0.4868308\tbest: 0.4868296 (399)\ttotal: 6.43s\tremaining: 9.61s\n",
      "500:\tlearn: 0.4394383\ttest: 0.4866585\tbest: 0.4866393 (489)\ttotal: 7.9s\tremaining: 7.87s\n",
      "600:\tlearn: 0.4373369\ttest: 0.4865952\tbest: 0.4865580 (541)\ttotal: 9.37s\tremaining: 6.22s\n",
      "700:\tlearn: 0.4355575\ttest: 0.4863836\tbest: 0.4863836 (700)\ttotal: 10.9s\tremaining: 4.63s\n",
      "800:\tlearn: 0.4339767\ttest: 0.4862315\tbest: 0.4862266 (785)\ttotal: 12.7s\tremaining: 3.17s\n",
      "900:\tlearn: 0.4324692\ttest: 0.4861986\tbest: 0.4861630 (840)\ttotal: 14.2s\tremaining: 1.56s\n",
      "999:\tlearn: 0.4311092\ttest: 0.4861554\tbest: 0.4861554 (999)\ttotal: 15.7s\tremaining: 0us\n",
      "bestTest = 0.4861554207\n",
      "bestIteration = 999\n",
      "===== ACCURACY SCORE 0.780374 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6878601\ttest: 0.6881161\tbest: 0.6881161 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4831095\ttest: 0.5034867\tbest: 0.5034867 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4551398\ttest: 0.4867910\tbest: 0.4867910 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4473092\ttest: 0.4847920\tbest: 0.4847890 (299)\ttotal: 4.48s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4433288\ttest: 0.4840754\tbest: 0.4840548 (398)\ttotal: 6.22s\tremaining: 9.3s\n",
      "500:\tlearn: 0.4406224\ttest: 0.4836574\tbest: 0.4836573 (499)\ttotal: 8.51s\tremaining: 8.48s\n",
      "600:\tlearn: 0.4385208\ttest: 0.4833581\tbest: 0.4833439 (597)\ttotal: 9.99s\tremaining: 6.63s\n",
      "700:\tlearn: 0.4366573\ttest: 0.4831915\tbest: 0.4831668 (664)\ttotal: 11.5s\tremaining: 4.89s\n",
      "800:\tlearn: 0.4350357\ttest: 0.4830176\tbest: 0.4830166 (796)\ttotal: 12.9s\tremaining: 3.21s\n",
      "900:\tlearn: 0.4334974\ttest: 0.4828832\tbest: 0.4828832 (900)\ttotal: 14.4s\tremaining: 1.58s\n",
      "999:\tlearn: 0.4320940\ttest: 0.4827627\tbest: 0.4827559 (998)\ttotal: 15.9s\tremaining: 0us\n",
      "bestTest = 0.4827559494\n",
      "bestIteration = 998\n",
      "Shrink model to first 999 iterations.\n",
      "===== ACCURACY SCORE 0.780648 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6878698\ttest: 0.6881315\tbest: 0.6881315 (0)\ttotal: 27.3ms\tremaining: 27.3s\n",
      "100:\tlearn: 0.4832535\ttest: 0.5046210\tbest: 0.5046210 (100)\ttotal: 1.64s\tremaining: 14.6s\n",
      "200:\tlearn: 0.4551788\ttest: 0.4896330\tbest: 0.4896330 (200)\ttotal: 3.12s\tremaining: 12.4s\n",
      "300:\tlearn: 0.4472411\ttest: 0.4887714\tbest: 0.4887304 (263)\ttotal: 4.59s\tremaining: 10.7s\n",
      "400:\tlearn: 0.4432090\ttest: 0.4888164\tbest: 0.4886706 (313)\ttotal: 6.05s\tremaining: 9.04s\n",
      "bestTest = 0.4886706339\n",
      "bestIteration = 313\n",
      "Shrink model to first 314 iterations.\n",
      "===== ACCURACY SCORE 0.779245 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6878202\ttest: 0.6879130\tbest: 0.6879130 (0)\ttotal: 16.9ms\tremaining: 16.9s\n",
      "100:\tlearn: 0.4845510\ttest: 0.5016159\tbest: 0.5016159 (100)\ttotal: 1.47s\tremaining: 13.1s\n",
      "200:\tlearn: 0.4565385\ttest: 0.4854595\tbest: 0.4854595 (200)\ttotal: 3s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4486935\ttest: 0.4843351\tbest: 0.4842859 (294)\ttotal: 4.79s\tremaining: 11.1s\n",
      "400:\tlearn: 0.4447252\ttest: 0.4844162\tbest: 0.4842456 (326)\ttotal: 6.25s\tremaining: 9.34s\n",
      "bestTest = 0.4842456001\n",
      "bestIteration = 326\n",
      "Shrink model to first 327 iterations.\n",
      "===== ACCURACY SCORE 0.780471 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6879361\ttest: 0.6881646\tbest: 0.6881646 (0)\ttotal: 15.2ms\tremaining: 15.2s\n",
      "100:\tlearn: 0.4835300\ttest: 0.5053928\tbest: 0.5053928 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4552918\ttest: 0.4913711\tbest: 0.4913711 (200)\ttotal: 2.99s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4474339\ttest: 0.4908529\tbest: 0.4907748 (260)\ttotal: 4.45s\tremaining: 10.3s\n",
      "bestTest = 0.4907747966\n",
      "bestIteration = 260\n",
      "Shrink model to first 261 iterations.\n",
      "===== ACCURACY SCORE 0.776570 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6878816\ttest: 0.6881979\tbest: 0.6881979 (0)\ttotal: 43.1ms\tremaining: 43.1s\n",
      "100:\tlearn: 0.4837556\ttest: 0.5070768\tbest: 0.5070768 (100)\ttotal: 2.17s\tremaining: 19.3s\n",
      "200:\tlearn: 0.4555747\ttest: 0.4923345\tbest: 0.4923345 (200)\ttotal: 3.64s\tremaining: 14.5s\n",
      "300:\tlearn: 0.4477708\ttest: 0.4910335\tbest: 0.4910335 (300)\ttotal: 5.11s\tremaining: 11.9s\n",
      "400:\tlearn: 0.4436871\ttest: 0.4908891\tbest: 0.4908597 (385)\ttotal: 6.6s\tremaining: 9.87s\n",
      "500:\tlearn: 0.4410118\ttest: 0.4907581\tbest: 0.4907359 (465)\ttotal: 8.1s\tremaining: 8.07s\n",
      "600:\tlearn: 0.4389079\ttest: 0.4906321\tbest: 0.4906116 (596)\ttotal: 9.58s\tremaining: 6.36s\n",
      "700:\tlearn: 0.4370952\ttest: 0.4905246\tbest: 0.4905177 (685)\ttotal: 11.2s\tremaining: 4.77s\n",
      "800:\tlearn: 0.4354398\ttest: 0.4905489\tbest: 0.4904890 (734)\ttotal: 12.9s\tremaining: 3.21s\n",
      "bestTest = 0.4904889809\n",
      "bestIteration = 734\n",
      "Shrink model to first 735 iterations.\n",
      "===== ACCURACY SCORE 0.777018 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6878470\ttest: 0.6881291\tbest: 0.6881291 (0)\ttotal: 15.8ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4826201\ttest: 0.5044954\tbest: 0.5044954 (100)\ttotal: 1.57s\tremaining: 14s\n",
      "200:\tlearn: 0.4545178\ttest: 0.4886582\tbest: 0.4886582 (200)\ttotal: 3.05s\tremaining: 12.1s\n",
      "300:\tlearn: 0.4466548\ttest: 0.4872001\tbest: 0.4871881 (294)\ttotal: 4.52s\tremaining: 10.5s\n",
      "400:\tlearn: 0.4427252\ttest: 0.4866148\tbest: 0.4866132 (399)\ttotal: 5.99s\tremaining: 8.94s\n",
      "500:\tlearn: 0.4400326\ttest: 0.4863949\tbest: 0.4863949 (500)\ttotal: 7.55s\tremaining: 7.52s\n",
      "600:\tlearn: 0.4379794\ttest: 0.4863855\tbest: 0.4863758 (549)\ttotal: 9.43s\tremaining: 6.26s\n",
      "700:\tlearn: 0.4361238\ttest: 0.4861809\tbest: 0.4861697 (692)\ttotal: 10.9s\tremaining: 4.66s\n",
      "800:\tlearn: 0.4345718\ttest: 0.4861247\tbest: 0.4860801 (782)\ttotal: 12.4s\tremaining: 3.09s\n",
      "bestTest = 0.4860801145\n",
      "bestIteration = 782\n",
      "Shrink model to first 783 iterations.\n",
      "===== ACCURACY SCORE 0.780067 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779060 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6878984\ttest: 0.6881290\tbest: 0.6881290 (0)\ttotal: 14.4ms\tremaining: 14.4s\n",
      "100:\tlearn: 0.4827672\ttest: 0.5009504\tbest: 0.5009504 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4547161\ttest: 0.4840261\tbest: 0.4840261 (200)\ttotal: 3.87s\tremaining: 15.4s\n",
      "300:\tlearn: 0.4470296\ttest: 0.4816227\tbest: 0.4816225 (299)\ttotal: 5.62s\tremaining: 13s\n",
      "400:\tlearn: 0.4431143\ttest: 0.4811509\tbest: 0.4811321 (398)\ttotal: 7.11s\tremaining: 10.6s\n",
      "500:\tlearn: 0.4405175\ttest: 0.4810469\tbest: 0.4809979 (491)\ttotal: 8.6s\tremaining: 8.56s\n",
      "600:\tlearn: 0.4384291\ttest: 0.4809286\tbest: 0.4809280 (598)\ttotal: 10.1s\tremaining: 6.71s\n",
      "700:\tlearn: 0.4366358\ttest: 0.4808311\tbest: 0.4808161 (688)\ttotal: 11.6s\tremaining: 4.93s\n",
      "800:\tlearn: 0.4350608\ttest: 0.4807642\tbest: 0.4807384 (779)\ttotal: 13s\tremaining: 3.24s\n",
      "bestTest = 0.4807383855\n",
      "bestIteration = 779\n",
      "Shrink model to first 780 iterations.\n",
      "===== ACCURACY SCORE 0.784851 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6879507\ttest: 0.6881247\tbest: 0.6881247 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4842967\ttest: 0.5015756\tbest: 0.5015756 (100)\ttotal: 1.52s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4561623\ttest: 0.4847291\tbest: 0.4847291 (200)\ttotal: 3s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4483145\ttest: 0.4824202\tbest: 0.4824202 (300)\ttotal: 4.48s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4444261\ttest: 0.4817580\tbest: 0.4817524 (398)\ttotal: 5.94s\tremaining: 8.88s\n",
      "500:\tlearn: 0.4417460\ttest: 0.4812831\tbest: 0.4812831 (500)\ttotal: 7.4s\tremaining: 7.37s\n",
      "600:\tlearn: 0.4396395\ttest: 0.4811300\tbest: 0.4811300 (600)\ttotal: 8.88s\tremaining: 5.9s\n",
      "700:\tlearn: 0.4378851\ttest: 0.4809501\tbest: 0.4809429 (696)\ttotal: 10.7s\tremaining: 4.57s\n",
      "800:\tlearn: 0.4362883\ttest: 0.4807376\tbest: 0.4807376 (800)\ttotal: 12.3s\tremaining: 3.06s\n",
      "900:\tlearn: 0.4348527\ttest: 0.4807265\tbest: 0.4806635 (869)\ttotal: 13.8s\tremaining: 1.51s\n",
      "999:\tlearn: 0.4335417\ttest: 0.4805605\tbest: 0.4805499 (994)\ttotal: 15.3s\tremaining: 0us\n",
      "bestTest = 0.480549942\n",
      "bestIteration = 994\n",
      "Shrink model to first 995 iterations.\n",
      "===== ACCURACY SCORE 0.784759 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6879395\ttest: 0.6880605\tbest: 0.6880605 (0)\ttotal: 16ms\tremaining: 16s\n",
      "100:\tlearn: 0.4856457\ttest: 0.4983966\tbest: 0.4983966 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4577464\ttest: 0.4806878\tbest: 0.4806878 (200)\ttotal: 3.77s\tremaining: 15s\n",
      "300:\tlearn: 0.4499518\ttest: 0.4783344\tbest: 0.4783344 (300)\ttotal: 5.79s\tremaining: 13.4s\n",
      "400:\tlearn: 0.4459887\ttest: 0.4778007\tbest: 0.4777859 (399)\ttotal: 7.25s\tremaining: 10.8s\n",
      "500:\tlearn: 0.4432221\ttest: 0.4773771\tbest: 0.4773771 (500)\ttotal: 8.75s\tremaining: 8.71s\n",
      "600:\tlearn: 0.4410643\ttest: 0.4773133\tbest: 0.4772626 (578)\ttotal: 10.2s\tremaining: 6.79s\n",
      "700:\tlearn: 0.4392966\ttest: 0.4771768\tbest: 0.4771691 (692)\ttotal: 11.7s\tremaining: 5s\n",
      "800:\tlearn: 0.4376432\ttest: 0.4770299\tbest: 0.4770299 (800)\ttotal: 13.2s\tremaining: 3.28s\n",
      "900:\tlearn: 0.4361981\ttest: 0.4769475\tbest: 0.4769405 (898)\ttotal: 14.7s\tremaining: 1.61s\n",
      "999:\tlearn: 0.4348610\ttest: 0.4768372\tbest: 0.4768360 (998)\ttotal: 16.4s\tremaining: 0us\n",
      "bestTest = 0.4768360238\n",
      "bestIteration = 998\n",
      "Shrink model to first 999 iterations.\n",
      "===== ACCURACY SCORE 0.784207 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6878515\ttest: 0.6882244\tbest: 0.6882244 (0)\ttotal: 16.1ms\tremaining: 16s\n",
      "100:\tlearn: 0.4820514\ttest: 0.5101374\tbest: 0.5101374 (100)\ttotal: 1.53s\tremaining: 13.6s\n",
      "200:\tlearn: 0.4537260\ttest: 0.4963811\tbest: 0.4963811 (200)\ttotal: 2.99s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4458416\ttest: 0.4954799\tbest: 0.4954773 (294)\ttotal: 4.48s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4419142\ttest: 0.4955618\tbest: 0.4954772 (305)\ttotal: 5.95s\tremaining: 8.89s\n",
      "bestTest = 0.4954771783\n",
      "bestIteration = 305\n",
      "Shrink model to first 306 iterations.\n",
      "===== ACCURACY SCORE 0.772193 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6878418\ttest: 0.6880009\tbest: 0.6880009 (0)\ttotal: 16.1ms\tremaining: 16.1s\n",
      "100:\tlearn: 0.4843274\ttest: 0.5040591\tbest: 0.5040591 (100)\ttotal: 1.51s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4563450\ttest: 0.4884425\tbest: 0.4884425 (200)\ttotal: 3.34s\tremaining: 13.3s\n",
      "300:\tlearn: 0.4484058\ttest: 0.4873747\tbest: 0.4872955 (288)\ttotal: 4.79s\tremaining: 11.1s\n",
      "400:\tlearn: 0.4443691\ttest: 0.4874032\tbest: 0.4872865 (325)\ttotal: 6.25s\tremaining: 9.34s\n",
      "bestTest = 0.4872865159\n",
      "bestIteration = 325\n",
      "Shrink model to first 326 iterations.\n",
      "===== ACCURACY SCORE 0.775905 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6878703\ttest: 0.6881358\tbest: 0.6881358 (0)\ttotal: 16.6ms\tremaining: 16.6s\n",
      "100:\tlearn: 0.4836292\ttest: 0.5046119\tbest: 0.5046119 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4555583\ttest: 0.4887720\tbest: 0.4887720 (200)\ttotal: 3.81s\tremaining: 15.1s\n",
      "300:\tlearn: 0.4476591\ttest: 0.4871242\tbest: 0.4871242 (300)\ttotal: 5.33s\tremaining: 12.4s\n",
      "400:\tlearn: 0.4436416\ttest: 0.4865678\tbest: 0.4865663 (399)\ttotal: 7.17s\tremaining: 10.7s\n",
      "500:\tlearn: 0.4409694\ttest: 0.4863574\tbest: 0.4863511 (484)\ttotal: 8.64s\tremaining: 8.6s\n",
      "600:\tlearn: 0.4388338\ttest: 0.4861853\tbest: 0.4861508 (592)\ttotal: 10.1s\tremaining: 6.71s\n",
      "700:\tlearn: 0.4370096\ttest: 0.4860429\tbest: 0.4860429 (700)\ttotal: 11.6s\tremaining: 4.93s\n",
      "800:\tlearn: 0.4354009\ttest: 0.4858390\tbest: 0.4858183 (791)\ttotal: 13s\tremaining: 3.24s\n",
      "900:\tlearn: 0.4338987\ttest: 0.4856317\tbest: 0.4856228 (895)\ttotal: 14.5s\tremaining: 1.59s\n",
      "999:\tlearn: 0.4325104\ttest: 0.4855258\tbest: 0.4855174 (955)\ttotal: 16s\tremaining: 0us\n",
      "bestTest = 0.4855174311\n",
      "bestIteration = 955\n",
      "Shrink model to first 956 iterations.\n",
      "===== ACCURACY SCORE 0.778822 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6878734\ttest: 0.6882247\tbest: 0.6882247 (0)\ttotal: 31.7ms\tremaining: 31.7s\n",
      "100:\tlearn: 0.4839426\ttest: 0.5081883\tbest: 0.5081883 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4562780\ttest: 0.4935070\tbest: 0.4935070 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4485515\ttest: 0.4922437\tbest: 0.4922335 (299)\ttotal: 4.43s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4446932\ttest: 0.4919501\tbest: 0.4919241 (398)\ttotal: 5.92s\tremaining: 8.84s\n",
      "500:\tlearn: 0.4420082\ttest: 0.4917508\tbest: 0.4917508 (500)\ttotal: 7.37s\tremaining: 7.34s\n",
      "600:\tlearn: 0.4399564\ttest: 0.4916489\tbest: 0.4916226 (590)\ttotal: 8.82s\tremaining: 5.85s\n",
      "700:\tlearn: 0.4381921\ttest: 0.4915074\tbest: 0.4914805 (687)\ttotal: 10.4s\tremaining: 4.45s\n",
      "800:\tlearn: 0.4365663\ttest: 0.4913775\tbest: 0.4913774 (799)\ttotal: 12.2s\tremaining: 3.03s\n",
      "900:\tlearn: 0.4350009\ttest: 0.4913552\tbest: 0.4913320 (882)\ttotal: 13.6s\tremaining: 1.5s\n",
      "999:\tlearn: 0.4335757\ttest: 0.4912368\tbest: 0.4912212 (988)\ttotal: 15.1s\tremaining: 0us\n",
      "bestTest = 0.4912212181\n",
      "bestIteration = 988\n",
      "Shrink model to first 989 iterations.\n",
      "===== ACCURACY SCORE 0.781189 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878947\ttest: 0.6881956\tbest: 0.6881956 (0)\ttotal: 16.1ms\tremaining: 16.1s\n",
      "100:\tlearn: 0.4844617\ttest: 0.5070038\tbest: 0.5070038 (100)\ttotal: 2.37s\tremaining: 21.1s\n",
      "200:\tlearn: 0.4564151\ttest: 0.4919575\tbest: 0.4919575 (200)\ttotal: 3.87s\tremaining: 15.4s\n",
      "300:\tlearn: 0.4485768\ttest: 0.4908919\tbest: 0.4908914 (282)\ttotal: 5.59s\tremaining: 13s\n",
      "400:\tlearn: 0.4445660\ttest: 0.4907769\tbest: 0.4907690 (399)\ttotal: 7.18s\tremaining: 10.7s\n",
      "500:\tlearn: 0.4419007\ttest: 0.4908076\tbest: 0.4907216 (422)\ttotal: 8.69s\tremaining: 8.66s\n",
      "bestTest = 0.490721576\n",
      "bestIteration = 422\n",
      "Shrink model to first 423 iterations.\n",
      "===== ACCURACY SCORE 0.774739 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6878183\ttest: 0.6881754\tbest: 0.6881754 (0)\ttotal: 15.9ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4823066\ttest: 0.5068839\tbest: 0.5068839 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4542204\ttest: 0.4928897\tbest: 0.4928897 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4463294\ttest: 0.4927000\tbest: 0.4923753 (243)\ttotal: 4.42s\tremaining: 10.3s\n",
      "bestTest = 0.4923752968\n",
      "bestIteration = 243\n",
      "Shrink model to first 244 iterations.\n",
      "===== ACCURACY SCORE 0.776257 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6878899\ttest: 0.6881258\tbest: 0.6881258 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4838895\ttest: 0.5045931\tbest: 0.5045931 (100)\ttotal: 1.83s\tremaining: 16.3s\n",
      "200:\tlearn: 0.4557654\ttest: 0.4890714\tbest: 0.4890714 (200)\ttotal: 3.36s\tremaining: 13.3s\n",
      "300:\tlearn: 0.4478044\ttest: 0.4874513\tbest: 0.4874419 (299)\ttotal: 4.83s\tremaining: 11.2s\n",
      "400:\tlearn: 0.4438203\ttest: 0.4874489\tbest: 0.4873673 (366)\ttotal: 6.28s\tremaining: 9.38s\n",
      "bestTest = 0.4873673177\n",
      "bestIteration = 366\n",
      "Shrink model to first 367 iterations.\n",
      "===== ACCURACY SCORE 0.778011 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779090 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6879013\ttest: 0.6879939\tbest: 0.6879939 (0)\ttotal: 16.5ms\tremaining: 16.5s\n",
      "100:\tlearn: 0.4842089\ttest: 0.4963425\tbest: 0.4963425 (100)\ttotal: 1.51s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4560897\ttest: 0.4778091\tbest: 0.4778091 (200)\ttotal: 3.24s\tremaining: 12.9s\n",
      "300:\tlearn: 0.4480691\ttest: 0.4747989\tbest: 0.4747989 (300)\ttotal: 4.88s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4439994\ttest: 0.4739795\tbest: 0.4739795 (400)\ttotal: 6.33s\tremaining: 9.46s\n",
      "500:\tlearn: 0.4412072\ttest: 0.4734859\tbest: 0.4734859 (500)\ttotal: 8.03s\tremaining: 7.99s\n",
      "600:\tlearn: 0.4390832\ttest: 0.4732839\tbest: 0.4732652 (593)\ttotal: 10.1s\tremaining: 6.68s\n",
      "700:\tlearn: 0.4372467\ttest: 0.4730799\tbest: 0.4730799 (700)\ttotal: 11.5s\tremaining: 4.91s\n",
      "800:\tlearn: 0.4356315\ttest: 0.4729244\tbest: 0.4728964 (790)\ttotal: 13s\tremaining: 3.24s\n",
      "900:\tlearn: 0.4341635\ttest: 0.4728777\tbest: 0.4728777 (900)\ttotal: 14.9s\tremaining: 1.64s\n",
      "999:\tlearn: 0.4327409\ttest: 0.4727325\tbest: 0.4727325 (999)\ttotal: 16.4s\tremaining: 0us\n",
      "bestTest = 0.4727324693\n",
      "bestIteration = 999\n",
      "===== ACCURACY SCORE 0.789074 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6878345\ttest: 0.6882473\tbest: 0.6882473 (0)\ttotal: 16ms\tremaining: 16s\n",
      "100:\tlearn: 0.4820474\ttest: 0.5109182\tbest: 0.5109182 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4538306\ttest: 0.4979349\tbest: 0.4979349 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4460280\ttest: 0.4975826\tbest: 0.4973903 (235)\ttotal: 4.44s\tremaining: 10.3s\n",
      "bestTest = 0.4973903347\n",
      "bestIteration = 235\n",
      "Shrink model to first 236 iterations.\n",
      "===== ACCURACY SCORE 0.775514 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6878030\ttest: 0.6880065\tbest: 0.6880065 (0)\ttotal: 16.5ms\tremaining: 16.5s\n",
      "100:\tlearn: 0.4831136\ttest: 0.5067621\tbest: 0.5067621 (100)\ttotal: 1.9s\tremaining: 16.9s\n",
      "200:\tlearn: 0.4550446\ttest: 0.4926654\tbest: 0.4926654 (200)\ttotal: 3.48s\tremaining: 13.8s\n",
      "300:\tlearn: 0.4472076\ttest: 0.4919496\tbest: 0.4918451 (276)\ttotal: 4.94s\tremaining: 11.5s\n",
      "bestTest = 0.4918450671\n",
      "bestIteration = 276\n",
      "Shrink model to first 277 iterations.\n",
      "===== ACCURACY SCORE 0.775251 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6878938\ttest: 0.6881364\tbest: 0.6881364 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4836958\ttest: 0.5030521\tbest: 0.5030521 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4555217\ttest: 0.4861200\tbest: 0.4861200 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4475589\ttest: 0.4843567\tbest: 0.4843567 (300)\ttotal: 4.45s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4435151\ttest: 0.4838043\tbest: 0.4837898 (394)\ttotal: 6.32s\tremaining: 9.44s\n",
      "500:\tlearn: 0.4408102\ttest: 0.4834039\tbest: 0.4834039 (500)\ttotal: 7.77s\tremaining: 7.74s\n",
      "600:\tlearn: 0.4386818\ttest: 0.4831326\tbest: 0.4831277 (597)\ttotal: 9.41s\tremaining: 6.24s\n",
      "700:\tlearn: 0.4367923\ttest: 0.4827652\tbest: 0.4827611 (688)\ttotal: 11.6s\tremaining: 4.93s\n",
      "800:\tlearn: 0.4351381\ttest: 0.4826164\tbest: 0.4826008 (792)\ttotal: 13.1s\tremaining: 3.25s\n",
      "900:\tlearn: 0.4336546\ttest: 0.4824396\tbest: 0.4824365 (899)\ttotal: 14.6s\tremaining: 1.6s\n",
      "999:\tlearn: 0.4322573\ttest: 0.4822549\tbest: 0.4822444 (991)\ttotal: 16.2s\tremaining: 0us\n",
      "bestTest = 0.4822443979\n",
      "bestIteration = 991\n",
      "Shrink model to first 992 iterations.\n",
      "===== ACCURACY SCORE 0.782236 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6879316\ttest: 0.6882118\tbest: 0.6882118 (0)\ttotal: 16.3ms\tremaining: 16.3s\n",
      "100:\tlearn: 0.4851212\ttest: 0.5069425\tbest: 0.5069425 (100)\ttotal: 1.52s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4570310\ttest: 0.4918140\tbest: 0.4918140 (200)\ttotal: 3s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4492354\ttest: 0.4904533\tbest: 0.4904533 (300)\ttotal: 4.48s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4451895\ttest: 0.4901966\tbest: 0.4901761 (395)\ttotal: 5.95s\tremaining: 8.89s\n",
      "500:\tlearn: 0.4424919\ttest: 0.4901215\tbest: 0.4900852 (454)\ttotal: 7.47s\tremaining: 7.44s\n",
      "bestTest = 0.490085178\n",
      "bestIteration = 454\n",
      "Shrink model to first 455 iterations.\n",
      "===== ACCURACY SCORE 0.774516 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6879045\ttest: 0.6880950\tbest: 0.6880950 (0)\ttotal: 16.8ms\tremaining: 16.8s\n",
      "100:\tlearn: 0.4846807\ttest: 0.5003930\tbest: 0.5003930 (100)\ttotal: 1.82s\tremaining: 16.2s\n",
      "200:\tlearn: 0.4564893\ttest: 0.4822748\tbest: 0.4822748 (200)\ttotal: 3.28s\tremaining: 13s\n",
      "300:\tlearn: 0.4485818\ttest: 0.4801240\tbest: 0.4801099 (296)\ttotal: 4.75s\tremaining: 11s\n",
      "400:\tlearn: 0.4445128\ttest: 0.4796986\tbest: 0.4796892 (398)\ttotal: 6.21s\tremaining: 9.27s\n",
      "500:\tlearn: 0.4417860\ttest: 0.4796833\tbest: 0.4796090 (436)\ttotal: 7.68s\tremaining: 7.65s\n",
      "bestTest = 0.4796089702\n",
      "bestIteration = 436\n",
      "Shrink model to first 437 iterations.\n",
      "===== ACCURACY SCORE 0.784206 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6878942\ttest: 0.6880861\tbest: 0.6880861 (0)\ttotal: 16.9ms\tremaining: 16.9s\n",
      "100:\tlearn: 0.4839570\ttest: 0.5005402\tbest: 0.5005402 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4558610\ttest: 0.4842856\tbest: 0.4842856 (200)\ttotal: 3.43s\tremaining: 13.6s\n",
      "300:\tlearn: 0.4477986\ttest: 0.4827353\tbest: 0.4827130 (294)\ttotal: 4.89s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4437138\ttest: 0.4824051\tbest: 0.4823448 (382)\ttotal: 7.14s\tremaining: 10.7s\n",
      "bestTest = 0.4823447675\n",
      "bestIteration = 382\n",
      "Shrink model to first 383 iterations.\n",
      "===== ACCURACY SCORE 0.778816 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6879537\ttest: 0.6883084\tbest: 0.6883084 (0)\ttotal: 14.1ms\tremaining: 14.1s\n",
      "100:\tlearn: 0.4849277\ttest: 0.5122232\tbest: 0.5122232 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4572023\ttest: 0.4992783\tbest: 0.4992780 (199)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4493920\ttest: 0.4988322\tbest: 0.4987400 (244)\ttotal: 4.89s\tremaining: 11.4s\n",
      "bestTest = 0.498740035\n",
      "bestIteration = 244\n",
      "Shrink model to first 245 iterations.\n",
      "===== ACCURACY SCORE 0.770894 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6878293\ttest: 0.6881051\tbest: 0.6881051 (0)\ttotal: 15.8ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4825185\ttest: 0.5054420\tbest: 0.5054420 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4545874\ttest: 0.4911104\tbest: 0.4911104 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4467269\ttest: 0.4901387\tbest: 0.4901072 (289)\ttotal: 4.42s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4427647\ttest: 0.4902022\tbest: 0.4900894 (326)\ttotal: 5.89s\tremaining: 8.79s\n",
      "bestTest = 0.4900894409\n",
      "bestIteration = 326\n",
      "Shrink model to first 327 iterations.\n",
      "===== ACCURACY SCORE 0.774760 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6879135\ttest: 0.6881588\tbest: 0.6881588 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4848977\ttest: 0.5040438\tbest: 0.5040438 (100)\ttotal: 1.82s\tremaining: 16.2s\n",
      "200:\tlearn: 0.4568592\ttest: 0.4875627\tbest: 0.4875627 (200)\ttotal: 3.35s\tremaining: 13.3s\n",
      "300:\tlearn: 0.4490020\ttest: 0.4854236\tbest: 0.4854236 (300)\ttotal: 4.83s\tremaining: 11.2s\n",
      "400:\tlearn: 0.4450498\ttest: 0.4845267\tbest: 0.4845267 (400)\ttotal: 6.33s\tremaining: 9.45s\n",
      "500:\tlearn: 0.4422936\ttest: 0.4840871\tbest: 0.4840871 (500)\ttotal: 7.83s\tremaining: 7.8s\n",
      "600:\tlearn: 0.4401332\ttest: 0.4837807\tbest: 0.4837439 (593)\ttotal: 9.3s\tremaining: 6.17s\n",
      "700:\tlearn: 0.4382838\ttest: 0.4834691\tbest: 0.4834691 (700)\ttotal: 10.8s\tremaining: 4.6s\n",
      "800:\tlearn: 0.4366949\ttest: 0.4833589\tbest: 0.4833589 (800)\ttotal: 12.4s\tremaining: 3.08s\n",
      "900:\tlearn: 0.4351435\ttest: 0.4831400\tbest: 0.4831343 (882)\ttotal: 14.1s\tremaining: 1.55s\n",
      "999:\tlearn: 0.4337695\ttest: 0.4829353\tbest: 0.4829353 (999)\ttotal: 16.5s\tremaining: 0us\n",
      "bestTest = 0.4829353345\n",
      "bestIteration = 999\n",
      "===== ACCURACY SCORE 0.783006 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778840 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6879129\ttest: 0.6882238\tbest: 0.6882238 (0)\ttotal: 16.1ms\tremaining: 16.1s\n",
      "100:\tlearn: 0.4849710\ttest: 0.5064655\tbest: 0.5064655 (100)\ttotal: 1.51s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4570217\ttest: 0.4910505\tbest: 0.4910505 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4491461\ttest: 0.4901436\tbest: 0.4901073 (274)\ttotal: 4.43s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4450965\ttest: 0.4902113\tbest: 0.4900968 (307)\ttotal: 6.17s\tremaining: 9.22s\n",
      "bestTest = 0.4900967578\n",
      "bestIteration = 307\n",
      "Shrink model to first 308 iterations.\n",
      "===== ACCURACY SCORE 0.777822 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6879389\ttest: 0.6881339\tbest: 0.6881339 (0)\ttotal: 14ms\tremaining: 13.9s\n",
      "100:\tlearn: 0.4843480\ttest: 0.5039048\tbest: 0.5039048 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4563337\ttest: 0.4880364\tbest: 0.4880364 (200)\ttotal: 2.94s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4485336\ttest: 0.4860753\tbest: 0.4860753 (300)\ttotal: 4.39s\tremaining: 10.2s\n",
      "400:\tlearn: 0.4445609\ttest: 0.4857942\tbest: 0.4857894 (389)\ttotal: 5.86s\tremaining: 8.76s\n",
      "500:\tlearn: 0.4418937\ttest: 0.4854388\tbest: 0.4854388 (500)\ttotal: 7.32s\tremaining: 7.29s\n",
      "600:\tlearn: 0.4397957\ttest: 0.4853935\tbest: 0.4852779 (543)\ttotal: 8.86s\tremaining: 5.88s\n",
      "bestTest = 0.4852779389\n",
      "bestIteration = 543\n",
      "Shrink model to first 544 iterations.\n",
      "===== ACCURACY SCORE 0.779612 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6878923\ttest: 0.6881615\tbest: 0.6881615 (0)\ttotal: 16.7ms\tremaining: 16.7s\n",
      "100:\tlearn: 0.4836928\ttest: 0.5034859\tbest: 0.5034859 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4556950\ttest: 0.4870610\tbest: 0.4870610 (200)\ttotal: 2.94s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4478727\ttest: 0.4854691\tbest: 0.4854691 (300)\ttotal: 4.4s\tremaining: 10.2s\n",
      "400:\tlearn: 0.4438628\ttest: 0.4854054\tbest: 0.4853658 (393)\ttotal: 5.86s\tremaining: 8.75s\n",
      "500:\tlearn: 0.4412010\ttest: 0.4852729\tbest: 0.4852433 (488)\ttotal: 7.31s\tremaining: 7.28s\n",
      "600:\tlearn: 0.4390879\ttest: 0.4850512\tbest: 0.4850376 (598)\ttotal: 8.79s\tremaining: 5.83s\n",
      "700:\tlearn: 0.4372595\ttest: 0.4850053\tbest: 0.4850034 (699)\ttotal: 11.5s\tremaining: 4.89s\n",
      "800:\tlearn: 0.4356559\ttest: 0.4848999\tbest: 0.4848932 (799)\ttotal: 13.2s\tremaining: 3.28s\n",
      "900:\tlearn: 0.4342059\ttest: 0.4849051\tbest: 0.4848811 (823)\ttotal: 14.7s\tremaining: 1.61s\n",
      "bestTest = 0.4848810733\n",
      "bestIteration = 823\n",
      "Shrink model to first 824 iterations.\n",
      "===== ACCURACY SCORE 0.779575 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6879113\ttest: 0.6880647\tbest: 0.6880647 (0)\ttotal: 22.5ms\tremaining: 22.4s\n",
      "100:\tlearn: 0.4849407\ttest: 0.4997783\tbest: 0.4997783 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4570162\ttest: 0.4825157\tbest: 0.4825157 (200)\ttotal: 2.98s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4491888\ttest: 0.4803314\tbest: 0.4803164 (293)\ttotal: 4.6s\tremaining: 10.7s\n",
      "400:\tlearn: 0.4451835\ttest: 0.4800299\tbest: 0.4800282 (399)\ttotal: 6.27s\tremaining: 9.36s\n",
      "500:\tlearn: 0.4424483\ttest: 0.4798650\tbest: 0.4798369 (494)\ttotal: 7.74s\tremaining: 7.71s\n",
      "600:\tlearn: 0.4403225\ttest: 0.4797749\tbest: 0.4797368 (546)\ttotal: 9.2s\tremaining: 6.11s\n",
      "bestTest = 0.4797368448\n",
      "bestIteration = 546\n",
      "Shrink model to first 547 iterations.\n",
      "===== ACCURACY SCORE 0.783231 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6878327\ttest: 0.6881481\tbest: 0.6881481 (0)\ttotal: 16.7ms\tremaining: 16.7s\n",
      "100:\tlearn: 0.4822405\ttest: 0.5063848\tbest: 0.5063848 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4540666\ttest: 0.4914254\tbest: 0.4914254 (200)\ttotal: 2.99s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4460855\ttest: 0.4900374\tbest: 0.4900374 (300)\ttotal: 4.6s\tremaining: 10.7s\n",
      "400:\tlearn: 0.4420333\ttest: 0.4897669\tbest: 0.4897342 (399)\ttotal: 6.35s\tremaining: 9.48s\n",
      "bestTest = 0.4897342368\n",
      "bestIteration = 399\n",
      "Shrink model to first 400 iterations.\n",
      "===== ACCURACY SCORE 0.775157 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6878456\ttest: 0.6881325\tbest: 0.6881325 (0)\ttotal: 16ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4822468\ttest: 0.5037488\tbest: 0.5037488 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4542581\ttest: 0.4875872\tbest: 0.4875872 (200)\ttotal: 2.98s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4463513\ttest: 0.4859376\tbest: 0.4859376 (300)\ttotal: 4.48s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4424402\ttest: 0.4857408\tbest: 0.4857359 (399)\ttotal: 5.99s\tremaining: 8.95s\n",
      "500:\tlearn: 0.4397651\ttest: 0.4856777\tbest: 0.4856749 (497)\ttotal: 8.56s\tremaining: 8.52s\n",
      "600:\tlearn: 0.4376356\ttest: 0.4855327\tbest: 0.4855327 (600)\ttotal: 10s\tremaining: 6.65s\n",
      "700:\tlearn: 0.4358268\ttest: 0.4855201\tbest: 0.4855201 (700)\ttotal: 11.5s\tremaining: 4.9s\n",
      "800:\tlearn: 0.4342244\ttest: 0.4855297\tbest: 0.4855156 (712)\ttotal: 13s\tremaining: 3.22s\n",
      "900:\tlearn: 0.4327564\ttest: 0.4855977\tbest: 0.4855115 (805)\ttotal: 14.5s\tremaining: 1.59s\n",
      "bestTest = 0.4855114877\n",
      "bestIteration = 805\n",
      "Shrink model to first 806 iterations.\n",
      "===== ACCURACY SCORE 0.782662 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6878527\ttest: 0.6881994\tbest: 0.6881994 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4827473\ttest: 0.5101540\tbest: 0.5101540 (100)\ttotal: 1.53s\tremaining: 13.7s\n",
      "200:\tlearn: 0.4545765\ttest: 0.4970568\tbest: 0.4970568 (200)\ttotal: 3.44s\tremaining: 13.7s\n",
      "300:\tlearn: 0.4465461\ttest: 0.4963353\tbest: 0.4963132 (299)\ttotal: 4.92s\tremaining: 11.4s\n",
      "400:\tlearn: 0.4425795\ttest: 0.4964976\tbest: 0.4963081 (306)\ttotal: 6.38s\tremaining: 9.53s\n",
      "bestTest = 0.4963081409\n",
      "bestIteration = 306\n",
      "Shrink model to first 307 iterations.\n",
      "===== ACCURACY SCORE 0.772274 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6879523\ttest: 0.6881028\tbest: 0.6881028 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4858658\ttest: 0.5006326\tbest: 0.5006326 (100)\ttotal: 1.51s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4578477\ttest: 0.4832146\tbest: 0.4832146 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4498043\ttest: 0.4811477\tbest: 0.4811477 (300)\ttotal: 4.44s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4457329\ttest: 0.4806532\tbest: 0.4806496 (399)\ttotal: 6.27s\tremaining: 9.37s\n",
      "500:\tlearn: 0.4429599\ttest: 0.4805197\tbest: 0.4804911 (437)\ttotal: 7.81s\tremaining: 7.78s\n",
      "600:\tlearn: 0.4408529\ttest: 0.4805247\tbest: 0.4804740 (537)\ttotal: 9.27s\tremaining: 6.15s\n",
      "bestTest = 0.4804739767\n",
      "bestIteration = 537\n",
      "Shrink model to first 538 iterations.\n",
      "===== ACCURACY SCORE 0.783413 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6878470\ttest: 0.6881705\tbest: 0.6881705 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4828282\ttest: 0.5070874\tbest: 0.5070874 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4546878\ttest: 0.4925622\tbest: 0.4925622 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4468521\ttest: 0.4911944\tbest: 0.4911944 (300)\ttotal: 4.53s\tremaining: 10.5s\n",
      "400:\tlearn: 0.4429795\ttest: 0.4911139\tbest: 0.4909765 (368)\ttotal: 7.12s\tremaining: 10.6s\n",
      "bestTest = 0.4909765178\n",
      "bestIteration = 368\n",
      "Shrink model to first 369 iterations.\n",
      "===== ACCURACY SCORE 0.778817 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6878761\ttest: 0.6881671\tbest: 0.6881671 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4840742\ttest: 0.5049318\tbest: 0.5049318 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4562207\ttest: 0.4898481\tbest: 0.4898481 (200)\ttotal: 2.94s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4485268\ttest: 0.4889253\tbest: 0.4889177 (299)\ttotal: 4.41s\tremaining: 10.2s\n",
      "400:\tlearn: 0.4445825\ttest: 0.4886656\tbest: 0.4886434 (390)\ttotal: 5.87s\tremaining: 8.77s\n",
      "bestTest = 0.4886433805\n",
      "bestIteration = 390\n",
      "Shrink model to first 391 iterations.\n",
      "===== ACCURACY SCORE 0.776681 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778910 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6878675\ttest: 0.6880073\tbest: 0.6880073 (0)\ttotal: 15.6ms\tremaining: 15.6s\n",
      "100:\tlearn: 0.4832449\ttest: 0.4969858\tbest: 0.4969858 (100)\ttotal: 1.51s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4552030\ttest: 0.4796202\tbest: 0.4796202 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4474298\ttest: 0.4772754\tbest: 0.4772754 (300)\ttotal: 4.42s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4435124\ttest: 0.4766240\tbest: 0.4766234 (390)\ttotal: 5.88s\tremaining: 8.78s\n",
      "500:\tlearn: 0.4408007\ttest: 0.4765266\tbest: 0.4764772 (477)\ttotal: 7.34s\tremaining: 7.31s\n",
      "600:\tlearn: 0.4386365\ttest: 0.4765454\tbest: 0.4764427 (537)\ttotal: 8.81s\tremaining: 5.85s\n",
      "bestTest = 0.4764427052\n",
      "bestIteration = 537\n",
      "Shrink model to first 538 iterations.\n",
      "===== ACCURACY SCORE 0.784927 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6879011\ttest: 0.6881313\tbest: 0.6881313 (0)\ttotal: 22.6ms\tremaining: 22.6s\n",
      "100:\tlearn: 0.4848663\ttest: 0.5015377\tbest: 0.5015377 (100)\ttotal: 1.74s\tremaining: 15.5s\n",
      "200:\tlearn: 0.4568427\ttest: 0.4842339\tbest: 0.4842339 (200)\ttotal: 3.19s\tremaining: 12.7s\n",
      "300:\tlearn: 0.4488474\ttest: 0.4820969\tbest: 0.4820969 (300)\ttotal: 4.69s\tremaining: 10.9s\n",
      "400:\tlearn: 0.4448094\ttest: 0.4816197\tbest: 0.4816197 (400)\ttotal: 6.15s\tremaining: 9.19s\n",
      "500:\tlearn: 0.4421041\ttest: 0.4815179\tbest: 0.4815012 (472)\ttotal: 7.62s\tremaining: 7.59s\n",
      "600:\tlearn: 0.4400048\ttest: 0.4814435\tbest: 0.4814088 (589)\ttotal: 9.99s\tremaining: 6.63s\n",
      "700:\tlearn: 0.4381708\ttest: 0.4812494\tbest: 0.4812307 (669)\ttotal: 11.8s\tremaining: 5.05s\n",
      "800:\tlearn: 0.4365647\ttest: 0.4811842\tbest: 0.4811629 (782)\ttotal: 13.3s\tremaining: 3.31s\n",
      "900:\tlearn: 0.4351115\ttest: 0.4811838\tbest: 0.4811313 (862)\ttotal: 14.8s\tremaining: 1.62s\n",
      "999:\tlearn: 0.4336891\ttest: 0.4810212\tbest: 0.4810212 (999)\ttotal: 16.2s\tremaining: 0us\n",
      "bestTest = 0.481021173\n",
      "bestIteration = 999\n",
      "===== ACCURACY SCORE 0.781625 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6879166\ttest: 0.6881993\tbest: 0.6881993 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4847679\ttest: 0.5072401\tbest: 0.5072401 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4569753\ttest: 0.4920126\tbest: 0.4920126 (200)\ttotal: 2.95s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4492573\ttest: 0.4903800\tbest: 0.4903800 (300)\ttotal: 4.64s\tremaining: 10.8s\n",
      "400:\tlearn: 0.4453135\ttest: 0.4903435\tbest: 0.4902615 (318)\ttotal: 6.22s\tremaining: 9.29s\n",
      "bestTest = 0.4902614694\n",
      "bestIteration = 318\n",
      "Shrink model to first 319 iterations.\n",
      "===== ACCURACY SCORE 0.775859 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6878579\ttest: 0.6881815\tbest: 0.6881815 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4829324\ttest: 0.5077391\tbest: 0.5077391 (100)\ttotal: 1.51s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4545972\ttest: 0.4944245\tbest: 0.4944245 (200)\ttotal: 2.99s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4466401\ttest: 0.4940939\tbest: 0.4938832 (248)\ttotal: 4.45s\tremaining: 10.3s\n",
      "bestTest = 0.4938831968\n",
      "bestIteration = 248\n",
      "Shrink model to first 249 iterations.\n",
      "===== ACCURACY SCORE 0.776715 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6878820\ttest: 0.6882513\tbest: 0.6882513 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4839156\ttest: 0.5102929\tbest: 0.5102929 (100)\ttotal: 1.59s\tremaining: 14.2s\n",
      "200:\tlearn: 0.4556530\ttest: 0.4964958\tbest: 0.4964958 (200)\ttotal: 3.25s\tremaining: 12.9s\n",
      "300:\tlearn: 0.4477461\ttest: 0.4956423\tbest: 0.4956378 (298)\ttotal: 4.73s\tremaining: 11s\n",
      "400:\tlearn: 0.4436848\ttest: 0.4956447\tbest: 0.4955836 (383)\ttotal: 6.19s\tremaining: 9.25s\n",
      "500:\tlearn: 0.4409559\ttest: 0.4956167\tbest: 0.4955726 (448)\ttotal: 7.66s\tremaining: 7.63s\n",
      "600:\tlearn: 0.4387968\ttest: 0.4955982\tbest: 0.4955480 (547)\ttotal: 9.24s\tremaining: 6.13s\n",
      "700:\tlearn: 0.4369077\ttest: 0.4955942\tbest: 0.4955308 (654)\ttotal: 11.4s\tremaining: 4.86s\n",
      "bestTest = 0.4955307847\n",
      "bestIteration = 654\n",
      "Shrink model to first 655 iterations.\n",
      "===== ACCURACY SCORE 0.772903 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6878495\ttest: 0.6881407\tbest: 0.6881407 (0)\ttotal: 16ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4831379\ttest: 0.5069503\tbest: 0.5069503 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4551413\ttest: 0.4926945\tbest: 0.4926945 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4472782\ttest: 0.4921907\tbest: 0.4921246 (269)\ttotal: 4.44s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4432702\ttest: 0.4921606\tbest: 0.4920395 (327)\ttotal: 5.9s\tremaining: 8.82s\n",
      "bestTest = 0.4920394635\n",
      "bestIteration = 327\n",
      "Shrink model to first 328 iterations.\n",
      "===== ACCURACY SCORE 0.776289 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6879224\ttest: 0.6880519\tbest: 0.6880519 (0)\ttotal: 15.1ms\tremaining: 15.1s\n",
      "100:\tlearn: 0.4838841\ttest: 0.4983875\tbest: 0.4983875 (100)\ttotal: 1.51s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4558529\ttest: 0.4806754\tbest: 0.4806754 (200)\ttotal: 3.21s\tremaining: 12.8s\n",
      "300:\tlearn: 0.4480542\ttest: 0.4783369\tbest: 0.4783369 (300)\ttotal: 4.83s\tremaining: 11.2s\n",
      "400:\tlearn: 0.4440415\ttest: 0.4777999\tbest: 0.4777630 (393)\ttotal: 6.29s\tremaining: 9.4s\n",
      "500:\tlearn: 0.4413612\ttest: 0.4777236\tbest: 0.4777232 (497)\ttotal: 7.74s\tremaining: 7.71s\n",
      "600:\tlearn: 0.4391700\ttest: 0.4776978\tbest: 0.4776536 (542)\ttotal: 9.28s\tremaining: 6.16s\n",
      "bestTest = 0.4776535605\n",
      "bestIteration = 542\n",
      "Shrink model to first 543 iterations.\n",
      "===== ACCURACY SCORE 0.788240 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878638\ttest: 0.6881485\tbest: 0.6881485 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4832781\ttest: 0.5059383\tbest: 0.5059383 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4550860\ttest: 0.4912381\tbest: 0.4912381 (200)\ttotal: 3.12s\tremaining: 12.4s\n",
      "300:\tlearn: 0.4471942\ttest: 0.4905495\tbest: 0.4904726 (293)\ttotal: 4.86s\tremaining: 11.3s\n",
      "bestTest = 0.4904726283\n",
      "bestIteration = 293\n",
      "Shrink model to first 294 iterations.\n",
      "===== ACCURACY SCORE 0.775300 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6878936\ttest: 0.6881918\tbest: 0.6881918 (0)\ttotal: 16.7ms\tremaining: 16.7s\n",
      "100:\tlearn: 0.4841885\ttest: 0.5051938\tbest: 0.5051938 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4563148\ttest: 0.4890558\tbest: 0.4890558 (200)\ttotal: 3.84s\tremaining: 15.3s\n",
      "300:\tlearn: 0.4485447\ttest: 0.4871708\tbest: 0.4871706 (299)\ttotal: 5.3s\tremaining: 12.3s\n",
      "400:\tlearn: 0.4445580\ttest: 0.4864354\tbest: 0.4864354 (400)\ttotal: 6.85s\tremaining: 10.2s\n",
      "500:\tlearn: 0.4418745\ttest: 0.4859027\tbest: 0.4859027 (500)\ttotal: 8.61s\tremaining: 8.57s\n",
      "600:\tlearn: 0.4397410\ttest: 0.4858253\tbest: 0.4857512 (557)\ttotal: 10.1s\tremaining: 6.69s\n",
      "700:\tlearn: 0.4378820\ttest: 0.4855501\tbest: 0.4855344 (692)\ttotal: 11.5s\tremaining: 4.92s\n",
      "800:\tlearn: 0.4362806\ttest: 0.4852975\tbest: 0.4852809 (797)\ttotal: 13s\tremaining: 3.24s\n",
      "900:\tlearn: 0.4348417\ttest: 0.4851696\tbest: 0.4851676 (892)\ttotal: 14.5s\tremaining: 1.59s\n",
      "999:\tlearn: 0.4334260\ttest: 0.4851089\tbest: 0.4850930 (913)\ttotal: 15.9s\tremaining: 0us\n",
      "bestTest = 0.4850930262\n",
      "bestIteration = 913\n",
      "Shrink model to first 914 iterations.\n",
      "===== ACCURACY SCORE 0.778533 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6879140\ttest: 0.6881662\tbest: 0.6881662 (0)\ttotal: 15.9ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4849433\ttest: 0.5051476\tbest: 0.5051476 (100)\ttotal: 1.83s\tremaining: 16.3s\n",
      "200:\tlearn: 0.4568076\ttest: 0.4891266\tbest: 0.4891266 (200)\ttotal: 3.29s\tremaining: 13.1s\n",
      "300:\tlearn: 0.4488202\ttest: 0.4874861\tbest: 0.4874861 (300)\ttotal: 4.76s\tremaining: 11.1s\n",
      "400:\tlearn: 0.4447098\ttest: 0.4873374\tbest: 0.4872589 (363)\ttotal: 6.21s\tremaining: 9.28s\n",
      "500:\tlearn: 0.4419431\ttest: 0.4871910\tbest: 0.4871513 (478)\ttotal: 7.66s\tremaining: 7.63s\n",
      "bestTest = 0.487151274\n",
      "bestIteration = 478\n",
      "Shrink model to first 479 iterations.\n",
      "===== ACCURACY SCORE 0.775822 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778610 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6879400\ttest: 0.6881000\tbest: 0.6881000 (0)\ttotal: 15.4ms\tremaining: 15.3s\n",
      "100:\tlearn: 0.4846834\ttest: 0.5005360\tbest: 0.5005360 (100)\ttotal: 1.55s\tremaining: 13.8s\n",
      "200:\tlearn: 0.4566450\ttest: 0.4828668\tbest: 0.4828668 (200)\ttotal: 3.29s\tremaining: 13.1s\n",
      "300:\tlearn: 0.4487612\ttest: 0.4807331\tbest: 0.4807331 (300)\ttotal: 4.77s\tremaining: 11.1s\n",
      "400:\tlearn: 0.4446828\ttest: 0.4807396\tbest: 0.4806894 (360)\ttotal: 6.22s\tremaining: 9.29s\n",
      "bestTest = 0.4806894208\n",
      "bestIteration = 360\n",
      "Shrink model to first 361 iterations.\n",
      "===== ACCURACY SCORE 0.782019 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6879421\ttest: 0.6880792\tbest: 0.6880792 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4859942\ttest: 0.5003232\tbest: 0.5003232 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4580859\ttest: 0.4831194\tbest: 0.4831194 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4502876\ttest: 0.4810339\tbest: 0.4810339 (300)\ttotal: 4.67s\tremaining: 10.9s\n",
      "400:\tlearn: 0.4463081\ttest: 0.4803248\tbest: 0.4803248 (400)\ttotal: 6.3s\tremaining: 9.4s\n",
      "500:\tlearn: 0.4436048\ttest: 0.4800909\tbest: 0.4800905 (495)\ttotal: 7.76s\tremaining: 7.73s\n",
      "600:\tlearn: 0.4414898\ttest: 0.4797766\tbest: 0.4797632 (599)\ttotal: 9.23s\tremaining: 6.13s\n",
      "700:\tlearn: 0.4396359\ttest: 0.4795035\tbest: 0.4794985 (697)\ttotal: 10.7s\tremaining: 4.56s\n",
      "800:\tlearn: 0.4379563\ttest: 0.4794079\tbest: 0.4794079 (800)\ttotal: 12.2s\tremaining: 3.02s\n",
      "900:\tlearn: 0.4363935\ttest: 0.4793792\tbest: 0.4793601 (832)\ttotal: 13.6s\tremaining: 1.5s\n",
      "999:\tlearn: 0.4349877\ttest: 0.4794242\tbest: 0.4793524 (910)\ttotal: 15.2s\tremaining: 0us\n",
      "bestTest = 0.4793524002\n",
      "bestIteration = 910\n",
      "Shrink model to first 911 iterations.\n",
      "===== ACCURACY SCORE 0.784239 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6878670\ttest: 0.6880661\tbest: 0.6880661 (0)\ttotal: 16.7ms\tremaining: 16.6s\n",
      "100:\tlearn: 0.4837293\ttest: 0.4990643\tbest: 0.4990643 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4556408\ttest: 0.4815478\tbest: 0.4815478 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4475476\ttest: 0.4794311\tbest: 0.4794282 (299)\ttotal: 4.43s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4434587\ttest: 0.4790488\tbest: 0.4789945 (379)\ttotal: 5.91s\tremaining: 8.83s\n",
      "500:\tlearn: 0.4406874\ttest: 0.4787472\tbest: 0.4787472 (500)\ttotal: 7.38s\tremaining: 7.36s\n",
      "600:\tlearn: 0.4385678\ttest: 0.4786659\tbest: 0.4786629 (538)\ttotal: 8.87s\tremaining: 5.89s\n",
      "700:\tlearn: 0.4367399\ttest: 0.4785250\tbest: 0.4785246 (666)\ttotal: 10.8s\tremaining: 4.62s\n",
      "800:\tlearn: 0.4351181\ttest: 0.4784297\tbest: 0.4784067 (797)\ttotal: 12.3s\tremaining: 3.05s\n",
      "900:\tlearn: 0.4336886\ttest: 0.4783190\tbest: 0.4783062 (899)\ttotal: 14s\tremaining: 1.54s\n",
      "999:\tlearn: 0.4323258\ttest: 0.4783010\tbest: 0.4782825 (971)\ttotal: 16s\tremaining: 0us\n",
      "bestTest = 0.4782825454\n",
      "bestIteration = 971\n",
      "Shrink model to first 972 iterations.\n",
      "===== ACCURACY SCORE 0.785000 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6879306\ttest: 0.6881964\tbest: 0.6881964 (0)\ttotal: 16.7ms\tremaining: 16.7s\n",
      "100:\tlearn: 0.4850643\ttest: 0.5060712\tbest: 0.5060712 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4571884\ttest: 0.4909524\tbest: 0.4909524 (200)\ttotal: 3.07s\tremaining: 12.2s\n",
      "300:\tlearn: 0.4495125\ttest: 0.4896288\tbest: 0.4896232 (299)\ttotal: 4.95s\tremaining: 11.5s\n",
      "400:\tlearn: 0.4456299\ttest: 0.4892053\tbest: 0.4891746 (390)\ttotal: 6.4s\tremaining: 9.56s\n",
      "500:\tlearn: 0.4429769\ttest: 0.4891510\tbest: 0.4891276 (409)\ttotal: 7.86s\tremaining: 7.83s\n",
      "600:\tlearn: 0.4409125\ttest: 0.4891070\tbest: 0.4890411 (548)\ttotal: 9.32s\tremaining: 6.19s\n",
      "700:\tlearn: 0.4390891\ttest: 0.4889149\tbest: 0.4888816 (695)\ttotal: 10.8s\tremaining: 4.59s\n",
      "800:\tlearn: 0.4374663\ttest: 0.4888975\tbest: 0.4888714 (787)\ttotal: 12.3s\tremaining: 3.04s\n",
      "900:\tlearn: 0.4358937\ttest: 0.4888804\tbest: 0.4888250 (826)\ttotal: 13.7s\tremaining: 1.51s\n",
      "bestTest = 0.48882503\n",
      "bestIteration = 826\n",
      "Shrink model to first 827 iterations.\n",
      "===== ACCURACY SCORE 0.776987 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6878999\ttest: 0.6882819\tbest: 0.6882819 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4841577\ttest: 0.5097436\tbest: 0.5097436 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4560349\ttest: 0.4953158\tbest: 0.4953158 (200)\ttotal: 2.98s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4480007\ttest: 0.4940204\tbest: 0.4940087 (299)\ttotal: 4.44s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4438979\ttest: 0.4937762\tbest: 0.4937755 (395)\ttotal: 5.89s\tremaining: 8.8s\n",
      "500:\tlearn: 0.4411936\ttest: 0.4934661\tbest: 0.4934602 (499)\ttotal: 7.37s\tremaining: 7.34s\n",
      "600:\tlearn: 0.4390476\ttest: 0.4932423\tbest: 0.4932423 (600)\ttotal: 8.83s\tremaining: 5.86s\n",
      "700:\tlearn: 0.4372223\ttest: 0.4930571\tbest: 0.4930465 (699)\ttotal: 10.6s\tremaining: 4.54s\n",
      "800:\tlearn: 0.4356454\ttest: 0.4928907\tbest: 0.4928907 (800)\ttotal: 12.1s\tremaining: 3s\n",
      "900:\tlearn: 0.4340749\ttest: 0.4928248\tbest: 0.4927902 (884)\ttotal: 14.5s\tremaining: 1.59s\n",
      "999:\tlearn: 0.4326843\ttest: 0.4926857\tbest: 0.4926857 (999)\ttotal: 16s\tremaining: 0us\n",
      "bestTest = 0.4926857078\n",
      "bestIteration = 999\n",
      "===== ACCURACY SCORE 0.773808 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6879011\ttest: 0.6881792\tbest: 0.6881792 (0)\ttotal: 16.1ms\tremaining: 16.1s\n",
      "100:\tlearn: 0.4843605\ttest: 0.5059583\tbest: 0.5059583 (100)\ttotal: 1.51s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4560911\ttest: 0.4897028\tbest: 0.4897028 (200)\ttotal: 3.04s\tremaining: 12.1s\n",
      "300:\tlearn: 0.4481543\ttest: 0.4876384\tbest: 0.4876384 (300)\ttotal: 5s\tremaining: 11.6s\n",
      "400:\tlearn: 0.4442206\ttest: 0.4871039\tbest: 0.4871039 (400)\ttotal: 6.46s\tremaining: 9.65s\n",
      "500:\tlearn: 0.4414475\ttest: 0.4866890\tbest: 0.4866503 (494)\ttotal: 7.92s\tremaining: 7.89s\n",
      "600:\tlearn: 0.4393020\ttest: 0.4865560\tbest: 0.4865243 (593)\ttotal: 9.42s\tremaining: 6.25s\n",
      "700:\tlearn: 0.4374728\ttest: 0.4862421\tbest: 0.4862376 (687)\ttotal: 10.9s\tremaining: 4.64s\n",
      "800:\tlearn: 0.4358243\ttest: 0.4862201\tbest: 0.4861896 (793)\ttotal: 12.3s\tremaining: 3.06s\n",
      "900:\tlearn: 0.4343477\ttest: 0.4861296\tbest: 0.4861267 (896)\ttotal: 13.8s\tremaining: 1.52s\n",
      "999:\tlearn: 0.4329414\ttest: 0.4860707\tbest: 0.4860553 (946)\ttotal: 15.6s\tremaining: 0us\n",
      "bestTest = 0.4860553209\n",
      "bestIteration = 946\n",
      "Shrink model to first 947 iterations.\n",
      "===== ACCURACY SCORE 0.777900 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6878900\ttest: 0.6882819\tbest: 0.6882819 (0)\ttotal: 16.1ms\tremaining: 16.1s\n",
      "100:\tlearn: 0.4846832\ttest: 0.5112289\tbest: 0.5112289 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4565739\ttest: 0.4978778\tbest: 0.4978778 (200)\ttotal: 2.98s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4487245\ttest: 0.4973346\tbest: 0.4972970 (293)\ttotal: 4.47s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4447543\ttest: 0.4975463\tbest: 0.4972902 (317)\ttotal: 5.92s\tremaining: 8.85s\n",
      "bestTest = 0.4972902049\n",
      "bestIteration = 317\n",
      "Shrink model to first 318 iterations.\n",
      "===== ACCURACY SCORE 0.773781 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878396\ttest: 0.6881951\tbest: 0.6881951 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4824874\ttest: 0.5088442\tbest: 0.5088442 (100)\ttotal: 1.54s\tremaining: 13.7s\n",
      "200:\tlearn: 0.4543004\ttest: 0.4956742\tbest: 0.4956742 (200)\ttotal: 3.42s\tremaining: 13.6s\n",
      "300:\tlearn: 0.4464676\ttest: 0.4951897\tbest: 0.4951024 (291)\ttotal: 5.65s\tremaining: 13.1s\n",
      "400:\tlearn: 0.4425105\ttest: 0.4950798\tbest: 0.4950152 (363)\ttotal: 7.12s\tremaining: 10.6s\n",
      "bestTest = 0.4950151805\n",
      "bestIteration = 363\n",
      "Shrink model to first 364 iterations.\n",
      "===== ACCURACY SCORE 0.773530 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6878560\ttest: 0.6880961\tbest: 0.6880961 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4835836\ttest: 0.5013753\tbest: 0.5013753 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4557652\ttest: 0.4848129\tbest: 0.4848129 (200)\ttotal: 2.98s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4479418\ttest: 0.4832572\tbest: 0.4832572 (300)\ttotal: 4.87s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4439441\ttest: 0.4829210\tbest: 0.4829198 (396)\ttotal: 6.34s\tremaining: 9.48s\n",
      "500:\tlearn: 0.4412250\ttest: 0.4829245\tbest: 0.4828948 (426)\ttotal: 7.8s\tremaining: 7.77s\n",
      "600:\tlearn: 0.4390383\ttest: 0.4830294\tbest: 0.4828874 (515)\ttotal: 9.26s\tremaining: 6.15s\n",
      "bestTest = 0.4828873743\n",
      "bestIteration = 515\n",
      "Shrink model to first 516 iterations.\n",
      "===== ACCURACY SCORE 0.779049 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6879195\ttest: 0.6881676\tbest: 0.6881676 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4844075\ttest: 0.5062361\tbest: 0.5062361 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4564029\ttest: 0.4916056\tbest: 0.4916056 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4486697\ttest: 0.4902596\tbest: 0.4902475 (299)\ttotal: 4.67s\tremaining: 10.8s\n",
      "400:\tlearn: 0.4447448\ttest: 0.4899040\tbest: 0.4898818 (399)\ttotal: 6.34s\tremaining: 9.47s\n",
      "500:\tlearn: 0.4420463\ttest: 0.4896460\tbest: 0.4896044 (483)\ttotal: 7.81s\tremaining: 7.78s\n",
      "600:\tlearn: 0.4399446\ttest: 0.4894547\tbest: 0.4894265 (583)\ttotal: 9.27s\tremaining: 6.15s\n",
      "700:\tlearn: 0.4381308\ttest: 0.4893891\tbest: 0.4893366 (694)\ttotal: 10.7s\tremaining: 4.58s\n",
      "800:\tlearn: 0.4364649\ttest: 0.4892581\tbest: 0.4892343 (796)\ttotal: 12.2s\tremaining: 3.03s\n",
      "900:\tlearn: 0.4349586\ttest: 0.4892030\tbest: 0.4891411 (880)\ttotal: 13.7s\tremaining: 1.5s\n",
      "999:\tlearn: 0.4334990\ttest: 0.4891401\tbest: 0.4891020 (964)\ttotal: 15.2s\tremaining: 0us\n",
      "bestTest = 0.4891020347\n",
      "bestIteration = 964\n",
      "Shrink model to first 965 iterations.\n",
      "===== ACCURACY SCORE 0.780937 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778710 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6879155\ttest: 0.6881277\tbest: 0.6881277 (0)\ttotal: 53ms\tremaining: 53s\n",
      "100:\tlearn: 0.4842667\ttest: 0.5027025\tbest: 0.5027025 (100)\ttotal: 1.94s\tremaining: 17.3s\n",
      "200:\tlearn: 0.4563917\ttest: 0.4861713\tbest: 0.4861713 (200)\ttotal: 3.39s\tremaining: 13.5s\n",
      "300:\tlearn: 0.4485172\ttest: 0.4843892\tbest: 0.4843862 (293)\ttotal: 4.85s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4444904\ttest: 0.4841536\tbest: 0.4841482 (390)\ttotal: 6.32s\tremaining: 9.44s\n",
      "500:\tlearn: 0.4416020\ttest: 0.4840722\tbest: 0.4840560 (493)\ttotal: 7.77s\tremaining: 7.74s\n",
      "600:\tlearn: 0.4394512\ttest: 0.4842056\tbest: 0.4840242 (542)\ttotal: 9.37s\tremaining: 6.22s\n",
      "bestTest = 0.4840241773\n",
      "bestIteration = 542\n",
      "Shrink model to first 543 iterations.\n",
      "===== ACCURACY SCORE 0.780404 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6879354\ttest: 0.6881939\tbest: 0.6881939 (0)\ttotal: 15.2ms\tremaining: 15.2s\n",
      "100:\tlearn: 0.4839231\ttest: 0.5042047\tbest: 0.5042047 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4557372\ttest: 0.4879640\tbest: 0.4879640 (200)\ttotal: 2.94s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4479013\ttest: 0.4863475\tbest: 0.4863475 (300)\ttotal: 4.41s\tremaining: 10.2s\n",
      "400:\tlearn: 0.4438640\ttest: 0.4859753\tbest: 0.4858867 (390)\ttotal: 5.89s\tremaining: 8.79s\n",
      "500:\tlearn: 0.4410487\ttest: 0.4858908\tbest: 0.4858019 (463)\ttotal: 7.38s\tremaining: 7.35s\n",
      "bestTest = 0.4858019393\n",
      "bestIteration = 463\n",
      "Shrink model to first 464 iterations.\n",
      "===== ACCURACY SCORE 0.777479 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6878609\ttest: 0.6882374\tbest: 0.6882374 (0)\ttotal: 29.1ms\tremaining: 29.1s\n",
      "100:\tlearn: 0.4832625\ttest: 0.5112611\tbest: 0.5112611 (100)\ttotal: 1.7s\tremaining: 15.1s\n",
      "200:\tlearn: 0.4550465\ttest: 0.4975232\tbest: 0.4975232 (200)\ttotal: 3.15s\tremaining: 12.5s\n",
      "300:\tlearn: 0.4472283\ttest: 0.4964354\tbest: 0.4964263 (294)\ttotal: 4.61s\tremaining: 10.7s\n",
      "400:\tlearn: 0.4431968\ttest: 0.4958961\tbest: 0.4958902 (395)\ttotal: 6.06s\tremaining: 9.06s\n",
      "500:\tlearn: 0.4405268\ttest: 0.4956328\tbest: 0.4956293 (477)\ttotal: 7.51s\tremaining: 7.48s\n",
      "600:\tlearn: 0.4384162\ttest: 0.4954482\tbest: 0.4954213 (596)\ttotal: 8.98s\tremaining: 5.96s\n",
      "700:\tlearn: 0.4366205\ttest: 0.4952703\tbest: 0.4952537 (682)\ttotal: 10.8s\tremaining: 4.61s\n",
      "800:\tlearn: 0.4350260\ttest: 0.4951872\tbest: 0.4951803 (799)\ttotal: 13s\tremaining: 3.22s\n",
      "900:\tlearn: 0.4335980\ttest: 0.4950976\tbest: 0.4950660 (881)\ttotal: 14.4s\tremaining: 1.58s\n",
      "999:\tlearn: 0.4321887\ttest: 0.4950413\tbest: 0.4950258 (977)\ttotal: 15.9s\tremaining: 0us\n",
      "bestTest = 0.4950258073\n",
      "bestIteration = 977\n",
      "Shrink model to first 978 iterations.\n",
      "===== ACCURACY SCORE 0.773778 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6879356\ttest: 0.6881202\tbest: 0.6881202 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4853092\ttest: 0.5019909\tbest: 0.5019909 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4574217\ttest: 0.4852180\tbest: 0.4852180 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4495648\ttest: 0.4837489\tbest: 0.4837256 (296)\ttotal: 4.47s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4456315\ttest: 0.4838059\tbest: 0.4837213 (303)\ttotal: 6.26s\tremaining: 9.36s\n",
      "bestTest = 0.4837212915\n",
      "bestIteration = 303\n",
      "Shrink model to first 304 iterations.\n",
      "===== ACCURACY SCORE 0.783695 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6879005\ttest: 0.6881310\tbest: 0.6881310 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4838085\ttest: 0.5046616\tbest: 0.5046616 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4556933\ttest: 0.4892783\tbest: 0.4892783 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4477793\ttest: 0.4878689\tbest: 0.4878689 (300)\ttotal: 4.45s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4438120\ttest: 0.4875787\tbest: 0.4875787 (400)\ttotal: 5.92s\tremaining: 8.84s\n",
      "500:\tlearn: 0.4410286\ttest: 0.4873550\tbest: 0.4873493 (493)\ttotal: 7.39s\tremaining: 7.37s\n",
      "600:\tlearn: 0.4388830\ttest: 0.4871734\tbest: 0.4871527 (597)\ttotal: 9.22s\tremaining: 6.12s\n",
      "700:\tlearn: 0.4370456\ttest: 0.4871095\tbest: 0.4871095 (700)\ttotal: 10.7s\tremaining: 4.57s\n",
      "800:\tlearn: 0.4354269\ttest: 0.4869479\tbest: 0.4869428 (790)\ttotal: 12.2s\tremaining: 3.03s\n",
      "900:\tlearn: 0.4339513\ttest: 0.4868484\tbest: 0.4868269 (851)\ttotal: 13.7s\tremaining: 1.5s\n",
      "999:\tlearn: 0.4325688\ttest: 0.4867189\tbest: 0.4867096 (987)\ttotal: 15.2s\tremaining: 0us\n",
      "bestTest = 0.4867096375\n",
      "bestIteration = 987\n",
      "Shrink model to first 988 iterations.\n",
      "===== ACCURACY SCORE 0.781738 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6878874\ttest: 0.6881397\tbest: 0.6881397 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4840850\ttest: 0.5046152\tbest: 0.5046152 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4562258\ttest: 0.4894084\tbest: 0.4894084 (200)\ttotal: 4.17s\tremaining: 16.6s\n",
      "300:\tlearn: 0.4484123\ttest: 0.4878415\tbest: 0.4878378 (299)\ttotal: 5.71s\tremaining: 13.3s\n",
      "400:\tlearn: 0.4443878\ttest: 0.4875491\tbest: 0.4875491 (400)\ttotal: 7.17s\tremaining: 10.7s\n",
      "500:\tlearn: 0.4416687\ttest: 0.4874325\tbest: 0.4874115 (455)\ttotal: 8.67s\tremaining: 8.64s\n",
      "bestTest = 0.4874115402\n",
      "bestIteration = 455\n",
      "Shrink model to first 456 iterations.\n",
      "===== ACCURACY SCORE 0.779266 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6879095\ttest: 0.6881856\tbest: 0.6881856 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4840944\ttest: 0.5045958\tbest: 0.5045958 (100)\ttotal: 1.52s\tremaining: 13.6s\n",
      "200:\tlearn: 0.4560442\ttest: 0.4884896\tbest: 0.4884896 (200)\ttotal: 3s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4481824\ttest: 0.4869237\tbest: 0.4869202 (299)\ttotal: 4.83s\tremaining: 11.2s\n",
      "400:\tlearn: 0.4442130\ttest: 0.4865384\tbest: 0.4865384 (400)\ttotal: 6.29s\tremaining: 9.4s\n",
      "500:\tlearn: 0.4414984\ttest: 0.4861936\tbest: 0.4861836 (497)\ttotal: 7.84s\tremaining: 7.81s\n",
      "600:\tlearn: 0.4394264\ttest: 0.4861111\tbest: 0.4860186 (550)\ttotal: 9.32s\tremaining: 6.19s\n",
      "700:\tlearn: 0.4376493\ttest: 0.4858967\tbest: 0.4858966 (699)\ttotal: 10.8s\tremaining: 4.6s\n",
      "800:\tlearn: 0.4360021\ttest: 0.4857869\tbest: 0.4857718 (784)\ttotal: 12.2s\tremaining: 3.04s\n",
      "900:\tlearn: 0.4345014\ttest: 0.4856811\tbest: 0.4856715 (891)\ttotal: 13.7s\tremaining: 1.51s\n",
      "999:\tlearn: 0.4330666\ttest: 0.4855046\tbest: 0.4855007 (997)\ttotal: 15.6s\tremaining: 0us\n",
      "bestTest = 0.4855007051\n",
      "bestIteration = 997\n",
      "Shrink model to first 998 iterations.\n",
      "===== ACCURACY SCORE 0.783246 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878530\ttest: 0.6880938\tbest: 0.6880938 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4828595\ttest: 0.5012538\tbest: 0.5012538 (100)\ttotal: 1.53s\tremaining: 13.6s\n",
      "200:\tlearn: 0.4548915\ttest: 0.4851292\tbest: 0.4851292 (200)\ttotal: 2.99s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4471792\ttest: 0.4835247\tbest: 0.4835247 (300)\ttotal: 4.45s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4431643\ttest: 0.4831876\tbest: 0.4831778 (394)\ttotal: 5.92s\tremaining: 8.84s\n",
      "500:\tlearn: 0.4405021\ttest: 0.4832085\tbest: 0.4831002 (463)\ttotal: 8.46s\tremaining: 8.42s\n",
      "bestTest = 0.4831002058\n",
      "bestIteration = 463\n",
      "Shrink model to first 464 iterations.\n",
      "===== ACCURACY SCORE 0.780140 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6877690\ttest: 0.6879587\tbest: 0.6879587 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4825246\ttest: 0.5047400\tbest: 0.5047400 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4544538\ttest: 0.4890513\tbest: 0.4890513 (200)\ttotal: 2.98s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4465914\ttest: 0.4871365\tbest: 0.4871365 (300)\ttotal: 4.44s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4425465\ttest: 0.4868096\tbest: 0.4867743 (390)\ttotal: 5.89s\tremaining: 8.81s\n",
      "500:\tlearn: 0.4397983\ttest: 0.4868018\tbest: 0.4867573 (465)\ttotal: 7.35s\tremaining: 7.32s\n",
      "bestTest = 0.4867572811\n",
      "bestIteration = 465\n",
      "Shrink model to first 466 iterations.\n",
      "===== ACCURACY SCORE 0.777058 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6878830\ttest: 0.6881317\tbest: 0.6881317 (0)\ttotal: 27.1ms\tremaining: 27s\n",
      "100:\tlearn: 0.4828108\ttest: 0.5062053\tbest: 0.5062053 (100)\ttotal: 1.79s\tremaining: 15.9s\n",
      "200:\tlearn: 0.4546591\ttest: 0.4921700\tbest: 0.4921700 (200)\ttotal: 3.26s\tremaining: 12.9s\n",
      "300:\tlearn: 0.4469406\ttest: 0.4915767\tbest: 0.4914885 (275)\ttotal: 4.73s\tremaining: 11s\n",
      "bestTest = 0.4914885214\n",
      "bestIteration = 275\n",
      "Shrink model to first 276 iterations.\n",
      "===== ACCURACY SCORE 0.774970 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779170 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6878455\ttest: 0.6881999\tbest: 0.6881999 (0)\ttotal: 15.6ms\tremaining: 15.6s\n",
      "100:\tlearn: 0.4829031\ttest: 0.5089467\tbest: 0.5089467 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4546339\ttest: 0.4949931\tbest: 0.4949914 (198)\ttotal: 2.94s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4466557\ttest: 0.4938867\tbest: 0.4938867 (300)\ttotal: 4.76s\tremaining: 11s\n",
      "400:\tlearn: 0.4425879\ttest: 0.4936107\tbest: 0.4936086 (395)\ttotal: 6.26s\tremaining: 9.35s\n",
      "500:\tlearn: 0.4398620\ttest: 0.4935459\tbest: 0.4935009 (483)\ttotal: 7.71s\tremaining: 7.68s\n",
      "600:\tlearn: 0.4376875\ttest: 0.4933534\tbest: 0.4933247 (595)\ttotal: 9.18s\tremaining: 6.1s\n",
      "700:\tlearn: 0.4358437\ttest: 0.4933910\tbest: 0.4932975 (648)\ttotal: 10.7s\tremaining: 4.54s\n",
      "bestTest = 0.4932975154\n",
      "bestIteration = 648\n",
      "Shrink model to first 649 iterations.\n",
      "===== ACCURACY SCORE 0.777514 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6879215\ttest: 0.6880581\tbest: 0.6880581 (0)\ttotal: 15.4ms\tremaining: 15.4s\n",
      "100:\tlearn: 0.4838969\ttest: 0.4984788\tbest: 0.4984788 (100)\ttotal: 1.62s\tremaining: 14.4s\n",
      "200:\tlearn: 0.4560074\ttest: 0.4808267\tbest: 0.4808267 (200)\ttotal: 3.45s\tremaining: 13.7s\n",
      "300:\tlearn: 0.4482411\ttest: 0.4787144\tbest: 0.4787144 (300)\ttotal: 4.92s\tremaining: 11.4s\n",
      "400:\tlearn: 0.4442969\ttest: 0.4783228\tbest: 0.4783228 (400)\ttotal: 6.38s\tremaining: 9.53s\n",
      "500:\tlearn: 0.4416009\ttest: 0.4781441\tbest: 0.4781168 (493)\ttotal: 7.86s\tremaining: 7.83s\n",
      "600:\tlearn: 0.4394357\ttest: 0.4782474\tbest: 0.4781111 (511)\ttotal: 9.35s\tremaining: 6.21s\n",
      "bestTest = 0.4781111441\n",
      "bestIteration = 511\n",
      "Shrink model to first 512 iterations.\n",
      "===== ACCURACY SCORE 0.783819 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6879157\ttest: 0.6881004\tbest: 0.6881004 (0)\ttotal: 14.1ms\tremaining: 14.1s\n",
      "100:\tlearn: 0.4837601\ttest: 0.5024591\tbest: 0.5024591 (100)\ttotal: 1.51s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4557896\ttest: 0.4863454\tbest: 0.4863454 (200)\ttotal: 3.43s\tremaining: 13.6s\n",
      "300:\tlearn: 0.4479451\ttest: 0.4846426\tbest: 0.4846426 (300)\ttotal: 4.93s\tremaining: 11.5s\n",
      "400:\tlearn: 0.4439760\ttest: 0.4843629\tbest: 0.4843022 (388)\ttotal: 6.43s\tremaining: 9.6s\n",
      "bestTest = 0.4843021684\n",
      "bestIteration = 388\n",
      "Shrink model to first 389 iterations.\n",
      "===== ACCURACY SCORE 0.777017 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6879012\ttest: 0.6881910\tbest: 0.6881910 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4840534\ttest: 0.5075299\tbest: 0.5075299 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4561219\ttest: 0.4925240\tbest: 0.4925240 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4482779\ttest: 0.4907591\tbest: 0.4907591 (300)\ttotal: 4.46s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4442744\ttest: 0.4905712\tbest: 0.4905496 (399)\ttotal: 6.27s\tremaining: 9.36s\n",
      "500:\tlearn: 0.4415306\ttest: 0.4906386\tbest: 0.4904767 (424)\ttotal: 7.73s\tremaining: 7.7s\n",
      "bestTest = 0.4904766642\n",
      "bestIteration = 424\n",
      "Shrink model to first 425 iterations.\n",
      "===== ACCURACY SCORE 0.773698 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6879288\ttest: 0.6881467\tbest: 0.6881467 (0)\ttotal: 14.3ms\tremaining: 14.2s\n",
      "100:\tlearn: 0.4835922\ttest: 0.5030271\tbest: 0.5030271 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4555777\ttest: 0.4875954\tbest: 0.4875954 (200)\ttotal: 3.84s\tremaining: 15.3s\n",
      "300:\tlearn: 0.4477542\ttest: 0.4860322\tbest: 0.4859792 (293)\ttotal: 5.3s\tremaining: 12.3s\n",
      "400:\tlearn: 0.4437828\ttest: 0.4857427\tbest: 0.4857427 (400)\ttotal: 6.9s\tremaining: 10.3s\n",
      "500:\tlearn: 0.4411076\ttest: 0.4855702\tbest: 0.4855545 (493)\ttotal: 8.56s\tremaining: 8.52s\n",
      "600:\tlearn: 0.4389582\ttest: 0.4854437\tbest: 0.4854313 (593)\ttotal: 10s\tremaining: 6.66s\n",
      "700:\tlearn: 0.4371020\ttest: 0.4852589\tbest: 0.4852412 (691)\ttotal: 11.5s\tremaining: 4.9s\n",
      "800:\tlearn: 0.4354316\ttest: 0.4852228\tbest: 0.4852058 (791)\ttotal: 13s\tremaining: 3.22s\n",
      "900:\tlearn: 0.4339243\ttest: 0.4852253\tbest: 0.4851676 (848)\ttotal: 14.4s\tremaining: 1.58s\n",
      "999:\tlearn: 0.4325406\ttest: 0.4851430\tbest: 0.4851263 (985)\ttotal: 15.9s\tremaining: 0us\n",
      "bestTest = 0.4851263102\n",
      "bestIteration = 985\n",
      "Shrink model to first 986 iterations.\n",
      "===== ACCURACY SCORE 0.780430 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6879092\ttest: 0.6880605\tbest: 0.6880605 (0)\ttotal: 16.6ms\tremaining: 16.6s\n",
      "100:\tlearn: 0.4838672\ttest: 0.5000267\tbest: 0.5000267 (100)\ttotal: 1.87s\tremaining: 16.6s\n",
      "200:\tlearn: 0.4557175\ttest: 0.4832990\tbest: 0.4832990 (200)\ttotal: 3.34s\tremaining: 13.3s\n",
      "300:\tlearn: 0.4477809\ttest: 0.4816880\tbest: 0.4816820 (299)\ttotal: 4.8s\tremaining: 11.2s\n",
      "400:\tlearn: 0.4437587\ttest: 0.4814845\tbest: 0.4814740 (378)\ttotal: 6.29s\tremaining: 9.4s\n",
      "500:\tlearn: 0.4410107\ttest: 0.4814342\tbest: 0.4813999 (474)\ttotal: 7.76s\tremaining: 7.72s\n",
      "600:\tlearn: 0.4388792\ttest: 0.4813233\tbest: 0.4813036 (561)\ttotal: 9.23s\tremaining: 6.13s\n",
      "700:\tlearn: 0.4369944\ttest: 0.4812407\tbest: 0.4812217 (662)\ttotal: 10.7s\tremaining: 4.57s\n",
      "800:\tlearn: 0.4353734\ttest: 0.4810216\tbest: 0.4810216 (800)\ttotal: 12.5s\tremaining: 3.1s\n",
      "900:\tlearn: 0.4338548\ttest: 0.4808816\tbest: 0.4808762 (888)\ttotal: 14s\tremaining: 1.53s\n",
      "999:\tlearn: 0.4324080\ttest: 0.4808838\tbest: 0.4808466 (930)\ttotal: 15.5s\tremaining: 0us\n",
      "bestTest = 0.480846589\n",
      "bestIteration = 930\n",
      "Shrink model to first 931 iterations.\n",
      "===== ACCURACY SCORE 0.784164 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6878809\ttest: 0.6881626\tbest: 0.6881626 (0)\ttotal: 42.1ms\tremaining: 42.1s\n",
      "100:\tlearn: 0.4836131\ttest: 0.5055475\tbest: 0.5055475 (100)\ttotal: 2.29s\tremaining: 20.3s\n",
      "200:\tlearn: 0.4552557\ttest: 0.4907505\tbest: 0.4907505 (200)\ttotal: 3.75s\tremaining: 14.9s\n",
      "300:\tlearn: 0.4472566\ttest: 0.4896103\tbest: 0.4895745 (293)\ttotal: 5.21s\tremaining: 12.1s\n",
      "400:\tlearn: 0.4432697\ttest: 0.4893691\tbest: 0.4892926 (365)\ttotal: 7.06s\tremaining: 10.6s\n",
      "500:\tlearn: 0.4405260\ttest: 0.4891614\tbest: 0.4891584 (498)\ttotal: 8.53s\tremaining: 8.5s\n",
      "600:\tlearn: 0.4383078\ttest: 0.4889211\tbest: 0.4889208 (599)\ttotal: 10s\tremaining: 6.65s\n",
      "700:\tlearn: 0.4364540\ttest: 0.4887831\tbest: 0.4887348 (692)\ttotal: 11.5s\tremaining: 4.9s\n",
      "800:\tlearn: 0.4348026\ttest: 0.4886788\tbest: 0.4886788 (800)\ttotal: 13s\tremaining: 3.22s\n",
      "900:\tlearn: 0.4332682\ttest: 0.4886173\tbest: 0.4886067 (848)\ttotal: 14.4s\tremaining: 1.58s\n",
      "999:\tlearn: 0.4318779\ttest: 0.4884605\tbest: 0.4884605 (999)\ttotal: 15.9s\tremaining: 0us\n",
      "bestTest = 0.4884604858\n",
      "bestIteration = 999\n",
      "===== ACCURACY SCORE 0.780466 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878662\ttest: 0.6882748\tbest: 0.6882748 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4833536\ttest: 0.5118482\tbest: 0.5118482 (100)\ttotal: 1.91s\tremaining: 17s\n",
      "200:\tlearn: 0.4551815\ttest: 0.4980871\tbest: 0.4980871 (200)\ttotal: 3.4s\tremaining: 13.5s\n",
      "300:\tlearn: 0.4472813\ttest: 0.4971089\tbest: 0.4971089 (300)\ttotal: 4.88s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4433105\ttest: 0.4968933\tbest: 0.4968656 (395)\ttotal: 6.36s\tremaining: 9.5s\n",
      "500:\tlearn: 0.4405843\ttest: 0.4968421\tbest: 0.4967975 (416)\ttotal: 7.88s\tremaining: 7.84s\n",
      "600:\tlearn: 0.4384363\ttest: 0.4966973\tbest: 0.4966775 (558)\ttotal: 9.35s\tremaining: 6.21s\n",
      "700:\tlearn: 0.4366365\ttest: 0.4968534\tbest: 0.4966601 (654)\ttotal: 10.9s\tremaining: 4.66s\n",
      "bestTest = 0.4966600969\n",
      "bestIteration = 654\n",
      "Shrink model to first 655 iterations.\n",
      "===== ACCURACY SCORE 0.774164 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6879637\ttest: 0.6881828\tbest: 0.6881828 (0)\ttotal: 15.6ms\tremaining: 15.6s\n",
      "100:\tlearn: 0.4863262\ttest: 0.5034207\tbest: 0.5034207 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4584223\ttest: 0.4863793\tbest: 0.4863793 (200)\ttotal: 3.71s\tremaining: 14.7s\n",
      "300:\tlearn: 0.4505811\ttest: 0.4846861\tbest: 0.4846210 (293)\ttotal: 5.16s\tremaining: 12s\n",
      "bestTest = 0.4846209956\n",
      "bestIteration = 293\n",
      "Shrink model to first 294 iterations.\n",
      "===== ACCURACY SCORE 0.779354 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6878965\ttest: 0.6881837\tbest: 0.6881837 (0)\ttotal: 17.1ms\tremaining: 17.1s\n",
      "100:\tlearn: 0.4844063\ttest: 0.5061787\tbest: 0.5061787 (100)\ttotal: 1.7s\tremaining: 15.2s\n",
      "200:\tlearn: 0.4563935\ttest: 0.4910113\tbest: 0.4910113 (200)\ttotal: 3.3s\tremaining: 13.1s\n",
      "300:\tlearn: 0.4484469\ttest: 0.4900461\tbest: 0.4900461 (300)\ttotal: 4.76s\tremaining: 11s\n",
      "400:\tlearn: 0.4444214\ttest: 0.4901220\tbest: 0.4900367 (303)\ttotal: 6.24s\tremaining: 9.31s\n",
      "bestTest = 0.4900367166\n",
      "bestIteration = 303\n",
      "Shrink model to first 304 iterations.\n",
      "===== ACCURACY SCORE 0.777745 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778840 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6878822\ttest: 0.6882822\tbest: 0.6882822 (0)\ttotal: 16.1ms\tremaining: 16.1s\n",
      "100:\tlearn: 0.4834016\ttest: 0.5126421\tbest: 0.5126421 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4553333\ttest: 0.4996212\tbest: 0.4996212 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4474453\ttest: 0.4990972\tbest: 0.4990972 (300)\ttotal: 4.51s\tremaining: 10.5s\n",
      "400:\tlearn: 0.4433650\ttest: 0.4994449\tbest: 0.4990348 (312)\ttotal: 6.39s\tremaining: 9.55s\n",
      "bestTest = 0.4990347569\n",
      "bestIteration = 312\n",
      "Shrink model to first 313 iterations.\n",
      "===== ACCURACY SCORE 0.770061 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6879141\ttest: 0.6880178\tbest: 0.6880178 (0)\ttotal: 15.8ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4844432\ttest: 0.4962369\tbest: 0.4962369 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4562188\ttest: 0.4775041\tbest: 0.4775041 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4483030\ttest: 0.4750192\tbest: 0.4750192 (300)\ttotal: 4.43s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4443385\ttest: 0.4742794\tbest: 0.4742665 (399)\ttotal: 5.96s\tremaining: 8.9s\n",
      "500:\tlearn: 0.4415857\ttest: 0.4740272\tbest: 0.4740160 (494)\ttotal: 7.43s\tremaining: 7.4s\n",
      "600:\tlearn: 0.4394441\ttest: 0.4739879\tbest: 0.4739212 (584)\ttotal: 9.2s\tremaining: 6.11s\n",
      "bestTest = 0.4739211556\n",
      "bestIteration = 584\n",
      "Shrink model to first 585 iterations.\n",
      "===== ACCURACY SCORE 0.789505 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6879201\ttest: 0.6882004\tbest: 0.6882004 (0)\ttotal: 49.9ms\tremaining: 49.9s\n",
      "100:\tlearn: 0.4834645\ttest: 0.5058568\tbest: 0.5058568 (100)\ttotal: 2.22s\tremaining: 19.8s\n",
      "200:\tlearn: 0.4555987\ttest: 0.4906023\tbest: 0.4906023 (200)\ttotal: 3.67s\tremaining: 14.6s\n",
      "300:\tlearn: 0.4477970\ttest: 0.4893634\tbest: 0.4893634 (300)\ttotal: 5.17s\tremaining: 12s\n",
      "400:\tlearn: 0.4438387\ttest: 0.4889953\tbest: 0.4889953 (400)\ttotal: 6.64s\tremaining: 9.92s\n",
      "500:\tlearn: 0.4411549\ttest: 0.4890240\tbest: 0.4889505 (420)\ttotal: 8.3s\tremaining: 8.27s\n",
      "bestTest = 0.4889504657\n",
      "bestIteration = 420\n",
      "Shrink model to first 421 iterations.\n",
      "===== ACCURACY SCORE 0.776875 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6879836\ttest: 0.6881873\tbest: 0.6881873 (0)\ttotal: 15.2ms\tremaining: 15.2s\n",
      "100:\tlearn: 0.4854212\ttest: 0.5053949\tbest: 0.5053949 (100)\ttotal: 1.53s\tremaining: 13.6s\n",
      "200:\tlearn: 0.4573887\ttest: 0.4889838\tbest: 0.4889838 (200)\ttotal: 3s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4494467\ttest: 0.4871013\tbest: 0.4871013 (300)\ttotal: 4.46s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4453243\ttest: 0.4865612\tbest: 0.4865425 (399)\ttotal: 5.94s\tremaining: 8.88s\n",
      "500:\tlearn: 0.4425694\ttest: 0.4862673\tbest: 0.4862673 (500)\ttotal: 7.4s\tremaining: 7.37s\n",
      "600:\tlearn: 0.4404836\ttest: 0.4861339\tbest: 0.4861047 (596)\ttotal: 8.93s\tremaining: 5.92s\n",
      "700:\tlearn: 0.4386792\ttest: 0.4861040\tbest: 0.4860775 (675)\ttotal: 10.7s\tremaining: 4.58s\n",
      "800:\tlearn: 0.4370727\ttest: 0.4860236\tbest: 0.4860069 (776)\ttotal: 12.2s\tremaining: 3.03s\n",
      "900:\tlearn: 0.4355421\ttest: 0.4859225\tbest: 0.4859220 (899)\ttotal: 13.7s\tremaining: 1.5s\n",
      "999:\tlearn: 0.4341895\ttest: 0.4858891\tbest: 0.4858706 (947)\ttotal: 15.1s\tremaining: 0us\n",
      "bestTest = 0.485870631\n",
      "bestIteration = 947\n",
      "Shrink model to first 948 iterations.\n",
      "===== ACCURACY SCORE 0.779366 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6878233\ttest: 0.6879400\tbest: 0.6879400 (0)\ttotal: 16.7ms\tremaining: 16.7s\n",
      "100:\tlearn: 0.4835050\ttest: 0.5040783\tbest: 0.5040783 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4554025\ttest: 0.4892098\tbest: 0.4892098 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4474326\ttest: 0.4880376\tbest: 0.4880185 (296)\ttotal: 4.79s\tremaining: 11.1s\n",
      "400:\tlearn: 0.4433605\ttest: 0.4879025\tbest: 0.4878511 (391)\ttotal: 6.81s\tremaining: 10.2s\n",
      "500:\tlearn: 0.4406343\ttest: 0.4878569\tbest: 0.4878417 (427)\ttotal: 8.58s\tremaining: 8.54s\n",
      "600:\tlearn: 0.4384934\ttest: 0.4878277\tbest: 0.4878051 (561)\ttotal: 10.1s\tremaining: 6.68s\n",
      "700:\tlearn: 0.4366379\ttest: 0.4877417\tbest: 0.4876764 (665)\ttotal: 11.5s\tremaining: 4.92s\n",
      "bestTest = 0.4876764236\n",
      "bestIteration = 665\n",
      "Shrink model to first 666 iterations.\n",
      "===== ACCURACY SCORE 0.779421 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6879007\ttest: 0.6880926\tbest: 0.6880926 (0)\ttotal: 15.8ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4844976\ttest: 0.5021941\tbest: 0.5021941 (100)\ttotal: 1.59s\tremaining: 14.2s\n",
      "200:\tlearn: 0.4562488\ttest: 0.4857266\tbest: 0.4857266 (200)\ttotal: 3.29s\tremaining: 13.1s\n",
      "300:\tlearn: 0.4482393\ttest: 0.4839885\tbest: 0.4839885 (300)\ttotal: 4.76s\tremaining: 11.1s\n",
      "400:\tlearn: 0.4441576\ttest: 0.4836457\tbest: 0.4836340 (399)\ttotal: 6.25s\tremaining: 9.33s\n",
      "500:\tlearn: 0.4414145\ttest: 0.4834982\tbest: 0.4834716 (491)\ttotal: 7.7s\tremaining: 7.67s\n",
      "600:\tlearn: 0.4392414\ttest: 0.4835409\tbest: 0.4834283 (529)\ttotal: 9.15s\tremaining: 6.08s\n",
      "bestTest = 0.4834283333\n",
      "bestIteration = 529\n",
      "Shrink model to first 530 iterations.\n",
      "===== ACCURACY SCORE 0.784858 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6878799\ttest: 0.6882021\tbest: 0.6882021 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4837101\ttest: 0.5089773\tbest: 0.5089773 (100)\ttotal: 1.55s\tremaining: 13.8s\n",
      "200:\tlearn: 0.4557766\ttest: 0.4953472\tbest: 0.4953472 (200)\ttotal: 3.46s\tremaining: 13.7s\n",
      "300:\tlearn: 0.4479284\ttest: 0.4948916\tbest: 0.4946485 (245)\ttotal: 4.97s\tremaining: 11.5s\n",
      "bestTest = 0.4946484592\n",
      "bestIteration = 245\n",
      "Shrink model to first 246 iterations.\n",
      "===== ACCURACY SCORE 0.772474 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6879120\ttest: 0.6882239\tbest: 0.6882239 (0)\ttotal: 16.2ms\tremaining: 16.2s\n",
      "100:\tlearn: 0.4844899\ttest: 0.5081819\tbest: 0.5081819 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4564093\ttest: 0.4936250\tbest: 0.4936250 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4485293\ttest: 0.4927513\tbest: 0.4927355 (292)\ttotal: 4.43s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4446237\ttest: 0.4925011\tbest: 0.4924608 (362)\ttotal: 5.96s\tremaining: 8.9s\n",
      "500:\tlearn: 0.4419814\ttest: 0.4924500\tbest: 0.4923919 (462)\ttotal: 8.64s\tremaining: 8.6s\n",
      "bestTest = 0.4923918729\n",
      "bestIteration = 462\n",
      "Shrink model to first 463 iterations.\n",
      "===== ACCURACY SCORE 0.772919 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6878995\ttest: 0.6880827\tbest: 0.6880827 (0)\ttotal: 16.6ms\tremaining: 16.6s\n",
      "100:\tlearn: 0.4842806\ttest: 0.4992954\tbest: 0.4992954 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4561079\ttest: 0.4817164\tbest: 0.4817164 (200)\ttotal: 2.94s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4482352\ttest: 0.4793389\tbest: 0.4793389 (300)\ttotal: 4.42s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4442736\ttest: 0.4784798\tbest: 0.4784758 (399)\ttotal: 5.9s\tremaining: 8.82s\n",
      "500:\tlearn: 0.4415969\ttest: 0.4780865\tbest: 0.4780865 (500)\ttotal: 7.87s\tremaining: 7.84s\n",
      "600:\tlearn: 0.4395112\ttest: 0.4779809\tbest: 0.4779118 (536)\ttotal: 9.35s\tremaining: 6.2s\n",
      "700:\tlearn: 0.4376443\ttest: 0.4777091\tbest: 0.4776938 (688)\ttotal: 10.8s\tremaining: 4.61s\n",
      "800:\tlearn: 0.4360385\ttest: 0.4775866\tbest: 0.4775866 (800)\ttotal: 12.3s\tremaining: 3.05s\n",
      "900:\tlearn: 0.4345652\ttest: 0.4774560\tbest: 0.4774560 (900)\ttotal: 13.7s\tremaining: 1.51s\n",
      "999:\tlearn: 0.4331501\ttest: 0.4774182\tbest: 0.4773931 (967)\ttotal: 15.2s\tremaining: 0us\n",
      "bestTest = 0.4773930503\n",
      "bestIteration = 967\n",
      "Shrink model to first 968 iterations.\n",
      "===== ACCURACY SCORE 0.784733 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6878871\ttest: 0.6881498\tbest: 0.6881498 (0)\ttotal: 16.8ms\tremaining: 16.8s\n",
      "100:\tlearn: 0.4829183\ttest: 0.5037580\tbest: 0.5037580 (100)\ttotal: 1.8s\tremaining: 16s\n",
      "200:\tlearn: 0.4547650\ttest: 0.4879454\tbest: 0.4879454 (200)\ttotal: 3.42s\tremaining: 13.6s\n",
      "300:\tlearn: 0.4468330\ttest: 0.4862163\tbest: 0.4862100 (299)\ttotal: 4.89s\tremaining: 11.4s\n",
      "400:\tlearn: 0.4428424\ttest: 0.4859210\tbest: 0.4859210 (400)\ttotal: 6.36s\tremaining: 9.49s\n",
      "500:\tlearn: 0.4400866\ttest: 0.4856807\tbest: 0.4856389 (481)\ttotal: 7.83s\tremaining: 7.79s\n",
      "600:\tlearn: 0.4380020\ttest: 0.4855690\tbest: 0.4855642 (595)\ttotal: 9.29s\tremaining: 6.17s\n",
      "700:\tlearn: 0.4361598\ttest: 0.4853712\tbest: 0.4853585 (676)\ttotal: 10.8s\tremaining: 4.6s\n",
      "800:\tlearn: 0.4345415\ttest: 0.4852520\tbest: 0.4852520 (800)\ttotal: 13.4s\tremaining: 3.32s\n",
      "900:\tlearn: 0.4330326\ttest: 0.4850591\tbest: 0.4850591 (900)\ttotal: 15s\tremaining: 1.65s\n",
      "999:\tlearn: 0.4317006\ttest: 0.4849811\tbest: 0.4849612 (966)\ttotal: 16.5s\tremaining: 0us\n",
      "bestTest = 0.4849611981\n",
      "bestIteration = 966\n",
      "Shrink model to first 967 iterations.\n",
      "===== ACCURACY SCORE 0.779403 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778950 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6879346\ttest: 0.6881590\tbest: 0.6881590 (0)\ttotal: 16.5ms\tremaining: 16.5s\n",
      "100:\tlearn: 0.4855658\ttest: 0.5058473\tbest: 0.5058473 (100)\ttotal: 1.52s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4577149\ttest: 0.4902706\tbest: 0.4902706 (200)\ttotal: 3s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4498739\ttest: 0.4884150\tbest: 0.4884150 (300)\ttotal: 4.48s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4459297\ttest: 0.4879005\tbest: 0.4879005 (400)\ttotal: 6.17s\tremaining: 9.22s\n",
      "500:\tlearn: 0.4432674\ttest: 0.4875865\tbest: 0.4875865 (500)\ttotal: 7.73s\tremaining: 7.7s\n",
      "600:\tlearn: 0.4411661\ttest: 0.4873866\tbest: 0.4873866 (600)\ttotal: 9.2s\tremaining: 6.11s\n",
      "700:\tlearn: 0.4393569\ttest: 0.4871528\tbest: 0.4871406 (660)\ttotal: 10.7s\tremaining: 4.55s\n",
      "800:\tlearn: 0.4376982\ttest: 0.4869034\tbest: 0.4868971 (799)\ttotal: 12.1s\tremaining: 3.01s\n",
      "900:\tlearn: 0.4361961\ttest: 0.4866744\tbest: 0.4866744 (900)\ttotal: 13.6s\tremaining: 1.5s\n",
      "999:\tlearn: 0.4348940\ttest: 0.4865199\tbest: 0.4865199 (999)\ttotal: 15.1s\tremaining: 0us\n",
      "bestTest = 0.4865199463\n",
      "bestIteration = 999\n",
      "===== ACCURACY SCORE 0.777064 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6878720\ttest: 0.6880739\tbest: 0.6880739 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4834783\ttest: 0.4994571\tbest: 0.4994571 (100)\ttotal: 1.91s\tremaining: 17s\n",
      "200:\tlearn: 0.4554387\ttest: 0.4819926\tbest: 0.4819926 (200)\ttotal: 3.37s\tremaining: 13.4s\n",
      "300:\tlearn: 0.4476224\ttest: 0.4800168\tbest: 0.4800168 (300)\ttotal: 4.84s\tremaining: 11.2s\n",
      "400:\tlearn: 0.4436198\ttest: 0.4798774\tbest: 0.4797937 (381)\ttotal: 6.29s\tremaining: 9.4s\n",
      "500:\tlearn: 0.4408907\ttest: 0.4796549\tbest: 0.4796201 (485)\ttotal: 7.8s\tremaining: 7.77s\n",
      "600:\tlearn: 0.4387692\ttest: 0.4796182\tbest: 0.4795862 (522)\ttotal: 9.29s\tremaining: 6.17s\n",
      "bestTest = 0.4795862479\n",
      "bestIteration = 522\n",
      "Shrink model to first 523 iterations.\n",
      "===== ACCURACY SCORE 0.784489 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6878777\ttest: 0.6882221\tbest: 0.6882221 (0)\ttotal: 28.8ms\tremaining: 28.8s\n",
      "100:\tlearn: 0.4834765\ttest: 0.5098958\tbest: 0.5098958 (100)\ttotal: 2.09s\tremaining: 18.6s\n",
      "200:\tlearn: 0.4555720\ttest: 0.4960737\tbest: 0.4960737 (200)\ttotal: 3.56s\tremaining: 14.1s\n",
      "300:\tlearn: 0.4478268\ttest: 0.4952732\tbest: 0.4952732 (300)\ttotal: 5.05s\tremaining: 11.7s\n",
      "400:\tlearn: 0.4438878\ttest: 0.4950646\tbest: 0.4950341 (390)\ttotal: 6.54s\tremaining: 9.77s\n",
      "500:\tlearn: 0.4412557\ttest: 0.4949184\tbest: 0.4948638 (495)\ttotal: 8.01s\tremaining: 7.98s\n",
      "600:\tlearn: 0.4391588\ttest: 0.4948025\tbest: 0.4947632 (578)\ttotal: 9.46s\tremaining: 6.28s\n",
      "700:\tlearn: 0.4373467\ttest: 0.4946524\tbest: 0.4946524 (700)\ttotal: 11s\tremaining: 4.68s\n",
      "800:\tlearn: 0.4357464\ttest: 0.4944654\tbest: 0.4944583 (799)\ttotal: 12.8s\tremaining: 3.18s\n",
      "900:\tlearn: 0.4343006\ttest: 0.4942770\tbest: 0.4942580 (881)\ttotal: 14.3s\tremaining: 1.57s\n",
      "999:\tlearn: 0.4328842\ttest: 0.4941789\tbest: 0.4941715 (994)\ttotal: 15.8s\tremaining: 0us\n",
      "bestTest = 0.4941715054\n",
      "bestIteration = 994\n",
      "Shrink model to first 995 iterations.\n",
      "===== ACCURACY SCORE 0.774803 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6878857\ttest: 0.6882134\tbest: 0.6882134 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4845243\ttest: 0.5070415\tbest: 0.5070415 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4565582\ttest: 0.4913608\tbest: 0.4913608 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4487980\ttest: 0.4899070\tbest: 0.4899029 (299)\ttotal: 4.44s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4447873\ttest: 0.4894159\tbest: 0.4893825 (390)\ttotal: 6.25s\tremaining: 9.34s\n",
      "bestTest = 0.4893825172\n",
      "bestIteration = 390\n",
      "Shrink model to first 391 iterations.\n",
      "===== ACCURACY SCORE 0.778319 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6878952\ttest: 0.6881866\tbest: 0.6881866 (0)\ttotal: 15.8ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4852006\ttest: 0.5052075\tbest: 0.5052075 (100)\ttotal: 1.51s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4573502\ttest: 0.4891460\tbest: 0.4891460 (200)\ttotal: 2.98s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4496030\ttest: 0.4872438\tbest: 0.4872438 (299)\ttotal: 4.46s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4456518\ttest: 0.4867926\tbest: 0.4867833 (399)\ttotal: 6.59s\tremaining: 9.84s\n",
      "500:\tlearn: 0.4429741\ttest: 0.4864565\tbest: 0.4864565 (500)\ttotal: 8.36s\tremaining: 8.32s\n",
      "600:\tlearn: 0.4408395\ttest: 0.4861942\tbest: 0.4861942 (600)\ttotal: 10s\tremaining: 6.66s\n",
      "700:\tlearn: 0.4390356\ttest: 0.4860315\tbest: 0.4860274 (699)\ttotal: 11.5s\tremaining: 4.92s\n",
      "800:\tlearn: 0.4374306\ttest: 0.4858960\tbest: 0.4858960 (800)\ttotal: 13s\tremaining: 3.23s\n",
      "900:\tlearn: 0.4359318\ttest: 0.4859131\tbest: 0.4858573 (854)\ttotal: 14.5s\tremaining: 1.59s\n",
      "bestTest = 0.4858573292\n",
      "bestIteration = 854\n",
      "Shrink model to first 855 iterations.\n",
      "===== ACCURACY SCORE 0.778076 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6878487\ttest: 0.6882326\tbest: 0.6882326 (0)\ttotal: 16ms\tremaining: 16s\n",
      "100:\tlearn: 0.4821818\ttest: 0.5097461\tbest: 0.5097461 (100)\ttotal: 1.51s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4537288\ttest: 0.4958091\tbest: 0.4958077 (198)\ttotal: 3.33s\tremaining: 13.3s\n",
      "300:\tlearn: 0.4458890\ttest: 0.4950641\tbest: 0.4949137 (255)\ttotal: 4.9s\tremaining: 11.4s\n",
      "bestTest = 0.4949136599\n",
      "bestIteration = 255\n",
      "Shrink model to first 256 iterations.\n",
      "===== ACCURACY SCORE 0.774644 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6879135\ttest: 0.6880451\tbest: 0.6880451 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4850676\ttest: 0.4969322\tbest: 0.4969322 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4574470\ttest: 0.4780797\tbest: 0.4780797 (200)\ttotal: 2.98s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4496770\ttest: 0.4752600\tbest: 0.4752600 (300)\ttotal: 4.44s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4457171\ttest: 0.4743507\tbest: 0.4743439 (399)\ttotal: 5.91s\tremaining: 8.83s\n",
      "500:\tlearn: 0.4430176\ttest: 0.4738461\tbest: 0.4738381 (499)\ttotal: 7.66s\tremaining: 7.63s\n",
      "600:\tlearn: 0.4408684\ttest: 0.4734975\tbest: 0.4734975 (600)\ttotal: 9.21s\tremaining: 6.12s\n",
      "700:\tlearn: 0.4390553\ttest: 0.4732678\tbest: 0.4732299 (683)\ttotal: 10.7s\tremaining: 4.56s\n",
      "800:\tlearn: 0.4374137\ttest: 0.4730658\tbest: 0.4730658 (800)\ttotal: 12.1s\tremaining: 3.02s\n",
      "900:\tlearn: 0.4358446\ttest: 0.4728471\tbest: 0.4728471 (900)\ttotal: 13.6s\tremaining: 1.5s\n",
      "999:\tlearn: 0.4345093\ttest: 0.4727418\tbest: 0.4727347 (984)\ttotal: 15.9s\tremaining: 0us\n",
      "bestTest = 0.4727347029\n",
      "bestIteration = 984\n",
      "Shrink model to first 985 iterations.\n",
      "===== ACCURACY SCORE 0.787470 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878830\ttest: 0.6881782\tbest: 0.6881782 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4837243\ttest: 0.5045067\tbest: 0.5045067 (100)\ttotal: 1.96s\tremaining: 17.4s\n",
      "200:\tlearn: 0.4557738\ttest: 0.4896958\tbest: 0.4896953 (199)\ttotal: 3.42s\tremaining: 13.6s\n",
      "300:\tlearn: 0.4480707\ttest: 0.4884150\tbest: 0.4884150 (300)\ttotal: 4.88s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4441322\ttest: 0.4884765\tbest: 0.4883875 (359)\ttotal: 6.35s\tremaining: 9.48s\n",
      "bestTest = 0.4883874762\n",
      "bestIteration = 359\n",
      "Shrink model to first 360 iterations.\n",
      "===== ACCURACY SCORE 0.777480 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6878680\ttest: 0.6881786\tbest: 0.6881786 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4838967\ttest: 0.5071479\tbest: 0.5071479 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4558641\ttest: 0.4929960\tbest: 0.4929960 (200)\ttotal: 2.98s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4479843\ttest: 0.4924210\tbest: 0.4923732 (261)\ttotal: 4.87s\tremaining: 11.3s\n",
      "bestTest = 0.4923731754\n",
      "bestIteration = 261\n",
      "Shrink model to first 262 iterations.\n",
      "===== ACCURACY SCORE 0.777610 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6879346\ttest: 0.6880759\tbest: 0.6880759 (0)\ttotal: 14.3ms\tremaining: 14.3s\n",
      "100:\tlearn: 0.4836948\ttest: 0.5013287\tbest: 0.5013287 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4554601\ttest: 0.4851326\tbest: 0.4851326 (200)\ttotal: 2.99s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4474139\ttest: 0.4834281\tbest: 0.4834281 (300)\ttotal: 4.45s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4432888\ttest: 0.4829484\tbest: 0.4829484 (400)\ttotal: 5.93s\tremaining: 8.86s\n",
      "500:\tlearn: 0.4404961\ttest: 0.4828957\tbest: 0.4828889 (498)\ttotal: 7.41s\tremaining: 7.38s\n",
      "600:\tlearn: 0.4383158\ttest: 0.4828460\tbest: 0.4828029 (548)\ttotal: 9.34s\tremaining: 6.2s\n",
      "700:\tlearn: 0.4364739\ttest: 0.4827554\tbest: 0.4827527 (698)\ttotal: 10.8s\tremaining: 4.61s\n",
      "800:\tlearn: 0.4348718\ttest: 0.4826391\tbest: 0.4826298 (799)\ttotal: 12.3s\tremaining: 3.05s\n",
      "900:\tlearn: 0.4333956\ttest: 0.4824840\tbest: 0.4824840 (900)\ttotal: 13.8s\tremaining: 1.51s\n",
      "999:\tlearn: 0.4320315\ttest: 0.4824617\tbest: 0.4824360 (945)\ttotal: 16.3s\tremaining: 0us\n",
      "bestTest = 0.4824359752\n",
      "bestIteration = 945\n",
      "Shrink model to first 946 iterations.\n",
      "===== ACCURACY SCORE 0.780594 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779050 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6878885\ttest: 0.6882375\tbest: 0.6882375 (0)\ttotal: 16.7ms\tremaining: 16.7s\n",
      "100:\tlearn: 0.4844291\ttest: 0.5088362\tbest: 0.5088362 (100)\ttotal: 1.65s\tremaining: 14.7s\n",
      "200:\tlearn: 0.4564009\ttest: 0.4939472\tbest: 0.4939472 (200)\ttotal: 3.38s\tremaining: 13.4s\n",
      "300:\tlearn: 0.4485224\ttest: 0.4924352\tbest: 0.4924297 (299)\ttotal: 4.85s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4445852\ttest: 0.4921516\tbest: 0.4921246 (394)\ttotal: 6.31s\tremaining: 9.43s\n",
      "500:\tlearn: 0.4418103\ttest: 0.4919715\tbest: 0.4919176 (471)\ttotal: 7.79s\tremaining: 7.76s\n",
      "600:\tlearn: 0.4396863\ttest: 0.4919010\tbest: 0.4918473 (585)\ttotal: 9.28s\tremaining: 6.16s\n",
      "700:\tlearn: 0.4378632\ttest: 0.4918150\tbest: 0.4918091 (694)\ttotal: 10.8s\tremaining: 4.59s\n",
      "800:\tlearn: 0.4362127\ttest: 0.4918418\tbest: 0.4917944 (707)\ttotal: 12.3s\tremaining: 3.06s\n",
      "bestTest = 0.4917943777\n",
      "bestIteration = 707\n",
      "Shrink model to first 708 iterations.\n",
      "===== ACCURACY SCORE 0.777545 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6879216\ttest: 0.6881246\tbest: 0.6881246 (0)\ttotal: 15.6ms\tremaining: 15.6s\n",
      "100:\tlearn: 0.4853967\ttest: 0.5024775\tbest: 0.5024775 (100)\ttotal: 1.52s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4573941\ttest: 0.4856571\tbest: 0.4856571 (200)\ttotal: 2.99s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4495283\ttest: 0.4837673\tbest: 0.4837673 (300)\ttotal: 4.47s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4455563\ttest: 0.4833470\tbest: 0.4833470 (400)\ttotal: 5.95s\tremaining: 8.89s\n",
      "500:\tlearn: 0.4428529\ttest: 0.4831633\tbest: 0.4831633 (500)\ttotal: 7.43s\tremaining: 7.4s\n",
      "600:\tlearn: 0.4406450\ttest: 0.4831314\tbest: 0.4830969 (579)\ttotal: 8.9s\tremaining: 5.91s\n",
      "bestTest = 0.4830969012\n",
      "bestIteration = 579\n",
      "Shrink model to first 580 iterations.\n",
      "===== ACCURACY SCORE 0.780218 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6878977\ttest: 0.6880789\tbest: 0.6880789 (0)\ttotal: 17ms\tremaining: 17s\n",
      "100:\tlearn: 0.4847122\ttest: 0.5007313\tbest: 0.5007313 (100)\ttotal: 1.5s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4566921\ttest: 0.4841137\tbest: 0.4841137 (200)\ttotal: 3s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4488394\ttest: 0.4822480\tbest: 0.4822480 (300)\ttotal: 5.71s\tremaining: 13.3s\n",
      "400:\tlearn: 0.4448099\ttest: 0.4820092\tbest: 0.4819334 (382)\ttotal: 7.17s\tremaining: 10.7s\n",
      "500:\tlearn: 0.4420758\ttest: 0.4819590\tbest: 0.4819257 (436)\ttotal: 8.63s\tremaining: 8.6s\n",
      "600:\tlearn: 0.4398579\ttest: 0.4819563\tbest: 0.4818537 (552)\ttotal: 10.5s\tremaining: 6.95s\n",
      "bestTest = 0.4818536791\n",
      "bestIteration = 552\n",
      "Shrink model to first 553 iterations.\n",
      "===== ACCURACY SCORE 0.783495 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6878846\ttest: 0.6881644\tbest: 0.6881644 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4840632\ttest: 0.5050460\tbest: 0.5050460 (100)\ttotal: 1.52s\tremaining: 13.6s\n",
      "200:\tlearn: 0.4561919\ttest: 0.4900321\tbest: 0.4900321 (200)\ttotal: 2.99s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4484795\ttest: 0.4886900\tbest: 0.4886900 (300)\ttotal: 4.48s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4445530\ttest: 0.4885938\tbest: 0.4885938 (400)\ttotal: 5.95s\tremaining: 8.89s\n",
      "500:\tlearn: 0.4418691\ttest: 0.4886409\tbest: 0.4885176 (430)\ttotal: 7.5s\tremaining: 7.47s\n",
      "bestTest = 0.488517553\n",
      "bestIteration = 430\n",
      "Shrink model to first 431 iterations.\n",
      "===== ACCURACY SCORE 0.778591 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6878369\ttest: 0.6880796\tbest: 0.6880796 (0)\ttotal: 16.7ms\tremaining: 16.6s\n",
      "100:\tlearn: 0.4826878\ttest: 0.5043293\tbest: 0.5043293 (100)\ttotal: 1.52s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4546754\ttest: 0.4898506\tbest: 0.4898506 (200)\ttotal: 3s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4468905\ttest: 0.4889952\tbest: 0.4889593 (274)\ttotal: 4.48s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4428642\ttest: 0.4891810\tbest: 0.4889291 (308)\ttotal: 5.95s\tremaining: 8.89s\n",
      "bestTest = 0.488929099\n",
      "bestIteration = 308\n",
      "Shrink model to first 309 iterations.\n",
      "===== ACCURACY SCORE 0.778463 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6879286\ttest: 0.6881132\tbest: 0.6881132 (0)\ttotal: 14.7ms\tremaining: 14.7s\n",
      "100:\tlearn: 0.4834270\ttest: 0.5009745\tbest: 0.5009745 (100)\ttotal: 1.51s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4553255\ttest: 0.4850557\tbest: 0.4850557 (200)\ttotal: 3.25s\tremaining: 12.9s\n",
      "300:\tlearn: 0.4474188\ttest: 0.4831345\tbest: 0.4831345 (300)\ttotal: 4.88s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4433837\ttest: 0.4823413\tbest: 0.4823413 (400)\ttotal: 6.4s\tremaining: 9.55s\n",
      "500:\tlearn: 0.4407161\ttest: 0.4820041\tbest: 0.4819999 (475)\ttotal: 8.66s\tremaining: 8.62s\n",
      "600:\tlearn: 0.4386155\ttest: 0.4816861\tbest: 0.4816832 (593)\ttotal: 10.1s\tremaining: 6.72s\n",
      "700:\tlearn: 0.4367998\ttest: 0.4814876\tbest: 0.4814874 (699)\ttotal: 11.6s\tremaining: 4.94s\n",
      "800:\tlearn: 0.4351217\ttest: 0.4813274\tbest: 0.4813155 (787)\ttotal: 13.1s\tremaining: 3.25s\n",
      "900:\tlearn: 0.4336218\ttest: 0.4810960\tbest: 0.4810960 (900)\ttotal: 15s\tremaining: 1.65s\n",
      "999:\tlearn: 0.4322334\ttest: 0.4808620\tbest: 0.4808552 (998)\ttotal: 16.5s\tremaining: 0us\n",
      "bestTest = 0.480855205\n",
      "bestIteration = 998\n",
      "Shrink model to first 999 iterations.\n",
      "===== ACCURACY SCORE 0.781331 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6878647\ttest: 0.6880598\tbest: 0.6880598 (0)\ttotal: 15.8ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4829724\ttest: 0.5011915\tbest: 0.5011915 (100)\ttotal: 1.51s\tremaining: 13.4s\n",
      "200:\tlearn: 0.4550371\ttest: 0.4856899\tbest: 0.4856899 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4472001\ttest: 0.4842995\tbest: 0.4842644 (297)\ttotal: 4.44s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4432339\ttest: 0.4842246\tbest: 0.4841916 (393)\ttotal: 5.92s\tremaining: 8.84s\n",
      "500:\tlearn: 0.4405398\ttest: 0.4841840\tbest: 0.4841332 (468)\ttotal: 7.78s\tremaining: 7.75s\n",
      "bestTest = 0.4841331569\n",
      "bestIteration = 468\n",
      "Shrink model to first 469 iterations.\n",
      "===== ACCURACY SCORE 0.781179 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878866\ttest: 0.6882214\tbest: 0.6882214 (0)\ttotal: 16ms\tremaining: 16s\n",
      "100:\tlearn: 0.4834015\ttest: 0.5082629\tbest: 0.5082629 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4553971\ttest: 0.4935871\tbest: 0.4935871 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4475872\ttest: 0.4929004\tbest: 0.4927941 (265)\ttotal: 4.44s\tremaining: 10.3s\n",
      "bestTest = 0.4927940976\n",
      "bestIteration = 265\n",
      "Shrink model to first 266 iterations.\n",
      "===== ACCURACY SCORE 0.776119 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6878783\ttest: 0.6881232\tbest: 0.6881232 (0)\ttotal: 15.9ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4839305\ttest: 0.5046502\tbest: 0.5046502 (100)\ttotal: 1.59s\tremaining: 14.1s\n",
      "200:\tlearn: 0.4558216\ttest: 0.4892424\tbest: 0.4892424 (200)\ttotal: 3.46s\tremaining: 13.8s\n",
      "300:\tlearn: 0.4479948\ttest: 0.4879756\tbest: 0.4879756 (300)\ttotal: 4.99s\tremaining: 11.6s\n",
      "400:\tlearn: 0.4440482\ttest: 0.4878025\tbest: 0.4877026 (382)\ttotal: 7.25s\tremaining: 10.8s\n",
      "bestTest = 0.4877026262\n",
      "bestIteration = 382\n",
      "Shrink model to first 383 iterations.\n",
      "===== ACCURACY SCORE 0.779038 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6878987\ttest: 0.6882261\tbest: 0.6882261 (0)\ttotal: 16.1ms\tremaining: 16.1s\n",
      "100:\tlearn: 0.4843973\ttest: 0.5080109\tbest: 0.5080109 (100)\ttotal: 1.52s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4563467\ttest: 0.4924868\tbest: 0.4924868 (200)\ttotal: 3.02s\tremaining: 12s\n",
      "300:\tlearn: 0.4485079\ttest: 0.4907878\tbest: 0.4907878 (300)\ttotal: 4.92s\tremaining: 11.4s\n",
      "400:\tlearn: 0.4444474\ttest: 0.4903003\tbest: 0.4902977 (399)\ttotal: 6.38s\tremaining: 9.53s\n",
      "500:\tlearn: 0.4417010\ttest: 0.4900871\tbest: 0.4900820 (498)\ttotal: 7.84s\tremaining: 7.8s\n",
      "600:\tlearn: 0.4395303\ttest: 0.4900300\tbest: 0.4900139 (596)\ttotal: 9.3s\tremaining: 6.17s\n",
      "700:\tlearn: 0.4376233\ttest: 0.4899606\tbest: 0.4899587 (699)\ttotal: 10.8s\tremaining: 4.6s\n",
      "800:\tlearn: 0.4360227\ttest: 0.4899454\tbest: 0.4899111 (712)\ttotal: 12.2s\tremaining: 3.04s\n",
      "bestTest = 0.4899111356\n",
      "bestIteration = 712\n",
      "Shrink model to first 713 iterations.\n",
      "===== ACCURACY SCORE 0.775431 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779150 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6878476\ttest: 0.6882162\tbest: 0.6882162 (0)\ttotal: 16.3ms\tremaining: 16.2s\n",
      "100:\tlearn: 0.4827950\ttest: 0.5088822\tbest: 0.5088822 (100)\ttotal: 1.9s\tremaining: 16.9s\n",
      "200:\tlearn: 0.4547924\ttest: 0.4943948\tbest: 0.4943948 (200)\ttotal: 3.37s\tremaining: 13.4s\n",
      "300:\tlearn: 0.4470600\ttest: 0.4931706\tbest: 0.4931684 (299)\ttotal: 4.85s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4431588\ttest: 0.4931695\tbest: 0.4930855 (324)\ttotal: 6.31s\tremaining: 9.43s\n",
      "bestTest = 0.4930855417\n",
      "bestIteration = 324\n",
      "Shrink model to first 325 iterations.\n",
      "===== ACCURACY SCORE 0.768217 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6878297\ttest: 0.6881556\tbest: 0.6881556 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4822214\ttest: 0.5077370\tbest: 0.5077370 (100)\ttotal: 1.52s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4541006\ttest: 0.4935141\tbest: 0.4935141 (200)\ttotal: 3.02s\tremaining: 12s\n",
      "300:\tlearn: 0.4463528\ttest: 0.4925558\tbest: 0.4925398 (299)\ttotal: 4.74s\tremaining: 11s\n",
      "400:\tlearn: 0.4423549\ttest: 0.4924782\tbest: 0.4924470 (390)\ttotal: 6.43s\tremaining: 9.61s\n",
      "bestTest = 0.4924469899\n",
      "bestIteration = 390\n",
      "Shrink model to first 391 iterations.\n",
      "===== ACCURACY SCORE 0.775405 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6878894\ttest: 0.6881339\tbest: 0.6881339 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4839156\ttest: 0.5024901\tbest: 0.5024901 (100)\ttotal: 1.54s\tremaining: 13.8s\n",
      "200:\tlearn: 0.4557482\ttest: 0.4853561\tbest: 0.4853561 (200)\ttotal: 2.99s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4479353\ttest: 0.4835271\tbest: 0.4835271 (300)\ttotal: 4.45s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4439748\ttest: 0.4831483\tbest: 0.4831210 (395)\ttotal: 6.09s\tremaining: 9.09s\n",
      "500:\tlearn: 0.4412920\ttest: 0.4829844\tbest: 0.4829764 (498)\ttotal: 7.77s\tremaining: 7.74s\n",
      "600:\tlearn: 0.4391999\ttest: 0.4828984\tbest: 0.4828725 (592)\ttotal: 9.24s\tremaining: 6.14s\n",
      "700:\tlearn: 0.4373044\ttest: 0.4828120\tbest: 0.4828014 (698)\ttotal: 10.7s\tremaining: 4.58s\n",
      "bestTest = 0.4828013936\n",
      "bestIteration = 698\n",
      "Shrink model to first 699 iterations.\n",
      "===== ACCURACY SCORE 0.784274 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6879243\ttest: 0.6880987\tbest: 0.6880987 (0)\ttotal: 16ms\tremaining: 16s\n",
      "100:\tlearn: 0.4852671\ttest: 0.4999780\tbest: 0.4999780 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4572110\ttest: 0.4823514\tbest: 0.4823514 (200)\ttotal: 2.98s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4493080\ttest: 0.4804308\tbest: 0.4804308 (300)\ttotal: 4.83s\tremaining: 11.2s\n",
      "400:\tlearn: 0.4452896\ttest: 0.4801200\tbest: 0.4800551 (384)\ttotal: 6.29s\tremaining: 9.4s\n",
      "bestTest = 0.4800551173\n",
      "bestIteration = 384\n",
      "Shrink model to first 385 iterations.\n",
      "===== ACCURACY SCORE 0.782739 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6879183\ttest: 0.6882049\tbest: 0.6882049 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4852948\ttest: 0.5071284\tbest: 0.5071284 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4570737\ttest: 0.4924254\tbest: 0.4924254 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4491402\ttest: 0.4917536\tbest: 0.4916369 (281)\ttotal: 4.44s\tremaining: 10.3s\n",
      "bestTest = 0.4916369285\n",
      "bestIteration = 281\n",
      "Shrink model to first 282 iterations.\n",
      "===== ACCURACY SCORE 0.776103 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6878959\ttest: 0.6880523\tbest: 0.6880523 (0)\ttotal: 17.7ms\tremaining: 17.7s\n",
      "100:\tlearn: 0.4841010\ttest: 0.4981415\tbest: 0.4981415 (100)\ttotal: 2.19s\tremaining: 19.5s\n",
      "200:\tlearn: 0.4559861\ttest: 0.4795582\tbest: 0.4795582 (200)\ttotal: 3.66s\tremaining: 14.5s\n",
      "300:\tlearn: 0.4480709\ttest: 0.4769020\tbest: 0.4769020 (300)\ttotal: 5.13s\tremaining: 11.9s\n",
      "400:\tlearn: 0.4440415\ttest: 0.4759066\tbest: 0.4759066 (400)\ttotal: 6.57s\tremaining: 9.82s\n",
      "500:\tlearn: 0.4413719\ttest: 0.4754839\tbest: 0.4754839 (500)\ttotal: 8.03s\tremaining: 8s\n",
      "600:\tlearn: 0.4392432\ttest: 0.4751849\tbest: 0.4751849 (600)\ttotal: 9.51s\tremaining: 6.31s\n",
      "700:\tlearn: 0.4374701\ttest: 0.4749519\tbest: 0.4749373 (698)\ttotal: 11.4s\tremaining: 4.86s\n",
      "800:\tlearn: 0.4358380\ttest: 0.4747705\tbest: 0.4747705 (800)\ttotal: 12.9s\tremaining: 3.19s\n",
      "900:\tlearn: 0.4344207\ttest: 0.4745722\tbest: 0.4745722 (900)\ttotal: 14.3s\tremaining: 1.57s\n",
      "999:\tlearn: 0.4329841\ttest: 0.4743806\tbest: 0.4743806 (999)\ttotal: 15.7s\tremaining: 0us\n",
      "bestTest = 0.4743806399\n",
      "bestIteration = 999\n",
      "===== ACCURACY SCORE 0.786258 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6879365\ttest: 0.6881172\tbest: 0.6881172 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4856503\ttest: 0.5046049\tbest: 0.5046049 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4577837\ttest: 0.4899538\tbest: 0.4899538 (200)\ttotal: 2.95s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4500146\ttest: 0.4887795\tbest: 0.4887782 (293)\ttotal: 4.66s\tremaining: 10.8s\n",
      "400:\tlearn: 0.4460918\ttest: 0.4886225\tbest: 0.4886035 (395)\ttotal: 6.33s\tremaining: 9.45s\n",
      "500:\tlearn: 0.4433480\ttest: 0.4886164\tbest: 0.4885192 (467)\ttotal: 7.79s\tremaining: 7.75s\n",
      "bestTest = 0.4885191897\n",
      "bestIteration = 467\n",
      "Shrink model to first 468 iterations.\n",
      "===== ACCURACY SCORE 0.779841 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878667\ttest: 0.6882401\tbest: 0.6882401 (0)\ttotal: 14.9ms\tremaining: 14.8s\n",
      "100:\tlearn: 0.4816057\ttest: 0.5113846\tbest: 0.5113846 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4532613\ttest: 0.4984704\tbest: 0.4984703 (199)\ttotal: 2.95s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4453337\ttest: 0.4977415\tbest: 0.4976743 (294)\ttotal: 4.42s\tremaining: 10.3s\n",
      "bestTest = 0.4976743221\n",
      "bestIteration = 294\n",
      "Shrink model to first 295 iterations.\n",
      "===== ACCURACY SCORE 0.773560 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6878010\ttest: 0.6879492\tbest: 0.6879492 (0)\ttotal: 16.1ms\tremaining: 16.1s\n",
      "100:\tlearn: 0.4839592\ttest: 0.5030129\tbest: 0.5030129 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4560212\ttest: 0.4872668\tbest: 0.4872668 (200)\ttotal: 2.94s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4483666\ttest: 0.4857396\tbest: 0.4857396 (300)\ttotal: 4.39s\tremaining: 10.2s\n",
      "400:\tlearn: 0.4443881\ttest: 0.4853078\tbest: 0.4852937 (393)\ttotal: 5.85s\tremaining: 8.74s\n",
      "500:\tlearn: 0.4416883\ttest: 0.4854231\tbest: 0.4852750 (408)\ttotal: 7.34s\tremaining: 7.31s\n",
      "bestTest = 0.4852749531\n",
      "bestIteration = 408\n",
      "Shrink model to first 409 iterations.\n",
      "===== ACCURACY SCORE 0.780585 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6879542\ttest: 0.6881336\tbest: 0.6881336 (0)\ttotal: 14.1ms\tremaining: 14.1s\n",
      "100:\tlearn: 0.4840435\ttest: 0.5029898\tbest: 0.5029898 (100)\ttotal: 1.89s\tremaining: 16.8s\n",
      "200:\tlearn: 0.4559297\ttest: 0.4871301\tbest: 0.4871301 (200)\ttotal: 3.34s\tremaining: 13.3s\n",
      "300:\tlearn: 0.4480942\ttest: 0.4853517\tbest: 0.4853370 (299)\ttotal: 4.8s\tremaining: 11.1s\n",
      "400:\tlearn: 0.4441501\ttest: 0.4847312\tbest: 0.4847254 (399)\ttotal: 6.27s\tremaining: 9.37s\n",
      "500:\tlearn: 0.4415191\ttest: 0.4843699\tbest: 0.4843636 (497)\ttotal: 7.72s\tremaining: 7.69s\n",
      "600:\tlearn: 0.4394164\ttest: 0.4841184\tbest: 0.4841133 (593)\ttotal: 9.19s\tremaining: 6.1s\n",
      "700:\tlearn: 0.4376338\ttest: 0.4838677\tbest: 0.4838538 (695)\ttotal: 10.7s\tremaining: 4.57s\n",
      "800:\tlearn: 0.4360580\ttest: 0.4837571\tbest: 0.4837571 (800)\ttotal: 12.5s\tremaining: 3.11s\n",
      "900:\tlearn: 0.4345921\ttest: 0.4836037\tbest: 0.4835583 (880)\ttotal: 14s\tremaining: 1.54s\n",
      "999:\tlearn: 0.4332141\ttest: 0.4835345\tbest: 0.4835151 (963)\ttotal: 15.5s\tremaining: 0us\n",
      "bestTest = 0.4835151481\n",
      "bestIteration = 963\n",
      "Shrink model to first 964 iterations.\n",
      "===== ACCURACY SCORE 0.783784 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779070 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6878753\ttest: 0.6882781\tbest: 0.6882781 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4835990\ttest: 0.5116476\tbest: 0.5116476 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4555697\ttest: 0.4977158\tbest: 0.4977158 (200)\ttotal: 2.99s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4477019\ttest: 0.4967275\tbest: 0.4967068 (299)\ttotal: 4.88s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4436703\ttest: 0.4965658\tbest: 0.4964896 (382)\ttotal: 7.04s\tremaining: 10.5s\n",
      "500:\tlearn: 0.4409389\ttest: 0.4964652\tbest: 0.4964644 (499)\ttotal: 8.5s\tremaining: 8.47s\n",
      "bestTest = 0.4964644492\n",
      "bestIteration = 499\n",
      "Shrink model to first 500 iterations.\n",
      "===== ACCURACY SCORE 0.768889 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6879585\ttest: 0.6881583\tbest: 0.6881583 (0)\ttotal: 14.3ms\tremaining: 14.3s\n",
      "100:\tlearn: 0.4843491\ttest: 0.5034717\tbest: 0.5034717 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4562640\ttest: 0.4873557\tbest: 0.4873557 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4483020\ttest: 0.4856435\tbest: 0.4856421 (299)\ttotal: 4.42s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4442303\ttest: 0.4850625\tbest: 0.4850270 (390)\ttotal: 6.17s\tremaining: 9.22s\n",
      "500:\tlearn: 0.4415459\ttest: 0.4847027\tbest: 0.4846978 (495)\ttotal: 7.71s\tremaining: 7.67s\n",
      "600:\tlearn: 0.4393907\ttest: 0.4844961\tbest: 0.4844800 (596)\ttotal: 9.17s\tremaining: 6.09s\n",
      "700:\tlearn: 0.4375405\ttest: 0.4844787\tbest: 0.4844292 (689)\ttotal: 10.6s\tremaining: 4.53s\n",
      "800:\tlearn: 0.4358924\ttest: 0.4843200\tbest: 0.4843200 (800)\ttotal: 12.1s\tremaining: 3.01s\n",
      "900:\tlearn: 0.4344222\ttest: 0.4842771\tbest: 0.4842551 (883)\ttotal: 13.6s\tremaining: 1.49s\n",
      "bestTest = 0.4842551296\n",
      "bestIteration = 883\n",
      "Shrink model to first 884 iterations.\n",
      "===== ACCURACY SCORE 0.780637 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6879621\ttest: 0.6881446\tbest: 0.6881446 (0)\ttotal: 14.1ms\tremaining: 14.1s\n",
      "100:\tlearn: 0.4845363\ttest: 0.5027992\tbest: 0.5027992 (100)\ttotal: 1.97s\tremaining: 17.5s\n",
      "200:\tlearn: 0.4566078\ttest: 0.4861717\tbest: 0.4861717 (200)\ttotal: 3.44s\tremaining: 13.7s\n",
      "300:\tlearn: 0.4488303\ttest: 0.4845353\tbest: 0.4845353 (300)\ttotal: 4.9s\tremaining: 11.4s\n",
      "400:\tlearn: 0.4447984\ttest: 0.4841794\tbest: 0.4841738 (395)\ttotal: 6.38s\tremaining: 9.54s\n",
      "500:\tlearn: 0.4420346\ttest: 0.4842059\tbest: 0.4841301 (412)\ttotal: 7.84s\tremaining: 7.81s\n",
      "bestTest = 0.4841300994\n",
      "bestIteration = 412\n",
      "Shrink model to first 413 iterations.\n",
      "===== ACCURACY SCORE 0.783713 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6879353\ttest: 0.6881313\tbest: 0.6881313 (0)\ttotal: 15.9ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4848112\ttest: 0.5015945\tbest: 0.5015945 (100)\ttotal: 2.42s\tremaining: 21.5s\n",
      "200:\tlearn: 0.4569986\ttest: 0.4849301\tbest: 0.4849301 (200)\ttotal: 4.18s\tremaining: 16.6s\n",
      "300:\tlearn: 0.4492153\ttest: 0.4831418\tbest: 0.4831418 (300)\ttotal: 5.63s\tremaining: 13.1s\n",
      "400:\tlearn: 0.4452383\ttest: 0.4827930\tbest: 0.4827653 (394)\ttotal: 7.1s\tremaining: 10.6s\n",
      "500:\tlearn: 0.4425849\ttest: 0.4828793\tbest: 0.4827568 (432)\ttotal: 8.58s\tremaining: 8.54s\n",
      "bestTest = 0.4827567827\n",
      "bestIteration = 432\n",
      "Shrink model to first 433 iterations.\n",
      "===== ACCURACY SCORE 0.777889 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6879110\ttest: 0.6880336\tbest: 0.6880336 (0)\ttotal: 15.7ms\tremaining: 15.6s\n",
      "100:\tlearn: 0.4849231\ttest: 0.4993364\tbest: 0.4993364 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4569987\ttest: 0.4818994\tbest: 0.4818994 (200)\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4491884\ttest: 0.4795374\tbest: 0.4795341 (299)\ttotal: 4.84s\tremaining: 11.2s\n",
      "400:\tlearn: 0.4451171\ttest: 0.4788120\tbest: 0.4788120 (400)\ttotal: 6.31s\tremaining: 9.43s\n",
      "500:\tlearn: 0.4423417\ttest: 0.4785736\tbest: 0.4785645 (499)\ttotal: 7.77s\tremaining: 7.74s\n",
      "600:\tlearn: 0.4401998\ttest: 0.4784945\tbest: 0.4784945 (600)\ttotal: 9.22s\tremaining: 6.12s\n",
      "700:\tlearn: 0.4383582\ttest: 0.4782661\tbest: 0.4782599 (680)\ttotal: 10.7s\tremaining: 4.55s\n",
      "800:\tlearn: 0.4366961\ttest: 0.4782625\tbest: 0.4781905 (761)\ttotal: 12.1s\tremaining: 3.02s\n",
      "bestTest = 0.478190473\n",
      "bestIteration = 761\n",
      "Shrink model to first 762 iterations.\n",
      "===== ACCURACY SCORE 0.785517 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6878443\ttest: 0.6881860\tbest: 0.6881860 (0)\ttotal: 15.8ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4832300\ttest: 0.5089888\tbest: 0.5089888 (100)\ttotal: 1.84s\tremaining: 16.4s\n",
      "200:\tlearn: 0.4556147\ttest: 0.4950970\tbest: 0.4950970 (200)\ttotal: 3.29s\tremaining: 13.1s\n",
      "300:\tlearn: 0.4479190\ttest: 0.4942716\tbest: 0.4942716 (300)\ttotal: 4.75s\tremaining: 11s\n",
      "400:\tlearn: 0.4439674\ttest: 0.4943100\tbest: 0.4942484 (307)\ttotal: 6.2s\tremaining: 9.26s\n",
      "bestTest = 0.494248411\n",
      "bestIteration = 307\n",
      "Shrink model to first 308 iterations.\n",
      "===== ACCURACY SCORE 0.775982 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6879242\ttest: 0.6881270\tbest: 0.6881270 (0)\ttotal: 14.3ms\tremaining: 14.3s\n",
      "100:\tlearn: 0.4829213\ttest: 0.5014639\tbest: 0.5014639 (100)\ttotal: 2.1s\tremaining: 18.7s\n",
      "200:\tlearn: 0.4548374\ttest: 0.4860557\tbest: 0.4860557 (200)\ttotal: 3.89s\tremaining: 15.5s\n",
      "300:\tlearn: 0.4470270\ttest: 0.4849175\tbest: 0.4848689 (293)\ttotal: 5.76s\tremaining: 13.4s\n",
      "bestTest = 0.4848689123\n",
      "bestIteration = 293\n",
      "Shrink model to first 294 iterations.\n",
      "===== ACCURACY SCORE 0.778881 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878970\ttest: 0.6881788\tbest: 0.6881788 (0)\ttotal: 15.6ms\tremaining: 15.6s\n",
      "100:\tlearn: 0.4846617\ttest: 0.5047402\tbest: 0.5047402 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4566723\ttest: 0.4878235\tbest: 0.4878235 (200)\ttotal: 2.94s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4487161\ttest: 0.4855490\tbest: 0.4855490 (300)\ttotal: 4.42s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4446834\ttest: 0.4848738\tbest: 0.4848738 (400)\ttotal: 5.89s\tremaining: 8.8s\n",
      "500:\tlearn: 0.4420088\ttest: 0.4845938\tbest: 0.4845835 (495)\ttotal: 7.59s\tremaining: 7.56s\n",
      "600:\tlearn: 0.4399775\ttest: 0.4842972\tbest: 0.4842756 (594)\ttotal: 9.18s\tremaining: 6.09s\n",
      "700:\tlearn: 0.4381536\ttest: 0.4840678\tbest: 0.4840678 (700)\ttotal: 10.6s\tremaining: 4.54s\n",
      "800:\tlearn: 0.4364955\ttest: 0.4838247\tbest: 0.4838247 (800)\ttotal: 12.1s\tremaining: 3.01s\n",
      "900:\tlearn: 0.4350340\ttest: 0.4836257\tbest: 0.4836199 (897)\ttotal: 13.6s\tremaining: 1.49s\n",
      "999:\tlearn: 0.4336538\ttest: 0.4835077\tbest: 0.4835077 (999)\ttotal: 15s\tremaining: 0us\n",
      "bestTest = 0.4835076751\n",
      "bestIteration = 999\n",
      "===== ACCURACY SCORE 0.778894 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6878217\ttest: 0.6879826\tbest: 0.6879826 (0)\ttotal: 17.3ms\tremaining: 17.2s\n",
      "100:\tlearn: 0.4843595\ttest: 0.5039832\tbest: 0.5039832 (100)\ttotal: 1.6s\tremaining: 14.3s\n",
      "200:\tlearn: 0.4566042\ttest: 0.4889126\tbest: 0.4889126 (200)\ttotal: 3.39s\tremaining: 13.5s\n",
      "300:\tlearn: 0.4489058\ttest: 0.4869980\tbest: 0.4869980 (300)\ttotal: 4.86s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4449715\ttest: 0.4862867\tbest: 0.4862846 (395)\ttotal: 6.31s\tremaining: 9.43s\n",
      "500:\tlearn: 0.4423431\ttest: 0.4858585\tbest: 0.4858261 (482)\ttotal: 7.78s\tremaining: 7.75s\n",
      "600:\tlearn: 0.4402187\ttest: 0.4854891\tbest: 0.4854777 (592)\ttotal: 10.3s\tremaining: 6.87s\n",
      "700:\tlearn: 0.4383954\ttest: 0.4852943\tbest: 0.4852388 (685)\ttotal: 11.8s\tremaining: 5.04s\n",
      "800:\tlearn: 0.4368208\ttest: 0.4851210\tbest: 0.4851210 (800)\ttotal: 13.8s\tremaining: 3.42s\n",
      "900:\tlearn: 0.4353340\ttest: 0.4850110\tbest: 0.4849912 (883)\ttotal: 15.2s\tremaining: 1.67s\n",
      "999:\tlearn: 0.4339633\ttest: 0.4848992\tbest: 0.4848862 (997)\ttotal: 16.7s\tremaining: 0us\n",
      "bestTest = 0.4848862447\n",
      "bestIteration = 997\n",
      "Shrink model to first 998 iterations.\n",
      "===== ACCURACY SCORE 0.781974 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6878622\ttest: 0.6881897\tbest: 0.6881897 (0)\ttotal: 16ms\tremaining: 16s\n",
      "100:\tlearn: 0.4836789\ttest: 0.5072080\tbest: 0.5072080 (100)\ttotal: 1.47s\tremaining: 13.1s\n",
      "200:\tlearn: 0.4558675\ttest: 0.4932819\tbest: 0.4932819 (200)\ttotal: 2.95s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4481509\ttest: 0.4925729\tbest: 0.4924140 (274)\ttotal: 4.42s\tremaining: 10.3s\n",
      "bestTest = 0.4924140197\n",
      "bestIteration = 274\n",
      "Shrink model to first 275 iterations.\n",
      "===== ACCURACY SCORE 0.776804 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.778930 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6878601\ttest: 0.6881921\tbest: 0.6881921 (0)\ttotal: 50ms\tremaining: 50s\n",
      "100:\tlearn: 0.4836584\ttest: 0.5059729\tbest: 0.5059729 (100)\ttotal: 1.63s\tremaining: 14.5s\n",
      "200:\tlearn: 0.4556113\ttest: 0.4906290\tbest: 0.4906290 (200)\ttotal: 3.09s\tremaining: 12.3s\n",
      "300:\tlearn: 0.4477801\ttest: 0.4893381\tbest: 0.4892982 (294)\ttotal: 4.53s\tremaining: 10.5s\n",
      "400:\tlearn: 0.4437293\ttest: 0.4893630\tbest: 0.4892628 (382)\ttotal: 6.03s\tremaining: 9.01s\n",
      "bestTest = 0.4892628318\n",
      "bestIteration = 382\n",
      "Shrink model to first 383 iterations.\n",
      "===== ACCURACY SCORE 0.781238 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6879391\ttest: 0.6881196\tbest: 0.6881196 (0)\ttotal: 16.4ms\tremaining: 16.4s\n",
      "100:\tlearn: 0.4854335\ttest: 0.5025383\tbest: 0.5025383 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4576890\ttest: 0.4858788\tbest: 0.4858788 (200)\ttotal: 3.49s\tremaining: 13.9s\n",
      "300:\tlearn: 0.4499200\ttest: 0.4840342\tbest: 0.4840342 (300)\ttotal: 4.96s\tremaining: 11.5s\n",
      "400:\tlearn: 0.4459434\ttest: 0.4835268\tbest: 0.4835261 (399)\ttotal: 6.42s\tremaining: 9.6s\n",
      "500:\tlearn: 0.4432057\ttest: 0.4832386\tbest: 0.4832386 (500)\ttotal: 8.12s\tremaining: 8.09s\n",
      "600:\tlearn: 0.4410125\ttest: 0.4831680\tbest: 0.4831680 (600)\ttotal: 10.2s\tremaining: 6.76s\n",
      "700:\tlearn: 0.4391215\ttest: 0.4829459\tbest: 0.4829337 (698)\ttotal: 11.6s\tremaining: 4.96s\n",
      "800:\tlearn: 0.4374800\ttest: 0.4827784\tbest: 0.4827634 (798)\ttotal: 13.2s\tremaining: 3.28s\n",
      "900:\tlearn: 0.4359535\ttest: 0.4825928\tbest: 0.4825928 (900)\ttotal: 15s\tremaining: 1.65s\n",
      "999:\tlearn: 0.4345822\ttest: 0.4825210\tbest: 0.4825151 (965)\ttotal: 16.4s\tremaining: 0us\n",
      "bestTest = 0.4825150666\n",
      "bestIteration = 965\n",
      "Shrink model to first 966 iterations.\n",
      "===== ACCURACY SCORE 0.783490 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6878130\ttest: 0.6878717\tbest: 0.6878717 (0)\ttotal: 17.2ms\tremaining: 17.2s\n",
      "100:\tlearn: 0.4843957\ttest: 0.5008936\tbest: 0.5008936 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4565099\ttest: 0.4841794\tbest: 0.4841794 (200)\ttotal: 2.98s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4487379\ttest: 0.4820989\tbest: 0.4820989 (300)\ttotal: 4.45s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4447919\ttest: 0.4815999\tbest: 0.4815999 (400)\ttotal: 5.92s\tremaining: 8.85s\n",
      "500:\tlearn: 0.4421117\ttest: 0.4811056\tbest: 0.4811056 (500)\ttotal: 7.77s\tremaining: 7.74s\n",
      "600:\tlearn: 0.4400759\ttest: 0.4809187\tbest: 0.4809157 (595)\ttotal: 9.21s\tremaining: 6.11s\n",
      "700:\tlearn: 0.4382606\ttest: 0.4808148\tbest: 0.4808148 (700)\ttotal: 10.8s\tremaining: 4.59s\n",
      "800:\tlearn: 0.4366727\ttest: 0.4806749\tbest: 0.4806716 (799)\ttotal: 12.2s\tremaining: 3.04s\n",
      "900:\tlearn: 0.4351696\ttest: 0.4806126\tbest: 0.4806027 (899)\ttotal: 13.7s\tremaining: 1.5s\n",
      "999:\tlearn: 0.4337880\ttest: 0.4805836\tbest: 0.4805790 (998)\ttotal: 15.1s\tremaining: 0us\n",
      "bestTest = 0.4805790086\n",
      "bestIteration = 998\n",
      "Shrink model to first 999 iterations.\n",
      "===== ACCURACY SCORE 0.778515 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6878299\ttest: 0.6879094\tbest: 0.6879094 (0)\ttotal: 15.8ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4841763\ttest: 0.5015229\tbest: 0.5015229 (100)\ttotal: 1.62s\tremaining: 14.4s\n",
      "200:\tlearn: 0.4560824\ttest: 0.4854820\tbest: 0.4854820 (200)\ttotal: 3.37s\tremaining: 13.4s\n",
      "300:\tlearn: 0.4481597\ttest: 0.4840312\tbest: 0.4840263 (296)\ttotal: 4.85s\tremaining: 11.3s\n",
      "400:\tlearn: 0.4441534\ttest: 0.4838985\tbest: 0.4838474 (361)\ttotal: 6.84s\tremaining: 10.2s\n",
      "bestTest = 0.4838474435\n",
      "bestIteration = 361\n",
      "Shrink model to first 362 iterations.\n",
      "===== ACCURACY SCORE 0.779776 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6878007\ttest: 0.6878186\tbest: 0.6878186 (0)\ttotal: 16.9ms\tremaining: 16.9s\n",
      "100:\tlearn: 0.4834404\ttest: 0.4977870\tbest: 0.4977870 (100)\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4551952\ttest: 0.4810509\tbest: 0.4810509 (200)\ttotal: 3.01s\tremaining: 12s\n",
      "300:\tlearn: 0.4471971\ttest: 0.4792687\tbest: 0.4792653 (299)\ttotal: 4.81s\tremaining: 11.2s\n",
      "400:\tlearn: 0.4431410\ttest: 0.4789285\tbest: 0.4789271 (379)\ttotal: 6.26s\tremaining: 9.36s\n",
      "500:\tlearn: 0.4404014\ttest: 0.4787379\tbest: 0.4787379 (500)\ttotal: 7.71s\tremaining: 7.68s\n",
      "600:\tlearn: 0.4382618\ttest: 0.4786478\tbest: 0.4786381 (599)\ttotal: 9.18s\tremaining: 6.09s\n",
      "700:\tlearn: 0.4363799\ttest: 0.4786581\tbest: 0.4785951 (656)\ttotal: 10.7s\tremaining: 4.54s\n",
      "bestTest = 0.4785951399\n",
      "bestIteration = 656\n",
      "Shrink model to first 657 iterations.\n",
      "===== ACCURACY SCORE 0.787309 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6879094\ttest: 0.6881493\tbest: 0.6881493 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4848265\ttest: 0.5048229\tbest: 0.5048229 (100)\ttotal: 1.55s\tremaining: 13.8s\n",
      "200:\tlearn: 0.4568292\ttest: 0.4886862\tbest: 0.4886862 (200)\ttotal: 3.48s\tremaining: 13.8s\n",
      "300:\tlearn: 0.4490146\ttest: 0.4868536\tbest: 0.4868536 (300)\ttotal: 4.95s\tremaining: 11.5s\n",
      "400:\tlearn: 0.4449590\ttest: 0.4864950\tbest: 0.4864950 (400)\ttotal: 6.42s\tremaining: 9.59s\n",
      "500:\tlearn: 0.4422296\ttest: 0.4863885\tbest: 0.4863645 (495)\ttotal: 7.89s\tremaining: 7.85s\n",
      "600:\tlearn: 0.4400382\ttest: 0.4862856\tbest: 0.4862731 (594)\ttotal: 9.35s\tremaining: 6.21s\n",
      "700:\tlearn: 0.4380942\ttest: 0.4861490\tbest: 0.4861490 (700)\ttotal: 10.8s\tremaining: 4.61s\n",
      "800:\tlearn: 0.4364988\ttest: 0.4861377\tbest: 0.4861303 (707)\ttotal: 12.3s\tremaining: 3.05s\n",
      "900:\tlearn: 0.4349728\ttest: 0.4859247\tbest: 0.4859216 (896)\ttotal: 14.1s\tremaining: 1.55s\n",
      "999:\tlearn: 0.4335594\ttest: 0.4858959\tbest: 0.4858439 (967)\ttotal: 15.5s\tremaining: 0us\n",
      "bestTest = 0.4858438508\n",
      "bestIteration = 967\n",
      "Shrink model to first 968 iterations.\n",
      "===== ACCURACY SCORE 0.780502 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6878912\ttest: 0.6881508\tbest: 0.6881508 (0)\ttotal: 38ms\tremaining: 38s\n",
      "100:\tlearn: 0.4838526\ttest: 0.5054058\tbest: 0.5054058 (100)\ttotal: 1.91s\tremaining: 17s\n",
      "200:\tlearn: 0.4559383\ttest: 0.4904226\tbest: 0.4904226 (200)\ttotal: 3.38s\tremaining: 13.4s\n",
      "300:\tlearn: 0.4480172\ttest: 0.4890972\tbest: 0.4890718 (284)\ttotal: 4.84s\tremaining: 11.2s\n",
      "400:\tlearn: 0.4439299\ttest: 0.4887595\tbest: 0.4887445 (399)\ttotal: 6.32s\tremaining: 9.45s\n",
      "500:\tlearn: 0.4411570\ttest: 0.4885925\tbest: 0.4885825 (497)\ttotal: 8.18s\tremaining: 8.15s\n",
      "600:\tlearn: 0.4389732\ttest: 0.4883809\tbest: 0.4883809 (600)\ttotal: 9.63s\tremaining: 6.4s\n",
      "700:\tlearn: 0.4371285\ttest: 0.4883027\tbest: 0.4882435 (674)\ttotal: 11.1s\tremaining: 4.73s\n",
      "bestTest = 0.4882435274\n",
      "bestIteration = 674\n",
      "Shrink model to first 675 iterations.\n",
      "===== ACCURACY SCORE 0.777990 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878411\ttest: 0.6879443\tbest: 0.6879443 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4845091\ttest: 0.5018887\tbest: 0.5018887 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4565325\ttest: 0.4846617\tbest: 0.4846617 (200)\ttotal: 2.98s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4485749\ttest: 0.4829932\tbest: 0.4829932 (300)\ttotal: 4.53s\tremaining: 10.5s\n",
      "400:\tlearn: 0.4445341\ttest: 0.4825701\tbest: 0.4825366 (395)\ttotal: 6.37s\tremaining: 9.51s\n",
      "500:\tlearn: 0.4417897\ttest: 0.4824546\tbest: 0.4824037 (453)\ttotal: 7.83s\tremaining: 7.8s\n",
      "600:\tlearn: 0.4396431\ttest: 0.4823862\tbest: 0.4823771 (594)\ttotal: 9.29s\tremaining: 6.17s\n",
      "bestTest = 0.4823771473\n",
      "bestIteration = 594\n",
      "Shrink model to first 595 iterations.\n",
      "===== ACCURACY SCORE 0.783486 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6878233\ttest: 0.6881432\tbest: 0.6881432 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4839543\ttest: 0.5151567\tbest: 0.5151567 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4557414\ttest: 0.5029780\tbest: 0.5029780 (200)\ttotal: 2.98s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4478420\ttest: 0.5027820\tbest: 0.5026417 (243)\ttotal: 4.79s\tremaining: 11.1s\n",
      "bestTest = 0.5026417455\n",
      "bestIteration = 243\n",
      "Shrink model to first 244 iterations.\n",
      "===== ACCURACY SCORE 0.766726 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6878537\ttest: 0.6882616\tbest: 0.6882616 (0)\ttotal: 28.4ms\tremaining: 28.4s\n",
      "100:\tlearn: 0.4827943\ttest: 0.5103056\tbest: 0.5103056 (100)\ttotal: 2.14s\tremaining: 19s\n",
      "200:\tlearn: 0.4545636\ttest: 0.4962678\tbest: 0.4962678 (200)\ttotal: 3.59s\tremaining: 14.3s\n",
      "300:\tlearn: 0.4466796\ttest: 0.4949725\tbest: 0.4949595 (295)\ttotal: 5.08s\tremaining: 11.8s\n",
      "400:\tlearn: 0.4427481\ttest: 0.4948676\tbest: 0.4948638 (390)\ttotal: 6.52s\tremaining: 9.74s\n",
      "500:\tlearn: 0.4400630\ttest: 0.4949207\tbest: 0.4948582 (453)\ttotal: 7.99s\tremaining: 7.95s\n",
      "600:\tlearn: 0.4380483\ttest: 0.4948161\tbest: 0.4948161 (600)\ttotal: 9.9s\tremaining: 6.57s\n",
      "700:\tlearn: 0.4362043\ttest: 0.4948059\tbest: 0.4947659 (613)\ttotal: 11.4s\tremaining: 4.85s\n",
      "800:\tlearn: 0.4345900\ttest: 0.4946404\tbest: 0.4946404 (800)\ttotal: 12.8s\tremaining: 3.19s\n",
      "900:\tlearn: 0.4331307\ttest: 0.4945033\tbest: 0.4944974 (895)\ttotal: 14.3s\tremaining: 1.57s\n",
      "999:\tlearn: 0.4317137\ttest: 0.4943496\tbest: 0.4943326 (983)\ttotal: 15.7s\tremaining: 0us\n",
      "bestTest = 0.4943325531\n",
      "bestIteration = 983\n",
      "Shrink model to first 984 iterations.\n",
      "===== ACCURACY SCORE 0.771572 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779060 =====\n",
      "===== FOLD 0 =====\n",
      "0:\tlearn: 0.6878041\ttest: 0.6879231\tbest: 0.6879231 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4840618\ttest: 0.5030203\tbest: 0.5030203 (100)\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.4558988\ttest: 0.4875525\tbest: 0.4875525 (200)\ttotal: 3.16s\tremaining: 12.6s\n",
      "300:\tlearn: 0.4481730\ttest: 0.4856660\tbest: 0.4856660 (300)\ttotal: 4.82s\tremaining: 11.2s\n",
      "400:\tlearn: 0.4441724\ttest: 0.4849242\tbest: 0.4849242 (400)\ttotal: 6.28s\tremaining: 9.39s\n",
      "500:\tlearn: 0.4414049\ttest: 0.4843120\tbest: 0.4842876 (495)\ttotal: 7.76s\tremaining: 7.73s\n",
      "600:\tlearn: 0.4392401\ttest: 0.4838780\tbest: 0.4838780 (600)\ttotal: 9.22s\tremaining: 6.12s\n",
      "700:\tlearn: 0.4373725\ttest: 0.4836992\tbest: 0.4836832 (684)\ttotal: 10.7s\tremaining: 4.56s\n",
      "800:\tlearn: 0.4357290\ttest: 0.4834467\tbest: 0.4834467 (800)\ttotal: 12.1s\tremaining: 3.02s\n",
      "900:\tlearn: 0.4342029\ttest: 0.4833344\tbest: 0.4833254 (897)\ttotal: 13.7s\tremaining: 1.5s\n",
      "999:\tlearn: 0.4327891\ttest: 0.4832383\tbest: 0.4832240 (998)\ttotal: 16.2s\tremaining: 0us\n",
      "bestTest = 0.4832239778\n",
      "bestIteration = 998\n",
      "Shrink model to first 999 iterations.\n",
      "===== ACCURACY SCORE 0.778737 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 0.6878573\ttest: 0.6880382\tbest: 0.6880382 (0)\ttotal: 15.8ms\tremaining: 15.7s\n",
      "100:\tlearn: 0.4836097\ttest: 0.4989141\tbest: 0.4989141 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4555757\ttest: 0.4818223\tbest: 0.4818223 (200)\ttotal: 2.93s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4475453\ttest: 0.4800425\tbest: 0.4800113 (293)\ttotal: 4.4s\tremaining: 10.2s\n",
      "400:\tlearn: 0.4434850\ttest: 0.4798524\tbest: 0.4798141 (364)\ttotal: 5.86s\tremaining: 8.75s\n",
      "500:\tlearn: 0.4407500\ttest: 0.4797066\tbest: 0.4796930 (495)\ttotal: 7.39s\tremaining: 7.36s\n",
      "600:\tlearn: 0.4386334\ttest: 0.4796619\tbest: 0.4796592 (597)\ttotal: 9.08s\tremaining: 6.03s\n",
      "700:\tlearn: 0.4368565\ttest: 0.4796200\tbest: 0.4796067 (696)\ttotal: 10.6s\tremaining: 4.51s\n",
      "800:\tlearn: 0.4352197\ttest: 0.4797102\tbest: 0.4795628 (739)\ttotal: 12s\tremaining: 2.99s\n",
      "bestTest = 0.4795627981\n",
      "bestIteration = 739\n",
      "Shrink model to first 740 iterations.\n",
      "===== ACCURACY SCORE 0.786301 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 0.6879142\ttest: 0.6881950\tbest: 0.6881950 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4847684\ttest: 0.5058217\tbest: 0.5058217 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4567531\ttest: 0.4892648\tbest: 0.4892648 (200)\ttotal: 2.93s\tremaining: 11.6s\n",
      "300:\tlearn: 0.4488813\ttest: 0.4868166\tbest: 0.4868166 (300)\ttotal: 4.44s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4449508\ttest: 0.4861034\tbest: 0.4861034 (400)\ttotal: 6.28s\tremaining: 9.38s\n",
      "500:\tlearn: 0.4422407\ttest: 0.4857556\tbest: 0.4857556 (500)\ttotal: 7.76s\tremaining: 7.73s\n",
      "600:\tlearn: 0.4401549\ttest: 0.4855143\tbest: 0.4855143 (600)\ttotal: 9.21s\tremaining: 6.12s\n",
      "700:\tlearn: 0.4383345\ttest: 0.4852713\tbest: 0.4852713 (700)\ttotal: 10.7s\tremaining: 4.55s\n",
      "800:\tlearn: 0.4367096\ttest: 0.4851946\tbest: 0.4851728 (782)\ttotal: 12.1s\tremaining: 3.02s\n",
      "900:\tlearn: 0.4351743\ttest: 0.4851543\tbest: 0.4851418 (898)\ttotal: 13.6s\tremaining: 1.49s\n",
      "999:\tlearn: 0.4338732\ttest: 0.4851486\tbest: 0.4851263 (968)\ttotal: 15.1s\tremaining: 0us\n",
      "bestTest = 0.485126317\n",
      "bestIteration = 968\n",
      "Shrink model to first 969 iterations.\n",
      "===== ACCURACY SCORE 0.781556 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 0.6879115\ttest: 0.6882267\tbest: 0.6882267 (0)\ttotal: 16.6ms\tremaining: 16.6s\n",
      "100:\tlearn: 0.4841162\ttest: 0.5085527\tbest: 0.5085527 (100)\ttotal: 1.54s\tremaining: 13.7s\n",
      "200:\tlearn: 0.4562393\ttest: 0.4934539\tbest: 0.4934539 (200)\ttotal: 3s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4484352\ttest: 0.4918002\tbest: 0.4918002 (300)\ttotal: 4.46s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4444902\ttest: 0.4914800\tbest: 0.4914066 (386)\ttotal: 5.92s\tremaining: 8.84s\n",
      "500:\tlearn: 0.4418394\ttest: 0.4913438\tbest: 0.4913438 (500)\ttotal: 7.39s\tremaining: 7.36s\n",
      "600:\tlearn: 0.4397593\ttest: 0.4911611\tbest: 0.4911527 (574)\ttotal: 8.85s\tremaining: 5.87s\n",
      "700:\tlearn: 0.4379435\ttest: 0.4910612\tbest: 0.4910405 (664)\ttotal: 10.7s\tremaining: 4.56s\n",
      "800:\tlearn: 0.4362994\ttest: 0.4908455\tbest: 0.4908455 (800)\ttotal: 12.2s\tremaining: 3.02s\n",
      "900:\tlearn: 0.4347083\ttest: 0.4908737\tbest: 0.4908286 (847)\ttotal: 13.6s\tremaining: 1.5s\n",
      "999:\tlearn: 0.4333592\ttest: 0.4907282\tbest: 0.4907282 (999)\ttotal: 15.1s\tremaining: 0us\n",
      "bestTest = 0.4907282316\n",
      "bestIteration = 999\n",
      "===== ACCURACY SCORE 0.773438 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 0.6878985\ttest: 0.6881731\tbest: 0.6881731 (0)\ttotal: 17.1ms\tremaining: 17.1s\n",
      "100:\tlearn: 0.4840859\ttest: 0.5065482\tbest: 0.5065482 (100)\ttotal: 1.49s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4559826\ttest: 0.4916076\tbest: 0.4916076 (200)\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.4481398\ttest: 0.4902797\tbest: 0.4902797 (300)\ttotal: 4.5s\tremaining: 10.5s\n",
      "400:\tlearn: 0.4440633\ttest: 0.4901412\tbest: 0.4900878 (383)\ttotal: 6.28s\tremaining: 9.38s\n",
      "500:\tlearn: 0.4413678\ttest: 0.4901582\tbest: 0.4900410 (417)\ttotal: 7.74s\tremaining: 7.71s\n",
      "bestTest = 0.4900410258\n",
      "bestIteration = 417\n",
      "Shrink model to first 418 iterations.\n",
      "===== ACCURACY SCORE 0.777155 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 0.6879182\ttest: 0.6881547\tbest: 0.6881547 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4842213\ttest: 0.5058911\tbest: 0.5058911 (100)\ttotal: 1.51s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4561978\ttest: 0.4909194\tbest: 0.4909194 (200)\ttotal: 2.99s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4483942\ttest: 0.4897293\tbest: 0.4897293 (300)\ttotal: 4.47s\tremaining: 10.4s\n",
      "400:\tlearn: 0.4444212\ttest: 0.4894237\tbest: 0.4893412 (390)\ttotal: 6.89s\tremaining: 10.3s\n",
      "500:\tlearn: 0.4417670\ttest: 0.4894652\tbest: 0.4893141 (464)\ttotal: 8.56s\tremaining: 8.52s\n",
      "bestTest = 0.4893141053\n",
      "bestIteration = 464\n",
      "Shrink model to first 465 iterations.\n",
      "===== ACCURACY SCORE 0.778394 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "0:\tlearn: 0.6878934\ttest: 0.6881909\tbest: 0.6881909 (0)\ttotal: 15.9ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.4844021\ttest: 0.5063015\tbest: 0.5063015 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4564296\ttest: 0.4911492\tbest: 0.4911492 (200)\ttotal: 2.94s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4485757\ttest: 0.4900790\tbest: 0.4900790 (300)\ttotal: 4.45s\tremaining: 10.3s\n",
      "400:\tlearn: 0.4445099\ttest: 0.4902747\tbest: 0.4900790 (300)\ttotal: 5.91s\tremaining: 8.83s\n",
      "bestTest = 0.4900790377\n",
      "bestIteration = 300\n",
      "Shrink model to first 301 iterations.\n",
      "===== ACCURACY SCORE 0.778300 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "0:\tlearn: 0.6878380\ttest: 0.6881745\tbest: 0.6881745 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "100:\tlearn: 0.4828820\ttest: 0.5048739\tbest: 0.5048739 (100)\ttotal: 2.02s\tremaining: 17.9s\n",
      "200:\tlearn: 0.4549680\ttest: 0.4891566\tbest: 0.4891560 (199)\ttotal: 3.46s\tremaining: 13.8s\n",
      "300:\tlearn: 0.4470849\ttest: 0.4881934\tbest: 0.4880940 (255)\ttotal: 4.92s\tremaining: 11.4s\n",
      "bestTest = 0.4880939904\n",
      "bestIteration = 255\n",
      "Shrink model to first 256 iterations.\n",
      "===== ACCURACY SCORE 0.777668 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "0:\tlearn: 0.6879681\ttest: 0.6881080\tbest: 0.6881080 (0)\ttotal: 17.2ms\tremaining: 17.2s\n",
      "100:\tlearn: 0.4856951\ttest: 0.5003402\tbest: 0.5003402 (100)\ttotal: 1.52s\tremaining: 13.5s\n",
      "200:\tlearn: 0.4578784\ttest: 0.4829657\tbest: 0.4829657 (200)\ttotal: 2.98s\tremaining: 11.9s\n",
      "300:\tlearn: 0.4500616\ttest: 0.4810038\tbest: 0.4809955 (299)\ttotal: 4.54s\tremaining: 10.5s\n",
      "400:\tlearn: 0.4461159\ttest: 0.4805843\tbest: 0.4805812 (398)\ttotal: 6.23s\tremaining: 9.31s\n",
      "500:\tlearn: 0.4435144\ttest: 0.4804398\tbest: 0.4803916 (463)\ttotal: 7.69s\tremaining: 7.66s\n",
      "600:\tlearn: 0.4414188\ttest: 0.4801852\tbest: 0.4801587 (594)\ttotal: 9.15s\tremaining: 6.07s\n",
      "700:\tlearn: 0.4396291\ttest: 0.4800655\tbest: 0.4800527 (689)\ttotal: 10.6s\tremaining: 4.54s\n",
      "800:\tlearn: 0.4380484\ttest: 0.4798573\tbest: 0.4798572 (794)\ttotal: 12.1s\tremaining: 3.01s\n",
      "900:\tlearn: 0.4365648\ttest: 0.4797038\tbest: 0.4796468 (880)\ttotal: 14.1s\tremaining: 1.55s\n",
      "999:\tlearn: 0.4351622\ttest: 0.4796872\tbest: 0.4796234 (936)\ttotal: 16.1s\tremaining: 0us\n",
      "bestTest = 0.4796234338\n",
      "bestIteration = 936\n",
      "Shrink model to first 937 iterations.\n",
      "===== ACCURACY SCORE 0.781787 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "0:\tlearn: 0.6878576\ttest: 0.6881662\tbest: 0.6881662 (0)\ttotal: 16.5ms\tremaining: 16.5s\n",
      "100:\tlearn: 0.4828681\ttest: 0.5070571\tbest: 0.5070571 (100)\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4546706\ttest: 0.4930014\tbest: 0.4929979 (199)\ttotal: 2.95s\tremaining: 11.7s\n",
      "300:\tlearn: 0.4466761\ttest: 0.4921913\tbest: 0.4921339 (295)\ttotal: 4.4s\tremaining: 10.2s\n",
      "bestTest = 0.4921339469\n",
      "bestIteration = 295\n",
      "Shrink model to first 296 iterations.\n",
      "===== ACCURACY SCORE 0.777945 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.779140 =====\n"
     ]
    }
   ],
   "source": [
    "ctb_full_preds = []\n",
    "for SEED in range(N_ITERS):\n",
    "    ctb_oof = np.zeros(train_df.shape[0])\n",
    "    ctb_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importances = pd.DataFrame()\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(all_df, all_df[TARGET])):\n",
    "        print(f\"===== FOLD {fold} =====\")\n",
    "        oof_idx = np.array([idx for idx in valid_idx if idx < train_df.shape[0]])\n",
    "        preds_idx = np.array([idx for idx in valid_idx if idx >= train_df.shape[0]])\n",
    "\n",
    "        X_train, y_train = all_df.iloc[train_idx].drop(TARGET, axis=1), all_df.iloc[train_idx][TARGET]\n",
    "        X_train = apply_noise(X_train)\n",
    "        X_valid, y_valid = all_df.iloc[oof_idx].drop(TARGET, axis=1), all_df.iloc[oof_idx][TARGET]\n",
    "        X_test = all_df.iloc[preds_idx].drop(TARGET, axis=1)\n",
    "\n",
    "        model = ctb.CatBoostClassifier(**params)\n",
    "        model.fit(X_train, y_train,\n",
    "                  eval_set=[(X_valid, y_valid)],\n",
    "                  use_best_model=True,\n",
    "                  early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "                  verbose=VERBOSE\n",
    "                  )\n",
    "\n",
    "        fi_tmp = pd.DataFrame()\n",
    "        fi_tmp[\"feature\"] = X_test.columns.to_list()\n",
    "        fi_tmp[\"importance\"] = model.get_feature_importance()\n",
    "        fi_tmp[\"fold\"] = fold\n",
    "        fi_tmp[\"seed\"] = SEED\n",
    "        feature_importances = feature_importances.append(fi_tmp)\n",
    "\n",
    "        ctb_oof[oof_idx] = model.predict(X_valid)\n",
    "        ctb_preds[preds_idx-train_df.shape[0]] = model.predict(X_test)\n",
    "\n",
    "        acc_score = accuracy_score(y_valid, np.where(ctb_oof[oof_idx]>0.5, 1, 0))\n",
    "        print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\\n\")\n",
    "\n",
    "    acc_score = accuracy_score(all_df[:train_df.shape[0]][TARGET], np.where(ctb_oof>0.5, 1, 0))\n",
    "    print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\")\n",
    "    ctb_full_preds.append(ctb_preds)\n",
    "ctb_full_preds = np.stack(ctb_full_preds, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T10:41:40.040342Z",
     "iopub.status.busy": "2023-03-24T10:41:40.039983Z",
     "iopub.status.idle": "2023-03-24T10:41:40.798828Z",
     "shell.execute_reply": "2023-03-24T10:41:40.797964Z",
     "shell.execute_reply.started": "2023-03-24T10:41:40.040300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# just to get ideas to improve\n",
    "order = list(feature_importances.groupby(\"feature\").mean().sort_values(\"importance\", ascending=False).index)\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=feature_importances, order=order)\n",
    "plt.title(\"{} importance\".format(\"CatBoostClassifier\"))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T10:41:58.180367Z",
     "iopub.status.busy": "2023-03-24T10:41:58.180023Z",
     "iopub.status.idle": "2023-03-24T10:42:21.115155Z",
     "shell.execute_reply": "2023-03-24T10:42:21.114036Z",
     "shell.execute_reply.started": "2023-03-24T10:41:58.180334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'min_samples_leaf': 2}\n"
     ]
    }
   ],
   "source": [
    "# Tuning the DecisionTreeClassifier by the GridSearchCV\n",
    "parameters = {\n",
    "    'max_depth': np.arange(2, 5, dtype=int),\n",
    "    'min_samples_leaf':  np.arange(2, 5, dtype=int)\n",
    "}\n",
    "\n",
    "classifier = DecisionTreeClassifier(random_state=2021)\n",
    "\n",
    "model = GridSearchCV(\n",
    "    estimator=classifier,\n",
    "    param_grid=parameters,\n",
    "    scoring='accuracy',\n",
    "    cv=10,\n",
    "    n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "best_parameters = model.best_params_\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T10:42:23.891391Z",
     "iopub.status.busy": "2023-03-24T10:42:23.891027Z",
     "iopub.status.idle": "2023-03-24T10:46:21.729317Z",
     "shell.execute_reply": "2023-03-24T10:46:21.728342Z",
     "shell.execute_reply.started": "2023-03-24T10:42:23.891357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.766660 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.768746 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.765781 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.767629 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.781782 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.764788 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.769454 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.772060 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.765107 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.766466 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.768850 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.767859 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.775030 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.762052 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.766740 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.776062 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.768062 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.761130 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.773886 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.773910 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.770913 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.769560 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.769185 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.769353 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.764415 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.765893 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.766121 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.774402 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.770923 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.773293 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.772893 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.773673 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.770020 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.766577 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.767384 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.776419 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.762656 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.763158 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.764067 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.774891 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.774107 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.763804 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.773317 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.768630 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.777690 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.774769 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.755463 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.765701 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.763748 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.767222 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.771792 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.779472 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.770078 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.770846 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.769700 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.770462 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.776398 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.765981 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.767180 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.758145 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.776337 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.770139 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.765549 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.772773 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.772897 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.769580 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.766900 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.773651 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.762463 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.771374 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.767704 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.769716 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.775187 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.767859 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.768122 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.765078 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.768800 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.772268 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.768163 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.768727 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.767966 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.765169 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.759201 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.771814 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.769718 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.765038 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.774546 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.768270 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.770982 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.765155 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.779823 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.770253 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.771176 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.764975 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.769970 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.767132 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.770998 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.767845 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.769840 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.775375 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.768190 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.770802 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.762312 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.774119 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.771877 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.762873 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.759295 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.767845 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.772451 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.768510 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.775117 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.760973 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.772682 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.766723 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.776794 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.768466 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.760108 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.757861 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.769867 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.770296 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.767920 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.763906 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.771817 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.765000 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.768731 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.769499 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.772267 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.771759 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.773138 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.766500 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.770835 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.769340 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.772984 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.769246 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.769679 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.779637 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.772974 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.764575 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.778686 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.758435 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.765516 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.771031 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.770260 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.768655 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.772434 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.764051 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.768444 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.766623 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.770760 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.771268 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.778663 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.769716 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.765435 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.769610 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.761796 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.771665 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.769623 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.761065 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.764300 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.773132 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.772501 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.766781 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.770452 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.766773 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.767810 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.768119 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.771189 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.766947 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.767007 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.767137 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.774842 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.772791 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.771538 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.757698 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.767585 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.768490 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.776456 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.772394 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.774362 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.761346 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.764670 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.768415 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.770071 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.768001 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.767728 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.770602 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.769400 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.773195 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.763009 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.768036 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.775449 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.764927 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.772223 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.773535 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.766167 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.765475 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.766954 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.768900 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.768481 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.769527 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.767595 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.774262 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.769861 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.769698 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.762901 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.771909 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.765678 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.770338 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.769010 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.775205 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.771307 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.767818 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.768441 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.762878 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.767193 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.782380 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.762688 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.766640 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.772000 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.769640 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.774686 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.773267 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.775102 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.770973 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.762854 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.766290 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.763289 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.762292 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.768404 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.774101 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.769110 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.771818 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.769407 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.766439 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.775702 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.771225 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.768369 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.772399 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.774152 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.770879 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.765042 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.770540 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.771878 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.769901 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.768859 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.762822 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.766110 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.774819 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.768319 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.768794 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.770033 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.769704 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.769120 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.764216 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.778390 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.762905 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.770629 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.773788 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.768777 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.768430 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.766700 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.772214 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.765665 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.769150 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.773448 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.777466 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.762714 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.765987 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.765145 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.765972 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.771383 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.771119 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.768264 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.775444 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.769680 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.764659 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.772260 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.773006 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.768359 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.768554 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.771400 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.773749 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.767805 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.770405 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.760412 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.769070 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.761130 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.769474 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.771738 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.772075 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.767718 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.777444 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.767493 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.766412 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.771897 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.771124 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.769650 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.757273 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.774229 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.773270 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.766913 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.778719 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.764478 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.772764 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.766734 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.770393 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.767347 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.769230 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.767565 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.769914 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.773687 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.772382 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.775998 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.769824 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.768937 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.773753 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.756770 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.764741 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.769350 =====\n",
      "===== FOLD 0 =====\n",
      "===== ACCURACY SCORE 0.771810 =====\n",
      "\n",
      "===== FOLD 1 =====\n",
      "===== ACCURACY SCORE 0.770662 =====\n",
      "\n",
      "===== FOLD 2 =====\n",
      "===== ACCURACY SCORE 0.776021 =====\n",
      "\n",
      "===== FOLD 3 =====\n",
      "===== ACCURACY SCORE 0.756611 =====\n",
      "\n",
      "===== FOLD 4 =====\n",
      "===== ACCURACY SCORE 0.768154 =====\n",
      "\n",
      "===== FOLD 5 =====\n",
      "===== ACCURACY SCORE 0.765595 =====\n",
      "\n",
      "===== FOLD 6 =====\n",
      "===== ACCURACY SCORE 0.768483 =====\n",
      "\n",
      "===== FOLD 7 =====\n",
      "===== ACCURACY SCORE 0.766917 =====\n",
      "\n",
      "===== FOLD 8 =====\n",
      "===== ACCURACY SCORE 0.772391 =====\n",
      "\n",
      "===== FOLD 9 =====\n",
      "===== ACCURACY SCORE 0.767437 =====\n",
      "\n",
      "===== ACCURACY SCORE 0.768420 =====\n"
     ]
    }
   ],
   "source": [
    "dtm_full_preds = []\n",
    "for SEED in range(N_ITERS):\n",
    "    dtm_oof = np.zeros(train_df.shape[0])\n",
    "    dtm_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importances = pd.DataFrame()\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(all_df, all_df[TARGET])):\n",
    "        print(f\"===== FOLD {fold} =====\")\n",
    "        oof_idx = np.array([idx for idx in valid_idx if idx < train_df.shape[0]])\n",
    "        preds_idx = np.array([idx for idx in valid_idx if idx >= train_df.shape[0]])\n",
    "\n",
    "        X_train, y_train = all_df.iloc[train_idx].drop(TARGET, axis=1), all_df.iloc[train_idx][TARGET]\n",
    "        X_train = apply_noise(X_train)\n",
    "        X_valid, y_valid = all_df.iloc[oof_idx].drop(TARGET, axis=1), all_df.iloc[oof_idx][TARGET]\n",
    "        X_test = all_df.iloc[preds_idx].drop(TARGET, axis=1)\n",
    "\n",
    "        model = DecisionTreeClassifier(\n",
    "            max_depth=best_parameters['max_depth'],\n",
    "            min_samples_leaf=best_parameters['min_samples_leaf'],\n",
    "            random_state=SEED\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        dtm_oof[oof_idx] = model.predict(X_valid)\n",
    "        dtm_preds[preds_idx-train_df.shape[0]] = model.predict(X_test)\n",
    "\n",
    "        acc_score = accuracy_score(y_valid, np.where(dtm_oof[oof_idx]>0.5, 1, 0))\n",
    "        print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\\n\")\n",
    "\n",
    "    acc_score = accuracy_score(all_df[:train_df.shape[0]][TARGET], np.where(dtm_oof>0.5, 1, 0))\n",
    "    print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\")\n",
    "    dtm_full_preds.append(dtm_preds)\n",
    "dtm_full_preds = np.stack(dtm_full_preds, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T10:47:16.947624Z",
     "iopub.status.busy": "2023-03-24T10:47:16.947290Z",
     "iopub.status.idle": "2023-03-24T10:47:17.466719Z",
     "shell.execute_reply": "2023-03-24T10:47:17.465202Z",
     "shell.execute_reply.started": "2023-03-24T10:47:16.947594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.47.0 (20210316.1410)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"2909pt\" height=\"552pt\"\n",
       " viewBox=\"0.00 0.00 2908.50 552.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 548)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-548 2904.5,-548 2904.5,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"#f5d0b5\" stroke=\"black\" points=\"1499.5,-544 1304.5,-544 1304.5,-461 1499.5,-461 1499.5,-544\"/>\n",
       "<text text-anchor=\"start\" x=\"1367\" y=\"-528.8\" font-family=\"Times-Roman\" font-size=\"14.00\">Sex ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"1358\" y=\"-513.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.474</text>\n",
       "<text text-anchor=\"start\" x=\"1334\" y=\"-498.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 180000</text>\n",
       "<text text-anchor=\"start\" x=\"1312.5\" y=\"-483.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [110555, 69445]</text>\n",
       "<text text-anchor=\"start\" x=\"1369\" y=\"-468.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#90c8f0\" stroke=\"black\" points=\"1128,-425 942,-425 942,-342 1128,-342 1128,-425\"/>\n",
       "<text text-anchor=\"start\" x=\"968.5\" y=\"-409.8\" font-family=\"Times-Roman\" font-size=\"14.00\">Embarked_S ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"991\" y=\"-394.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.423</text>\n",
       "<text text-anchor=\"start\" x=\"971.5\" y=\"-379.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 66814</text>\n",
       "<text text-anchor=\"start\" x=\"950\" y=\"-364.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [20320, 46494]</text>\n",
       "<text text-anchor=\"start\" x=\"1002\" y=\"-349.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1304.13,-470.3C1252.76,-453.92 1189.84,-433.86 1137.76,-417.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1138.76,-413.91 1128.17,-414.2 1136.63,-420.57 1138.76,-413.91\"/>\n",
       "<text text-anchor=\"middle\" x=\"1139.64\" y=\"-432.71\" font-family=\"Times-Roman\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>16</title>\n",
       "<polygon fill=\"#eca16b\" stroke=\"black\" points=\"1866,-425 1680,-425 1680,-342 1866,-342 1866,-425\"/>\n",
       "<text text-anchor=\"start\" x=\"1722\" y=\"-409.8\" font-family=\"Times-Roman\" font-size=\"14.00\">Cabin_X ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"1729\" y=\"-394.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.323</text>\n",
       "<text text-anchor=\"start\" x=\"1705\" y=\"-379.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 113186</text>\n",
       "<text text-anchor=\"start\" x=\"1688\" y=\"-364.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [90235, 22951]</text>\n",
       "<text text-anchor=\"start\" x=\"1740\" y=\"-349.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>0&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1499.96,-470.61C1552.41,-454.07 1616.96,-433.71 1670.14,-416.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1671.44,-420.2 1679.93,-413.85 1669.34,-413.52 1671.44,-420.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"1668.39\" y=\"-432.33\" font-family=\"Times-Roman\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#67b4eb\" stroke=\"black\" points=\"614.5,-306 437.5,-306 437.5,-223 614.5,-223 614.5,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"479.5\" y=\"-290.8\" font-family=\"Times-Roman\" font-size=\"14.00\">Fare ≤ 1.604</text>\n",
       "<text text-anchor=\"start\" x=\"482\" y=\"-275.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.305</text>\n",
       "<text text-anchor=\"start\" x=\"462.5\" y=\"-260.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 26812</text>\n",
       "<text text-anchor=\"start\" x=\"445.5\" y=\"-245.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [5037, 21775]</text>\n",
       "<text text-anchor=\"start\" x=\"493\" y=\"-230.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M941.94,-361.11C851.98,-340.43 716.2,-309.22 624.46,-288.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"625.14,-284.7 614.61,-285.87 623.57,-291.52 625.14,-284.7\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"#b3daf5\" stroke=\"black\" points=\"1128,-306 942,-306 942,-223 1128,-223 1128,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"992.5\" y=\"-290.8\" font-family=\"Times-Roman\" font-size=\"14.00\">Ticket ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"991\" y=\"-275.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.472</text>\n",
       "<text text-anchor=\"start\" x=\"971.5\" y=\"-260.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 40002</text>\n",
       "<text text-anchor=\"start\" x=\"950\" y=\"-245.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [15283, 24719]</text>\n",
       "<text text-anchor=\"start\" x=\"1002\" y=\"-230.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>1&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1035,-341.91C1035,-333.65 1035,-324.86 1035,-316.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1038.5,-316.02 1035,-306.02 1031.5,-316.02 1038.5,-316.02\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"#6fb8ec\" stroke=\"black\" points=\"344.5,-187 167.5,-187 167.5,-104 344.5,-104 344.5,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"213.5\" y=\"-171.8\" font-family=\"Times-Roman\" font-size=\"14.00\">Ticket ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"212\" y=\"-156.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.335</text>\n",
       "<text text-anchor=\"start\" x=\"192.5\" y=\"-141.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 21320</text>\n",
       "<text text-anchor=\"start\" x=\"175.5\" y=\"-126.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [4539, 16781]</text>\n",
       "<text text-anchor=\"start\" x=\"223\" y=\"-111.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M437.22,-225.03C410.68,-213.53 381.44,-200.86 354.33,-189.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"355.4,-185.76 344.84,-185 352.62,-192.18 355.4,-185.76\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"#4da7e8\" stroke=\"black\" points=\"605.5,-187 446.5,-187 446.5,-104 605.5,-104 605.5,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"475\" y=\"-171.8\" font-family=\"Times-Roman\" font-size=\"14.00\">Cabin_A ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"482\" y=\"-156.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.165</text>\n",
       "<text text-anchor=\"start\" x=\"467\" y=\"-141.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 5492</text>\n",
       "<text text-anchor=\"start\" x=\"454.5\" y=\"-126.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [498, 4994]</text>\n",
       "<text text-anchor=\"start\" x=\"493\" y=\"-111.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M526,-222.91C526,-214.65 526,-205.86 526,-197.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"529.5,-197.02 526,-187.02 522.5,-197.02 529.5,-197.02\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"#fef9f6\" stroke=\"black\" points=\"150,-68 0,-68 0,0 150,0 150,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"40\" y=\"-52.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"20.5\" y=\"-37.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 473</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-22.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [242, 231]</text>\n",
       "<text text-anchor=\"start\" x=\"42\" y=\"-7.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M188.86,-103.88C172.39,-93.92 154.82,-83.29 138.52,-73.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"139.99,-70.22 129.62,-68.04 136.36,-76.21 139.99,-70.22\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"#6cb6ec\" stroke=\"black\" points=\"344.5,-68 167.5,-68 167.5,0 344.5,0 344.5,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"212\" y=\"-52.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.327</text>\n",
       "<text text-anchor=\"start\" x=\"192.5\" y=\"-37.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 20847</text>\n",
       "<text text-anchor=\"start\" x=\"175.5\" y=\"-22.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [4297, 16550]</text>\n",
       "<text text-anchor=\"start\" x=\"223\" y=\"-7.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M256,-103.73C256,-95.52 256,-86.86 256,-78.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"259.5,-78.3 256,-68.3 252.5,-78.3 259.5,-78.3\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"#4ba6e7\" stroke=\"black\" points=\"521.5,-68 362.5,-68 362.5,0 521.5,0 521.5,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"398\" y=\"-52.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.153</text>\n",
       "<text text-anchor=\"start\" x=\"383\" y=\"-37.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 5284</text>\n",
       "<text text-anchor=\"start\" x=\"370.5\" y=\"-22.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [442, 4842]</text>\n",
       "<text text-anchor=\"start\" x=\"409\" y=\"-7.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M494.72,-103.73C487.86,-94.79 480.6,-85.32 473.72,-76.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"476.41,-74.1 467.54,-68.3 470.85,-78.36 476.41,-74.1\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"#82c1ef\" stroke=\"black\" points=\"680.5,-68 539.5,-68 539.5,0 680.5,0 680.5,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"566\" y=\"-52.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.393</text>\n",
       "<text text-anchor=\"start\" x=\"555.5\" y=\"-37.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 208</text>\n",
       "<text text-anchor=\"start\" x=\"547.5\" y=\"-22.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [56, 152]</text>\n",
       "<text text-anchor=\"start\" x=\"577\" y=\"-7.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>6&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M557.28,-103.73C564.14,-94.79 571.4,-85.32 578.28,-76.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"581.15,-78.36 584.46,-68.3 575.59,-74.1 581.15,-78.36\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"#eead7f\" stroke=\"black\" points=\"1019.5,-187 860.5,-187 860.5,-104 1019.5,-104 1019.5,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"887\" y=\"-171.8\" font-family=\"Times-Roman\" font-size=\"14.00\">Pclass ≤ 0.302</text>\n",
       "<text text-anchor=\"start\" x=\"896\" y=\"-156.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.385</text>\n",
       "<text text-anchor=\"start\" x=\"881\" y=\"-141.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 1482</text>\n",
       "<text text-anchor=\"start\" x=\"868.5\" y=\"-126.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [1096, 386]</text>\n",
       "<text text-anchor=\"start\" x=\"907\" y=\"-111.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1002.04,-222.91C994.75,-213.92 986.94,-204.32 979.42,-195.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"981.92,-192.58 972.9,-187.02 976.49,-196.99 981.92,-192.58\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<polygon fill=\"#acd6f4\" stroke=\"black\" points=\"1223,-187 1037,-187 1037,-104 1223,-104 1223,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"1083.5\" y=\"-171.8\" font-family=\"Times-Roman\" font-size=\"14.00\">Fare ≤ 1.552</text>\n",
       "<text text-anchor=\"start\" x=\"1086\" y=\"-156.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.465</text>\n",
       "<text text-anchor=\"start\" x=\"1066.5\" y=\"-141.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 38520</text>\n",
       "<text text-anchor=\"start\" x=\"1045\" y=\"-126.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [14187, 24333]</text>\n",
       "<text text-anchor=\"start\" x=\"1097\" y=\"-111.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>9&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1067.96,-222.91C1075.25,-213.92 1083.06,-204.32 1090.58,-195.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1093.51,-196.99 1097.1,-187.02 1088.08,-192.58 1093.51,-196.99\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"#fbe9dd\" stroke=\"black\" points=\"849,-68 699,-68 699,0 849,0 849,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"730\" y=\"-52.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.496</text>\n",
       "<text text-anchor=\"start\" x=\"719.5\" y=\"-37.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 424</text>\n",
       "<text text-anchor=\"start\" x=\"707\" y=\"-22.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [232, 192]</text>\n",
       "<text text-anchor=\"start\" x=\"741\" y=\"-7.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>10&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M878.19,-103.73C863.32,-93.92 847.47,-83.46 832.74,-73.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"834.49,-70.71 824.22,-68.13 830.64,-76.55 834.49,-70.71\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<polygon fill=\"#eb9d65\" stroke=\"black\" points=\"1017,-68 867,-68 867,0 1017,0 1017,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"898\" y=\"-52.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.299</text>\n",
       "<text text-anchor=\"start\" x=\"883\" y=\"-37.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 1058</text>\n",
       "<text text-anchor=\"start\" x=\"875\" y=\"-22.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [864, 194]</text>\n",
       "<text text-anchor=\"start\" x=\"909\" y=\"-7.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>10&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M940.74,-103.73C940.89,-95.52 941.05,-86.86 941.2,-78.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"944.71,-78.36 941.39,-68.3 937.71,-78.23 944.71,-78.36\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<polygon fill=\"#b5daf5\" stroke=\"black\" points=\"1221,-68 1035,-68 1035,0 1221,0 1221,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"1084\" y=\"-52.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.474</text>\n",
       "<text text-anchor=\"start\" x=\"1064.5\" y=\"-37.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 34603</text>\n",
       "<text text-anchor=\"start\" x=\"1043\" y=\"-22.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [13328, 21275]</text>\n",
       "<text text-anchor=\"start\" x=\"1095\" y=\"-7.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>13&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1129.26,-103.73C1129.11,-95.52 1128.95,-86.86 1128.8,-78.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1132.29,-78.23 1128.61,-68.3 1125.29,-78.36 1132.29,-78.23\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>15</title>\n",
       "<polygon fill=\"#71b9ec\" stroke=\"black\" points=\"1397.5,-68 1238.5,-68 1238.5,0 1397.5,0 1397.5,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"1274\" y=\"-52.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.342</text>\n",
       "<text text-anchor=\"start\" x=\"1259\" y=\"-37.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 3917</text>\n",
       "<text text-anchor=\"start\" x=\"1246.5\" y=\"-22.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [859, 3058]</text>\n",
       "<text text-anchor=\"start\" x=\"1285\" y=\"-7.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;15 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>13&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1199.74,-103.88C1217,-93.83 1235.44,-83.09 1252.49,-73.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1254.39,-76.1 1261.27,-68.04 1250.87,-70.05 1254.39,-76.1\"/>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>17</title>\n",
       "<polygon fill=\"#f5ceb3\" stroke=\"black\" points=\"1866,-306 1680,-306 1680,-223 1866,-223 1866,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"1706.5\" y=\"-290.8\" font-family=\"Times-Roman\" font-size=\"14.00\">Embarked_S ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"1729\" y=\"-275.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.471</text>\n",
       "<text text-anchor=\"start\" x=\"1709.5\" y=\"-260.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 30317</text>\n",
       "<text text-anchor=\"start\" x=\"1688\" y=\"-245.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [18779, 11538]</text>\n",
       "<text text-anchor=\"start\" x=\"1740\" y=\"-230.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;17 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>16&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1773,-341.91C1773,-333.65 1773,-324.86 1773,-316.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1776.5,-316.02 1773,-306.02 1769.5,-316.02 1776.5,-316.02\"/>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>24</title>\n",
       "<polygon fill=\"#e99559\" stroke=\"black\" points=\"2427,-306 2241,-306 2241,-223 2427,-223 2427,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"2281\" y=\"-290.8\" font-family=\"Times-Roman\" font-size=\"14.00\">Pclass ≤ 0.302</text>\n",
       "<text text-anchor=\"start\" x=\"2290\" y=\"-275.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.238</text>\n",
       "<text text-anchor=\"start\" x=\"2270.5\" y=\"-260.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 82869</text>\n",
       "<text text-anchor=\"start\" x=\"2249\" y=\"-245.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [71456, 11413]</text>\n",
       "<text text-anchor=\"start\" x=\"2301\" y=\"-230.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;24 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>16&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1866.27,-363.05C1966.93,-342.06 2126.79,-308.71 2231.06,-286.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2231.9,-290.37 2240.98,-284.9 2230.47,-283.52 2231.9,-290.37\"/>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>18</title>\n",
       "<polygon fill=\"#b7dbf5\" stroke=\"black\" points=\"1762,-187 1594,-187 1594,-104 1762,-104 1762,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"1631.5\" y=\"-171.8\" font-family=\"Times-Roman\" font-size=\"14.00\">Fare ≤ 1.646</text>\n",
       "<text text-anchor=\"start\" x=\"1634\" y=\"-156.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.475</text>\n",
       "<text text-anchor=\"start\" x=\"1614.5\" y=\"-141.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 10868</text>\n",
       "<text text-anchor=\"start\" x=\"1602\" y=\"-126.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [4218, 6650]</text>\n",
       "<text text-anchor=\"start\" x=\"1645\" y=\"-111.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;18 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>17&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1740.04,-222.91C1732.75,-213.92 1724.94,-204.32 1717.42,-195.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1719.92,-192.58 1710.9,-187.02 1714.49,-196.99 1719.92,-192.58\"/>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>21</title>\n",
       "<polygon fill=\"#eeab7b\" stroke=\"black\" points=\"1956.5,-187 1779.5,-187 1779.5,-104 1956.5,-104 1956.5,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"1821.5\" y=\"-171.8\" font-family=\"Times-Roman\" font-size=\"14.00\">Fare ≤ 1.368</text>\n",
       "<text text-anchor=\"start\" x=\"1824\" y=\"-156.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.376</text>\n",
       "<text text-anchor=\"start\" x=\"1804.5\" y=\"-141.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 19449</text>\n",
       "<text text-anchor=\"start\" x=\"1787.5\" y=\"-126.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [14561, 4888]</text>\n",
       "<text text-anchor=\"start\" x=\"1835\" y=\"-111.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;21 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>17&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1805.96,-222.91C1813.25,-213.92 1821.06,-204.32 1828.58,-195.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1831.51,-196.99 1835.1,-187.02 1826.08,-192.58 1831.51,-196.99\"/>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>19</title>\n",
       "<polygon fill=\"#e8f3fc\" stroke=\"black\" points=\"1583,-68 1415,-68 1415,0 1583,0 1583,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"1455\" y=\"-52.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.498</text>\n",
       "<text text-anchor=\"start\" x=\"1440\" y=\"-37.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 7948</text>\n",
       "<text text-anchor=\"start\" x=\"1423\" y=\"-22.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [3724, 4224]</text>\n",
       "<text text-anchor=\"start\" x=\"1466\" y=\"-7.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;19 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>18&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1611.6,-103.88C1595.32,-93.92 1577.93,-83.29 1561.82,-73.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1563.37,-70.28 1553.02,-68.04 1559.72,-76.25 1563.37,-70.28\"/>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>20</title>\n",
       "<polygon fill=\"#61b1ea\" stroke=\"black\" points=\"1759.5,-68 1600.5,-68 1600.5,0 1759.5,0 1759.5,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"1636\" y=\"-52.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.281</text>\n",
       "<text text-anchor=\"start\" x=\"1621\" y=\"-37.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 2920</text>\n",
       "<text text-anchor=\"start\" x=\"1608.5\" y=\"-22.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [494, 2426]</text>\n",
       "<text text-anchor=\"start\" x=\"1647\" y=\"-7.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;20 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>18&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1678.74,-103.73C1678.89,-95.52 1679.05,-86.86 1679.2,-78.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1682.71,-78.36 1679.39,-68.3 1675.71,-78.23 1682.71,-78.36\"/>\n",
       "</g>\n",
       "<!-- 22 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>22</title>\n",
       "<polygon fill=\"#eca26d\" stroke=\"black\" points=\"1954.5,-68 1777.5,-68 1777.5,0 1954.5,0 1954.5,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"1822\" y=\"-52.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.329</text>\n",
       "<text text-anchor=\"start\" x=\"1802.5\" y=\"-37.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 16095</text>\n",
       "<text text-anchor=\"start\" x=\"1785.5\" y=\"-22.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [12755, 3340]</text>\n",
       "<text text-anchor=\"start\" x=\"1833\" y=\"-7.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;22 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>21&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1867.26,-103.73C1867.11,-95.52 1866.95,-86.86 1866.8,-78.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1870.29,-78.23 1866.61,-68.3 1863.29,-78.36 1870.29,-78.23\"/>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>23</title>\n",
       "<polygon fill=\"#fbede3\" stroke=\"black\" points=\"2140,-68 1972,-68 1972,0 2140,0 2140,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"2012\" y=\"-52.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.497</text>\n",
       "<text text-anchor=\"start\" x=\"1997\" y=\"-37.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 3354</text>\n",
       "<text text-anchor=\"start\" x=\"1980\" y=\"-22.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [1806, 1548]</text>\n",
       "<text text-anchor=\"start\" x=\"2023\" y=\"-7.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;23 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>21&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1937.74,-103.88C1955,-93.83 1973.44,-83.09 1990.49,-73.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1992.39,-76.1 1999.27,-68.04 1988.87,-70.05 1992.39,-76.1\"/>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>25</title>\n",
       "<polygon fill=\"#eca571\" stroke=\"black\" points=\"2422.5,-187 2245.5,-187 2245.5,-104 2422.5,-104 2422.5,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"2267.5\" y=\"-171.8\" font-family=\"Times-Roman\" font-size=\"14.00\">Embarked_S ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"2290\" y=\"-156.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.345</text>\n",
       "<text text-anchor=\"start\" x=\"2270.5\" y=\"-141.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 27032</text>\n",
       "<text text-anchor=\"start\" x=\"2253.5\" y=\"-126.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [21037, 5995]</text>\n",
       "<text text-anchor=\"start\" x=\"2301\" y=\"-111.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 24&#45;&gt;25 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>24&#45;&gt;25</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2334,-222.91C2334,-214.65 2334,-205.86 2334,-197.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2337.5,-197.02 2334,-187.02 2330.5,-197.02 2337.5,-197.02\"/>\n",
       "</g>\n",
       "<!-- 28 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>28</title>\n",
       "<polygon fill=\"#e88f4e\" stroke=\"black\" points=\"2710.5,-187 2533.5,-187 2533.5,-104 2710.5,-104 2710.5,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"2555.5\" y=\"-171.8\" font-family=\"Times-Roman\" font-size=\"14.00\">Embarked_S ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"2578\" y=\"-156.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.175</text>\n",
       "<text text-anchor=\"start\" x=\"2558.5\" y=\"-141.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 55837</text>\n",
       "<text text-anchor=\"start\" x=\"2541.5\" y=\"-126.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [50419, 5418]</text>\n",
       "<text text-anchor=\"start\" x=\"2589\" y=\"-111.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 24&#45;&gt;28 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>24&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2427.11,-225.68C2457.94,-213.15 2492.34,-199.17 2523.56,-186.49\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2525.19,-189.61 2533.13,-182.6 2522.55,-183.12 2525.19,-189.61\"/>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>26</title>\n",
       "<polygon fill=\"#f5ceb2\" stroke=\"black\" points=\"2326,-68 2158,-68 2158,0 2326,0 2326,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"2198\" y=\"-52.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.471</text>\n",
       "<text text-anchor=\"start\" x=\"2183\" y=\"-37.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 5702</text>\n",
       "<text text-anchor=\"start\" x=\"2166\" y=\"-22.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [3535, 2167]</text>\n",
       "<text text-anchor=\"start\" x=\"2209\" y=\"-7.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;26 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>25&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2299.74,-103.73C2292.16,-94.7 2284.11,-85.12 2276.52,-76.08\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2279.09,-73.7 2269.98,-68.3 2273.73,-78.21 2279.09,-73.7\"/>\n",
       "</g>\n",
       "<!-- 27 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>27</title>\n",
       "<polygon fill=\"#eb9d64\" stroke=\"black\" points=\"2520.5,-68 2343.5,-68 2343.5,0 2520.5,0 2520.5,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"2388\" y=\"-52.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.295</text>\n",
       "<text text-anchor=\"start\" x=\"2368.5\" y=\"-37.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 21330</text>\n",
       "<text text-anchor=\"start\" x=\"2351.5\" y=\"-22.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [17502, 3828]</text>\n",
       "<text text-anchor=\"start\" x=\"2399\" y=\"-7.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;27 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>25&#45;&gt;27</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2370.49,-103.73C2378.65,-94.61 2387.31,-84.93 2395.48,-75.81\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2398.14,-78.09 2402.2,-68.3 2392.92,-73.42 2398.14,-78.09\"/>\n",
       "</g>\n",
       "<!-- 29 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>29</title>\n",
       "<polygon fill=\"#ea995f\" stroke=\"black\" points=\"2706,-68 2538,-68 2538,0 2706,0 2706,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"2578\" y=\"-52.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.271</text>\n",
       "<text text-anchor=\"start\" x=\"2563\" y=\"-37.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 9775</text>\n",
       "<text text-anchor=\"start\" x=\"2546\" y=\"-22.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [8195, 1580]</text>\n",
       "<text text-anchor=\"start\" x=\"2589\" y=\"-7.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;29 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>28&#45;&gt;29</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2622,-103.73C2622,-95.52 2622,-86.86 2622,-78.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2625.5,-78.3 2622,-68.3 2618.5,-78.3 2625.5,-78.3\"/>\n",
       "</g>\n",
       "<!-- 30 -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>30</title>\n",
       "<polygon fill=\"#e78c4b\" stroke=\"black\" points=\"2900.5,-68 2723.5,-68 2723.5,0 2900.5,0 2900.5,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"2768\" y=\"-52.8\" font-family=\"Times-Roman\" font-size=\"14.00\">gini = 0.153</text>\n",
       "<text text-anchor=\"start\" x=\"2748.5\" y=\"-37.8\" font-family=\"Times-Roman\" font-size=\"14.00\">samples = 46062</text>\n",
       "<text text-anchor=\"start\" x=\"2731.5\" y=\"-22.8\" font-family=\"Times-Roman\" font-size=\"14.00\">value = [42224, 3838]</text>\n",
       "<text text-anchor=\"start\" x=\"2779\" y=\"-7.8\" font-family=\"Times-Roman\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;30 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>28&#45;&gt;30</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2692.48,-103.88C2709.93,-93.83 2728.56,-83.09 2745.79,-73.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2747.75,-76.07 2754.66,-68.04 2744.25,-70 2747.75,-76.07\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f1c0a4dd210>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot tree\n",
    "dot_data = export_graphviz(\n",
    "    model,\n",
    "    out_file=None,\n",
    "    feature_names=X_train.columns,\n",
    "    class_names=['0', '1'],\n",
    "    filled=True,\n",
    "    rounded=False,\n",
    "    special_characters=True,\n",
    "    precision=3\n",
    ")\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T10:47:28.402342Z",
     "iopub.status.busy": "2023-03-24T10:47:28.401953Z",
     "iopub.status.idle": "2023-03-24T10:47:30.983801Z",
     "shell.execute_reply": "2023-03-24T10:47:30.982750Z",
     "shell.execute_reply.started": "2023-03-24T10:47:28.402306Z"
    }
   },
   "outputs": [],
   "source": [
    "submission[['submit_lgb_{}'.format(i) for i in range(N_ITERS)]] = np.where(lgb_full_preds>0.5, 1, 0)\n",
    "submission[['submit_ctb_{}'.format(i) for i in range(N_ITERS)]] = np.where(ctb_full_preds>0.5, 1, 0)\n",
    "submission[['submit_dtm_{}'.format(i) for i in range(N_ITERS)]] = np.where(dtm_full_preds>0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T10:47:30.985733Z",
     "iopub.status.busy": "2023-03-24T10:47:30.985390Z",
     "iopub.status.idle": "2023-03-24T10:47:31.008335Z",
     "shell.execute_reply": "2023-03-24T10:47:31.007497Z",
     "shell.execute_reply.started": "2023-03-24T10:47:30.985698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>submit_lgb_0</th>\n",
       "      <th>submit_lgb_1</th>\n",
       "      <th>submit_lgb_2</th>\n",
       "      <th>submit_lgb_3</th>\n",
       "      <th>submit_lgb_4</th>\n",
       "      <th>submit_lgb_5</th>\n",
       "      <th>submit_lgb_6</th>\n",
       "      <th>submit_lgb_7</th>\n",
       "      <th>...</th>\n",
       "      <th>submit_dtm_20</th>\n",
       "      <th>submit_dtm_21</th>\n",
       "      <th>submit_dtm_22</th>\n",
       "      <th>submit_dtm_23</th>\n",
       "      <th>submit_dtm_24</th>\n",
       "      <th>submit_dtm_25</th>\n",
       "      <th>submit_dtm_26</th>\n",
       "      <th>submit_dtm_27</th>\n",
       "      <th>submit_dtm_28</th>\n",
       "      <th>submit_dtm_29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  submit_lgb_0  submit_lgb_1  submit_lgb_2  \\\n",
       "0       100000         1             0             0             0   \n",
       "1       100001         1             1             1             1   \n",
       "2       100002         1             1             1             1   \n",
       "3       100003         1             0             0             0   \n",
       "4       100004         1             1             1             1   \n",
       "\n",
       "   submit_lgb_3  submit_lgb_4  submit_lgb_5  submit_lgb_6  submit_lgb_7  ...  \\\n",
       "0             0             0             0             0             0  ...   \n",
       "1             1             1             1             1             1  ...   \n",
       "2             1             1             1             1             1  ...   \n",
       "3             0             0             0             0             0  ...   \n",
       "4             1             1             1             1             1  ...   \n",
       "\n",
       "   submit_dtm_20  submit_dtm_21  submit_dtm_22  submit_dtm_23  submit_dtm_24  \\\n",
       "0              0              0              0              0              0   \n",
       "1              1              1              1              1              1   \n",
       "2              1              1              1              1              1   \n",
       "3              0              0              0              0              0   \n",
       "4              1              1              1              1              1   \n",
       "\n",
       "   submit_dtm_25  submit_dtm_26  submit_dtm_27  submit_dtm_28  submit_dtm_29  \n",
       "0              0              0              0              0              0  \n",
       "1              1              1              1              1              1  \n",
       "2              1              1              1              1              1  \n",
       "3              0              0              0              0              0  \n",
       "4              1              1              1              1              1  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T10:47:31.609768Z",
     "iopub.status.busy": "2023-03-24T10:47:31.609435Z",
     "iopub.status.idle": "2023-03-24T10:47:31.697383Z",
     "shell.execute_reply": "2023-03-24T10:47:31.696361Z",
     "shell.execute_reply.started": "2023-03-24T10:47:31.609734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     61859\n",
       "90    29456\n",
       "30     1451\n",
       "60      891\n",
       "89      409\n",
       "      ...  \n",
       "68       16\n",
       "4        16\n",
       "69       14\n",
       "34       14\n",
       "65       13\n",
       "Length: 91, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[[col for col in submission.columns if col.startswith('submit_')]].sum(axis = 1).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
